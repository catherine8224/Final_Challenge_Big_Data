Container: container_e10_1609183734776_5900_02_000001 on hadoop02.cusp.nyu.edu_8041
LogAggregationType: AGGREGATED
===================================================================================
LogType:container-localizer-syslog
LogLastModifiedTime:Wed May 19 02:48:18 -0400 2021
LogLength:506
LogContents:
2021-05-19 02:46:42,966 INFO [main] org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ContainerLocalizer: Disk Validator: yarn.nodemanager.disk-validator is loaded.
2021-05-19 02:46:44,250 WARN [ContainerLocalizer Downloader] org.apache.hadoop.ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ipc.StandbyException): Operation category READ is not supported in state standby. Visit https://s.apache.org/sbnn-error

End of LogType:container-localizer-syslog
*******************************************************************************************


End of LogType:prelaunch.err
******************************************************************************

Container: container_e10_1609183734776_5900_02_000001 on hadoop02.cusp.nyu.edu_8041
LogAggregationType: AGGREGATED
===================================================================================
LogType:prelaunch.out
LogLastModifiedTime:Wed May 19 02:48:18 -0400 2021
LogLength:70
LogContents:
Setting up env variables
Setting up job resources
Launching container

End of LogType:prelaunch.out
******************************************************************************

Container: container_e10_1609183734776_5900_02_000001 on hadoop02.cusp.nyu.edu_8041
LogAggregationType: AGGREGATED
===================================================================================
LogType:stderr
LogLastModifiedTime:Wed May 19 02:48:18 -0400 2021
LogLength:529
LogContents:
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/localhome/cdp/yarn/nm/filecache/25/spark-jars-2.4.0-hadoop2.7.jar/slf4j-log4j12-1.7.16.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-6.1.0-1.cdh6.1.0.p0.770702/jars/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]

End of LogType:stderr
***********************************************************************

Container: container_e10_1609183734776_5900_02_000001 on hadoop02.cusp.nyu.edu_8041
LogAggregationType: AGGREGATED
===================================================================================
LogType:stdout
LogLastModifiedTime:Wed May 19 02:48:18 -0400 2021
LogLength:313814
LogContents:
2021-05-19 02:46:45 INFO  SignalUtils:54 - Registered signal handler for TERM
2021-05-19 02:46:45 INFO  SignalUtils:54 - Registered signal handler for HUP
2021-05-19 02:46:45 INFO  SignalUtils:54 - Registered signal handler for INT
2021-05-19 02:46:45 INFO  SecurityManager:54 - Changing view acls to: catherine.ng60
2021-05-19 02:46:45 INFO  SecurityManager:54 - Changing modify acls to: catherine.ng60
2021-05-19 02:46:45 INFO  SecurityManager:54 - Changing view acls groups to: 
2021-05-19 02:46:45 INFO  SecurityManager:54 - Changing modify acls groups to: 
2021-05-19 02:46:45 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(catherine.ng60); groups with view permissions: Set(); users  with modify permissions: Set(catherine.ng60); groups with modify permissions: Set()
2021-05-19 02:46:46 INFO  ApplicationMaster:54 - Preparing Local resources
2021-05-19 02:46:48 INFO  ApplicationMaster:54 - ApplicationAttemptId: appattempt_1609183734776_5900_000002
2021-05-19 02:46:48 INFO  ApplicationMaster:54 - Starting the user application in a separate Thread
2021-05-19 02:46:48 INFO  ApplicationMaster:54 - Waiting for spark context initialization...
2021-05-19 02:46:49 INFO  SparkContext:54 - Running Spark version 2.4.0
2021-05-19 02:46:49 INFO  SparkContext:54 - Submitted application: BDM_HW4.py
2021-05-19 02:46:49 INFO  SecurityManager:54 - Changing view acls to: catherine.ng60
2021-05-19 02:46:49 INFO  SecurityManager:54 - Changing modify acls to: catherine.ng60
2021-05-19 02:46:49 INFO  SecurityManager:54 - Changing view acls groups to: 
2021-05-19 02:46:49 INFO  SecurityManager:54 - Changing modify acls groups to: 
2021-05-19 02:46:49 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(catherine.ng60); groups with view permissions: Set(); users  with modify permissions: Set(catherine.ng60); groups with modify permissions: Set()
2021-05-19 02:46:49 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 60108.
2021-05-19 02:46:49 INFO  SparkEnv:54 - Registering MapOutputTracker
2021-05-19 02:46:49 INFO  SparkEnv:54 - Registering BlockManagerMaster
2021-05-19 02:46:49 INFO  BlockManagerMasterEndpoint:54 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2021-05-19 02:46:49 INFO  BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up
2021-05-19 02:46:49 INFO  DiskBlockManager:54 - Created local directory at /localhome/cdp/yarn/nm/usercache/catherine.ng60/appcache/application_1609183734776_5900/blockmgr-d6c553c4-a02e-4590-87a0-2f73d8c4cfca
2021-05-19 02:46:49 INFO  MemoryStore:54 - MemoryStore started with capacity 366.3 MB
2021-05-19 02:46:49 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2021-05-19 02:46:49 INFO  log:192 - Logging initialized @5064ms
2021-05-19 02:46:49 INFO  JettyUtils:54 - Adding filter org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter to /jobs, /jobs/json, /jobs/job, /jobs/job/json, /stages, /stages/json, /stages/stage, /stages/stage/json, /stages/pool, /stages/pool/json, /storage, /storage/json, /storage/rdd, /storage/rdd/json, /environment, /environment/json, /executors, /executors/json, /executors/threadDump, /executors/threadDump/json, /static, /, /api, /jobs/job/kill, /stages/stage/kill.
2021-05-19 02:46:49 INFO  Server:351 - jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2021-05-19 02:46:49 INFO  Server:419 - Started @5306ms
2021-05-19 02:46:49 INFO  AbstractConnector:278 - Started ServerConnector@337c3ed2{HTTP/1.1,[http/1.1]}{0.0.0.0:53810}
2021-05-19 02:46:49 INFO  Utils:54 - Successfully started service 'SparkUI' on port 53810.
2021-05-19 02:46:49 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4b4182b3{/jobs,null,AVAILABLE,@Spark}
2021-05-19 02:46:49 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@523f2c81{/jobs/json,null,AVAILABLE,@Spark}
2021-05-19 02:46:49 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5f615e4a{/jobs/job,null,AVAILABLE,@Spark}
2021-05-19 02:46:49 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1a6248e0{/jobs/job/json,null,AVAILABLE,@Spark}
2021-05-19 02:46:49 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@31923409{/stages,null,AVAILABLE,@Spark}
2021-05-19 02:46:49 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@64d4bf7f{/stages/json,null,AVAILABLE,@Spark}
2021-05-19 02:46:49 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@264a6448{/stages/stage,null,AVAILABLE,@Spark}
2021-05-19 02:46:49 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4f9b3f66{/stages/stage/json,null,AVAILABLE,@Spark}
2021-05-19 02:46:49 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3a067af9{/stages/pool,null,AVAILABLE,@Spark}
2021-05-19 02:46:49 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2c1eb6c5{/stages/pool/json,null,AVAILABLE,@Spark}
2021-05-19 02:46:49 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@87b3410{/storage,null,AVAILABLE,@Spark}
2021-05-19 02:46:49 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1e8d5a76{/storage/json,null,AVAILABLE,@Spark}
2021-05-19 02:46:49 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@17d52aec{/storage/rdd,null,AVAILABLE,@Spark}
2021-05-19 02:46:49 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4ea41e4d{/storage/rdd/json,null,AVAILABLE,@Spark}
2021-05-19 02:46:49 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1fae683d{/environment,null,AVAILABLE,@Spark}
2021-05-19 02:46:49 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6b04df54{/environment/json,null,AVAILABLE,@Spark}
2021-05-19 02:46:49 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@55380a92{/executors,null,AVAILABLE,@Spark}
2021-05-19 02:46:49 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3b80200e{/executors/json,null,AVAILABLE,@Spark}
2021-05-19 02:46:49 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@570358c3{/executors/threadDump,null,AVAILABLE,@Spark}
2021-05-19 02:46:49 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1a30c308{/executors/threadDump/json,null,AVAILABLE,@Spark}
2021-05-19 02:46:49 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@fc93646{/static,null,AVAILABLE,@Spark}
2021-05-19 02:46:50 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4174024b{/,null,AVAILABLE,@Spark}
2021-05-19 02:46:50 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@68ea4549{/api,null,AVAILABLE,@Spark}
2021-05-19 02:46:50 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@46c9047f{/jobs/job/kill,null,AVAILABLE,@Spark}
2021-05-19 02:46:50 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2a80e5ed{/stages/stage/kill,null,AVAILABLE,@Spark}
2021-05-19 02:46:50 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://hadoop02.cusp.nyu.edu:53810
2021-05-19 02:46:50 INFO  YarnClusterScheduler:54 - Created YarnClusterScheduler
2021-05-19 02:46:50 INFO  SchedulerExtensionServices:54 - Starting Yarn extension services with app application_1609183734776_5900 and attemptId Some(appattempt_1609183734776_5900_000002)
2021-05-19 02:46:50 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 49352.
2021-05-19 02:46:50 INFO  NettyBlockTransferService:54 - Server created on hadoop02.cusp.nyu.edu:49352
2021-05-19 02:46:50 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2021-05-19 02:46:50 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, hadoop02.cusp.nyu.edu, 49352, None)
2021-05-19 02:46:50 INFO  BlockManagerMasterEndpoint:54 - Registering block manager hadoop02.cusp.nyu.edu:49352 with 366.3 MB RAM, BlockManagerId(driver, hadoop02.cusp.nyu.edu, 49352, None)
2021-05-19 02:46:50 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, hadoop02.cusp.nyu.edu, 49352, None)
2021-05-19 02:46:50 INFO  BlockManager:54 - external shuffle service port = 7337
2021-05-19 02:46:50 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(driver, hadoop02.cusp.nyu.edu, 49352, None)
2021-05-19 02:46:50 INFO  JettyUtils:54 - Adding filter org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter to /metrics/json.
2021-05-19 02:46:50 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3e86ffd4{/metrics/json,null,AVAILABLE,@Spark}
2021-05-19 02:46:50 INFO  EventLoggingListener:54 - Logging events to hdfs://NameService1/user/spark/applicationHistory/application_1609183734776_5900_2
2021-05-19 02:46:50 INFO  YarnRMClient:54 - Registering the ApplicationMaster
2021-05-19 02:46:51 INFO  ApplicationMaster:54 - 
===============================================================================
YARN executor launch context:
  env:
    CLASSPATH -> {{HADOOP_COMMON_HOME}}/../../../CDH/lib/hive/lib/datanucleus-core-4.1.6.jar:{{HADOOP_COMMON_HOME}}/../../../CDH/lib/hive/lib/datanucleus-api-jdo-4.2.1.jar:{{HADOOP_COMMON_HOME}}/../../../CDH/lib/hive/lib/datanucleus-rdbms-4.1.7.jar<CPS>{{PWD}}<CPS>{{PWD}}/__spark_conf__<CPS>{{PWD}}/__spark_libs__/*<CPS>$HADOOP_CLIENT_CONF_DIR<CPS>$HADOOP_COMMON_HOME/*<CPS>$HADOOP_COMMON_HOME/lib/*<CPS>$HADOOP_HDFS_HOME/*<CPS>$HADOOP_HDFS_HOME/lib/*<CPS>$HADOOP_YARN_HOME/*<CPS>$HADOOP_YARN_HOME/lib/*<CPS>$HADOOP_CLIENT_CONF_DIR<CPS>$PWD/mr-framework/*<CPS>$MR2_CLASSPATH<CPS>/etc/hadoop/conf:{{HADOOP_COMMON_HOME}}/../../../CDH-6.1.0-1.cdh6.1.0.p0.770702/lib/hadoop/libexec/../../hadoop/lib/*:{{HADOOP_COMMON_HOME}}/../../../CDH-6.1.0-1.cdh6.1.0.p0.770702/lib/hadoop/libexec/../../hadoop/.//*:{{HADOOP_COMMON_HOME}}/../../../CDH-6.1.0-1.cdh6.1.0.p0.770702/lib/hadoop/libexec/../../hadoop-hdfs/./:{{HADOOP_COMMON_HOME}}/../../../CDH-6.1.0-1.cdh6.1.0.p0.770702/lib/hadoop/libexec/../../hadoop-hdfs/lib/*:{{HADOOP_COMMON_HOME}}/../../../CDH-6.1.0-1.cdh6.1.0.p0.770702/lib/hadoop/libexec/../../hadoop-hdfs/.//*:{{HADOOP_COMMON_HOME}}/../../../CDH/lib/hadoop-mapreduce/.//*:{{HADOOP_COMMON_HOME}}/../../../CDH-6.1.0-1.cdh6.1.0.p0.770702/lib/hadoop/libexec/../../hadoop-yarn/lib/*:{{HADOOP_COMMON_HOME}}/../../../CDH-6.1.0-1.cdh6.1.0.p0.770702/lib/hadoop/libexec/../../hadoop-yarn/.//*<CPS>{{PWD}}/__spark_conf__/__hadoop_conf__
    SPARK_DIST_CLASSPATH -> /etc/hadoop/conf:/opt/cloudera/parcels/CDH-6.1.0-1.cdh6.1.0.p0.770702/lib/hadoop/libexec/../../hadoop/lib/*:/opt/cloudera/parcels/CDH-6.1.0-1.cdh6.1.0.p0.770702/lib/hadoop/libexec/../../hadoop/.//*:/opt/cloudera/parcels/CDH-6.1.0-1.cdh6.1.0.p0.770702/lib/hadoop/libexec/../../hadoop-hdfs/./:/opt/cloudera/parcels/CDH-6.1.0-1.cdh6.1.0.p0.770702/lib/hadoop/libexec/../../hadoop-hdfs/lib/*:/opt/cloudera/parcels/CDH-6.1.0-1.cdh6.1.0.p0.770702/lib/hadoop/libexec/../../hadoop-hdfs/.//*:/opt/cloudera/parcels/CDH/lib/hadoop-mapreduce/.//*:/opt/cloudera/parcels/CDH-6.1.0-1.cdh6.1.0.p0.770702/lib/hadoop/libexec/../../hadoop-yarn/lib/*:/opt/cloudera/parcels/CDH-6.1.0-1.cdh6.1.0.p0.770702/lib/hadoop/libexec/../../hadoop-yarn/.//*
    SPARK_YARN_STAGING_DIR -> hdfs://NameService1/user/catherine.ng60/.sparkStaging/application_1609183734776_5900
    SPARK_USER -> catherine.ng60
    PYTHONPATH -> {{PWD}}/pyspark.zip<CPS>{{PWD}}/py4j-0.10.7-src.zip

  command:
    LD_LIBRARY_PATH=\"{{HADOOP_COMMON_HOME}}/../../../CDH/lib/hadoop/lib/native:$LD_LIBRARY_PATH\" \ 
      {{JAVA_HOME}}/bin/java \ 
      -server \ 
      -Xmx1024m \ 
      -Djava.io.tmpdir={{PWD}}/tmp \ 
      '-Dspark.driver.port=60108' \ 
      '-Dspark.authenticate=false' \ 
      '-Dspark.shuffle.service.port=7337' \ 
      '-Dspark.ui.port=0' \ 
      -Dspark.yarn.app.container.log.dir=<LOG_DIR> \ 
      -XX:OnOutOfMemoryError='kill %p' \ 
      org.apache.spark.executor.CoarseGrainedExecutorBackend \ 
      --driver-url \ 
      spark://CoarseGrainedScheduler@hadoop02.cusp.nyu.edu:60108 \ 
      --executor-id \ 
      <executorId> \ 
      --hostname \ 
      <hostname> \ 
      --cores \ 
      10 \ 
      --app-id \ 
      application_1609183734776_5900 \ 
      --user-class-path \ 
      file:$PWD/__app__.jar \ 
      1><LOG_DIR>/stdout \ 
      2><LOG_DIR>/stderr

  resources:
    pyspark.zip -> resource { scheme: "hdfs" host: "NameService1" port: -1 file: "/user/catherine.ng60/.sparkStaging/application_1609183734776_5900/pyspark.zip" } size: 589244 timestamp: 1621406712809 type: FILE visibility: PRIVATE
    py4j-0.10.7-src.zip -> resource { scheme: "hdfs" host: "NameService1" port: -1 file: "/user/catherine.ng60/.sparkStaging/application_1609183734776_5900/py4j-0.10.7-src.zip" } size: 42437 timestamp: 1621406712851 type: FILE visibility: PRIVATE
    __spark_libs__ -> resource { scheme: "hdfs" host: "NameService1" port: -1 file: "/lib/spark-jars-2.4.0-hadoop2.7.jar" } size: 212061339 timestamp: 1550568561625 type: ARCHIVE visibility: PUBLIC
    __spark_conf__ -> resource { scheme: "hdfs" host: "NameService1" port: -1 file: "/user/catherine.ng60/.sparkStaging/application_1609183734776_5900/__spark_conf__.zip" } size: 145535 timestamp: 1621406713019 type: ARCHIVE visibility: PRIVATE

===============================================================================
2021-05-19 02:46:51 INFO  YarnAllocator:54 - Will request 5 executor container(s), each with 10 core(s) and 1408 MB memory (including 384 MB of overhead)
2021-05-19 02:46:51 INFO  YarnSchedulerBackend$YarnSchedulerEndpoint:54 - ApplicationMaster registered as NettyRpcEndpointRef(spark://YarnAM@hadoop02.cusp.nyu.edu:60108)
2021-05-19 02:46:51 INFO  YarnAllocator:54 - Submitted 5 unlocalized container requests.
2021-05-19 02:46:51 INFO  ApplicationMaster:54 - Started progress reporter thread with (heartbeat : 3000, initial allocation : 200) intervals
2021-05-19 02:46:51 INFO  AMRMClientImpl:360 - Received new token for : hadoop13.cusp.nyu.edu:8041
2021-05-19 02:46:51 INFO  AMRMClientImpl:360 - Received new token for : hadoop18.cusp.nyu.edu:8041
2021-05-19 02:46:51 INFO  AMRMClientImpl:360 - Received new token for : hadoop06.cusp.nyu.edu:8041
2021-05-19 02:46:51 INFO  AMRMClientImpl:360 - Received new token for : hadoop17.cusp.nyu.edu:8041
2021-05-19 02:46:51 INFO  AMRMClientImpl:360 - Received new token for : hadoop04.cusp.nyu.edu:8041
2021-05-19 02:46:51 INFO  YarnAllocator:54 - Launching container container_e10_1609183734776_5900_02_000002 on host hadoop13.cusp.nyu.edu for executor with ID 1
2021-05-19 02:46:51 INFO  YarnAllocator:54 - Launching container container_e10_1609183734776_5900_02_000003 on host hadoop18.cusp.nyu.edu for executor with ID 2
2021-05-19 02:46:51 INFO  YarnAllocator:54 - Launching container container_e10_1609183734776_5900_02_000004 on host hadoop04.cusp.nyu.edu for executor with ID 3
2021-05-19 02:46:51 INFO  YarnAllocator:54 - Launching container container_e10_1609183734776_5900_02_000005 on host hadoop06.cusp.nyu.edu for executor with ID 4
2021-05-19 02:46:51 INFO  YarnAllocator:54 - Launching container container_e10_1609183734776_5900_02_000006 on host hadoop17.cusp.nyu.edu for executor with ID 5
2021-05-19 02:46:51 INFO  YarnAllocator:54 - Received 5 containers from YARN, launching executors on 5 of them.
2021-05-19 02:46:51 INFO  ContainerManagementProtocolProxy:81 - yarn.client.max-cached-nodemanagers-proxies : 0
2021-05-19 02:46:51 INFO  ContainerManagementProtocolProxy:81 - yarn.client.max-cached-nodemanagers-proxies : 0
2021-05-19 02:46:51 INFO  ContainerManagementProtocolProxy:81 - yarn.client.max-cached-nodemanagers-proxies : 0
2021-05-19 02:46:51 INFO  ContainerManagementProtocolProxy:81 - yarn.client.max-cached-nodemanagers-proxies : 0
2021-05-19 02:46:51 INFO  ContainerManagementProtocolProxy:81 - yarn.client.max-cached-nodemanagers-proxies : 0
2021-05-19 02:46:51 INFO  ContainerManagementProtocolProxy:260 - Opening proxy : hadoop04.cusp.nyu.edu:8041
2021-05-19 02:46:51 INFO  ContainerManagementProtocolProxy:260 - Opening proxy : hadoop13.cusp.nyu.edu:8041
2021-05-19 02:46:51 INFO  ContainerManagementProtocolProxy:260 - Opening proxy : hadoop18.cusp.nyu.edu:8041
2021-05-19 02:46:51 INFO  ContainerManagementProtocolProxy:260 - Opening proxy : hadoop17.cusp.nyu.edu:8041
2021-05-19 02:46:51 INFO  ContainerManagementProtocolProxy:260 - Opening proxy : hadoop06.cusp.nyu.edu:8041
2021-05-19 02:46:55 INFO  YarnSchedulerBackend$YarnDriverEndpoint:54 - Registered executor NettyRpcEndpointRef(spark-client://Executor) (192.168.72.174:43399) with ID 3
2021-05-19 02:46:55 INFO  YarnSchedulerBackend$YarnDriverEndpoint:54 - Registered executor NettyRpcEndpointRef(spark-client://Executor) (192.168.72.183:57671) with ID 1
2021-05-19 02:46:55 INFO  YarnSchedulerBackend$YarnDriverEndpoint:54 - Registered executor NettyRpcEndpointRef(spark-client://Executor) (192.168.72.176:38350) with ID 4
2021-05-19 02:46:55 INFO  YarnSchedulerBackend$YarnDriverEndpoint:54 - Registered executor NettyRpcEndpointRef(spark-client://Executor) (192.168.72.188:41774) with ID 2
2021-05-19 02:46:55 INFO  YarnClusterSchedulerBackend:54 - SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.8
2021-05-19 02:46:55 INFO  YarnClusterScheduler:54 - YarnClusterScheduler.postStartHook done
2021-05-19 02:46:55 INFO  BlockManagerMasterEndpoint:54 - Registering block manager hadoop04.cusp.nyu.edu:41664 with 366.3 MB RAM, BlockManagerId(3, hadoop04.cusp.nyu.edu, 41664, None)
2021-05-19 02:46:55 INFO  BlockManagerMasterEndpoint:54 - Registering block manager hadoop13.cusp.nyu.edu:32809 with 366.3 MB RAM, BlockManagerId(1, hadoop13.cusp.nyu.edu, 32809, None)
2021-05-19 02:46:55 INFO  BlockManagerMasterEndpoint:54 - Registering block manager hadoop18.cusp.nyu.edu:37819 with 366.3 MB RAM, BlockManagerId(2, hadoop18.cusp.nyu.edu, 37819, None)
2021-05-19 02:46:55 INFO  BlockManagerMasterEndpoint:54 - Registering block manager hadoop06.cusp.nyu.edu:53410 with 366.3 MB RAM, BlockManagerId(4, hadoop06.cusp.nyu.edu, 53410, None)
2021-05-19 02:46:55 INFO  SharedState:54 - loading hive config file: file:/localhome/cdp/yarn/nm/usercache/catherine.ng60/filecache/205/__spark_conf__.zip/__hadoop_conf__/hive-site.xml
2021-05-19 02:46:55 INFO  SharedState:54 - spark.sql.warehouse.dir is not set, but hive.metastore.warehouse.dir is set. Setting spark.sql.warehouse.dir to the value of hive.metastore.warehouse.dir ('/user/hive/warehouse').
2021-05-19 02:46:55 INFO  SharedState:54 - Warehouse path is '/user/hive/warehouse'.
2021-05-19 02:46:55 INFO  JettyUtils:54 - Adding filter org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter to /SQL.
2021-05-19 02:46:55 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@776cfc67{/SQL,null,AVAILABLE,@Spark}
2021-05-19 02:46:55 INFO  JettyUtils:54 - Adding filter org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter to /SQL/json.
2021-05-19 02:46:55 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@13b1c09e{/SQL/json,null,AVAILABLE,@Spark}
2021-05-19 02:46:55 INFO  JettyUtils:54 - Adding filter org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter to /SQL/execution.
2021-05-19 02:46:55 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@54b3e0a2{/SQL/execution,null,AVAILABLE,@Spark}
2021-05-19 02:46:55 INFO  JettyUtils:54 - Adding filter org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter to /SQL/execution/json.
2021-05-19 02:46:55 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5e7a3d51{/SQL/execution/json,null,AVAILABLE,@Spark}
2021-05-19 02:46:55 INFO  JettyUtils:54 - Adding filter org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter to /static/sql.
2021-05-19 02:46:55 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7019c386{/static/sql,null,AVAILABLE,@Spark}
2021-05-19 02:46:56 INFO  StateStoreCoordinatorRef:54 - Registered StateStoreCoordinator endpoint
2021-05-19 02:46:58 INFO  YarnSchedulerBackend$YarnDriverEndpoint:54 - Registered executor NettyRpcEndpointRef(spark-client://Executor) (192.168.72.187:43911) with ID 5
2021-05-19 02:46:58 INFO  BlockManagerMasterEndpoint:54 - Registering block manager hadoop17.cusp.nyu.edu:39842 with 366.3 MB RAM, BlockManagerId(5, hadoop17.cusp.nyu.edu, 39842, None)
2021-05-19 02:46:59 INFO  FileSourceStrategy:54 - Pruning directories with: 
2021-05-19 02:46:59 INFO  FileSourceStrategy:54 - Post-Scan Filters: (length(trim(value#0, None)) > 0)
2021-05-19 02:46:59 INFO  FileSourceStrategy:54 - Output Data Schema: struct<value: string>
2021-05-19 02:46:59 INFO  FileSourceScanExec:54 - Pushed Filters: 
2021-05-19 02:46:59 INFO  CodeGenerator:54 - Code generated in 308.681959 ms
2021-05-19 02:46:59 INFO  CodeGenerator:54 - Code generated in 37.255982 ms
2021-05-19 02:47:00 INFO  MemoryStore:54 - Block broadcast_0 stored as values in memory (estimated size 332.8 KB, free 366.0 MB)
2021-05-19 02:47:00 INFO  MemoryStore:54 - Block broadcast_0_piece0 stored as bytes in memory (estimated size 33.4 KB, free 365.9 MB)
2021-05-19 02:47:00 INFO  BlockManagerInfo:54 - Added broadcast_0_piece0 in memory on hadoop02.cusp.nyu.edu:49352 (size: 33.4 KB, free: 366.3 MB)
2021-05-19 02:47:00 INFO  SparkContext:54 - Created broadcast 0 from csv at NativeMethodAccessorImpl.java:0
2021-05-19 02:47:00 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2021-05-19 02:47:00 INFO  SparkContext:54 - Starting job: csv at NativeMethodAccessorImpl.java:0
2021-05-19 02:47:00 INFO  DAGScheduler:54 - Got job 0 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
2021-05-19 02:47:00 INFO  DAGScheduler:54 - Final stage: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0)
2021-05-19 02:47:00 INFO  DAGScheduler:54 - Parents of final stage: List()
2021-05-19 02:47:00 INFO  DAGScheduler:54 - Missing parents: List()
2021-05-19 02:47:00 INFO  DAGScheduler:54 - Submitting ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
2021-05-19 02:47:00 INFO  MemoryStore:54 - Block broadcast_1 stored as values in memory (estimated size 8.8 KB, free 365.9 MB)
2021-05-19 02:47:00 INFO  MemoryStore:54 - Block broadcast_1_piece0 stored as bytes in memory (estimated size 4.5 KB, free 365.9 MB)
2021-05-19 02:47:00 INFO  BlockManagerInfo:54 - Added broadcast_1_piece0 in memory on hadoop02.cusp.nyu.edu:49352 (size: 4.5 KB, free: 366.3 MB)
2021-05-19 02:47:00 INFO  SparkContext:54 - Created broadcast 1 from broadcast at DAGScheduler.scala:1161
2021-05-19 02:47:00 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
2021-05-19 02:47:00 INFO  YarnClusterScheduler:54 - Adding task set 0.0 with 1 tasks
2021-05-19 02:47:00 INFO  TaskSetManager:54 - Starting task 0.0 in stage 0.0 (TID 0, hadoop17.cusp.nyu.edu, executor 5, partition 0, NODE_LOCAL, 8321 bytes)
2021-05-19 02:47:01 INFO  BlockManagerInfo:54 - Added broadcast_1_piece0 in memory on hadoop17.cusp.nyu.edu:39842 (size: 4.5 KB, free: 366.3 MB)
2021-05-19 02:47:02 INFO  BlockManagerInfo:54 - Added broadcast_0_piece0 in memory on hadoop17.cusp.nyu.edu:39842 (size: 33.4 KB, free: 366.3 MB)
2021-05-19 02:47:03 INFO  TaskSetManager:54 - Finished task 0.0 in stage 0.0 (TID 0) in 3075 ms on hadoop17.cusp.nyu.edu (executor 5) (1/1)
2021-05-19 02:47:04 INFO  YarnClusterScheduler:54 - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2021-05-19 02:47:04 INFO  DAGScheduler:54 - ResultStage 0 (csv at NativeMethodAccessorImpl.java:0) finished in 3.363 s
2021-05-19 02:47:04 INFO  DAGScheduler:54 - Job 0 finished: csv at NativeMethodAccessorImpl.java:0, took 3.427447 s
2021-05-19 02:47:04 INFO  FileSourceStrategy:54 - Pruning directories with: 
2021-05-19 02:47:04 INFO  FileSourceStrategy:54 - Post-Scan Filters: 
2021-05-19 02:47:04 INFO  FileSourceStrategy:54 - Output Data Schema: struct<value: string>
2021-05-19 02:47:04 INFO  FileSourceScanExec:54 - Pushed Filters: 
2021-05-19 02:47:04 INFO  CodeGenerator:54 - Code generated in 17.472 ms
2021-05-19 02:47:04 INFO  MemoryStore:54 - Block broadcast_2 stored as values in memory (estimated size 332.8 KB, free 365.6 MB)
2021-05-19 02:47:04 INFO  MemoryStore:54 - Block broadcast_2_piece0 stored as bytes in memory (estimated size 33.4 KB, free 365.6 MB)
2021-05-19 02:47:04 INFO  BlockManagerInfo:54 - Added broadcast_2_piece0 in memory on hadoop02.cusp.nyu.edu:49352 (size: 33.4 KB, free: 366.2 MB)
2021-05-19 02:47:04 INFO  SparkContext:54 - Created broadcast 2 from csv at NativeMethodAccessorImpl.java:0
2021-05-19 02:47:04 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2021-05-19 02:47:04 INFO  InMemoryFileIndex:54 - Listing leaf files and directories in parallel under: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/_SUCCESS, hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00000, hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00001, hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00002, hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00003, hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00004, hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00005, hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00006, hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00007, hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00008, hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00009, hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00010, hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00011, hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00012, hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00013, hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00014, hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00015, hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00016, hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00017, hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00018, hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00019, hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00020, hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00021, hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00022, hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00023, hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00024, hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00025, hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00026, hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00027, hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00028, hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00029, hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00030, hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00031, hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00032, hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00033, hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00034, hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00035, hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00036, hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00037, hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00038, hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00039, hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00040, hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00041, hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00042, hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00043, hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00044, hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00045, hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00046, hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00047, hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00048
2021-05-19 02:47:04 INFO  SparkContext:54 - Starting job: csv at NativeMethodAccessorImpl.java:0
2021-05-19 02:47:04 INFO  DAGScheduler:54 - Got job 1 (csv at NativeMethodAccessorImpl.java:0) with 50 output partitions
2021-05-19 02:47:04 INFO  DAGScheduler:54 - Final stage: ResultStage 1 (csv at NativeMethodAccessorImpl.java:0)
2021-05-19 02:47:04 INFO  DAGScheduler:54 - Parents of final stage: List()
2021-05-19 02:47:04 INFO  DAGScheduler:54 - Missing parents: List()
2021-05-19 02:47:04 INFO  DAGScheduler:54 - Submitting ResultStage 1 (MapPartitionsRDD[11] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
2021-05-19 02:47:04 INFO  MemoryStore:54 - Block broadcast_3 stored as values in memory (estimated size 129.0 KB, free 365.4 MB)
2021-05-19 02:47:04 INFO  MemoryStore:54 - Block broadcast_3_piece0 stored as bytes in memory (estimated size 35.0 KB, free 365.4 MB)
2021-05-19 02:47:04 INFO  BlockManagerInfo:54 - Added broadcast_3_piece0 in memory on hadoop02.cusp.nyu.edu:49352 (size: 35.0 KB, free: 366.2 MB)
2021-05-19 02:47:04 INFO  SparkContext:54 - Created broadcast 3 from broadcast at DAGScheduler.scala:1161
2021-05-19 02:47:04 INFO  DAGScheduler:54 - Submitting 50 missing tasks from ResultStage 1 (MapPartitionsRDD[11] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
2021-05-19 02:47:04 INFO  YarnClusterScheduler:54 - Adding task set 1.0 with 50 tasks
2021-05-19 02:47:04 INFO  TaskSetManager:54 - Starting task 0.0 in stage 1.0 (TID 1, hadoop06.cusp.nyu.edu, executor 4, partition 0, PROCESS_LOCAL, 7786 bytes)
2021-05-19 02:47:04 INFO  TaskSetManager:54 - Starting task 1.0 in stage 1.0 (TID 2, hadoop04.cusp.nyu.edu, executor 3, partition 1, PROCESS_LOCAL, 7788 bytes)
2021-05-19 02:47:04 INFO  TaskSetManager:54 - Starting task 2.0 in stage 1.0 (TID 3, hadoop18.cusp.nyu.edu, executor 2, partition 2, PROCESS_LOCAL, 7788 bytes)
2021-05-19 02:47:04 INFO  TaskSetManager:54 - Starting task 3.0 in stage 1.0 (TID 4, hadoop13.cusp.nyu.edu, executor 1, partition 3, PROCESS_LOCAL, 7788 bytes)
2021-05-19 02:47:04 INFO  TaskSetManager:54 - Starting task 4.0 in stage 1.0 (TID 5, hadoop17.cusp.nyu.edu, executor 5, partition 4, PROCESS_LOCAL, 7788 bytes)
2021-05-19 02:47:04 INFO  TaskSetManager:54 - Starting task 5.0 in stage 1.0 (TID 6, hadoop06.cusp.nyu.edu, executor 4, partition 5, PROCESS_LOCAL, 7788 bytes)
2021-05-19 02:47:04 INFO  TaskSetManager:54 - Starting task 6.0 in stage 1.0 (TID 7, hadoop04.cusp.nyu.edu, executor 3, partition 6, PROCESS_LOCAL, 7788 bytes)
2021-05-19 02:47:04 INFO  TaskSetManager:54 - Starting task 7.0 in stage 1.0 (TID 8, hadoop18.cusp.nyu.edu, executor 2, partition 7, PROCESS_LOCAL, 7788 bytes)
2021-05-19 02:47:04 INFO  TaskSetManager:54 - Starting task 8.0 in stage 1.0 (TID 9, hadoop13.cusp.nyu.edu, executor 1, partition 8, PROCESS_LOCAL, 7788 bytes)
2021-05-19 02:47:04 INFO  TaskSetManager:54 - Starting task 9.0 in stage 1.0 (TID 10, hadoop17.cusp.nyu.edu, executor 5, partition 9, PROCESS_LOCAL, 7788 bytes)
2021-05-19 02:47:04 INFO  TaskSetManager:54 - Starting task 10.0 in stage 1.0 (TID 11, hadoop06.cusp.nyu.edu, executor 4, partition 10, PROCESS_LOCAL, 7788 bytes)
2021-05-19 02:47:04 INFO  TaskSetManager:54 - Starting task 11.0 in stage 1.0 (TID 12, hadoop04.cusp.nyu.edu, executor 3, partition 11, PROCESS_LOCAL, 7788 bytes)
2021-05-19 02:47:04 INFO  TaskSetManager:54 - Starting task 12.0 in stage 1.0 (TID 13, hadoop18.cusp.nyu.edu, executor 2, partition 12, PROCESS_LOCAL, 7788 bytes)
2021-05-19 02:47:04 INFO  TaskSetManager:54 - Starting task 13.0 in stage 1.0 (TID 14, hadoop13.cusp.nyu.edu, executor 1, partition 13, PROCESS_LOCAL, 7788 bytes)
2021-05-19 02:47:04 INFO  TaskSetManager:54 - Starting task 14.0 in stage 1.0 (TID 15, hadoop17.cusp.nyu.edu, executor 5, partition 14, PROCESS_LOCAL, 7788 bytes)
2021-05-19 02:47:04 INFO  TaskSetManager:54 - Starting task 15.0 in stage 1.0 (TID 16, hadoop06.cusp.nyu.edu, executor 4, partition 15, PROCESS_LOCAL, 7788 bytes)
2021-05-19 02:47:04 INFO  TaskSetManager:54 - Starting task 16.0 in stage 1.0 (TID 17, hadoop04.cusp.nyu.edu, executor 3, partition 16, PROCESS_LOCAL, 7788 bytes)
2021-05-19 02:47:04 INFO  TaskSetManager:54 - Starting task 17.0 in stage 1.0 (TID 18, hadoop18.cusp.nyu.edu, executor 2, partition 17, PROCESS_LOCAL, 7788 bytes)
2021-05-19 02:47:04 INFO  TaskSetManager:54 - Starting task 18.0 in stage 1.0 (TID 19, hadoop13.cusp.nyu.edu, executor 1, partition 18, PROCESS_LOCAL, 7788 bytes)
2021-05-19 02:47:04 INFO  TaskSetManager:54 - Starting task 19.0 in stage 1.0 (TID 20, hadoop17.cusp.nyu.edu, executor 5, partition 19, PROCESS_LOCAL, 7788 bytes)
2021-05-19 02:47:04 INFO  TaskSetManager:54 - Starting task 20.0 in stage 1.0 (TID 21, hadoop06.cusp.nyu.edu, executor 4, partition 20, PROCESS_LOCAL, 7788 bytes)
2021-05-19 02:47:04 INFO  TaskSetManager:54 - Starting task 21.0 in stage 1.0 (TID 22, hadoop04.cusp.nyu.edu, executor 3, partition 21, PROCESS_LOCAL, 7788 bytes)
2021-05-19 02:47:04 INFO  TaskSetManager:54 - Starting task 22.0 in stage 1.0 (TID 23, hadoop18.cusp.nyu.edu, executor 2, partition 22, PROCESS_LOCAL, 7788 bytes)
2021-05-19 02:47:04 INFO  TaskSetManager:54 - Starting task 23.0 in stage 1.0 (TID 24, hadoop13.cusp.nyu.edu, executor 1, partition 23, PROCESS_LOCAL, 7788 bytes)
2021-05-19 02:47:04 INFO  TaskSetManager:54 - Starting task 24.0 in stage 1.0 (TID 25, hadoop17.cusp.nyu.edu, executor 5, partition 24, PROCESS_LOCAL, 7788 bytes)
2021-05-19 02:47:04 INFO  TaskSetManager:54 - Starting task 25.0 in stage 1.0 (TID 26, hadoop06.cusp.nyu.edu, executor 4, partition 25, PROCESS_LOCAL, 7788 bytes)
2021-05-19 02:47:04 INFO  TaskSetManager:54 - Starting task 26.0 in stage 1.0 (TID 27, hadoop04.cusp.nyu.edu, executor 3, partition 26, PROCESS_LOCAL, 7788 bytes)
2021-05-19 02:47:04 INFO  TaskSetManager:54 - Starting task 27.0 in stage 1.0 (TID 28, hadoop18.cusp.nyu.edu, executor 2, partition 27, PROCESS_LOCAL, 7788 bytes)
2021-05-19 02:47:04 INFO  TaskSetManager:54 - Starting task 28.0 in stage 1.0 (TID 29, hadoop13.cusp.nyu.edu, executor 1, partition 28, PROCESS_LOCAL, 7788 bytes)
2021-05-19 02:47:04 INFO  TaskSetManager:54 - Starting task 29.0 in stage 1.0 (TID 30, hadoop17.cusp.nyu.edu, executor 5, partition 29, PROCESS_LOCAL, 7788 bytes)
2021-05-19 02:47:04 INFO  TaskSetManager:54 - Starting task 30.0 in stage 1.0 (TID 31, hadoop06.cusp.nyu.edu, executor 4, partition 30, PROCESS_LOCAL, 7788 bytes)
2021-05-19 02:47:04 INFO  TaskSetManager:54 - Starting task 31.0 in stage 1.0 (TID 32, hadoop04.cusp.nyu.edu, executor 3, partition 31, PROCESS_LOCAL, 7788 bytes)
2021-05-19 02:47:04 INFO  TaskSetManager:54 - Starting task 32.0 in stage 1.0 (TID 33, hadoop18.cusp.nyu.edu, executor 2, partition 32, PROCESS_LOCAL, 7788 bytes)
2021-05-19 02:47:04 INFO  TaskSetManager:54 - Starting task 33.0 in stage 1.0 (TID 34, hadoop13.cusp.nyu.edu, executor 1, partition 33, PROCESS_LOCAL, 7788 bytes)
2021-05-19 02:47:04 INFO  TaskSetManager:54 - Starting task 34.0 in stage 1.0 (TID 35, hadoop17.cusp.nyu.edu, executor 5, partition 34, PROCESS_LOCAL, 7788 bytes)
2021-05-19 02:47:04 INFO  TaskSetManager:54 - Starting task 35.0 in stage 1.0 (TID 36, hadoop06.cusp.nyu.edu, executor 4, partition 35, PROCESS_LOCAL, 7788 bytes)
2021-05-19 02:47:04 INFO  TaskSetManager:54 - Starting task 36.0 in stage 1.0 (TID 37, hadoop04.cusp.nyu.edu, executor 3, partition 36, PROCESS_LOCAL, 7788 bytes)
2021-05-19 02:47:04 INFO  TaskSetManager:54 - Starting task 37.0 in stage 1.0 (TID 38, hadoop18.cusp.nyu.edu, executor 2, partition 37, PROCESS_LOCAL, 7788 bytes)
2021-05-19 02:47:04 INFO  TaskSetManager:54 - Starting task 38.0 in stage 1.0 (TID 39, hadoop13.cusp.nyu.edu, executor 1, partition 38, PROCESS_LOCAL, 7788 bytes)
2021-05-19 02:47:04 INFO  TaskSetManager:54 - Starting task 39.0 in stage 1.0 (TID 40, hadoop17.cusp.nyu.edu, executor 5, partition 39, PROCESS_LOCAL, 7788 bytes)
2021-05-19 02:47:04 INFO  TaskSetManager:54 - Starting task 40.0 in stage 1.0 (TID 41, hadoop06.cusp.nyu.edu, executor 4, partition 40, PROCESS_LOCAL, 7788 bytes)
2021-05-19 02:47:04 INFO  TaskSetManager:54 - Starting task 41.0 in stage 1.0 (TID 42, hadoop04.cusp.nyu.edu, executor 3, partition 41, PROCESS_LOCAL, 7788 bytes)
2021-05-19 02:47:04 INFO  TaskSetManager:54 - Starting task 42.0 in stage 1.0 (TID 43, hadoop18.cusp.nyu.edu, executor 2, partition 42, PROCESS_LOCAL, 7788 bytes)
2021-05-19 02:47:04 INFO  TaskSetManager:54 - Starting task 43.0 in stage 1.0 (TID 44, hadoop13.cusp.nyu.edu, executor 1, partition 43, PROCESS_LOCAL, 7788 bytes)
2021-05-19 02:47:04 INFO  TaskSetManager:54 - Starting task 44.0 in stage 1.0 (TID 45, hadoop17.cusp.nyu.edu, executor 5, partition 44, PROCESS_LOCAL, 7788 bytes)
2021-05-19 02:47:04 INFO  TaskSetManager:54 - Starting task 45.0 in stage 1.0 (TID 46, hadoop06.cusp.nyu.edu, executor 4, partition 45, PROCESS_LOCAL, 7788 bytes)
2021-05-19 02:47:04 INFO  TaskSetManager:54 - Starting task 46.0 in stage 1.0 (TID 47, hadoop04.cusp.nyu.edu, executor 3, partition 46, PROCESS_LOCAL, 7788 bytes)
2021-05-19 02:47:04 INFO  TaskSetManager:54 - Starting task 47.0 in stage 1.0 (TID 48, hadoop18.cusp.nyu.edu, executor 2, partition 47, PROCESS_LOCAL, 7788 bytes)
2021-05-19 02:47:04 INFO  TaskSetManager:54 - Starting task 48.0 in stage 1.0 (TID 49, hadoop13.cusp.nyu.edu, executor 1, partition 48, PROCESS_LOCAL, 7788 bytes)
2021-05-19 02:47:04 INFO  TaskSetManager:54 - Starting task 49.0 in stage 1.0 (TID 50, hadoop17.cusp.nyu.edu, executor 5, partition 49, PROCESS_LOCAL, 7788 bytes)
2021-05-19 02:47:05 INFO  BlockManagerInfo:54 - Added broadcast_3_piece0 in memory on hadoop17.cusp.nyu.edu:39842 (size: 35.0 KB, free: 366.2 MB)
2021-05-19 02:47:05 INFO  TaskSetManager:54 - Finished task 19.0 in stage 1.0 (TID 20) in 834 ms on hadoop17.cusp.nyu.edu (executor 5) (1/50)
2021-05-19 02:47:05 INFO  TaskSetManager:54 - Finished task 49.0 in stage 1.0 (TID 50) in 717 ms on hadoop17.cusp.nyu.edu (executor 5) (2/50)
2021-05-19 02:47:05 INFO  TaskSetManager:54 - Finished task 14.0 in stage 1.0 (TID 15) in 868 ms on hadoop17.cusp.nyu.edu (executor 5) (3/50)
2021-05-19 02:47:05 INFO  TaskSetManager:54 - Finished task 24.0 in stage 1.0 (TID 25) in 819 ms on hadoop17.cusp.nyu.edu (executor 5) (4/50)
2021-05-19 02:47:05 INFO  TaskSetManager:54 - Finished task 39.0 in stage 1.0 (TID 40) in 751 ms on hadoop17.cusp.nyu.edu (executor 5) (5/50)
2021-05-19 02:47:05 INFO  TaskSetManager:54 - Finished task 34.0 in stage 1.0 (TID 35) in 772 ms on hadoop17.cusp.nyu.edu (executor 5) (6/50)
2021-05-19 02:47:05 INFO  TaskSetManager:54 - Finished task 4.0 in stage 1.0 (TID 5) in 929 ms on hadoop17.cusp.nyu.edu (executor 5) (7/50)
2021-05-19 02:47:05 INFO  TaskSetManager:54 - Finished task 29.0 in stage 1.0 (TID 30) in 798 ms on hadoop17.cusp.nyu.edu (executor 5) (8/50)
2021-05-19 02:47:05 INFO  TaskSetManager:54 - Finished task 9.0 in stage 1.0 (TID 10) in 904 ms on hadoop17.cusp.nyu.edu (executor 5) (9/50)
2021-05-19 02:47:05 INFO  TaskSetManager:54 - Finished task 44.0 in stage 1.0 (TID 45) in 741 ms on hadoop17.cusp.nyu.edu (executor 5) (10/50)
2021-05-19 02:47:05 INFO  ContextCleaner:54 - Cleaned accumulator 29
2021-05-19 02:47:05 INFO  ContextCleaner:54 - Cleaned accumulator 36
2021-05-19 02:47:05 INFO  ContextCleaner:54 - Cleaned accumulator 35
2021-05-19 02:47:05 INFO  ContextCleaner:54 - Cleaned accumulator 23
2021-05-19 02:47:05 INFO  ContextCleaner:54 - Cleaned accumulator 24
2021-05-19 02:47:05 INFO  ContextCleaner:54 - Cleaned accumulator 33
2021-05-19 02:47:05 INFO  ContextCleaner:54 - Cleaned accumulator 30
2021-05-19 02:47:05 INFO  ContextCleaner:54 - Cleaned accumulator 19
2021-05-19 02:47:05 INFO  ContextCleaner:54 - Cleaned accumulator 14
2021-05-19 02:47:05 INFO  ContextCleaner:54 - Cleaned accumulator 4
2021-05-19 02:47:05 INFO  ContextCleaner:54 - Cleaned accumulator 31
2021-05-19 02:47:05 INFO  ContextCleaner:54 - Cleaned accumulator 7
2021-05-19 02:47:05 INFO  ContextCleaner:54 - Cleaned accumulator 6
2021-05-19 02:47:05 INFO  ContextCleaner:54 - Cleaned accumulator 8
2021-05-19 02:47:05 INFO  BlockManagerInfo:54 - Added broadcast_3_piece0 in memory on hadoop06.cusp.nyu.edu:53410 (size: 35.0 KB, free: 366.3 MB)
2021-05-19 02:47:05 INFO  BlockManagerInfo:54 - Added broadcast_3_piece0 in memory on hadoop18.cusp.nyu.edu:37819 (size: 35.0 KB, free: 366.3 MB)
2021-05-19 02:47:05 INFO  BlockManagerInfo:54 - Added broadcast_3_piece0 in memory on hadoop13.cusp.nyu.edu:32809 (size: 35.0 KB, free: 366.3 MB)
2021-05-19 02:47:05 INFO  BlockManagerInfo:54 - Removed broadcast_0_piece0 on hadoop02.cusp.nyu.edu:49352 in memory (size: 33.4 KB, free: 366.2 MB)
2021-05-19 02:47:05 INFO  BlockManagerInfo:54 - Removed broadcast_0_piece0 on hadoop17.cusp.nyu.edu:39842 in memory (size: 33.4 KB, free: 366.3 MB)
2021-05-19 02:47:05 INFO  BlockManagerInfo:54 - Added broadcast_3_piece0 in memory on hadoop04.cusp.nyu.edu:41664 (size: 35.0 KB, free: 366.3 MB)
2021-05-19 02:47:05 INFO  ContextCleaner:54 - Cleaned accumulator 17
2021-05-19 02:47:05 INFO  ContextCleaner:54 - Cleaned accumulator 26
2021-05-19 02:47:05 INFO  ContextCleaner:54 - Cleaned accumulator 11
2021-05-19 02:47:05 INFO  ContextCleaner:54 - Cleaned accumulator 34
2021-05-19 02:47:05 INFO  ContextCleaner:54 - Cleaned accumulator 12
2021-05-19 02:47:05 INFO  BlockManagerInfo:54 - Removed broadcast_1_piece0 on hadoop02.cusp.nyu.edu:49352 in memory (size: 4.5 KB, free: 366.2 MB)
2021-05-19 02:47:05 INFO  BlockManagerInfo:54 - Removed broadcast_1_piece0 on hadoop17.cusp.nyu.edu:39842 in memory (size: 4.5 KB, free: 366.3 MB)
2021-05-19 02:47:05 INFO  ContextCleaner:54 - Cleaned accumulator 27
2021-05-19 02:47:05 INFO  ContextCleaner:54 - Cleaned accumulator 15
2021-05-19 02:47:05 INFO  ContextCleaner:54 - Cleaned accumulator 13
2021-05-19 02:47:05 INFO  ContextCleaner:54 - Cleaned accumulator 16
2021-05-19 02:47:05 INFO  ContextCleaner:54 - Cleaned accumulator 21
2021-05-19 02:47:05 INFO  ContextCleaner:54 - Cleaned accumulator 5
2021-05-19 02:47:05 INFO  ContextCleaner:54 - Cleaned accumulator 3
2021-05-19 02:47:05 INFO  ContextCleaner:54 - Cleaned accumulator 10
2021-05-19 02:47:05 INFO  ContextCleaner:54 - Cleaned accumulator 2
2021-05-19 02:47:05 INFO  ContextCleaner:54 - Cleaned accumulator 9
2021-05-19 02:47:05 INFO  ContextCleaner:54 - Cleaned accumulator 25
2021-05-19 02:47:05 INFO  ContextCleaner:54 - Cleaned accumulator 18
2021-05-19 02:47:05 INFO  ContextCleaner:54 - Cleaned accumulator 28
2021-05-19 02:47:05 INFO  BlockManagerInfo:54 - Removed broadcast_2_piece0 on hadoop02.cusp.nyu.edu:49352 in memory (size: 33.4 KB, free: 366.3 MB)
2021-05-19 02:47:05 INFO  ContextCleaner:54 - Cleaned accumulator 32
2021-05-19 02:47:05 INFO  ContextCleaner:54 - Cleaned accumulator 20
2021-05-19 02:47:05 INFO  ContextCleaner:54 - Cleaned accumulator 1
2021-05-19 02:47:05 INFO  ContextCleaner:54 - Cleaned accumulator 22
2021-05-19 02:47:07 INFO  TaskSetManager:54 - Finished task 0.0 in stage 1.0 (TID 1) in 2880 ms on hadoop06.cusp.nyu.edu (executor 4) (11/50)
2021-05-19 02:47:07 INFO  TaskSetManager:54 - Finished task 17.0 in stage 1.0 (TID 18) in 2777 ms on hadoop18.cusp.nyu.edu (executor 2) (12/50)
2021-05-19 02:47:07 INFO  TaskSetManager:54 - Finished task 42.0 in stage 1.0 (TID 43) in 2665 ms on hadoop18.cusp.nyu.edu (executor 2) (13/50)
2021-05-19 02:47:07 INFO  TaskSetManager:54 - Finished task 22.0 in stage 1.0 (TID 23) in 2755 ms on hadoop18.cusp.nyu.edu (executor 2) (14/50)
2021-05-19 02:47:07 INFO  TaskSetManager:54 - Finished task 32.0 in stage 1.0 (TID 33) in 2715 ms on hadoop18.cusp.nyu.edu (executor 2) (15/50)
2021-05-19 02:47:07 INFO  TaskSetManager:54 - Finished task 47.0 in stage 1.0 (TID 48) in 2662 ms on hadoop18.cusp.nyu.edu (executor 2) (16/50)
2021-05-19 02:47:07 INFO  TaskSetManager:54 - Finished task 7.0 in stage 1.0 (TID 8) in 2845 ms on hadoop18.cusp.nyu.edu (executor 2) (17/50)
2021-05-19 02:47:07 INFO  TaskSetManager:54 - Finished task 37.0 in stage 1.0 (TID 38) in 2696 ms on hadoop18.cusp.nyu.edu (executor 2) (18/50)
2021-05-19 02:47:07 INFO  TaskSetManager:54 - Finished task 2.0 in stage 1.0 (TID 3) in 2882 ms on hadoop18.cusp.nyu.edu (executor 2) (19/50)
2021-05-19 02:47:07 INFO  TaskSetManager:54 - Finished task 12.0 in stage 1.0 (TID 13) in 2824 ms on hadoop18.cusp.nyu.edu (executor 2) (20/50)
2021-05-19 02:47:07 INFO  TaskSetManager:54 - Finished task 27.0 in stage 1.0 (TID 28) in 2752 ms on hadoop18.cusp.nyu.edu (executor 2) (21/50)
2021-05-19 02:47:07 INFO  TaskSetManager:54 - Finished task 35.0 in stage 1.0 (TID 36) in 2716 ms on hadoop06.cusp.nyu.edu (executor 4) (22/50)
2021-05-19 02:47:07 INFO  TaskSetManager:54 - Finished task 5.0 in stage 1.0 (TID 6) in 2873 ms on hadoop06.cusp.nyu.edu (executor 4) (23/50)
2021-05-19 02:47:07 INFO  TaskSetManager:54 - Finished task 25.0 in stage 1.0 (TID 26) in 2767 ms on hadoop06.cusp.nyu.edu (executor 4) (24/50)
2021-05-19 02:47:07 INFO  TaskSetManager:54 - Finished task 20.0 in stage 1.0 (TID 21) in 2796 ms on hadoop06.cusp.nyu.edu (executor 4) (25/50)
2021-05-19 02:47:07 INFO  TaskSetManager:54 - Finished task 15.0 in stage 1.0 (TID 16) in 2825 ms on hadoop06.cusp.nyu.edu (executor 4) (26/50)
2021-05-19 02:47:07 INFO  TaskSetManager:54 - Finished task 30.0 in stage 1.0 (TID 31) in 2751 ms on hadoop06.cusp.nyu.edu (executor 4) (27/50)
2021-05-19 02:47:07 INFO  TaskSetManager:54 - Finished task 45.0 in stage 1.0 (TID 46) in 2694 ms on hadoop06.cusp.nyu.edu (executor 4) (28/50)
2021-05-19 02:47:07 INFO  TaskSetManager:54 - Finished task 10.0 in stage 1.0 (TID 11) in 2856 ms on hadoop06.cusp.nyu.edu (executor 4) (29/50)
2021-05-19 02:47:07 INFO  TaskSetManager:54 - Finished task 40.0 in stage 1.0 (TID 41) in 2712 ms on hadoop06.cusp.nyu.edu (executor 4) (30/50)
2021-05-19 02:47:07 INFO  TaskSetManager:54 - Finished task 38.0 in stage 1.0 (TID 39) in 2786 ms on hadoop13.cusp.nyu.edu (executor 1) (31/50)
2021-05-19 02:47:07 INFO  TaskSetManager:54 - Finished task 18.0 in stage 1.0 (TID 19) in 2883 ms on hadoop13.cusp.nyu.edu (executor 1) (32/50)
2021-05-19 02:47:07 INFO  TaskSetManager:54 - Finished task 23.0 in stage 1.0 (TID 24) in 2861 ms on hadoop13.cusp.nyu.edu (executor 1) (33/50)
2021-05-19 02:47:07 INFO  TaskSetManager:54 - Finished task 13.0 in stage 1.0 (TID 14) in 2916 ms on hadoop13.cusp.nyu.edu (executor 1) (34/50)
2021-05-19 02:47:07 INFO  TaskSetManager:54 - Finished task 3.0 in stage 1.0 (TID 4) in 2973 ms on hadoop13.cusp.nyu.edu (executor 1) (35/50)
2021-05-19 02:47:07 INFO  TaskSetManager:54 - Finished task 43.0 in stage 1.0 (TID 44) in 2778 ms on hadoop13.cusp.nyu.edu (executor 1) (36/50)
2021-05-19 02:47:07 INFO  TaskSetManager:54 - Finished task 33.0 in stage 1.0 (TID 34) in 2818 ms on hadoop13.cusp.nyu.edu (executor 1) (37/50)
2021-05-19 02:47:07 INFO  TaskSetManager:54 - Finished task 8.0 in stage 1.0 (TID 9) in 2946 ms on hadoop13.cusp.nyu.edu (executor 1) (38/50)
2021-05-19 02:47:07 INFO  TaskSetManager:54 - Finished task 28.0 in stage 1.0 (TID 29) in 2847 ms on hadoop13.cusp.nyu.edu (executor 1) (39/50)
2021-05-19 02:47:07 INFO  TaskSetManager:54 - Finished task 48.0 in stage 1.0 (TID 49) in 2768 ms on hadoop13.cusp.nyu.edu (executor 1) (40/50)
2021-05-19 02:47:07 INFO  TaskSetManager:54 - Finished task 11.0 in stage 1.0 (TID 12) in 3131 ms on hadoop04.cusp.nyu.edu (executor 3) (41/50)
2021-05-19 02:47:07 INFO  TaskSetManager:54 - Finished task 31.0 in stage 1.0 (TID 32) in 3032 ms on hadoop04.cusp.nyu.edu (executor 3) (42/50)
2021-05-19 02:47:07 INFO  TaskSetManager:54 - Finished task 21.0 in stage 1.0 (TID 22) in 3083 ms on hadoop04.cusp.nyu.edu (executor 3) (43/50)
2021-05-19 02:47:07 INFO  TaskSetManager:54 - Finished task 46.0 in stage 1.0 (TID 47) in 2983 ms on hadoop04.cusp.nyu.edu (executor 3) (44/50)
2021-05-19 02:47:07 INFO  TaskSetManager:54 - Finished task 26.0 in stage 1.0 (TID 27) in 3066 ms on hadoop04.cusp.nyu.edu (executor 3) (45/50)
2021-05-19 02:47:07 INFO  TaskSetManager:54 - Finished task 36.0 in stage 1.0 (TID 37) in 3017 ms on hadoop04.cusp.nyu.edu (executor 3) (46/50)
2021-05-19 02:47:07 INFO  TaskSetManager:54 - Finished task 6.0 in stage 1.0 (TID 7) in 3172 ms on hadoop04.cusp.nyu.edu (executor 3) (47/50)
2021-05-19 02:47:07 INFO  TaskSetManager:54 - Finished task 1.0 in stage 1.0 (TID 2) in 3216 ms on hadoop04.cusp.nyu.edu (executor 3) (48/50)
2021-05-19 02:47:07 INFO  TaskSetManager:54 - Finished task 41.0 in stage 1.0 (TID 42) in 3002 ms on hadoop04.cusp.nyu.edu (executor 3) (49/50)
2021-05-19 02:47:07 INFO  TaskSetManager:54 - Finished task 16.0 in stage 1.0 (TID 17) in 3119 ms on hadoop04.cusp.nyu.edu (executor 3) (50/50)
2021-05-19 02:47:07 INFO  YarnClusterScheduler:54 - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2021-05-19 02:47:07 INFO  DAGScheduler:54 - ResultStage 1 (csv at NativeMethodAccessorImpl.java:0) finished in 3.288 s
2021-05-19 02:47:07 INFO  DAGScheduler:54 - Job 1 finished: csv at NativeMethodAccessorImpl.java:0, took 3.305912 s
2021-05-19 02:47:07 INFO  InMemoryFileIndex:54 - Listing leaf files and directories in parallel under: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00000, hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00001, hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00002, hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00003, hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00004, hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00005, hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00006, hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00007, hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00008, hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00009, hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00010, hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00011, hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00012, hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00013, hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00014, hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00015, hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00016, hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00017, hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00018, hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00019, hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00020, hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00021, hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00022, hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00023, hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00024, hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00025, hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00026, hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00027, hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00028, hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00029, hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00030, hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00031, hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00032, hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00033, hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00034, hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00035, hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00036, hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00037, hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00038, hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00039, hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00040, hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00041, hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00042, hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00043, hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00044, hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00045, hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00046, hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00047, hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00048
2021-05-19 02:47:08 INFO  SparkContext:54 - Starting job: csv at NativeMethodAccessorImpl.java:0
2021-05-19 02:47:08 INFO  DAGScheduler:54 - Got job 2 (csv at NativeMethodAccessorImpl.java:0) with 49 output partitions
2021-05-19 02:47:08 INFO  DAGScheduler:54 - Final stage: ResultStage 2 (csv at NativeMethodAccessorImpl.java:0)
2021-05-19 02:47:08 INFO  DAGScheduler:54 - Parents of final stage: List()
2021-05-19 02:47:08 INFO  DAGScheduler:54 - Missing parents: List()
2021-05-19 02:47:08 INFO  DAGScheduler:54 - Submitting ResultStage 2 (MapPartitionsRDD[14] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
2021-05-19 02:47:08 INFO  MemoryStore:54 - Block broadcast_4 stored as values in memory (estimated size 129.0 KB, free 366.0 MB)
2021-05-19 02:47:08 INFO  MemoryStore:54 - Block broadcast_4_piece0 stored as bytes in memory (estimated size 35.0 KB, free 366.0 MB)
2021-05-19 02:47:08 INFO  BlockManagerInfo:54 - Added broadcast_4_piece0 in memory on hadoop02.cusp.nyu.edu:49352 (size: 35.0 KB, free: 366.2 MB)
2021-05-19 02:47:08 INFO  SparkContext:54 - Created broadcast 4 from broadcast at DAGScheduler.scala:1161
2021-05-19 02:47:08 INFO  DAGScheduler:54 - Submitting 49 missing tasks from ResultStage 2 (MapPartitionsRDD[14] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
2021-05-19 02:47:08 INFO  YarnClusterScheduler:54 - Adding task set 2.0 with 49 tasks
2021-05-19 02:47:08 INFO  TaskSetManager:54 - Starting task 0.0 in stage 2.0 (TID 51, hadoop06.cusp.nyu.edu, executor 4, partition 0, PROCESS_LOCAL, 7788 bytes)
2021-05-19 02:47:08 INFO  TaskSetManager:54 - Starting task 1.0 in stage 2.0 (TID 52, hadoop17.cusp.nyu.edu, executor 5, partition 1, PROCESS_LOCAL, 7788 bytes)
2021-05-19 02:47:08 INFO  TaskSetManager:54 - Starting task 2.0 in stage 2.0 (TID 53, hadoop13.cusp.nyu.edu, executor 1, partition 2, PROCESS_LOCAL, 7788 bytes)
2021-05-19 02:47:08 INFO  TaskSetManager:54 - Starting task 3.0 in stage 2.0 (TID 54, hadoop04.cusp.nyu.edu, executor 3, partition 3, PROCESS_LOCAL, 7788 bytes)
2021-05-19 02:47:08 INFO  TaskSetManager:54 - Starting task 4.0 in stage 2.0 (TID 55, hadoop18.cusp.nyu.edu, executor 2, partition 4, PROCESS_LOCAL, 7788 bytes)
2021-05-19 02:47:08 INFO  TaskSetManager:54 - Starting task 5.0 in stage 2.0 (TID 56, hadoop06.cusp.nyu.edu, executor 4, partition 5, PROCESS_LOCAL, 7788 bytes)
2021-05-19 02:47:08 INFO  TaskSetManager:54 - Starting task 6.0 in stage 2.0 (TID 57, hadoop17.cusp.nyu.edu, executor 5, partition 6, PROCESS_LOCAL, 7788 bytes)
2021-05-19 02:47:08 INFO  TaskSetManager:54 - Starting task 7.0 in stage 2.0 (TID 58, hadoop13.cusp.nyu.edu, executor 1, partition 7, PROCESS_LOCAL, 7788 bytes)
2021-05-19 02:47:08 INFO  TaskSetManager:54 - Starting task 8.0 in stage 2.0 (TID 59, hadoop04.cusp.nyu.edu, executor 3, partition 8, PROCESS_LOCAL, 7788 bytes)
2021-05-19 02:47:08 INFO  TaskSetManager:54 - Starting task 9.0 in stage 2.0 (TID 60, hadoop18.cusp.nyu.edu, executor 2, partition 9, PROCESS_LOCAL, 7788 bytes)
2021-05-19 02:47:08 INFO  TaskSetManager:54 - Starting task 10.0 in stage 2.0 (TID 61, hadoop06.cusp.nyu.edu, executor 4, partition 10, PROCESS_LOCAL, 7788 bytes)
2021-05-19 02:47:08 INFO  TaskSetManager:54 - Starting task 11.0 in stage 2.0 (TID 62, hadoop17.cusp.nyu.edu, executor 5, partition 11, PROCESS_LOCAL, 7788 bytes)
2021-05-19 02:47:08 INFO  TaskSetManager:54 - Starting task 12.0 in stage 2.0 (TID 63, hadoop13.cusp.nyu.edu, executor 1, partition 12, PROCESS_LOCAL, 7788 bytes)
2021-05-19 02:47:08 INFO  TaskSetManager:54 - Starting task 13.0 in stage 2.0 (TID 64, hadoop04.cusp.nyu.edu, executor 3, partition 13, PROCESS_LOCAL, 7788 bytes)
2021-05-19 02:47:08 INFO  TaskSetManager:54 - Starting task 14.0 in stage 2.0 (TID 65, hadoop18.cusp.nyu.edu, executor 2, partition 14, PROCESS_LOCAL, 7788 bytes)
2021-05-19 02:47:08 INFO  TaskSetManager:54 - Starting task 15.0 in stage 2.0 (TID 66, hadoop06.cusp.nyu.edu, executor 4, partition 15, PROCESS_LOCAL, 7788 bytes)
2021-05-19 02:47:08 INFO  TaskSetManager:54 - Starting task 16.0 in stage 2.0 (TID 67, hadoop17.cusp.nyu.edu, executor 5, partition 16, PROCESS_LOCAL, 7788 bytes)
2021-05-19 02:47:08 INFO  TaskSetManager:54 - Starting task 17.0 in stage 2.0 (TID 68, hadoop13.cusp.nyu.edu, executor 1, partition 17, PROCESS_LOCAL, 7788 bytes)
2021-05-19 02:47:08 INFO  TaskSetManager:54 - Starting task 18.0 in stage 2.0 (TID 69, hadoop04.cusp.nyu.edu, executor 3, partition 18, PROCESS_LOCAL, 7788 bytes)
2021-05-19 02:47:08 INFO  TaskSetManager:54 - Starting task 19.0 in stage 2.0 (TID 70, hadoop18.cusp.nyu.edu, executor 2, partition 19, PROCESS_LOCAL, 7788 bytes)
2021-05-19 02:47:08 INFO  TaskSetManager:54 - Starting task 20.0 in stage 2.0 (TID 71, hadoop06.cusp.nyu.edu, executor 4, partition 20, PROCESS_LOCAL, 7788 bytes)
2021-05-19 02:47:08 INFO  TaskSetManager:54 - Starting task 21.0 in stage 2.0 (TID 72, hadoop17.cusp.nyu.edu, executor 5, partition 21, PROCESS_LOCAL, 7788 bytes)
2021-05-19 02:47:08 INFO  TaskSetManager:54 - Starting task 22.0 in stage 2.0 (TID 73, hadoop13.cusp.nyu.edu, executor 1, partition 22, PROCESS_LOCAL, 7788 bytes)
2021-05-19 02:47:08 INFO  TaskSetManager:54 - Starting task 23.0 in stage 2.0 (TID 74, hadoop04.cusp.nyu.edu, executor 3, partition 23, PROCESS_LOCAL, 7788 bytes)
2021-05-19 02:47:08 INFO  TaskSetManager:54 - Starting task 24.0 in stage 2.0 (TID 75, hadoop18.cusp.nyu.edu, executor 2, partition 24, PROCESS_LOCAL, 7788 bytes)
2021-05-19 02:47:08 INFO  TaskSetManager:54 - Starting task 25.0 in stage 2.0 (TID 76, hadoop06.cusp.nyu.edu, executor 4, partition 25, PROCESS_LOCAL, 7788 bytes)
2021-05-19 02:47:08 INFO  TaskSetManager:54 - Starting task 26.0 in stage 2.0 (TID 77, hadoop17.cusp.nyu.edu, executor 5, partition 26, PROCESS_LOCAL, 7788 bytes)
2021-05-19 02:47:08 INFO  TaskSetManager:54 - Starting task 27.0 in stage 2.0 (TID 78, hadoop13.cusp.nyu.edu, executor 1, partition 27, PROCESS_LOCAL, 7788 bytes)
2021-05-19 02:47:08 INFO  TaskSetManager:54 - Starting task 28.0 in stage 2.0 (TID 79, hadoop04.cusp.nyu.edu, executor 3, partition 28, PROCESS_LOCAL, 7788 bytes)
2021-05-19 02:47:08 INFO  TaskSetManager:54 - Starting task 29.0 in stage 2.0 (TID 80, hadoop18.cusp.nyu.edu, executor 2, partition 29, PROCESS_LOCAL, 7788 bytes)
2021-05-19 02:47:08 INFO  TaskSetManager:54 - Starting task 30.0 in stage 2.0 (TID 81, hadoop06.cusp.nyu.edu, executor 4, partition 30, PROCESS_LOCAL, 7788 bytes)
2021-05-19 02:47:08 INFO  TaskSetManager:54 - Starting task 31.0 in stage 2.0 (TID 82, hadoop17.cusp.nyu.edu, executor 5, partition 31, PROCESS_LOCAL, 7788 bytes)
2021-05-19 02:47:08 INFO  TaskSetManager:54 - Starting task 32.0 in stage 2.0 (TID 83, hadoop13.cusp.nyu.edu, executor 1, partition 32, PROCESS_LOCAL, 7788 bytes)
2021-05-19 02:47:08 INFO  TaskSetManager:54 - Starting task 33.0 in stage 2.0 (TID 84, hadoop04.cusp.nyu.edu, executor 3, partition 33, PROCESS_LOCAL, 7788 bytes)
2021-05-19 02:47:08 INFO  TaskSetManager:54 - Starting task 34.0 in stage 2.0 (TID 85, hadoop18.cusp.nyu.edu, executor 2, partition 34, PROCESS_LOCAL, 7788 bytes)
2021-05-19 02:47:08 INFO  TaskSetManager:54 - Starting task 35.0 in stage 2.0 (TID 86, hadoop06.cusp.nyu.edu, executor 4, partition 35, PROCESS_LOCAL, 7788 bytes)
2021-05-19 02:47:08 INFO  TaskSetManager:54 - Starting task 36.0 in stage 2.0 (TID 87, hadoop17.cusp.nyu.edu, executor 5, partition 36, PROCESS_LOCAL, 7788 bytes)
2021-05-19 02:47:08 INFO  TaskSetManager:54 - Starting task 37.0 in stage 2.0 (TID 88, hadoop13.cusp.nyu.edu, executor 1, partition 37, PROCESS_LOCAL, 7788 bytes)
2021-05-19 02:47:08 INFO  TaskSetManager:54 - Starting task 38.0 in stage 2.0 (TID 89, hadoop04.cusp.nyu.edu, executor 3, partition 38, PROCESS_LOCAL, 7788 bytes)
2021-05-19 02:47:08 INFO  TaskSetManager:54 - Starting task 39.0 in stage 2.0 (TID 90, hadoop18.cusp.nyu.edu, executor 2, partition 39, PROCESS_LOCAL, 7788 bytes)
2021-05-19 02:47:08 INFO  TaskSetManager:54 - Starting task 40.0 in stage 2.0 (TID 91, hadoop06.cusp.nyu.edu, executor 4, partition 40, PROCESS_LOCAL, 7788 bytes)
2021-05-19 02:47:08 INFO  TaskSetManager:54 - Starting task 41.0 in stage 2.0 (TID 92, hadoop17.cusp.nyu.edu, executor 5, partition 41, PROCESS_LOCAL, 7788 bytes)
2021-05-19 02:47:08 INFO  TaskSetManager:54 - Starting task 42.0 in stage 2.0 (TID 93, hadoop13.cusp.nyu.edu, executor 1, partition 42, PROCESS_LOCAL, 7788 bytes)
2021-05-19 02:47:08 INFO  TaskSetManager:54 - Starting task 43.0 in stage 2.0 (TID 94, hadoop04.cusp.nyu.edu, executor 3, partition 43, PROCESS_LOCAL, 7788 bytes)
2021-05-19 02:47:08 INFO  TaskSetManager:54 - Starting task 44.0 in stage 2.0 (TID 95, hadoop18.cusp.nyu.edu, executor 2, partition 44, PROCESS_LOCAL, 7788 bytes)
2021-05-19 02:47:08 INFO  TaskSetManager:54 - Starting task 45.0 in stage 2.0 (TID 96, hadoop06.cusp.nyu.edu, executor 4, partition 45, PROCESS_LOCAL, 7788 bytes)
2021-05-19 02:47:08 INFO  TaskSetManager:54 - Starting task 46.0 in stage 2.0 (TID 97, hadoop17.cusp.nyu.edu, executor 5, partition 46, PROCESS_LOCAL, 7788 bytes)
2021-05-19 02:47:08 INFO  TaskSetManager:54 - Starting task 47.0 in stage 2.0 (TID 98, hadoop13.cusp.nyu.edu, executor 1, partition 47, PROCESS_LOCAL, 7788 bytes)
2021-05-19 02:47:08 INFO  TaskSetManager:54 - Starting task 48.0 in stage 2.0 (TID 99, hadoop04.cusp.nyu.edu, executor 3, partition 48, PROCESS_LOCAL, 7788 bytes)
2021-05-19 02:47:08 INFO  BlockManagerInfo:54 - Added broadcast_4_piece0 in memory on hadoop17.cusp.nyu.edu:39842 (size: 35.0 KB, free: 366.2 MB)
2021-05-19 02:47:08 INFO  BlockManagerInfo:54 - Added broadcast_4_piece0 in memory on hadoop04.cusp.nyu.edu:41664 (size: 35.0 KB, free: 366.2 MB)
2021-05-19 02:47:08 INFO  BlockManagerInfo:54 - Added broadcast_4_piece0 in memory on hadoop06.cusp.nyu.edu:53410 (size: 35.0 KB, free: 366.2 MB)
2021-05-19 02:47:08 INFO  BlockManagerInfo:54 - Added broadcast_4_piece0 in memory on hadoop13.cusp.nyu.edu:32809 (size: 35.0 KB, free: 366.2 MB)
2021-05-19 02:47:08 INFO  BlockManagerInfo:54 - Added broadcast_4_piece0 in memory on hadoop18.cusp.nyu.edu:37819 (size: 35.0 KB, free: 366.2 MB)
2021-05-19 02:47:08 INFO  TaskSetManager:54 - Finished task 13.0 in stage 2.0 (TID 64) in 269 ms on hadoop04.cusp.nyu.edu (executor 3) (1/49)
2021-05-19 02:47:08 INFO  TaskSetManager:54 - Finished task 14.0 in stage 2.0 (TID 65) in 304 ms on hadoop18.cusp.nyu.edu (executor 2) (2/49)
2021-05-19 02:47:08 INFO  TaskSetManager:54 - Finished task 5.0 in stage 2.0 (TID 56) in 356 ms on hadoop06.cusp.nyu.edu (executor 4) (3/49)
2021-05-19 02:47:08 INFO  TaskSetManager:54 - Finished task 22.0 in stage 2.0 (TID 73) in 315 ms on hadoop13.cusp.nyu.edu (executor 1) (4/49)
2021-05-19 02:47:08 INFO  TaskSetManager:54 - Finished task 30.0 in stage 2.0 (TID 81) in 298 ms on hadoop06.cusp.nyu.edu (executor 4) (5/49)
2021-05-19 02:47:08 INFO  TaskSetManager:54 - Finished task 37.0 in stage 2.0 (TID 88) in 282 ms on hadoop13.cusp.nyu.edu (executor 1) (6/49)
2021-05-19 02:47:08 INFO  TaskSetManager:54 - Finished task 32.0 in stage 2.0 (TID 83) in 299 ms on hadoop13.cusp.nyu.edu (executor 1) (7/49)
2021-05-19 02:47:08 INFO  TaskSetManager:54 - Finished task 12.0 in stage 2.0 (TID 63) in 354 ms on hadoop13.cusp.nyu.edu (executor 1) (8/49)
2021-05-19 02:47:08 INFO  TaskSetManager:54 - Finished task 47.0 in stage 2.0 (TID 98) in 263 ms on hadoop13.cusp.nyu.edu (executor 1) (9/49)
2021-05-19 02:47:08 INFO  TaskSetManager:54 - Finished task 7.0 in stage 2.0 (TID 58) in 373 ms on hadoop13.cusp.nyu.edu (executor 1) (10/49)
2021-05-19 02:47:08 INFO  TaskSetManager:54 - Finished task 0.0 in stage 2.0 (TID 51) in 404 ms on hadoop06.cusp.nyu.edu (executor 4) (11/49)
2021-05-19 02:47:08 INFO  TaskSetManager:54 - Finished task 27.0 in stage 2.0 (TID 78) in 326 ms on hadoop13.cusp.nyu.edu (executor 1) (12/49)
2021-05-19 02:47:08 INFO  TaskSetManager:54 - Finished task 35.0 in stage 2.0 (TID 86) in 310 ms on hadoop06.cusp.nyu.edu (executor 4) (13/49)
2021-05-19 02:47:08 INFO  TaskSetManager:54 - Finished task 40.0 in stage 2.0 (TID 91) in 299 ms on hadoop06.cusp.nyu.edu (executor 4) (14/49)
2021-05-19 02:47:08 INFO  TaskSetManager:54 - Finished task 2.0 in stage 2.0 (TID 53) in 403 ms on hadoop13.cusp.nyu.edu (executor 1) (15/49)
2021-05-19 02:47:08 INFO  TaskSetManager:54 - Finished task 25.0 in stage 2.0 (TID 76) in 340 ms on hadoop06.cusp.nyu.edu (executor 4) (16/49)
2021-05-19 02:47:08 INFO  TaskSetManager:54 - Finished task 42.0 in stage 2.0 (TID 93) in 307 ms on hadoop13.cusp.nyu.edu (executor 1) (17/49)
2021-05-19 02:47:08 INFO  TaskSetManager:54 - Finished task 41.0 in stage 2.0 (TID 92) in 311 ms on hadoop17.cusp.nyu.edu (executor 5) (18/49)
2021-05-19 02:47:08 INFO  TaskSetManager:54 - Finished task 17.0 in stage 2.0 (TID 68) in 376 ms on hadoop13.cusp.nyu.edu (executor 1) (19/49)
2021-05-19 02:47:08 INFO  TaskSetManager:54 - Finished task 31.0 in stage 2.0 (TID 82) in 343 ms on hadoop17.cusp.nyu.edu (executor 5) (20/49)
2021-05-19 02:47:08 INFO  TaskSetManager:54 - Finished task 45.0 in stage 2.0 (TID 96) in 308 ms on hadoop06.cusp.nyu.edu (executor 4) (21/49)
2021-05-19 02:47:08 INFO  TaskSetManager:54 - Finished task 20.0 in stage 2.0 (TID 71) in 376 ms on hadoop06.cusp.nyu.edu (executor 4) (22/49)
2021-05-19 02:47:08 INFO  TaskSetManager:54 - Finished task 10.0 in stage 2.0 (TID 61) in 405 ms on hadoop06.cusp.nyu.edu (executor 4) (23/49)
2021-05-19 02:47:08 INFO  TaskSetManager:54 - Finished task 15.0 in stage 2.0 (TID 66) in 393 ms on hadoop06.cusp.nyu.edu (executor 4) (24/49)
2021-05-19 02:47:08 INFO  TaskSetManager:54 - Finished task 6.0 in stage 2.0 (TID 57) in 424 ms on hadoop17.cusp.nyu.edu (executor 5) (25/49)
2021-05-19 02:47:08 INFO  TaskSetManager:54 - Finished task 46.0 in stage 2.0 (TID 97) in 324 ms on hadoop17.cusp.nyu.edu (executor 5) (26/49)
2021-05-19 02:47:08 INFO  TaskSetManager:54 - Finished task 1.0 in stage 2.0 (TID 52) in 457 ms on hadoop17.cusp.nyu.edu (executor 5) (27/49)
2021-05-19 02:47:08 INFO  TaskSetManager:54 - Finished task 11.0 in stage 2.0 (TID 62) in 427 ms on hadoop17.cusp.nyu.edu (executor 5) (28/49)
2021-05-19 02:47:08 INFO  TaskSetManager:54 - Finished task 21.0 in stage 2.0 (TID 72) in 400 ms on hadoop17.cusp.nyu.edu (executor 5) (29/49)
2021-05-19 02:47:08 INFO  TaskSetManager:54 - Finished task 36.0 in stage 2.0 (TID 87) in 363 ms on hadoop17.cusp.nyu.edu (executor 5) (30/49)
2021-05-19 02:47:08 INFO  TaskSetManager:54 - Finished task 26.0 in stage 2.0 (TID 77) in 394 ms on hadoop17.cusp.nyu.edu (executor 5) (31/49)
2021-05-19 02:47:08 INFO  TaskSetManager:54 - Finished task 16.0 in stage 2.0 (TID 67) in 422 ms on hadoop17.cusp.nyu.edu (executor 5) (32/49)
2021-05-19 02:47:08 INFO  TaskSetManager:54 - Finished task 23.0 in stage 2.0 (TID 74) in 417 ms on hadoop04.cusp.nyu.edu (executor 3) (33/49)
2021-05-19 02:47:08 INFO  TaskSetManager:54 - Finished task 28.0 in stage 2.0 (TID 79) in 410 ms on hadoop04.cusp.nyu.edu (executor 3) (34/49)
2021-05-19 02:47:08 INFO  TaskSetManager:54 - Finished task 33.0 in stage 2.0 (TID 84) in 407 ms on hadoop04.cusp.nyu.edu (executor 3) (35/49)
2021-05-19 02:47:08 INFO  TaskSetManager:54 - Finished task 43.0 in stage 2.0 (TID 94) in 383 ms on hadoop04.cusp.nyu.edu (executor 3) (36/49)
2021-05-19 02:47:08 INFO  TaskSetManager:54 - Finished task 48.0 in stage 2.0 (TID 99) in 382 ms on hadoop04.cusp.nyu.edu (executor 3) (37/49)
2021-05-19 02:47:08 INFO  TaskSetManager:54 - Finished task 8.0 in stage 2.0 (TID 59) in 488 ms on hadoop04.cusp.nyu.edu (executor 3) (38/49)
2021-05-19 02:47:08 INFO  TaskSetManager:54 - Finished task 18.0 in stage 2.0 (TID 69) in 461 ms on hadoop04.cusp.nyu.edu (executor 3) (39/49)
2021-05-19 02:47:08 INFO  TaskSetManager:54 - Finished task 3.0 in stage 2.0 (TID 54) in 505 ms on hadoop04.cusp.nyu.edu (executor 3) (40/49)
2021-05-19 02:47:08 INFO  TaskSetManager:54 - Finished task 19.0 in stage 2.0 (TID 70) in 464 ms on hadoop18.cusp.nyu.edu (executor 2) (41/49)
2021-05-19 02:47:08 INFO  TaskSetManager:54 - Finished task 38.0 in stage 2.0 (TID 89) in 416 ms on hadoop04.cusp.nyu.edu (executor 3) (42/49)
2021-05-19 02:47:08 INFO  TaskSetManager:54 - Finished task 9.0 in stage 2.0 (TID 60) in 495 ms on hadoop18.cusp.nyu.edu (executor 2) (43/49)
2021-05-19 02:47:08 INFO  TaskSetManager:54 - Finished task 44.0 in stage 2.0 (TID 95) in 410 ms on hadoop18.cusp.nyu.edu (executor 2) (44/49)
2021-05-19 02:47:08 INFO  TaskSetManager:54 - Finished task 39.0 in stage 2.0 (TID 90) in 430 ms on hadoop18.cusp.nyu.edu (executor 2) (45/49)
2021-05-19 02:47:08 INFO  TaskSetManager:54 - Finished task 24.0 in stage 2.0 (TID 75) in 469 ms on hadoop18.cusp.nyu.edu (executor 2) (46/49)
2021-05-19 02:47:08 INFO  TaskSetManager:54 - Finished task 4.0 in stage 2.0 (TID 55) in 524 ms on hadoop18.cusp.nyu.edu (executor 2) (47/49)
2021-05-19 02:47:08 INFO  TaskSetManager:54 - Finished task 34.0 in stage 2.0 (TID 85) in 502 ms on hadoop18.cusp.nyu.edu (executor 2) (48/49)
2021-05-19 02:47:08 INFO  TaskSetManager:54 - Finished task 29.0 in stage 2.0 (TID 80) in 514 ms on hadoop18.cusp.nyu.edu (executor 2) (49/49)
2021-05-19 02:47:08 INFO  YarnClusterScheduler:54 - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2021-05-19 02:47:08 INFO  DAGScheduler:54 - ResultStage 2 (csv at NativeMethodAccessorImpl.java:0) finished in 0.668 s
2021-05-19 02:47:08 INFO  ContextCleaner:54 - Cleaned accumulator 41
2021-05-19 02:47:08 INFO  ContextCleaner:54 - Cleaned accumulator 61
2021-05-19 02:47:08 INFO  ContextCleaner:54 - Cleaned accumulator 60
2021-05-19 02:47:08 INFO  ContextCleaner:54 - Cleaned accumulator 52
2021-05-19 02:47:08 INFO  ContextCleaner:54 - Cleaned accumulator 58
2021-05-19 02:47:08 INFO  DAGScheduler:54 - Job 2 finished: csv at NativeMethodAccessorImpl.java:0, took 0.685977 s
2021-05-19 02:47:08 INFO  ContextCleaner:54 - Cleaned accumulator 37
2021-05-19 02:47:08 INFO  BlockManagerInfo:54 - Removed broadcast_3_piece0 on hadoop02.cusp.nyu.edu:49352 in memory (size: 35.0 KB, free: 366.3 MB)
2021-05-19 02:47:08 INFO  BlockManagerInfo:54 - Removed broadcast_3_piece0 on hadoop17.cusp.nyu.edu:39842 in memory (size: 35.0 KB, free: 366.3 MB)
2021-05-19 02:47:08 INFO  BlockManagerInfo:54 - Removed broadcast_3_piece0 on hadoop06.cusp.nyu.edu:53410 in memory (size: 35.0 KB, free: 366.3 MB)
2021-05-19 02:47:08 INFO  BlockManagerInfo:54 - Removed broadcast_3_piece0 on hadoop04.cusp.nyu.edu:41664 in memory (size: 35.0 KB, free: 366.3 MB)
2021-05-19 02:47:08 INFO  BlockManagerInfo:54 - Removed broadcast_3_piece0 on hadoop13.cusp.nyu.edu:32809 in memory (size: 35.0 KB, free: 366.3 MB)
2021-05-19 02:47:08 INFO  BlockManagerInfo:54 - Removed broadcast_3_piece0 on hadoop18.cusp.nyu.edu:37819 in memory (size: 35.0 KB, free: 366.3 MB)
2021-05-19 02:47:08 INFO  ContextCleaner:54 - Cleaned accumulator 51
2021-05-19 02:47:08 INFO  ContextCleaner:54 - Cleaned accumulator 47
2021-05-19 02:47:08 INFO  ContextCleaner:54 - Cleaned accumulator 59
2021-05-19 02:47:08 INFO  ContextCleaner:54 - Cleaned accumulator 48
2021-05-19 02:47:08 INFO  ContextCleaner:54 - Cleaned accumulator 43
2021-05-19 02:47:08 INFO  ContextCleaner:54 - Cleaned accumulator 57
2021-05-19 02:47:08 INFO  ContextCleaner:54 - Cleaned accumulator 40
2021-05-19 02:47:08 INFO  ContextCleaner:54 - Cleaned accumulator 50
2021-05-19 02:47:08 INFO  ContextCleaner:54 - Cleaned accumulator 46
2021-05-19 02:47:08 INFO  ContextCleaner:54 - Cleaned accumulator 54
2021-05-19 02:47:08 INFO  ContextCleaner:54 - Cleaned accumulator 38
2021-05-19 02:47:08 INFO  ContextCleaner:54 - Cleaned accumulator 44
2021-05-19 02:47:08 INFO  ContextCleaner:54 - Cleaned accumulator 39
2021-05-19 02:47:08 INFO  ContextCleaner:54 - Cleaned accumulator 53
2021-05-19 02:47:08 INFO  ContextCleaner:54 - Cleaned accumulator 49
2021-05-19 02:47:08 INFO  ContextCleaner:54 - Cleaned accumulator 42
2021-05-19 02:47:08 INFO  ContextCleaner:54 - Cleaned accumulator 45
2021-05-19 02:47:08 INFO  ContextCleaner:54 - Cleaned accumulator 55
2021-05-19 02:47:08 INFO  ContextCleaner:54 - Cleaned accumulator 56
2021-05-19 02:47:08 INFO  FileSourceStrategy:54 - Pruning directories with: 
2021-05-19 02:47:08 INFO  FileSourceStrategy:54 - Post-Scan Filters: (length(trim(value#58, None)) > 0)
2021-05-19 02:47:08 INFO  FileSourceStrategy:54 - Output Data Schema: struct<value: string>
2021-05-19 02:47:08 INFO  FileSourceScanExec:54 - Pushed Filters: 
2021-05-19 02:47:08 INFO  MemoryStore:54 - Block broadcast_5 stored as values in memory (estimated size 332.8 KB, free 365.8 MB)
2021-05-19 02:47:08 INFO  MemoryStore:54 - Block broadcast_5_piece0 stored as bytes in memory (estimated size 33.4 KB, free 365.8 MB)
2021-05-19 02:47:08 INFO  BlockManagerInfo:54 - Added broadcast_5_piece0 in memory on hadoop02.cusp.nyu.edu:49352 (size: 33.4 KB, free: 366.2 MB)
2021-05-19 02:47:08 INFO  SparkContext:54 - Created broadcast 5 from csv at NativeMethodAccessorImpl.java:0
2021-05-19 02:47:08 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 134217728 bytes, open cost is considered as scanning 4194304 bytes.
2021-05-19 02:47:09 INFO  SparkContext:54 - Starting job: csv at NativeMethodAccessorImpl.java:0
2021-05-19 02:47:09 INFO  DAGScheduler:54 - Got job 3 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
2021-05-19 02:47:09 INFO  DAGScheduler:54 - Final stage: ResultStage 3 (csv at NativeMethodAccessorImpl.java:0)
2021-05-19 02:47:09 INFO  DAGScheduler:54 - Parents of final stage: List()
2021-05-19 02:47:09 INFO  DAGScheduler:54 - Missing parents: List()
2021-05-19 02:47:09 INFO  DAGScheduler:54 - Submitting ResultStage 3 (MapPartitionsRDD[18] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
2021-05-19 02:47:09 INFO  MemoryStore:54 - Block broadcast_6 stored as values in memory (estimated size 8.8 KB, free 365.8 MB)
2021-05-19 02:47:09 INFO  MemoryStore:54 - Block broadcast_6_piece0 stored as bytes in memory (estimated size 4.5 KB, free 365.8 MB)
2021-05-19 02:47:09 INFO  BlockManagerInfo:54 - Added broadcast_6_piece0 in memory on hadoop02.cusp.nyu.edu:49352 (size: 4.5 KB, free: 366.2 MB)
2021-05-19 02:47:09 INFO  SparkContext:54 - Created broadcast 6 from broadcast at DAGScheduler.scala:1161
2021-05-19 02:47:09 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[18] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
2021-05-19 02:47:09 INFO  YarnClusterScheduler:54 - Adding task set 3.0 with 1 tasks
2021-05-19 02:47:09 INFO  TaskSetManager:54 - Starting task 0.0 in stage 3.0 (TID 100, hadoop06.cusp.nyu.edu, executor 4, partition 0, NODE_LOCAL, 8342 bytes)
2021-05-19 02:47:09 INFO  BlockManagerInfo:54 - Added broadcast_6_piece0 in memory on hadoop06.cusp.nyu.edu:53410 (size: 4.5 KB, free: 366.3 MB)
2021-05-19 02:47:09 INFO  BlockManagerInfo:54 - Added broadcast_5_piece0 in memory on hadoop06.cusp.nyu.edu:53410 (size: 33.4 KB, free: 366.2 MB)
2021-05-19 02:47:10 INFO  TaskSetManager:54 - Finished task 0.0 in stage 3.0 (TID 100) in 882 ms on hadoop06.cusp.nyu.edu (executor 4) (1/1)
2021-05-19 02:47:10 INFO  YarnClusterScheduler:54 - Removed TaskSet 3.0, whose tasks have all completed, from pool 
2021-05-19 02:47:10 INFO  DAGScheduler:54 - ResultStage 3 (csv at NativeMethodAccessorImpl.java:0) finished in 0.975 s
2021-05-19 02:47:10 INFO  DAGScheduler:54 - Job 3 finished: csv at NativeMethodAccessorImpl.java:0, took 0.986746 s
2021-05-19 02:47:10 INFO  FileSourceStrategy:54 - Pruning directories with: 
2021-05-19 02:47:10 INFO  FileSourceStrategy:54 - Post-Scan Filters: 
2021-05-19 02:47:10 INFO  FileSourceStrategy:54 - Output Data Schema: struct<value: string>
2021-05-19 02:47:10 INFO  FileSourceScanExec:54 - Pushed Filters: 
2021-05-19 02:47:10 INFO  MemoryStore:54 - Block broadcast_7 stored as values in memory (estimated size 332.8 KB, free 365.4 MB)
2021-05-19 02:47:10 INFO  MemoryStore:54 - Block broadcast_7_piece0 stored as bytes in memory (estimated size 33.4 KB, free 365.4 MB)
2021-05-19 02:47:10 INFO  BlockManagerInfo:54 - Added broadcast_7_piece0 in memory on hadoop02.cusp.nyu.edu:49352 (size: 33.4 KB, free: 366.2 MB)
2021-05-19 02:47:10 INFO  SparkContext:54 - Created broadcast 7 from csv at NativeMethodAccessorImpl.java:0
2021-05-19 02:47:10 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 134217728 bytes, open cost is considered as scanning 4194304 bytes.
2021-05-19 02:47:10 INFO  FileSourceStrategy:54 - Pruning directories with: 
2021-05-19 02:47:10 INFO  FileSourceStrategy:54 - Post-Scan Filters: naics_code#19 INSET (445110,452210,445291,445292,445299,722410,445210,446110,445230,722513,311811,446191,722511,722515,452311,445220,445120)
2021-05-19 02:47:10 INFO  FileSourceStrategy:54 - Output Data Schema: struct<placekey: string, naics_code: string>
2021-05-19 02:47:10 INFO  FileSourceScanExec:54 - Pushed Filters: In(naics_code, [445110,452210,445291,445292,445299,722410,445210,446110,445230,722513,311811,446191,722511,722515,452311,445220,445120])
2021-05-19 02:47:10 INFO  CodeGenerator:54 - Code generated in 72.620999 ms
2021-05-19 02:47:10 INFO  CodeGenerator:54 - Code generated in 89.730451 ms
2021-05-19 02:47:10 INFO  CodeGenerator:54 - Code generated in 14.931997 ms
2021-05-19 02:47:11 INFO  ContextCleaner:54 - Cleaned accumulator 86
2021-05-19 02:47:11 INFO  ContextCleaner:54 - Cleaned accumulator 66
2021-05-19 02:47:11 INFO  ContextCleaner:54 - Cleaned accumulator 122
2021-05-19 02:47:11 INFO  ContextCleaner:54 - Cleaned accumulator 89
2021-05-19 02:47:11 INFO  ContextCleaner:54 - Cleaned accumulator 62
2021-05-19 02:47:11 INFO  ContextCleaner:54 - Cleaned accumulator 103
2021-05-19 02:47:11 INFO  ContextCleaner:54 - Cleaned accumulator 101
2021-05-19 02:47:11 INFO  ContextCleaner:54 - Cleaned accumulator 64
2021-05-19 02:47:11 INFO  ContextCleaner:54 - Cleaned accumulator 81
2021-05-19 02:47:11 INFO  ContextCleaner:54 - Cleaned accumulator 90
2021-05-19 02:47:11 INFO  ContextCleaner:54 - Cleaned accumulator 111
2021-05-19 02:47:11 INFO  ContextCleaner:54 - Cleaned accumulator 88
2021-05-19 02:47:11 INFO  ContextCleaner:54 - Cleaned accumulator 92
2021-05-19 02:47:11 INFO  ContextCleaner:54 - Cleaned accumulator 69
2021-05-19 02:47:11 INFO  ContextCleaner:54 - Cleaned accumulator 117
2021-05-19 02:47:11 INFO  ContextCleaner:54 - Cleaned accumulator 118
2021-05-19 02:47:11 INFO  ContextCleaner:54 - Cleaned accumulator 100
2021-05-19 02:47:11 INFO  ContextCleaner:54 - Cleaned accumulator 95
2021-05-19 02:47:11 INFO  ContextCleaner:54 - Cleaned accumulator 96
2021-05-19 02:47:11 INFO  ContextCleaner:54 - Cleaned accumulator 115
2021-05-19 02:47:11 INFO  ContextCleaner:54 - Cleaned accumulator 107
2021-05-19 02:47:11 INFO  ContextCleaner:54 - Cleaned accumulator 124
2021-05-19 02:47:11 INFO  ContextCleaner:54 - Cleaned accumulator 113
2021-05-19 02:47:11 INFO  ContextCleaner:54 - Cleaned accumulator 105
2021-05-19 02:47:11 INFO  ContextCleaner:54 - Cleaned accumulator 112
2021-05-19 02:47:11 INFO  ContextCleaner:54 - Cleaned accumulator 98
2021-05-19 02:47:11 INFO  ContextCleaner:54 - Cleaned accumulator 87
2021-05-19 02:47:11 INFO  ContextCleaner:54 - Cleaned accumulator 120
2021-05-19 02:47:11 INFO  ContextCleaner:54 - Cleaned accumulator 68
2021-05-19 02:47:11 INFO  ContextCleaner:54 - Cleaned accumulator 93
2021-05-19 02:47:11 INFO  ContextCleaner:54 - Cleaned accumulator 77
2021-05-19 02:47:11 INFO  ContextCleaner:54 - Cleaned accumulator 78
2021-05-19 02:47:11 INFO  ContextCleaner:54 - Cleaned accumulator 80
2021-05-19 02:47:11 INFO  ContextCleaner:54 - Cleaned accumulator 70
2021-05-19 02:47:11 INFO  ContextCleaner:54 - Cleaned accumulator 67
2021-05-19 02:47:11 INFO  ContextCleaner:54 - Cleaned accumulator 91
2021-05-19 02:47:11 INFO  ContextCleaner:54 - Cleaned accumulator 99
2021-05-19 02:47:11 INFO  ContextCleaner:54 - Cleaned accumulator 104
2021-05-19 02:47:11 INFO  ContextCleaner:54 - Cleaned accumulator 94
2021-05-19 02:47:11 INFO  ContextCleaner:54 - Cleaned accumulator 119
2021-05-19 02:47:11 INFO  ContextCleaner:54 - Cleaned accumulator 109
2021-05-19 02:47:11 INFO  BlockManagerInfo:54 - Removed broadcast_4_piece0 on hadoop02.cusp.nyu.edu:49352 in memory (size: 35.0 KB, free: 366.2 MB)
2021-05-19 02:47:11 INFO  BlockManagerInfo:54 - Removed broadcast_4_piece0 on hadoop18.cusp.nyu.edu:37819 in memory (size: 35.0 KB, free: 366.3 MB)
2021-05-19 02:47:11 INFO  BlockManagerInfo:54 - Removed broadcast_4_piece0 on hadoop04.cusp.nyu.edu:41664 in memory (size: 35.0 KB, free: 366.3 MB)
2021-05-19 02:47:11 INFO  BlockManagerInfo:54 - Removed broadcast_4_piece0 on hadoop17.cusp.nyu.edu:39842 in memory (size: 35.0 KB, free: 366.3 MB)
2021-05-19 02:47:11 INFO  CodeGenerator:54 - Code generated in 82.456945 ms
2021-05-19 02:47:11 INFO  BlockManagerInfo:54 - Removed broadcast_4_piece0 on hadoop06.cusp.nyu.edu:53410 in memory (size: 35.0 KB, free: 366.3 MB)
2021-05-19 02:47:11 INFO  BlockManagerInfo:54 - Removed broadcast_4_piece0 on hadoop13.cusp.nyu.edu:32809 in memory (size: 35.0 KB, free: 366.3 MB)
2021-05-19 02:47:11 INFO  MemoryStore:54 - Block broadcast_8 stored as values in memory (estimated size 332.8 KB, free 365.2 MB)
2021-05-19 02:47:11 INFO  ContextCleaner:54 - Cleaned accumulator 74
2021-05-19 02:47:11 INFO  ContextCleaner:54 - Cleaned accumulator 73
2021-05-19 02:47:11 INFO  ContextCleaner:54 - Cleaned accumulator 72
2021-05-19 02:47:11 INFO  ContextCleaner:54 - Cleaned accumulator 76
2021-05-19 02:47:11 INFO  ContextCleaner:54 - Cleaned accumulator 63
2021-05-19 02:47:11 INFO  ContextCleaner:54 - Cleaned accumulator 84
2021-05-19 02:47:11 INFO  ContextCleaner:54 - Cleaned accumulator 121
2021-05-19 02:47:11 INFO  ContextCleaner:54 - Cleaned accumulator 71
2021-05-19 02:47:11 INFO  ContextCleaner:54 - Cleaned accumulator 97
2021-05-19 02:47:11 INFO  BlockManagerInfo:54 - Removed broadcast_6_piece0 on hadoop02.cusp.nyu.edu:49352 in memory (size: 4.5 KB, free: 366.2 MB)
2021-05-19 02:47:11 INFO  BlockManagerInfo:54 - Removed broadcast_6_piece0 on hadoop06.cusp.nyu.edu:53410 in memory (size: 4.5 KB, free: 366.3 MB)
2021-05-19 02:47:11 INFO  ContextCleaner:54 - Cleaned accumulator 106
2021-05-19 02:47:11 INFO  ContextCleaner:54 - Cleaned accumulator 85
2021-05-19 02:47:11 INFO  ContextCleaner:54 - Cleaned accumulator 110
2021-05-19 02:47:11 INFO  ContextCleaner:54 - Cleaned accumulator 116
2021-05-19 02:47:11 INFO  ContextCleaner:54 - Cleaned accumulator 65
2021-05-19 02:47:11 INFO  ContextCleaner:54 - Cleaned accumulator 108
2021-05-19 02:47:11 INFO  BlockManagerInfo:54 - Removed broadcast_7_piece0 on hadoop02.cusp.nyu.edu:49352 in memory (size: 33.4 KB, free: 366.3 MB)
2021-05-19 02:47:11 INFO  MemoryStore:54 - Block broadcast_8_piece0 stored as bytes in memory (estimated size 33.4 KB, free 365.6 MB)
2021-05-19 02:47:11 INFO  BlockManagerInfo:54 - Added broadcast_8_piece0 in memory on hadoop02.cusp.nyu.edu:49352 (size: 33.4 KB, free: 366.2 MB)
2021-05-19 02:47:11 INFO  SparkContext:54 - Created broadcast 8 from collect at BDM_HW4.py:27
2021-05-19 02:47:11 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2021-05-19 02:47:11 INFO  ContextCleaner:54 - Cleaned accumulator 102
2021-05-19 02:47:11 INFO  ContextCleaner:54 - Cleaned accumulator 79
2021-05-19 02:47:11 INFO  ContextCleaner:54 - Cleaned accumulator 75
2021-05-19 02:47:11 INFO  BlockManagerInfo:54 - Removed broadcast_5_piece0 on hadoop02.cusp.nyu.edu:49352 in memory (size: 33.4 KB, free: 366.3 MB)
2021-05-19 02:47:11 INFO  BlockManagerInfo:54 - Removed broadcast_5_piece0 on hadoop06.cusp.nyu.edu:53410 in memory (size: 33.4 KB, free: 366.3 MB)
2021-05-19 02:47:11 INFO  ContextCleaner:54 - Cleaned accumulator 83
2021-05-19 02:47:11 INFO  ContextCleaner:54 - Cleaned accumulator 114
2021-05-19 02:47:11 INFO  ContextCleaner:54 - Cleaned accumulator 82
2021-05-19 02:47:11 INFO  SparkContext:54 - Starting job: collect at BDM_HW4.py:27
2021-05-19 02:47:11 INFO  DAGScheduler:54 - Registering RDD 34 (collect at BDM_HW4.py:27)
2021-05-19 02:47:11 INFO  DAGScheduler:54 - Got job 4 (collect at BDM_HW4.py:27) with 200 output partitions
2021-05-19 02:47:11 INFO  DAGScheduler:54 - Final stage: ResultStage 5 (collect at BDM_HW4.py:27)
2021-05-19 02:47:11 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 4)
2021-05-19 02:47:11 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 4)
2021-05-19 02:47:11 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 4 (MapPartitionsRDD[34] at collect at BDM_HW4.py:27), which has no missing parents
2021-05-19 02:47:11 INFO  MemoryStore:54 - Block broadcast_9 stored as values in memory (estimated size 42.3 KB, free 365.9 MB)
2021-05-19 02:47:11 INFO  MemoryStore:54 - Block broadcast_9_piece0 stored as bytes in memory (estimated size 20.3 KB, free 365.9 MB)
2021-05-19 02:47:11 INFO  BlockManagerInfo:54 - Added broadcast_9_piece0 in memory on hadoop02.cusp.nyu.edu:49352 (size: 20.3 KB, free: 366.2 MB)
2021-05-19 02:47:11 INFO  SparkContext:54 - Created broadcast 9 from broadcast at DAGScheduler.scala:1161
2021-05-19 02:47:11 INFO  DAGScheduler:54 - Submitting 8 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[34] at collect at BDM_HW4.py:27) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
2021-05-19 02:47:11 INFO  YarnClusterScheduler:54 - Adding task set 4.0 with 8 tasks
2021-05-19 02:47:11 INFO  TaskSetManager:54 - Starting task 0.0 in stage 4.0 (TID 101, hadoop17.cusp.nyu.edu, executor 5, partition 0, NODE_LOCAL, 8310 bytes)
2021-05-19 02:47:11 INFO  TaskSetManager:54 - Starting task 1.0 in stage 4.0 (TID 102, hadoop17.cusp.nyu.edu, executor 5, partition 1, NODE_LOCAL, 8310 bytes)
2021-05-19 02:47:11 INFO  TaskSetManager:54 - Starting task 2.0 in stage 4.0 (TID 103, hadoop17.cusp.nyu.edu, executor 5, partition 2, NODE_LOCAL, 8310 bytes)
2021-05-19 02:47:11 INFO  TaskSetManager:54 - Starting task 3.0 in stage 4.0 (TID 104, hadoop17.cusp.nyu.edu, executor 5, partition 3, NODE_LOCAL, 8310 bytes)
2021-05-19 02:47:11 INFO  TaskSetManager:54 - Starting task 4.0 in stage 4.0 (TID 105, hadoop17.cusp.nyu.edu, executor 5, partition 4, NODE_LOCAL, 8310 bytes)
2021-05-19 02:47:11 INFO  TaskSetManager:54 - Starting task 5.0 in stage 4.0 (TID 106, hadoop17.cusp.nyu.edu, executor 5, partition 5, NODE_LOCAL, 8310 bytes)
2021-05-19 02:47:11 INFO  TaskSetManager:54 - Starting task 6.0 in stage 4.0 (TID 107, hadoop17.cusp.nyu.edu, executor 5, partition 6, NODE_LOCAL, 8310 bytes)
2021-05-19 02:47:11 INFO  TaskSetManager:54 - Starting task 7.0 in stage 4.0 (TID 108, hadoop17.cusp.nyu.edu, executor 5, partition 7, NODE_LOCAL, 8310 bytes)
2021-05-19 02:47:11 INFO  BlockManagerInfo:54 - Added broadcast_9_piece0 in memory on hadoop17.cusp.nyu.edu:39842 (size: 20.3 KB, free: 366.3 MB)
2021-05-19 02:47:12 INFO  BlockManagerInfo:54 - Added broadcast_8_piece0 in memory on hadoop17.cusp.nyu.edu:39842 (size: 33.4 KB, free: 366.2 MB)
2021-05-19 02:47:13 INFO  BlockManagerInfo:54 - Added rdd_29_7 in memory on hadoop17.cusp.nyu.edu:39842 (size: 47.3 KB, free: 366.2 MB)
2021-05-19 02:47:13 INFO  BlockManagerInfo:54 - Added rdd_29_2 in memory on hadoop17.cusp.nyu.edu:39842 (size: 91.5 KB, free: 366.1 MB)
2021-05-19 02:47:13 INFO  BlockManagerInfo:54 - Added rdd_29_4 in memory on hadoop17.cusp.nyu.edu:39842 (size: 88.8 KB, free: 366.0 MB)
2021-05-19 02:47:13 INFO  BlockManagerInfo:54 - Added rdd_29_0 in memory on hadoop17.cusp.nyu.edu:39842 (size: 90.4 KB, free: 365.9 MB)
2021-05-19 02:47:13 INFO  BlockManagerInfo:54 - Added rdd_29_1 in memory on hadoop17.cusp.nyu.edu:39842 (size: 90.8 KB, free: 365.8 MB)
2021-05-19 02:47:13 INFO  BlockManagerInfo:54 - Added rdd_29_5 in memory on hadoop17.cusp.nyu.edu:39842 (size: 91.5 KB, free: 365.8 MB)
2021-05-19 02:47:13 INFO  BlockManagerInfo:54 - Added rdd_29_6 in memory on hadoop17.cusp.nyu.edu:39842 (size: 90.2 KB, free: 365.7 MB)
2021-05-19 02:47:13 INFO  BlockManagerInfo:54 - Added rdd_29_3 in memory on hadoop17.cusp.nyu.edu:39842 (size: 89.5 KB, free: 365.6 MB)
2021-05-19 02:47:14 INFO  TaskSetManager:54 - Finished task 5.0 in stage 4.0 (TID 106) in 2978 ms on hadoop17.cusp.nyu.edu (executor 5) (1/8)
2021-05-19 02:47:14 INFO  TaskSetManager:54 - Finished task 6.0 in stage 4.0 (TID 107) in 2977 ms on hadoop17.cusp.nyu.edu (executor 5) (2/8)
2021-05-19 02:47:14 INFO  TaskSetManager:54 - Finished task 0.0 in stage 4.0 (TID 101) in 2986 ms on hadoop17.cusp.nyu.edu (executor 5) (3/8)
2021-05-19 02:47:14 INFO  TaskSetManager:54 - Finished task 4.0 in stage 4.0 (TID 105) in 2981 ms on hadoop17.cusp.nyu.edu (executor 5) (4/8)
2021-05-19 02:47:14 INFO  TaskSetManager:54 - Finished task 3.0 in stage 4.0 (TID 104) in 2981 ms on hadoop17.cusp.nyu.edu (executor 5) (5/8)
2021-05-19 02:47:14 INFO  TaskSetManager:54 - Finished task 2.0 in stage 4.0 (TID 103) in 2983 ms on hadoop17.cusp.nyu.edu (executor 5) (6/8)
2021-05-19 02:47:14 INFO  TaskSetManager:54 - Finished task 7.0 in stage 4.0 (TID 108) in 2979 ms on hadoop17.cusp.nyu.edu (executor 5) (7/8)
2021-05-19 02:47:14 INFO  TaskSetManager:54 - Finished task 1.0 in stage 4.0 (TID 102) in 2984 ms on hadoop17.cusp.nyu.edu (executor 5) (8/8)
2021-05-19 02:47:14 INFO  YarnClusterScheduler:54 - Removed TaskSet 4.0, whose tasks have all completed, from pool 
2021-05-19 02:47:14 INFO  PythonAccumulatorV2:54 - Connected to AccumulatorServer at host: 127.0.0.1 port: 34832
2021-05-19 02:47:14 INFO  DAGScheduler:54 - ShuffleMapStage 4 (collect at BDM_HW4.py:27) finished in 3.029 s
2021-05-19 02:47:14 INFO  DAGScheduler:54 - looking for newly runnable stages
2021-05-19 02:47:14 INFO  DAGScheduler:54 - running: Set()
2021-05-19 02:47:14 INFO  DAGScheduler:54 - waiting: Set(ResultStage 5)
2021-05-19 02:47:14 INFO  DAGScheduler:54 - failed: Set()
2021-05-19 02:47:14 INFO  DAGScheduler:54 - Submitting ResultStage 5 (MapPartitionsRDD[37] at collect at BDM_HW4.py:27), which has no missing parents
2021-05-19 02:47:14 INFO  MemoryStore:54 - Block broadcast_10 stored as values in memory (estimated size 40.9 KB, free 365.8 MB)
2021-05-19 02:47:14 INFO  MemoryStore:54 - Block broadcast_10_piece0 stored as bytes in memory (estimated size 20.4 KB, free 365.8 MB)
2021-05-19 02:47:14 INFO  BlockManagerInfo:54 - Added broadcast_10_piece0 in memory on hadoop02.cusp.nyu.edu:49352 (size: 20.4 KB, free: 366.2 MB)
2021-05-19 02:47:14 INFO  SparkContext:54 - Created broadcast 10 from broadcast at DAGScheduler.scala:1161
2021-05-19 02:47:14 INFO  DAGScheduler:54 - Submitting 200 missing tasks from ResultStage 5 (MapPartitionsRDD[37] at collect at BDM_HW4.py:27) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
2021-05-19 02:47:14 INFO  YarnClusterScheduler:54 - Adding task set 5.0 with 200 tasks
2021-05-19 02:47:14 INFO  TaskSetManager:54 - Starting task 3.0 in stage 5.0 (TID 109, hadoop17.cusp.nyu.edu, executor 5, partition 3, NODE_LOCAL, 7756 bytes)
2021-05-19 02:47:14 INFO  TaskSetManager:54 - Starting task 18.0 in stage 5.0 (TID 110, hadoop17.cusp.nyu.edu, executor 5, partition 18, NODE_LOCAL, 7756 bytes)
2021-05-19 02:47:14 INFO  TaskSetManager:54 - Starting task 26.0 in stage 5.0 (TID 111, hadoop17.cusp.nyu.edu, executor 5, partition 26, NODE_LOCAL, 7756 bytes)
2021-05-19 02:47:14 INFO  TaskSetManager:54 - Starting task 35.0 in stage 5.0 (TID 112, hadoop17.cusp.nyu.edu, executor 5, partition 35, NODE_LOCAL, 7756 bytes)
2021-05-19 02:47:14 INFO  TaskSetManager:54 - Starting task 49.0 in stage 5.0 (TID 113, hadoop17.cusp.nyu.edu, executor 5, partition 49, NODE_LOCAL, 7756 bytes)
2021-05-19 02:47:14 INFO  TaskSetManager:54 - Starting task 75.0 in stage 5.0 (TID 114, hadoop17.cusp.nyu.edu, executor 5, partition 75, NODE_LOCAL, 7756 bytes)
2021-05-19 02:47:14 INFO  TaskSetManager:54 - Starting task 144.0 in stage 5.0 (TID 115, hadoop17.cusp.nyu.edu, executor 5, partition 144, NODE_LOCAL, 7756 bytes)
2021-05-19 02:47:14 INFO  TaskSetManager:54 - Starting task 166.0 in stage 5.0 (TID 116, hadoop17.cusp.nyu.edu, executor 5, partition 166, NODE_LOCAL, 7756 bytes)
2021-05-19 02:47:14 INFO  TaskSetManager:54 - Starting task 189.0 in stage 5.0 (TID 117, hadoop17.cusp.nyu.edu, executor 5, partition 189, NODE_LOCAL, 7756 bytes)
2021-05-19 02:47:14 INFO  TaskSetManager:54 - Starting task 0.0 in stage 5.0 (TID 118, hadoop04.cusp.nyu.edu, executor 3, partition 0, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:47:14 INFO  TaskSetManager:54 - Starting task 1.0 in stage 5.0 (TID 119, hadoop06.cusp.nyu.edu, executor 4, partition 1, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:47:14 INFO  TaskSetManager:54 - Starting task 2.0 in stage 5.0 (TID 120, hadoop18.cusp.nyu.edu, executor 2, partition 2, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:47:14 INFO  TaskSetManager:54 - Starting task 4.0 in stage 5.0 (TID 121, hadoop17.cusp.nyu.edu, executor 5, partition 4, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:47:14 INFO  TaskSetManager:54 - Starting task 5.0 in stage 5.0 (TID 122, hadoop13.cusp.nyu.edu, executor 1, partition 5, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:47:14 INFO  TaskSetManager:54 - Starting task 6.0 in stage 5.0 (TID 123, hadoop04.cusp.nyu.edu, executor 3, partition 6, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:47:14 INFO  TaskSetManager:54 - Starting task 7.0 in stage 5.0 (TID 124, hadoop06.cusp.nyu.edu, executor 4, partition 7, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:47:14 INFO  TaskSetManager:54 - Starting task 8.0 in stage 5.0 (TID 125, hadoop18.cusp.nyu.edu, executor 2, partition 8, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:47:14 INFO  TaskSetManager:54 - Starting task 9.0 in stage 5.0 (TID 126, hadoop13.cusp.nyu.edu, executor 1, partition 9, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:47:14 INFO  TaskSetManager:54 - Starting task 10.0 in stage 5.0 (TID 127, hadoop04.cusp.nyu.edu, executor 3, partition 10, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:47:14 INFO  TaskSetManager:54 - Starting task 11.0 in stage 5.0 (TID 128, hadoop06.cusp.nyu.edu, executor 4, partition 11, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:47:14 INFO  TaskSetManager:54 - Starting task 12.0 in stage 5.0 (TID 129, hadoop18.cusp.nyu.edu, executor 2, partition 12, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:47:14 INFO  TaskSetManager:54 - Starting task 13.0 in stage 5.0 (TID 130, hadoop13.cusp.nyu.edu, executor 1, partition 13, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:47:14 INFO  TaskSetManager:54 - Starting task 14.0 in stage 5.0 (TID 131, hadoop04.cusp.nyu.edu, executor 3, partition 14, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:47:14 INFO  TaskSetManager:54 - Starting task 15.0 in stage 5.0 (TID 132, hadoop06.cusp.nyu.edu, executor 4, partition 15, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:47:14 INFO  TaskSetManager:54 - Starting task 16.0 in stage 5.0 (TID 133, hadoop18.cusp.nyu.edu, executor 2, partition 16, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:47:14 INFO  TaskSetManager:54 - Starting task 17.0 in stage 5.0 (TID 134, hadoop13.cusp.nyu.edu, executor 1, partition 17, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:47:14 INFO  TaskSetManager:54 - Starting task 19.0 in stage 5.0 (TID 135, hadoop04.cusp.nyu.edu, executor 3, partition 19, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:47:14 INFO  TaskSetManager:54 - Starting task 20.0 in stage 5.0 (TID 136, hadoop06.cusp.nyu.edu, executor 4, partition 20, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:47:14 INFO  TaskSetManager:54 - Starting task 21.0 in stage 5.0 (TID 137, hadoop18.cusp.nyu.edu, executor 2, partition 21, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:47:14 INFO  TaskSetManager:54 - Starting task 22.0 in stage 5.0 (TID 138, hadoop13.cusp.nyu.edu, executor 1, partition 22, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:47:14 INFO  TaskSetManager:54 - Starting task 23.0 in stage 5.0 (TID 139, hadoop04.cusp.nyu.edu, executor 3, partition 23, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:47:14 INFO  TaskSetManager:54 - Starting task 24.0 in stage 5.0 (TID 140, hadoop06.cusp.nyu.edu, executor 4, partition 24, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:47:14 INFO  TaskSetManager:54 - Starting task 25.0 in stage 5.0 (TID 141, hadoop18.cusp.nyu.edu, executor 2, partition 25, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:47:14 INFO  TaskSetManager:54 - Starting task 27.0 in stage 5.0 (TID 142, hadoop13.cusp.nyu.edu, executor 1, partition 27, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:47:14 INFO  TaskSetManager:54 - Starting task 28.0 in stage 5.0 (TID 143, hadoop04.cusp.nyu.edu, executor 3, partition 28, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:47:14 INFO  TaskSetManager:54 - Starting task 29.0 in stage 5.0 (TID 144, hadoop06.cusp.nyu.edu, executor 4, partition 29, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:47:14 INFO  TaskSetManager:54 - Starting task 30.0 in stage 5.0 (TID 145, hadoop18.cusp.nyu.edu, executor 2, partition 30, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:47:14 INFO  TaskSetManager:54 - Starting task 31.0 in stage 5.0 (TID 146, hadoop13.cusp.nyu.edu, executor 1, partition 31, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:47:14 INFO  TaskSetManager:54 - Starting task 32.0 in stage 5.0 (TID 147, hadoop04.cusp.nyu.edu, executor 3, partition 32, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:47:14 INFO  TaskSetManager:54 - Starting task 33.0 in stage 5.0 (TID 148, hadoop06.cusp.nyu.edu, executor 4, partition 33, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:47:14 INFO  TaskSetManager:54 - Starting task 34.0 in stage 5.0 (TID 149, hadoop18.cusp.nyu.edu, executor 2, partition 34, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:47:14 INFO  TaskSetManager:54 - Starting task 36.0 in stage 5.0 (TID 150, hadoop13.cusp.nyu.edu, executor 1, partition 36, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:47:14 INFO  TaskSetManager:54 - Starting task 37.0 in stage 5.0 (TID 151, hadoop04.cusp.nyu.edu, executor 3, partition 37, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:47:14 INFO  TaskSetManager:54 - Starting task 38.0 in stage 5.0 (TID 152, hadoop06.cusp.nyu.edu, executor 4, partition 38, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:47:14 INFO  TaskSetManager:54 - Starting task 39.0 in stage 5.0 (TID 153, hadoop18.cusp.nyu.edu, executor 2, partition 39, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:47:14 INFO  TaskSetManager:54 - Starting task 40.0 in stage 5.0 (TID 154, hadoop13.cusp.nyu.edu, executor 1, partition 40, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:47:14 INFO  TaskSetManager:54 - Starting task 41.0 in stage 5.0 (TID 155, hadoop04.cusp.nyu.edu, executor 3, partition 41, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:47:14 INFO  TaskSetManager:54 - Starting task 42.0 in stage 5.0 (TID 156, hadoop06.cusp.nyu.edu, executor 4, partition 42, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:47:14 INFO  TaskSetManager:54 - Starting task 43.0 in stage 5.0 (TID 157, hadoop18.cusp.nyu.edu, executor 2, partition 43, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:47:14 INFO  TaskSetManager:54 - Starting task 44.0 in stage 5.0 (TID 158, hadoop13.cusp.nyu.edu, executor 1, partition 44, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:47:14 INFO  BlockManagerInfo:54 - Added broadcast_10_piece0 in memory on hadoop17.cusp.nyu.edu:39842 (size: 20.4 KB, free: 365.6 MB)
2021-05-19 02:47:14 INFO  BlockManagerInfo:54 - Added broadcast_10_piece0 in memory on hadoop04.cusp.nyu.edu:41664 (size: 20.4 KB, free: 366.3 MB)
2021-05-19 02:47:14 INFO  BlockManagerInfo:54 - Added broadcast_10_piece0 in memory on hadoop06.cusp.nyu.edu:53410 (size: 20.4 KB, free: 366.3 MB)
2021-05-19 02:47:14 INFO  BlockManagerInfo:54 - Added broadcast_10_piece0 in memory on hadoop18.cusp.nyu.edu:37819 (size: 20.4 KB, free: 366.3 MB)
2021-05-19 02:47:14 INFO  BlockManagerInfo:54 - Added broadcast_10_piece0 in memory on hadoop13.cusp.nyu.edu:32809 (size: 20.4 KB, free: 366.3 MB)
2021-05-19 02:47:14 INFO  MapOutputTrackerMasterEndpoint:54 - Asked to send map output locations for shuffle 0 to 192.168.72.187:43911
2021-05-19 02:47:14 INFO  TaskSetManager:54 - Starting task 45.0 in stage 5.0 (TID 159, hadoop17.cusp.nyu.edu, executor 5, partition 45, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:47:14 INFO  TaskSetManager:54 - Finished task 4.0 in stage 5.0 (TID 121) in 300 ms on hadoop17.cusp.nyu.edu (executor 5) (1/200)
2021-05-19 02:47:14 INFO  MapOutputTrackerMasterEndpoint:54 - Asked to send map output locations for shuffle 0 to 192.168.72.176:38350
2021-05-19 02:47:14 INFO  TaskSetManager:54 - Starting task 46.0 in stage 5.0 (TID 160, hadoop17.cusp.nyu.edu, executor 5, partition 46, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:47:14 INFO  TaskSetManager:54 - Finished task 166.0 in stage 5.0 (TID 116) in 332 ms on hadoop17.cusp.nyu.edu (executor 5) (2/200)
2021-05-19 02:47:14 INFO  TaskSetManager:54 - Starting task 47.0 in stage 5.0 (TID 161, hadoop17.cusp.nyu.edu, executor 5, partition 47, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:47:14 INFO  TaskSetManager:54 - Finished task 49.0 in stage 5.0 (TID 113) in 340 ms on hadoop17.cusp.nyu.edu (executor 5) (3/200)
2021-05-19 02:47:14 INFO  TaskSetManager:54 - Starting task 48.0 in stage 5.0 (TID 162, hadoop17.cusp.nyu.edu, executor 5, partition 48, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:47:14 INFO  TaskSetManager:54 - Finished task 189.0 in stage 5.0 (TID 117) in 342 ms on hadoop17.cusp.nyu.edu (executor 5) (4/200)
2021-05-19 02:47:14 INFO  TaskSetManager:54 - Starting task 50.0 in stage 5.0 (TID 163, hadoop17.cusp.nyu.edu, executor 5, partition 50, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:47:14 INFO  TaskSetManager:54 - Finished task 3.0 in stage 5.0 (TID 109) in 356 ms on hadoop17.cusp.nyu.edu (executor 5) (5/200)
2021-05-19 02:47:14 INFO  TaskSetManager:54 - Starting task 51.0 in stage 5.0 (TID 164, hadoop17.cusp.nyu.edu, executor 5, partition 51, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:47:14 INFO  TaskSetManager:54 - Finished task 75.0 in stage 5.0 (TID 114) in 352 ms on hadoop17.cusp.nyu.edu (executor 5) (6/200)
2021-05-19 02:47:14 INFO  TaskSetManager:54 - Starting task 52.0 in stage 5.0 (TID 165, hadoop17.cusp.nyu.edu, executor 5, partition 52, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:47:14 INFO  TaskSetManager:54 - Starting task 53.0 in stage 5.0 (TID 166, hadoop17.cusp.nyu.edu, executor 5, partition 53, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:47:14 INFO  TaskSetManager:54 - Finished task 18.0 in stage 5.0 (TID 110) in 360 ms on hadoop17.cusp.nyu.edu (executor 5) (7/200)
2021-05-19 02:47:14 INFO  TaskSetManager:54 - Finished task 35.0 in stage 5.0 (TID 112) in 359 ms on hadoop17.cusp.nyu.edu (executor 5) (8/200)
2021-05-19 02:47:14 INFO  TaskSetManager:54 - Starting task 54.0 in stage 5.0 (TID 167, hadoop17.cusp.nyu.edu, executor 5, partition 54, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:47:14 INFO  TaskSetManager:54 - Finished task 26.0 in stage 5.0 (TID 111) in 362 ms on hadoop17.cusp.nyu.edu (executor 5) (9/200)
2021-05-19 02:47:14 INFO  TaskSetManager:54 - Starting task 55.0 in stage 5.0 (TID 168, hadoop17.cusp.nyu.edu, executor 5, partition 55, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:47:14 INFO  TaskSetManager:54 - Finished task 45.0 in stage 5.0 (TID 159) in 65 ms on hadoop17.cusp.nyu.edu (executor 5) (10/200)
2021-05-19 02:47:14 INFO  TaskSetManager:54 - Starting task 56.0 in stage 5.0 (TID 169, hadoop17.cusp.nyu.edu, executor 5, partition 56, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:47:14 INFO  TaskSetManager:54 - Finished task 144.0 in stage 5.0 (TID 115) in 371 ms on hadoop17.cusp.nyu.edu (executor 5) (11/200)
2021-05-19 02:47:14 INFO  TaskSetManager:54 - Starting task 57.0 in stage 5.0 (TID 170, hadoop17.cusp.nyu.edu, executor 5, partition 57, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:47:14 INFO  TaskSetManager:54 - Finished task 46.0 in stage 5.0 (TID 160) in 45 ms on hadoop17.cusp.nyu.edu (executor 5) (12/200)
2021-05-19 02:47:14 INFO  TaskSetManager:54 - Starting task 58.0 in stage 5.0 (TID 171, hadoop17.cusp.nyu.edu, executor 5, partition 58, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:47:14 INFO  TaskSetManager:54 - Finished task 47.0 in stage 5.0 (TID 161) in 61 ms on hadoop17.cusp.nyu.edu (executor 5) (13/200)
2021-05-19 02:47:14 INFO  TaskSetManager:54 - Starting task 59.0 in stage 5.0 (TID 172, hadoop17.cusp.nyu.edu, executor 5, partition 59, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:47:14 INFO  TaskSetManager:54 - Finished task 50.0 in stage 5.0 (TID 163) in 54 ms on hadoop17.cusp.nyu.edu (executor 5) (14/200)
2021-05-19 02:47:14 INFO  TaskSetManager:54 - Starting task 60.0 in stage 5.0 (TID 173, hadoop17.cusp.nyu.edu, executor 5, partition 60, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:47:14 INFO  TaskSetManager:54 - Finished task 52.0 in stage 5.0 (TID 165) in 52 ms on hadoop17.cusp.nyu.edu (executor 5) (15/200)
2021-05-19 02:47:14 INFO  TaskSetManager:54 - Starting task 61.0 in stage 5.0 (TID 174, hadoop17.cusp.nyu.edu, executor 5, partition 61, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:47:14 INFO  TaskSetManager:54 - Finished task 48.0 in stage 5.0 (TID 162) in 71 ms on hadoop17.cusp.nyu.edu (executor 5) (16/200)
2021-05-19 02:47:14 INFO  TaskSetManager:54 - Starting task 62.0 in stage 5.0 (TID 175, hadoop17.cusp.nyu.edu, executor 5, partition 62, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:47:14 INFO  TaskSetManager:54 - Finished task 51.0 in stage 5.0 (TID 164) in 67 ms on hadoop17.cusp.nyu.edu (executor 5) (17/200)
2021-05-19 02:47:14 INFO  TaskSetManager:54 - Starting task 63.0 in stage 5.0 (TID 176, hadoop17.cusp.nyu.edu, executor 5, partition 63, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:47:14 INFO  TaskSetManager:54 - Starting task 64.0 in stage 5.0 (TID 177, hadoop17.cusp.nyu.edu, executor 5, partition 64, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:47:14 INFO  TaskSetManager:54 - Finished task 53.0 in stage 5.0 (TID 166) in 68 ms on hadoop17.cusp.nyu.edu (executor 5) (18/200)
2021-05-19 02:47:14 INFO  TaskSetManager:54 - Starting task 65.0 in stage 5.0 (TID 178, hadoop17.cusp.nyu.edu, executor 5, partition 65, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:47:14 INFO  TaskSetManager:54 - Finished task 54.0 in stage 5.0 (TID 167) in 72 ms on hadoop17.cusp.nyu.edu (executor 5) (19/200)
2021-05-19 02:47:14 INFO  TaskSetManager:54 - Starting task 66.0 in stage 5.0 (TID 179, hadoop17.cusp.nyu.edu, executor 5, partition 66, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:47:14 INFO  TaskSetManager:54 - Finished task 55.0 in stage 5.0 (TID 168) in 70 ms on hadoop17.cusp.nyu.edu (executor 5) (20/200)
2021-05-19 02:47:14 INFO  TaskSetManager:54 - Finished task 57.0 in stage 5.0 (TID 170) in 61 ms on hadoop17.cusp.nyu.edu (executor 5) (21/200)
2021-05-19 02:47:14 INFO  TaskSetManager:54 - Starting task 67.0 in stage 5.0 (TID 180, hadoop17.cusp.nyu.edu, executor 5, partition 67, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:47:14 INFO  TaskSetManager:54 - Finished task 56.0 in stage 5.0 (TID 169) in 71 ms on hadoop17.cusp.nyu.edu (executor 5) (22/200)
2021-05-19 02:47:14 INFO  TaskSetManager:54 - Starting task 68.0 in stage 5.0 (TID 181, hadoop17.cusp.nyu.edu, executor 5, partition 68, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:47:14 INFO  TaskSetManager:54 - Finished task 58.0 in stage 5.0 (TID 171) in 45 ms on hadoop17.cusp.nyu.edu (executor 5) (23/200)
2021-05-19 02:47:14 INFO  TaskSetManager:54 - Starting task 69.0 in stage 5.0 (TID 182, hadoop17.cusp.nyu.edu, executor 5, partition 69, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:47:14 INFO  TaskSetManager:54 - Finished task 59.0 in stage 5.0 (TID 172) in 44 ms on hadoop17.cusp.nyu.edu (executor 5) (24/200)
2021-05-19 02:47:14 INFO  TaskSetManager:54 - Starting task 70.0 in stage 5.0 (TID 183, hadoop17.cusp.nyu.edu, executor 5, partition 70, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:47:14 INFO  TaskSetManager:54 - Starting task 71.0 in stage 5.0 (TID 184, hadoop17.cusp.nyu.edu, executor 5, partition 71, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:47:14 INFO  TaskSetManager:54 - Finished task 60.0 in stage 5.0 (TID 173) in 43 ms on hadoop17.cusp.nyu.edu (executor 5) (25/200)
2021-05-19 02:47:14 INFO  TaskSetManager:54 - Finished task 61.0 in stage 5.0 (TID 174) in 40 ms on hadoop17.cusp.nyu.edu (executor 5) (26/200)
2021-05-19 02:47:14 INFO  TaskSetManager:54 - Starting task 72.0 in stage 5.0 (TID 185, hadoop17.cusp.nyu.edu, executor 5, partition 72, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:47:14 INFO  TaskSetManager:54 - Finished task 63.0 in stage 5.0 (TID 176) in 26 ms on hadoop17.cusp.nyu.edu (executor 5) (27/200)
2021-05-19 02:47:14 INFO  TaskSetManager:54 - Starting task 73.0 in stage 5.0 (TID 186, hadoop17.cusp.nyu.edu, executor 5, partition 73, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:47:14 INFO  TaskSetManager:54 - Starting task 74.0 in stage 5.0 (TID 187, hadoop17.cusp.nyu.edu, executor 5, partition 74, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:47:14 INFO  TaskSetManager:54 - Finished task 64.0 in stage 5.0 (TID 177) in 27 ms on hadoop17.cusp.nyu.edu (executor 5) (28/200)
2021-05-19 02:47:14 INFO  TaskSetManager:54 - Finished task 62.0 in stage 5.0 (TID 175) in 35 ms on hadoop17.cusp.nyu.edu (executor 5) (29/200)
2021-05-19 02:47:14 INFO  TaskSetManager:54 - Starting task 76.0 in stage 5.0 (TID 188, hadoop17.cusp.nyu.edu, executor 5, partition 76, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:47:14 INFO  TaskSetManager:54 - Finished task 65.0 in stage 5.0 (TID 178) in 29 ms on hadoop17.cusp.nyu.edu (executor 5) (30/200)
2021-05-19 02:47:14 INFO  MapOutputTrackerMasterEndpoint:54 - Asked to send map output locations for shuffle 0 to 192.168.72.188:41774
2021-05-19 02:47:14 INFO  TaskSetManager:54 - Starting task 77.0 in stage 5.0 (TID 189, hadoop17.cusp.nyu.edu, executor 5, partition 77, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:47:14 INFO  TaskSetManager:54 - Finished task 66.0 in stage 5.0 (TID 179) in 32 ms on hadoop17.cusp.nyu.edu (executor 5) (31/200)
2021-05-19 02:47:14 INFO  TaskSetManager:54 - Starting task 78.0 in stage 5.0 (TID 190, hadoop17.cusp.nyu.edu, executor 5, partition 78, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:47:14 INFO  TaskSetManager:54 - Finished task 68.0 in stage 5.0 (TID 181) in 23 ms on hadoop17.cusp.nyu.edu (executor 5) (32/200)
2021-05-19 02:47:14 INFO  TaskSetManager:54 - Starting task 79.0 in stage 5.0 (TID 191, hadoop17.cusp.nyu.edu, executor 5, partition 79, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:47:14 INFO  TaskSetManager:54 - Finished task 67.0 in stage 5.0 (TID 180) in 27 ms on hadoop17.cusp.nyu.edu (executor 5) (33/200)
2021-05-19 02:47:14 INFO  TaskSetManager:54 - Starting task 80.0 in stage 5.0 (TID 192, hadoop17.cusp.nyu.edu, executor 5, partition 80, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:47:14 INFO  TaskSetManager:54 - Finished task 72.0 in stage 5.0 (TID 185) in 24 ms on hadoop17.cusp.nyu.edu (executor 5) (34/200)
2021-05-19 02:47:14 INFO  TaskSetManager:54 - Starting task 81.0 in stage 5.0 (TID 193, hadoop17.cusp.nyu.edu, executor 5, partition 81, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:47:14 INFO  TaskSetManager:54 - Finished task 71.0 in stage 5.0 (TID 184) in 28 ms on hadoop17.cusp.nyu.edu (executor 5) (35/200)
2021-05-19 02:47:14 INFO  TaskSetManager:54 - Starting task 82.0 in stage 5.0 (TID 194, hadoop17.cusp.nyu.edu, executor 5, partition 82, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:47:14 INFO  TaskSetManager:54 - Finished task 69.0 in stage 5.0 (TID 182) in 32 ms on hadoop17.cusp.nyu.edu (executor 5) (36/200)
2021-05-19 02:47:14 INFO  TaskSetManager:54 - Starting task 83.0 in stage 5.0 (TID 195, hadoop17.cusp.nyu.edu, executor 5, partition 83, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:47:14 INFO  TaskSetManager:54 - Finished task 70.0 in stage 5.0 (TID 183) in 35 ms on hadoop17.cusp.nyu.edu (executor 5) (37/200)
2021-05-19 02:47:14 INFO  TaskSetManager:54 - Starting task 84.0 in stage 5.0 (TID 196, hadoop17.cusp.nyu.edu, executor 5, partition 84, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:47:14 INFO  TaskSetManager:54 - Finished task 73.0 in stage 5.0 (TID 186) in 33 ms on hadoop17.cusp.nyu.edu (executor 5) (38/200)
2021-05-19 02:47:14 INFO  TaskSetManager:54 - Starting task 85.0 in stage 5.0 (TID 197, hadoop17.cusp.nyu.edu, executor 5, partition 85, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:47:14 INFO  TaskSetManager:54 - Finished task 76.0 in stage 5.0 (TID 188) in 30 ms on hadoop17.cusp.nyu.edu (executor 5) (39/200)
2021-05-19 02:47:14 INFO  MapOutputTrackerMasterEndpoint:54 - Asked to send map output locations for shuffle 0 to 192.168.72.183:57671
2021-05-19 02:47:14 INFO  TaskSetManager:54 - Starting task 86.0 in stage 5.0 (TID 198, hadoop17.cusp.nyu.edu, executor 5, partition 86, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:47:14 INFO  TaskSetManager:54 - Finished task 77.0 in stage 5.0 (TID 189) in 52 ms on hadoop17.cusp.nyu.edu (executor 5) (40/200)
2021-05-19 02:47:14 INFO  TaskSetManager:54 - Starting task 87.0 in stage 5.0 (TID 199, hadoop17.cusp.nyu.edu, executor 5, partition 87, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:47:14 INFO  TaskSetManager:54 - Finished task 74.0 in stage 5.0 (TID 187) in 66 ms on hadoop17.cusp.nyu.edu (executor 5) (41/200)
2021-05-19 02:47:14 INFO  TaskSetManager:54 - Starting task 88.0 in stage 5.0 (TID 200, hadoop17.cusp.nyu.edu, executor 5, partition 88, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:47:14 INFO  TaskSetManager:54 - Finished task 79.0 in stage 5.0 (TID 191) in 52 ms on hadoop17.cusp.nyu.edu (executor 5) (42/200)
2021-05-19 02:47:14 INFO  TaskSetManager:54 - Starting task 89.0 in stage 5.0 (TID 201, hadoop17.cusp.nyu.edu, executor 5, partition 89, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:47:14 INFO  TaskSetManager:54 - Finished task 78.0 in stage 5.0 (TID 190) in 59 ms on hadoop17.cusp.nyu.edu (executor 5) (43/200)
2021-05-19 02:47:14 INFO  TaskSetManager:54 - Starting task 90.0 in stage 5.0 (TID 202, hadoop17.cusp.nyu.edu, executor 5, partition 90, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:47:14 INFO  TaskSetManager:54 - Finished task 80.0 in stage 5.0 (TID 192) in 59 ms on hadoop17.cusp.nyu.edu (executor 5) (44/200)
2021-05-19 02:47:14 INFO  TaskSetManager:54 - Starting task 91.0 in stage 5.0 (TID 203, hadoop17.cusp.nyu.edu, executor 5, partition 91, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:47:14 INFO  TaskSetManager:54 - Finished task 81.0 in stage 5.0 (TID 193) in 60 ms on hadoop17.cusp.nyu.edu (executor 5) (45/200)
2021-05-19 02:47:14 INFO  TaskSetManager:54 - Starting task 92.0 in stage 5.0 (TID 204, hadoop17.cusp.nyu.edu, executor 5, partition 92, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:47:14 INFO  TaskSetManager:54 - Finished task 82.0 in stage 5.0 (TID 194) in 60 ms on hadoop17.cusp.nyu.edu (executor 5) (46/200)
2021-05-19 02:47:14 INFO  TaskSetManager:54 - Starting task 93.0 in stage 5.0 (TID 205, hadoop17.cusp.nyu.edu, executor 5, partition 93, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:47:14 INFO  TaskSetManager:54 - Finished task 83.0 in stage 5.0 (TID 195) in 62 ms on hadoop17.cusp.nyu.edu (executor 5) (47/200)
2021-05-19 02:47:14 INFO  TaskSetManager:54 - Starting task 94.0 in stage 5.0 (TID 206, hadoop17.cusp.nyu.edu, executor 5, partition 94, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:47:14 INFO  TaskSetManager:54 - Finished task 86.0 in stage 5.0 (TID 198) in 28 ms on hadoop17.cusp.nyu.edu (executor 5) (48/200)
2021-05-19 02:47:14 INFO  TaskSetManager:54 - Starting task 95.0 in stage 5.0 (TID 207, hadoop17.cusp.nyu.edu, executor 5, partition 95, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:47:14 INFO  MapOutputTrackerMasterEndpoint:54 - Asked to send map output locations for shuffle 0 to 192.168.72.174:43399
2021-05-19 02:47:14 INFO  TaskSetManager:54 - Finished task 84.0 in stage 5.0 (TID 196) in 63 ms on hadoop17.cusp.nyu.edu (executor 5) (49/200)
2021-05-19 02:47:14 INFO  TaskSetManager:54 - Starting task 96.0 in stage 5.0 (TID 208, hadoop17.cusp.nyu.edu, executor 5, partition 96, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:47:14 INFO  TaskSetManager:54 - Finished task 88.0 in stage 5.0 (TID 200) in 29 ms on hadoop17.cusp.nyu.edu (executor 5) (50/200)
2021-05-19 02:47:14 INFO  TaskSetManager:54 - Starting task 97.0 in stage 5.0 (TID 209, hadoop17.cusp.nyu.edu, executor 5, partition 97, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:47:14 INFO  TaskSetManager:54 - Finished task 85.0 in stage 5.0 (TID 197) in 64 ms on hadoop17.cusp.nyu.edu (executor 5) (51/200)
2021-05-19 02:47:14 INFO  TaskSetManager:54 - Starting task 98.0 in stage 5.0 (TID 210, hadoop17.cusp.nyu.edu, executor 5, partition 98, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:47:14 INFO  TaskSetManager:54 - Finished task 87.0 in stage 5.0 (TID 199) in 34 ms on hadoop17.cusp.nyu.edu (executor 5) (52/200)
2021-05-19 02:47:14 INFO  TaskSetManager:54 - Starting task 99.0 in stage 5.0 (TID 211, hadoop17.cusp.nyu.edu, executor 5, partition 99, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:47:14 INFO  TaskSetManager:54 - Finished task 91.0 in stage 5.0 (TID 203) in 25 ms on hadoop17.cusp.nyu.edu (executor 5) (53/200)
2021-05-19 02:47:14 INFO  TaskSetManager:54 - Starting task 100.0 in stage 5.0 (TID 212, hadoop17.cusp.nyu.edu, executor 5, partition 100, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:47:14 INFO  TaskSetManager:54 - Finished task 89.0 in stage 5.0 (TID 201) in 38 ms on hadoop17.cusp.nyu.edu (executor 5) (54/200)
2021-05-19 02:47:14 INFO  TaskSetManager:54 - Starting task 101.0 in stage 5.0 (TID 213, hadoop17.cusp.nyu.edu, executor 5, partition 101, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:47:14 INFO  TaskSetManager:54 - Finished task 90.0 in stage 5.0 (TID 202) in 33 ms on hadoop17.cusp.nyu.edu (executor 5) (55/200)
2021-05-19 02:47:14 INFO  TaskSetManager:54 - Starting task 102.0 in stage 5.0 (TID 214, hadoop17.cusp.nyu.edu, executor 5, partition 102, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:47:14 INFO  TaskSetManager:54 - Finished task 95.0 in stage 5.0 (TID 207) in 22 ms on hadoop17.cusp.nyu.edu (executor 5) (56/200)
2021-05-19 02:47:14 INFO  TaskSetManager:54 - Starting task 103.0 in stage 5.0 (TID 215, hadoop17.cusp.nyu.edu, executor 5, partition 103, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:47:14 INFO  TaskSetManager:54 - Finished task 92.0 in stage 5.0 (TID 204) in 34 ms on hadoop17.cusp.nyu.edu (executor 5) (57/200)
2021-05-19 02:47:14 INFO  TaskSetManager:54 - Starting task 104.0 in stage 5.0 (TID 216, hadoop17.cusp.nyu.edu, executor 5, partition 104, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:47:14 INFO  TaskSetManager:54 - Finished task 94.0 in stage 5.0 (TID 206) in 28 ms on hadoop17.cusp.nyu.edu (executor 5) (58/200)
2021-05-19 02:47:14 INFO  TaskSetManager:54 - Starting task 105.0 in stage 5.0 (TID 217, hadoop17.cusp.nyu.edu, executor 5, partition 105, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:47:14 INFO  TaskSetManager:54 - Finished task 96.0 in stage 5.0 (TID 208) in 26 ms on hadoop17.cusp.nyu.edu (executor 5) (59/200)
2021-05-19 02:47:14 INFO  TaskSetManager:54 - Starting task 106.0 in stage 5.0 (TID 218, hadoop17.cusp.nyu.edu, executor 5, partition 106, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:47:14 INFO  TaskSetManager:54 - Finished task 93.0 in stage 5.0 (TID 205) in 32 ms on hadoop17.cusp.nyu.edu (executor 5) (60/200)
2021-05-19 02:47:14 INFO  TaskSetManager:54 - Starting task 107.0 in stage 5.0 (TID 219, hadoop17.cusp.nyu.edu, executor 5, partition 107, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:47:14 INFO  TaskSetManager:54 - Finished task 97.0 in stage 5.0 (TID 209) in 28 ms on hadoop17.cusp.nyu.edu (executor 5) (61/200)
2021-05-19 02:47:14 INFO  TaskSetManager:54 - Starting task 108.0 in stage 5.0 (TID 220, hadoop17.cusp.nyu.edu, executor 5, partition 108, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:47:14 INFO  TaskSetManager:54 - Finished task 98.0 in stage 5.0 (TID 210) in 27 ms on hadoop17.cusp.nyu.edu (executor 5) (62/200)
2021-05-19 02:47:14 INFO  TaskSetManager:54 - Starting task 109.0 in stage 5.0 (TID 221, hadoop17.cusp.nyu.edu, executor 5, partition 109, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:47:14 INFO  TaskSetManager:54 - Finished task 99.0 in stage 5.0 (TID 211) in 23 ms on hadoop17.cusp.nyu.edu (executor 5) (63/200)
2021-05-19 02:47:14 INFO  TaskSetManager:54 - Starting task 110.0 in stage 5.0 (TID 222, hadoop17.cusp.nyu.edu, executor 5, partition 110, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:47:14 INFO  TaskSetManager:54 - Finished task 101.0 in stage 5.0 (TID 213) in 19 ms on hadoop17.cusp.nyu.edu (executor 5) (64/200)
2021-05-19 02:47:14 INFO  TaskSetManager:54 - Starting task 111.0 in stage 5.0 (TID 223, hadoop17.cusp.nyu.edu, executor 5, partition 111, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:47:14 INFO  TaskSetManager:54 - Finished task 100.0 in stage 5.0 (TID 212) in 24 ms on hadoop17.cusp.nyu.edu (executor 5) (65/200)
2021-05-19 02:47:14 INFO  TaskSetManager:54 - Starting task 112.0 in stage 5.0 (TID 224, hadoop17.cusp.nyu.edu, executor 5, partition 112, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:47:14 INFO  TaskSetManager:54 - Finished task 102.0 in stage 5.0 (TID 214) in 22 ms on hadoop17.cusp.nyu.edu (executor 5) (66/200)
2021-05-19 02:47:14 INFO  TaskSetManager:54 - Starting task 113.0 in stage 5.0 (TID 225, hadoop17.cusp.nyu.edu, executor 5, partition 113, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:47:14 INFO  TaskSetManager:54 - Finished task 104.0 in stage 5.0 (TID 216) in 19 ms on hadoop17.cusp.nyu.edu (executor 5) (67/200)
2021-05-19 02:47:14 INFO  TaskSetManager:54 - Starting task 114.0 in stage 5.0 (TID 226, hadoop17.cusp.nyu.edu, executor 5, partition 114, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:47:14 INFO  TaskSetManager:54 - Finished task 103.0 in stage 5.0 (TID 215) in 23 ms on hadoop17.cusp.nyu.edu (executor 5) (68/200)
2021-05-19 02:47:14 INFO  TaskSetManager:54 - Starting task 115.0 in stage 5.0 (TID 227, hadoop17.cusp.nyu.edu, executor 5, partition 115, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:47:14 INFO  TaskSetManager:54 - Finished task 105.0 in stage 5.0 (TID 217) in 21 ms on hadoop17.cusp.nyu.edu (executor 5) (69/200)
2021-05-19 02:47:14 INFO  TaskSetManager:54 - Starting task 116.0 in stage 5.0 (TID 228, hadoop17.cusp.nyu.edu, executor 5, partition 116, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:47:14 INFO  TaskSetManager:54 - Finished task 106.0 in stage 5.0 (TID 218) in 21 ms on hadoop17.cusp.nyu.edu (executor 5) (70/200)
2021-05-19 02:47:14 INFO  TaskSetManager:54 - Starting task 117.0 in stage 5.0 (TID 229, hadoop17.cusp.nyu.edu, executor 5, partition 117, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:47:14 INFO  TaskSetManager:54 - Finished task 107.0 in stage 5.0 (TID 219) in 20 ms on hadoop17.cusp.nyu.edu (executor 5) (71/200)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Starting task 118.0 in stage 5.0 (TID 230, hadoop17.cusp.nyu.edu, executor 5, partition 118, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Finished task 108.0 in stage 5.0 (TID 220) in 24 ms on hadoop17.cusp.nyu.edu (executor 5) (72/200)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Starting task 119.0 in stage 5.0 (TID 231, hadoop17.cusp.nyu.edu, executor 5, partition 119, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Finished task 110.0 in stage 5.0 (TID 222) in 21 ms on hadoop17.cusp.nyu.edu (executor 5) (73/200)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Starting task 120.0 in stage 5.0 (TID 232, hadoop17.cusp.nyu.edu, executor 5, partition 120, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Finished task 109.0 in stage 5.0 (TID 221) in 24 ms on hadoop17.cusp.nyu.edu (executor 5) (74/200)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Starting task 121.0 in stage 5.0 (TID 233, hadoop17.cusp.nyu.edu, executor 5, partition 121, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Finished task 112.0 in stage 5.0 (TID 224) in 20 ms on hadoop17.cusp.nyu.edu (executor 5) (75/200)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Starting task 122.0 in stage 5.0 (TID 234, hadoop17.cusp.nyu.edu, executor 5, partition 122, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Finished task 111.0 in stage 5.0 (TID 223) in 24 ms on hadoop17.cusp.nyu.edu (executor 5) (76/200)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Starting task 123.0 in stage 5.0 (TID 235, hadoop17.cusp.nyu.edu, executor 5, partition 123, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Finished task 114.0 in stage 5.0 (TID 226) in 20 ms on hadoop17.cusp.nyu.edu (executor 5) (77/200)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Starting task 124.0 in stage 5.0 (TID 236, hadoop06.cusp.nyu.edu, executor 4, partition 124, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Finished task 42.0 in stage 5.0 (TID 156) in 594 ms on hadoop06.cusp.nyu.edu (executor 4) (78/200)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Starting task 125.0 in stage 5.0 (TID 237, hadoop06.cusp.nyu.edu, executor 4, partition 125, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Finished task 15.0 in stage 5.0 (TID 132) in 602 ms on hadoop06.cusp.nyu.edu (executor 4) (79/200)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Starting task 126.0 in stage 5.0 (TID 238, hadoop06.cusp.nyu.edu, executor 4, partition 126, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Finished task 20.0 in stage 5.0 (TID 136) in 603 ms on hadoop06.cusp.nyu.edu (executor 4) (80/200)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Starting task 127.0 in stage 5.0 (TID 239, hadoop17.cusp.nyu.edu, executor 5, partition 127, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Finished task 116.0 in stage 5.0 (TID 228) in 24 ms on hadoop17.cusp.nyu.edu (executor 5) (81/200)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Starting task 128.0 in stage 5.0 (TID 240, hadoop06.cusp.nyu.edu, executor 4, partition 128, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Finished task 33.0 in stage 5.0 (TID 148) in 603 ms on hadoop06.cusp.nyu.edu (executor 4) (82/200)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Starting task 129.0 in stage 5.0 (TID 241, hadoop17.cusp.nyu.edu, executor 5, partition 129, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Finished task 115.0 in stage 5.0 (TID 227) in 28 ms on hadoop17.cusp.nyu.edu (executor 5) (83/200)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Starting task 130.0 in stage 5.0 (TID 242, hadoop06.cusp.nyu.edu, executor 4, partition 130, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Finished task 1.0 in stage 5.0 (TID 119) in 616 ms on hadoop06.cusp.nyu.edu (executor 4) (84/200)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Starting task 131.0 in stage 5.0 (TID 243, hadoop17.cusp.nyu.edu, executor 5, partition 131, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Finished task 113.0 in stage 5.0 (TID 225) in 34 ms on hadoop17.cusp.nyu.edu (executor 5) (85/200)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Starting task 132.0 in stage 5.0 (TID 244, hadoop17.cusp.nyu.edu, executor 5, partition 132, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Finished task 117.0 in stage 5.0 (TID 229) in 30 ms on hadoop17.cusp.nyu.edu (executor 5) (86/200)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Starting task 133.0 in stage 5.0 (TID 245, hadoop06.cusp.nyu.edu, executor 4, partition 133, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Finished task 11.0 in stage 5.0 (TID 128) in 615 ms on hadoop06.cusp.nyu.edu (executor 4) (87/200)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Starting task 134.0 in stage 5.0 (TID 246, hadoop17.cusp.nyu.edu, executor 5, partition 134, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Finished task 119.0 in stage 5.0 (TID 231) in 27 ms on hadoop17.cusp.nyu.edu (executor 5) (88/200)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Starting task 135.0 in stage 5.0 (TID 247, hadoop06.cusp.nyu.edu, executor 4, partition 135, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Finished task 38.0 in stage 5.0 (TID 152) in 612 ms on hadoop06.cusp.nyu.edu (executor 4) (89/200)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Starting task 136.0 in stage 5.0 (TID 248, hadoop06.cusp.nyu.edu, executor 4, partition 136, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Finished task 29.0 in stage 5.0 (TID 144) in 617 ms on hadoop06.cusp.nyu.edu (executor 4) (90/200)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Starting task 137.0 in stage 5.0 (TID 249, hadoop06.cusp.nyu.edu, executor 4, partition 137, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Finished task 7.0 in stage 5.0 (TID 124) in 624 ms on hadoop06.cusp.nyu.edu (executor 4) (91/200)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Starting task 138.0 in stage 5.0 (TID 250, hadoop06.cusp.nyu.edu, executor 4, partition 138, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Finished task 24.0 in stage 5.0 (TID 140) in 620 ms on hadoop06.cusp.nyu.edu (executor 4) (92/200)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Starting task 139.0 in stage 5.0 (TID 251, hadoop17.cusp.nyu.edu, executor 5, partition 139, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Finished task 118.0 in stage 5.0 (TID 230) in 35 ms on hadoop17.cusp.nyu.edu (executor 5) (93/200)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Starting task 140.0 in stage 5.0 (TID 252, hadoop17.cusp.nyu.edu, executor 5, partition 140, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Finished task 121.0 in stage 5.0 (TID 233) in 31 ms on hadoop17.cusp.nyu.edu (executor 5) (94/200)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Starting task 141.0 in stage 5.0 (TID 253, hadoop17.cusp.nyu.edu, executor 5, partition 141, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Finished task 120.0 in stage 5.0 (TID 232) in 35 ms on hadoop17.cusp.nyu.edu (executor 5) (95/200)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Starting task 142.0 in stage 5.0 (TID 254, hadoop17.cusp.nyu.edu, executor 5, partition 142, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Finished task 122.0 in stage 5.0 (TID 234) in 32 ms on hadoop17.cusp.nyu.edu (executor 5) (96/200)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Starting task 143.0 in stage 5.0 (TID 255, hadoop17.cusp.nyu.edu, executor 5, partition 143, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Finished task 123.0 in stage 5.0 (TID 235) in 31 ms on hadoop17.cusp.nyu.edu (executor 5) (97/200)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Starting task 145.0 in stage 5.0 (TID 256, hadoop17.cusp.nyu.edu, executor 5, partition 145, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Finished task 127.0 in stage 5.0 (TID 239) in 26 ms on hadoop17.cusp.nyu.edu (executor 5) (98/200)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Starting task 146.0 in stage 5.0 (TID 257, hadoop17.cusp.nyu.edu, executor 5, partition 146, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Finished task 129.0 in stage 5.0 (TID 241) in 71 ms on hadoop17.cusp.nyu.edu (executor 5) (99/200)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Starting task 147.0 in stage 5.0 (TID 258, hadoop17.cusp.nyu.edu, executor 5, partition 147, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Finished task 131.0 in stage 5.0 (TID 243) in 69 ms on hadoop17.cusp.nyu.edu (executor 5) (100/200)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Starting task 148.0 in stage 5.0 (TID 259, hadoop17.cusp.nyu.edu, executor 5, partition 148, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Finished task 132.0 in stage 5.0 (TID 244) in 70 ms on hadoop17.cusp.nyu.edu (executor 5) (101/200)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Starting task 149.0 in stage 5.0 (TID 260, hadoop17.cusp.nyu.edu, executor 5, partition 149, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Starting task 150.0 in stage 5.0 (TID 261, hadoop06.cusp.nyu.edu, executor 4, partition 150, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Finished task 134.0 in stage 5.0 (TID 246) in 70 ms on hadoop17.cusp.nyu.edu (executor 5) (102/200)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Finished task 124.0 in stage 5.0 (TID 236) in 86 ms on hadoop06.cusp.nyu.edu (executor 4) (103/200)
2021-05-19 02:47:15 INFO  BlockManagerInfo:54 - Removed broadcast_9_piece0 on hadoop02.cusp.nyu.edu:49352 in memory (size: 20.3 KB, free: 366.2 MB)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Starting task 151.0 in stage 5.0 (TID 262, hadoop06.cusp.nyu.edu, executor 4, partition 151, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Finished task 133.0 in stage 5.0 (TID 245) in 74 ms on hadoop06.cusp.nyu.edu (executor 4) (104/200)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Starting task 152.0 in stage 5.0 (TID 263, hadoop06.cusp.nyu.edu, executor 4, partition 152, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:47:15 INFO  BlockManagerInfo:54 - Removed broadcast_9_piece0 on hadoop17.cusp.nyu.edu:39842 in memory (size: 20.3 KB, free: 365.6 MB)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Finished task 128.0 in stage 5.0 (TID 240) in 84 ms on hadoop06.cusp.nyu.edu (executor 4) (105/200)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Starting task 153.0 in stage 5.0 (TID 264, hadoop17.cusp.nyu.edu, executor 5, partition 153, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Finished task 139.0 in stage 5.0 (TID 251) in 70 ms on hadoop17.cusp.nyu.edu (executor 5) (106/200)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Starting task 154.0 in stage 5.0 (TID 265, hadoop06.cusp.nyu.edu, executor 4, partition 154, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Finished task 125.0 in stage 5.0 (TID 237) in 92 ms on hadoop06.cusp.nyu.edu (executor 4) (107/200)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Starting task 155.0 in stage 5.0 (TID 266, hadoop17.cusp.nyu.edu, executor 5, partition 155, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Finished task 140.0 in stage 5.0 (TID 252) in 71 ms on hadoop17.cusp.nyu.edu (executor 5) (108/200)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Starting task 156.0 in stage 5.0 (TID 267, hadoop06.cusp.nyu.edu, executor 4, partition 156, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Finished task 126.0 in stage 5.0 (TID 238) in 94 ms on hadoop06.cusp.nyu.edu (executor 4) (109/200)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Starting task 157.0 in stage 5.0 (TID 268, hadoop17.cusp.nyu.edu, executor 5, partition 157, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Finished task 141.0 in stage 5.0 (TID 253) in 72 ms on hadoop17.cusp.nyu.edu (executor 5) (110/200)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Starting task 158.0 in stage 5.0 (TID 269, hadoop17.cusp.nyu.edu, executor 5, partition 158, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Finished task 142.0 in stage 5.0 (TID 254) in 73 ms on hadoop17.cusp.nyu.edu (executor 5) (111/200)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Starting task 159.0 in stage 5.0 (TID 270, hadoop06.cusp.nyu.edu, executor 4, partition 159, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Starting task 160.0 in stage 5.0 (TID 271, hadoop06.cusp.nyu.edu, executor 4, partition 160, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Finished task 130.0 in stage 5.0 (TID 242) in 94 ms on hadoop06.cusp.nyu.edu (executor 4) (112/200)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Finished task 138.0 in stage 5.0 (TID 250) in 83 ms on hadoop06.cusp.nyu.edu (executor 4) (113/200)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Starting task 161.0 in stage 5.0 (TID 272, hadoop17.cusp.nyu.edu, executor 5, partition 161, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Finished task 143.0 in stage 5.0 (TID 255) in 76 ms on hadoop17.cusp.nyu.edu (executor 5) (114/200)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Starting task 162.0 in stage 5.0 (TID 273, hadoop06.cusp.nyu.edu, executor 4, partition 162, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Finished task 137.0 in stage 5.0 (TID 249) in 87 ms on hadoop06.cusp.nyu.edu (executor 4) (115/200)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Starting task 163.0 in stage 5.0 (TID 274, hadoop17.cusp.nyu.edu, executor 5, partition 163, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Finished task 145.0 in stage 5.0 (TID 256) in 79 ms on hadoop17.cusp.nyu.edu (executor 5) (116/200)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Starting task 164.0 in stage 5.0 (TID 275, hadoop06.cusp.nyu.edu, executor 4, partition 164, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Finished task 135.0 in stage 5.0 (TID 247) in 93 ms on hadoop06.cusp.nyu.edu (executor 4) (117/200)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Starting task 165.0 in stage 5.0 (TID 276, hadoop06.cusp.nyu.edu, executor 4, partition 165, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Finished task 136.0 in stage 5.0 (TID 248) in 95 ms on hadoop06.cusp.nyu.edu (executor 4) (118/200)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Starting task 167.0 in stage 5.0 (TID 277, hadoop17.cusp.nyu.edu, executor 5, partition 167, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Finished task 148.0 in stage 5.0 (TID 259) in 33 ms on hadoop17.cusp.nyu.edu (executor 5) (119/200)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Starting task 168.0 in stage 5.0 (TID 278, hadoop17.cusp.nyu.edu, executor 5, partition 168, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Finished task 149.0 in stage 5.0 (TID 260) in 33 ms on hadoop17.cusp.nyu.edu (executor 5) (120/200)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Starting task 169.0 in stage 5.0 (TID 279, hadoop17.cusp.nyu.edu, executor 5, partition 169, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Finished task 146.0 in stage 5.0 (TID 257) in 86 ms on hadoop17.cusp.nyu.edu (executor 5) (121/200)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Starting task 170.0 in stage 5.0 (TID 280, hadoop17.cusp.nyu.edu, executor 5, partition 170, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Finished task 147.0 in stage 5.0 (TID 258) in 41 ms on hadoop17.cusp.nyu.edu (executor 5) (122/200)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Starting task 171.0 in stage 5.0 (TID 281, hadoop17.cusp.nyu.edu, executor 5, partition 171, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Finished task 153.0 in stage 5.0 (TID 264) in 30 ms on hadoop17.cusp.nyu.edu (executor 5) (123/200)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Starting task 172.0 in stage 5.0 (TID 282, hadoop17.cusp.nyu.edu, executor 5, partition 172, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Finished task 155.0 in stage 5.0 (TID 266) in 29 ms on hadoop17.cusp.nyu.edu (executor 5) (124/200)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Starting task 173.0 in stage 5.0 (TID 283, hadoop17.cusp.nyu.edu, executor 5, partition 173, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Finished task 157.0 in stage 5.0 (TID 268) in 30 ms on hadoop17.cusp.nyu.edu (executor 5) (125/200)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Starting task 174.0 in stage 5.0 (TID 284, hadoop17.cusp.nyu.edu, executor 5, partition 174, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Finished task 158.0 in stage 5.0 (TID 269) in 28 ms on hadoop17.cusp.nyu.edu (executor 5) (126/200)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Starting task 175.0 in stage 5.0 (TID 285, hadoop17.cusp.nyu.edu, executor 5, partition 175, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Finished task 163.0 in stage 5.0 (TID 274) in 27 ms on hadoop17.cusp.nyu.edu (executor 5) (127/200)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Starting task 176.0 in stage 5.0 (TID 286, hadoop06.cusp.nyu.edu, executor 4, partition 176, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Finished task 151.0 in stage 5.0 (TID 262) in 49 ms on hadoop06.cusp.nyu.edu (executor 4) (128/200)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Starting task 177.0 in stage 5.0 (TID 287, hadoop17.cusp.nyu.edu, executor 5, partition 177, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Finished task 161.0 in stage 5.0 (TID 272) in 32 ms on hadoop17.cusp.nyu.edu (executor 5) (129/200)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Starting task 178.0 in stage 5.0 (TID 288, hadoop17.cusp.nyu.edu, executor 5, partition 178, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Finished task 168.0 in stage 5.0 (TID 278) in 24 ms on hadoop17.cusp.nyu.edu (executor 5) (130/200)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Starting task 179.0 in stage 5.0 (TID 289, hadoop17.cusp.nyu.edu, executor 5, partition 179, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Finished task 167.0 in stage 5.0 (TID 277) in 27 ms on hadoop17.cusp.nyu.edu (executor 5) (131/200)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Starting task 180.0 in stage 5.0 (TID 290, hadoop17.cusp.nyu.edu, executor 5, partition 180, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Finished task 169.0 in stage 5.0 (TID 279) in 26 ms on hadoop17.cusp.nyu.edu (executor 5) (132/200)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Starting task 181.0 in stage 5.0 (TID 291, hadoop17.cusp.nyu.edu, executor 5, partition 181, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Finished task 170.0 in stage 5.0 (TID 280) in 25 ms on hadoop17.cusp.nyu.edu (executor 5) (133/200)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Starting task 182.0 in stage 5.0 (TID 292, hadoop06.cusp.nyu.edu, executor 4, partition 182, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Finished task 156.0 in stage 5.0 (TID 267) in 49 ms on hadoop06.cusp.nyu.edu (executor 4) (134/200)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Starting task 183.0 in stage 5.0 (TID 293, hadoop06.cusp.nyu.edu, executor 4, partition 183, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Finished task 154.0 in stage 5.0 (TID 265) in 55 ms on hadoop06.cusp.nyu.edu (executor 4) (135/200)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Starting task 184.0 in stage 5.0 (TID 294, hadoop06.cusp.nyu.edu, executor 4, partition 184, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Finished task 150.0 in stage 5.0 (TID 261) in 64 ms on hadoop06.cusp.nyu.edu (executor 4) (136/200)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Starting task 185.0 in stage 5.0 (TID 295, hadoop06.cusp.nyu.edu, executor 4, partition 185, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Finished task 152.0 in stage 5.0 (TID 263) in 60 ms on hadoop06.cusp.nyu.edu (executor 4) (137/200)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Starting task 186.0 in stage 5.0 (TID 296, hadoop06.cusp.nyu.edu, executor 4, partition 186, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Finished task 165.0 in stage 5.0 (TID 276) in 44 ms on hadoop06.cusp.nyu.edu (executor 4) (138/200)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Starting task 187.0 in stage 5.0 (TID 297, hadoop06.cusp.nyu.edu, executor 4, partition 187, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Finished task 162.0 in stage 5.0 (TID 273) in 51 ms on hadoop06.cusp.nyu.edu (executor 4) (139/200)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Starting task 188.0 in stage 5.0 (TID 298, hadoop06.cusp.nyu.edu, executor 4, partition 188, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Finished task 159.0 in stage 5.0 (TID 270) in 58 ms on hadoop06.cusp.nyu.edu (executor 4) (140/200)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Starting task 190.0 in stage 5.0 (TID 299, hadoop06.cusp.nyu.edu, executor 4, partition 190, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Finished task 160.0 in stage 5.0 (TID 271) in 58 ms on hadoop06.cusp.nyu.edu (executor 4) (141/200)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Starting task 191.0 in stage 5.0 (TID 300, hadoop06.cusp.nyu.edu, executor 4, partition 191, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Finished task 164.0 in stage 5.0 (TID 275) in 51 ms on hadoop06.cusp.nyu.edu (executor 4) (142/200)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Starting task 192.0 in stage 5.0 (TID 301, hadoop17.cusp.nyu.edu, executor 5, partition 192, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Finished task 172.0 in stage 5.0 (TID 282) in 57 ms on hadoop17.cusp.nyu.edu (executor 5) (143/200)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Starting task 193.0 in stage 5.0 (TID 302, hadoop17.cusp.nyu.edu, executor 5, partition 193, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Finished task 173.0 in stage 5.0 (TID 283) in 55 ms on hadoop17.cusp.nyu.edu (executor 5) (144/200)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Starting task 194.0 in stage 5.0 (TID 303, hadoop17.cusp.nyu.edu, executor 5, partition 194, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Finished task 171.0 in stage 5.0 (TID 281) in 62 ms on hadoop17.cusp.nyu.edu (executor 5) (145/200)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Starting task 195.0 in stage 5.0 (TID 304, hadoop17.cusp.nyu.edu, executor 5, partition 195, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Finished task 174.0 in stage 5.0 (TID 284) in 55 ms on hadoop17.cusp.nyu.edu (executor 5) (146/200)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Starting task 196.0 in stage 5.0 (TID 305, hadoop06.cusp.nyu.edu, executor 4, partition 196, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Finished task 176.0 in stage 5.0 (TID 286) in 52 ms on hadoop06.cusp.nyu.edu (executor 4) (147/200)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Starting task 197.0 in stage 5.0 (TID 306, hadoop17.cusp.nyu.edu, executor 5, partition 197, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Finished task 175.0 in stage 5.0 (TID 285) in 54 ms on hadoop17.cusp.nyu.edu (executor 5) (148/200)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Starting task 198.0 in stage 5.0 (TID 307, hadoop17.cusp.nyu.edu, executor 5, partition 198, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Finished task 177.0 in stage 5.0 (TID 287) in 52 ms on hadoop17.cusp.nyu.edu (executor 5) (149/200)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Starting task 199.0 in stage 5.0 (TID 308, hadoop17.cusp.nyu.edu, executor 5, partition 199, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Finished task 178.0 in stage 5.0 (TID 288) in 53 ms on hadoop17.cusp.nyu.edu (executor 5) (150/200)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Finished task 180.0 in stage 5.0 (TID 290) in 50 ms on hadoop17.cusp.nyu.edu (executor 5) (151/200)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Finished task 179.0 in stage 5.0 (TID 289) in 52 ms on hadoop17.cusp.nyu.edu (executor 5) (152/200)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Finished task 181.0 in stage 5.0 (TID 291) in 49 ms on hadoop17.cusp.nyu.edu (executor 5) (153/200)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Finished task 192.0 in stage 5.0 (TID 301) in 20 ms on hadoop17.cusp.nyu.edu (executor 5) (154/200)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Finished task 195.0 in stage 5.0 (TID 304) in 15 ms on hadoop17.cusp.nyu.edu (executor 5) (155/200)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Finished task 193.0 in stage 5.0 (TID 302) in 19 ms on hadoop17.cusp.nyu.edu (executor 5) (156/200)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Finished task 194.0 in stage 5.0 (TID 303) in 20 ms on hadoop17.cusp.nyu.edu (executor 5) (157/200)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Finished task 198.0 in stage 5.0 (TID 307) in 15 ms on hadoop17.cusp.nyu.edu (executor 5) (158/200)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Finished task 197.0 in stage 5.0 (TID 306) in 17 ms on hadoop17.cusp.nyu.edu (executor 5) (159/200)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Finished task 183.0 in stage 5.0 (TID 293) in 60 ms on hadoop06.cusp.nyu.edu (executor 4) (160/200)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Finished task 184.0 in stage 5.0 (TID 294) in 62 ms on hadoop06.cusp.nyu.edu (executor 4) (161/200)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Finished task 199.0 in stage 5.0 (TID 308) in 20 ms on hadoop17.cusp.nyu.edu (executor 5) (162/200)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Finished task 185.0 in stage 5.0 (TID 295) in 61 ms on hadoop06.cusp.nyu.edu (executor 4) (163/200)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Finished task 182.0 in stage 5.0 (TID 292) in 66 ms on hadoop06.cusp.nyu.edu (executor 4) (164/200)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Finished task 187.0 in stage 5.0 (TID 297) in 59 ms on hadoop06.cusp.nyu.edu (executor 4) (165/200)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Finished task 190.0 in stage 5.0 (TID 299) in 63 ms on hadoop06.cusp.nyu.edu (executor 4) (166/200)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Finished task 196.0 in stage 5.0 (TID 305) in 37 ms on hadoop06.cusp.nyu.edu (executor 4) (167/200)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Finished task 186.0 in stage 5.0 (TID 296) in 68 ms on hadoop06.cusp.nyu.edu (executor 4) (168/200)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Finished task 188.0 in stage 5.0 (TID 298) in 66 ms on hadoop06.cusp.nyu.edu (executor 4) (169/200)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Finished task 191.0 in stage 5.0 (TID 300) in 64 ms on hadoop06.cusp.nyu.edu (executor 4) (170/200)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Finished task 22.0 in stage 5.0 (TID 138) in 1355 ms on hadoop13.cusp.nyu.edu (executor 1) (171/200)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Finished task 13.0 in stage 5.0 (TID 130) in 1358 ms on hadoop13.cusp.nyu.edu (executor 1) (172/200)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Finished task 40.0 in stage 5.0 (TID 154) in 1353 ms on hadoop13.cusp.nyu.edu (executor 1) (173/200)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Finished task 36.0 in stage 5.0 (TID 150) in 1354 ms on hadoop13.cusp.nyu.edu (executor 1) (174/200)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Finished task 17.0 in stage 5.0 (TID 134) in 1366 ms on hadoop13.cusp.nyu.edu (executor 1) (175/200)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Finished task 5.0 in stage 5.0 (TID 122) in 1374 ms on hadoop13.cusp.nyu.edu (executor 1) (176/200)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Finished task 31.0 in stage 5.0 (TID 146) in 1367 ms on hadoop13.cusp.nyu.edu (executor 1) (177/200)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Finished task 44.0 in stage 5.0 (TID 158) in 1364 ms on hadoop13.cusp.nyu.edu (executor 1) (178/200)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Finished task 9.0 in stage 5.0 (TID 126) in 1375 ms on hadoop13.cusp.nyu.edu (executor 1) (179/200)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Finished task 27.0 in stage 5.0 (TID 142) in 1370 ms on hadoop13.cusp.nyu.edu (executor 1) (180/200)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Finished task 21.0 in stage 5.0 (TID 137) in 1431 ms on hadoop18.cusp.nyu.edu (executor 2) (181/200)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Finished task 34.0 in stage 5.0 (TID 149) in 1431 ms on hadoop18.cusp.nyu.edu (executor 2) (182/200)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Finished task 12.0 in stage 5.0 (TID 129) in 1437 ms on hadoop18.cusp.nyu.edu (executor 2) (183/200)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Finished task 8.0 in stage 5.0 (TID 125) in 1440 ms on hadoop18.cusp.nyu.edu (executor 2) (184/200)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Finished task 16.0 in stage 5.0 (TID 133) in 1437 ms on hadoop18.cusp.nyu.edu (executor 2) (185/200)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Finished task 25.0 in stage 5.0 (TID 141) in 1436 ms on hadoop18.cusp.nyu.edu (executor 2) (186/200)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Finished task 2.0 in stage 5.0 (TID 120) in 1444 ms on hadoop18.cusp.nyu.edu (executor 2) (187/200)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Finished task 39.0 in stage 5.0 (TID 153) in 1434 ms on hadoop18.cusp.nyu.edu (executor 2) (188/200)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Finished task 30.0 in stage 5.0 (TID 145) in 1437 ms on hadoop18.cusp.nyu.edu (executor 2) (189/200)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Finished task 43.0 in stage 5.0 (TID 157) in 1435 ms on hadoop18.cusp.nyu.edu (executor 2) (190/200)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Finished task 37.0 in stage 5.0 (TID 151) in 1457 ms on hadoop04.cusp.nyu.edu (executor 3) (191/200)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Finished task 32.0 in stage 5.0 (TID 147) in 1460 ms on hadoop04.cusp.nyu.edu (executor 3) (192/200)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Finished task 10.0 in stage 5.0 (TID 127) in 1468 ms on hadoop04.cusp.nyu.edu (executor 3) (193/200)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Finished task 14.0 in stage 5.0 (TID 131) in 1468 ms on hadoop04.cusp.nyu.edu (executor 3) (194/200)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Finished task 23.0 in stage 5.0 (TID 139) in 1467 ms on hadoop04.cusp.nyu.edu (executor 3) (195/200)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Finished task 0.0 in stage 5.0 (TID 118) in 1475 ms on hadoop04.cusp.nyu.edu (executor 3) (196/200)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Finished task 19.0 in stage 5.0 (TID 135) in 1472 ms on hadoop04.cusp.nyu.edu (executor 3) (197/200)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Finished task 28.0 in stage 5.0 (TID 143) in 1471 ms on hadoop04.cusp.nyu.edu (executor 3) (198/200)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Finished task 41.0 in stage 5.0 (TID 155) in 1468 ms on hadoop04.cusp.nyu.edu (executor 3) (199/200)
2021-05-19 02:47:15 INFO  TaskSetManager:54 - Finished task 6.0 in stage 5.0 (TID 123) in 1485 ms on hadoop04.cusp.nyu.edu (executor 3) (200/200)
2021-05-19 02:47:15 INFO  YarnClusterScheduler:54 - Removed TaskSet 5.0, whose tasks have all completed, from pool 
2021-05-19 02:47:15 INFO  DAGScheduler:54 - ResultStage 5 (collect at BDM_HW4.py:27) finished in 1.539 s
2021-05-19 02:47:15 INFO  DAGScheduler:54 - Job 4 finished: collect at BDM_HW4.py:27, took 4.633528 s
2021-05-19 02:47:16 INFO  ContextCleaner:54 - Cleaned accumulator 193
2021-05-19 02:47:16 INFO  ContextCleaner:54 - Cleaned accumulator 159
2021-05-19 02:47:16 INFO  ContextCleaner:54 - Cleaned accumulator 132
2021-05-19 02:47:16 INFO  ContextCleaner:54 - Cleaned accumulator 136
2021-05-19 02:47:16 INFO  ContextCleaner:54 - Cleaned accumulator 137
2021-05-19 02:47:16 INFO  ContextCleaner:54 - Cleaned accumulator 152
2021-05-19 02:47:16 INFO  ContextCleaner:54 - Cleaned accumulator 184
2021-05-19 02:47:16 INFO  ContextCleaner:54 - Cleaned accumulator 127
2021-05-19 02:47:16 INFO  ContextCleaner:54 - Cleaned accumulator 186
2021-05-19 02:47:16 INFO  ContextCleaner:54 - Cleaned accumulator 180
2021-05-19 02:47:16 INFO  ContextCleaner:54 - Cleaned accumulator 163
2021-05-19 02:47:16 INFO  ContextCleaner:54 - Cleaned accumulator 133
2021-05-19 02:47:16 INFO  ContextCleaner:54 - Cleaned accumulator 131
2021-05-19 02:47:16 INFO  ContextCleaner:54 - Cleaned accumulator 172
2021-05-19 02:47:16 INFO  ContextCleaner:54 - Cleaned accumulator 176
2021-05-19 02:47:16 INFO  ContextCleaner:54 - Cleaned accumulator 187
2021-05-19 02:47:16 INFO  ContextCleaner:54 - Cleaned accumulator 192
2021-05-19 02:47:16 INFO  ContextCleaner:54 - Cleaned accumulator 168
2021-05-19 02:47:16 INFO  ContextCleaner:54 - Cleaned accumulator 162
2021-05-19 02:47:16 INFO  ContextCleaner:54 - Cleaned accumulator 165
2021-05-19 02:47:16 INFO  ContextCleaner:54 - Cleaned accumulator 177
2021-05-19 02:47:16 INFO  ContextCleaner:54 - Cleaned accumulator 147
2021-05-19 02:47:16 INFO  ContextCleaner:54 - Cleaned accumulator 169
2021-05-19 02:47:16 INFO  ContextCleaner:54 - Cleaned accumulator 157
2021-05-19 02:47:16 INFO  ContextCleaner:54 - Cleaned accumulator 183
2021-05-19 02:47:16 INFO  ContextCleaner:54 - Cleaned accumulator 188
2021-05-19 02:47:16 INFO  ContextCleaner:54 - Cleaned accumulator 196
2021-05-19 02:47:16 INFO  ContextCleaner:54 - Cleaned accumulator 178
2021-05-19 02:47:16 INFO  ContextCleaner:54 - Cleaned accumulator 158
2021-05-19 02:47:16 INFO  ContextCleaner:54 - Cleaned accumulator 128
2021-05-19 02:47:16 INFO  ContextCleaner:54 - Cleaned accumulator 191
2021-05-19 02:47:16 INFO  ContextCleaner:54 - Cleaned accumulator 139
2021-05-19 02:47:16 INFO  ContextCleaner:54 - Cleaned accumulator 154
2021-05-19 02:47:16 INFO  ContextCleaner:54 - Cleaned accumulator 185
2021-05-19 02:47:16 INFO  ContextCleaner:54 - Cleaned accumulator 156
2021-05-19 02:47:16 INFO  ContextCleaner:54 - Cleaned accumulator 190
2021-05-19 02:47:16 INFO  ContextCleaner:54 - Cleaned accumulator 148
2021-05-19 02:47:16 INFO  ContextCleaner:54 - Cleaned accumulator 173
2021-05-19 02:47:16 INFO  ContextCleaner:54 - Cleaned accumulator 153
2021-05-19 02:47:16 INFO  ContextCleaner:54 - Cleaned shuffle 0
2021-05-19 02:47:16 INFO  ContextCleaner:54 - Cleaned accumulator 166
2021-05-19 02:47:16 INFO  ContextCleaner:54 - Cleaned accumulator 134
2021-05-19 02:47:16 INFO  ContextCleaner:54 - Cleaned accumulator 151
2021-05-19 02:47:16 INFO  ContextCleaner:54 - Cleaned accumulator 135
2021-05-19 02:47:16 INFO  ContextCleaner:54 - Cleaned accumulator 150
2021-05-19 02:47:16 INFO  ContextCleaner:54 - Cleaned accumulator 174
2021-05-19 02:47:16 INFO  ContextCleaner:54 - Cleaned accumulator 182
2021-05-19 02:47:16 INFO  ContextCleaner:54 - Cleaned accumulator 126
2021-05-19 02:47:16 INFO  ContextCleaner:54 - Cleaned accumulator 167
2021-05-19 02:47:16 INFO  ContextCleaner:54 - Cleaned accumulator 161
2021-05-19 02:47:16 INFO  ContextCleaner:54 - Cleaned accumulator 149
2021-05-19 02:47:16 INFO  ContextCleaner:54 - Cleaned accumulator 194
2021-05-19 02:47:16 INFO  ContextCleaner:54 - Cleaned accumulator 138
2021-05-19 02:47:16 INFO  ContextCleaner:54 - Cleaned accumulator 155
2021-05-19 02:47:16 INFO  ContextCleaner:54 - Cleaned accumulator 164
2021-05-19 02:47:16 INFO  ContextCleaner:54 - Cleaned accumulator 179
2021-05-19 02:47:16 INFO  ContextCleaner:54 - Cleaned accumulator 125
2021-05-19 02:47:16 INFO  ContextCleaner:54 - Cleaned accumulator 160
2021-05-19 02:47:16 INFO  BlockManagerInfo:54 - Removed broadcast_10_piece0 on hadoop02.cusp.nyu.edu:49352 in memory (size: 20.4 KB, free: 366.3 MB)
2021-05-19 02:47:16 INFO  BlockManagerInfo:54 - Removed broadcast_10_piece0 on hadoop18.cusp.nyu.edu:37819 in memory (size: 20.4 KB, free: 366.3 MB)
2021-05-19 02:47:16 INFO  BlockManagerInfo:54 - Removed broadcast_10_piece0 on hadoop17.cusp.nyu.edu:39842 in memory (size: 20.4 KB, free: 365.6 MB)
2021-05-19 02:47:16 INFO  BlockManagerInfo:54 - Removed broadcast_10_piece0 on hadoop06.cusp.nyu.edu:53410 in memory (size: 20.4 KB, free: 366.3 MB)
2021-05-19 02:47:16 INFO  BlockManagerInfo:54 - Removed broadcast_10_piece0 on hadoop13.cusp.nyu.edu:32809 in memory (size: 20.4 KB, free: 366.3 MB)
2021-05-19 02:47:16 INFO  BlockManagerInfo:54 - Removed broadcast_10_piece0 on hadoop04.cusp.nyu.edu:41664 in memory (size: 20.4 KB, free: 366.3 MB)
2021-05-19 02:47:16 INFO  ContextCleaner:54 - Cleaned accumulator 171
2021-05-19 02:47:16 INFO  ContextCleaner:54 - Cleaned accumulator 170
2021-05-19 02:47:16 INFO  ContextCleaner:54 - Cleaned accumulator 195
2021-05-19 02:47:16 INFO  ContextCleaner:54 - Cleaned accumulator 130
2021-05-19 02:47:16 INFO  ContextCleaner:54 - Cleaned accumulator 175
2021-05-19 02:47:16 INFO  ContextCleaner:54 - Cleaned accumulator 181
2021-05-19 02:47:16 INFO  ContextCleaner:54 - Cleaned accumulator 189
2021-05-19 02:47:16 INFO  ContextCleaner:54 - Cleaned accumulator 129
2021-05-19 02:47:16 INFO  FileSourceStrategy:54 - Pruning directories with: 
2021-05-19 02:47:16 INFO  FileSourceStrategy:54 - Post-Scan Filters: isnotnull(placekey#68)
2021-05-19 02:47:16 INFO  FileSourceStrategy:54 - Output Data Schema: struct<placekey: string, date_range_start: string, visits_by_day: string ... 1 more fields>
2021-05-19 02:47:16 INFO  FileSourceScanExec:54 - Pushed Filters: IsNotNull(placekey)
2021-05-19 02:47:17 WARN  Utils:66 - Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.debug.maxToStringFields' in SparkEnv.conf.
2021-05-19 02:47:17 INFO  FileOutputCommitter:108 - File Output Committer Algorithm version is 1
2021-05-19 02:47:17 INFO  SQLHadoopMapReduceCommitProtocol:54 - Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2021-05-19 02:47:17 INFO  CodeGenerator:54 - Code generated in 25.796569 ms
2021-05-19 02:47:17 INFO  CodeGenerator:54 - Code generated in 34.924256 ms
2021-05-19 02:47:17 INFO  CodeGenerator:54 - Code generated in 46.957641 ms
2021-05-19 02:47:17 INFO  SparkContext:54 - Starting job: run at ThreadPoolExecutor.java:1149
2021-05-19 02:47:17 INFO  DAGScheduler:54 - Got job 5 (run at ThreadPoolExecutor.java:1149) with 8 output partitions
2021-05-19 02:47:17 INFO  DAGScheduler:54 - Final stage: ResultStage 6 (run at ThreadPoolExecutor.java:1149)
2021-05-19 02:47:17 INFO  DAGScheduler:54 - Parents of final stage: List()
2021-05-19 02:47:17 INFO  DAGScheduler:54 - Missing parents: List()
2021-05-19 02:47:17 INFO  DAGScheduler:54 - Submitting ResultStage 6 (MapPartitionsRDD[42] at run at ThreadPoolExecutor.java:1149), which has no missing parents
2021-05-19 02:47:17 INFO  MemoryStore:54 - Block broadcast_11 stored as values in memory (estimated size 29.9 KB, free 365.9 MB)
2021-05-19 02:47:17 INFO  MemoryStore:54 - Block broadcast_11_piece0 stored as bytes in memory (estimated size 14.1 KB, free 365.9 MB)
2021-05-19 02:47:17 INFO  BlockManagerInfo:54 - Added broadcast_11_piece0 in memory on hadoop02.cusp.nyu.edu:49352 (size: 14.1 KB, free: 366.3 MB)
2021-05-19 02:47:17 INFO  SparkContext:54 - Created broadcast 11 from broadcast at DAGScheduler.scala:1161
2021-05-19 02:47:17 INFO  DAGScheduler:54 - Submitting 8 missing tasks from ResultStage 6 (MapPartitionsRDD[42] at run at ThreadPoolExecutor.java:1149) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
2021-05-19 02:47:17 INFO  YarnClusterScheduler:54 - Adding task set 6.0 with 8 tasks
2021-05-19 02:47:17 INFO  TaskSetManager:54 - Starting task 0.0 in stage 6.0 (TID 309, hadoop17.cusp.nyu.edu, executor 5, partition 0, PROCESS_LOCAL, 8321 bytes)
2021-05-19 02:47:17 INFO  CodeGenerator:54 - Code generated in 35.076162 ms
2021-05-19 02:47:17 INFO  TaskSetManager:54 - Starting task 1.0 in stage 6.0 (TID 310, hadoop17.cusp.nyu.edu, executor 5, partition 1, PROCESS_LOCAL, 8321 bytes)
2021-05-19 02:47:17 INFO  TaskSetManager:54 - Starting task 2.0 in stage 6.0 (TID 311, hadoop17.cusp.nyu.edu, executor 5, partition 2, PROCESS_LOCAL, 8321 bytes)
2021-05-19 02:47:17 INFO  TaskSetManager:54 - Starting task 3.0 in stage 6.0 (TID 312, hadoop17.cusp.nyu.edu, executor 5, partition 3, PROCESS_LOCAL, 8321 bytes)
2021-05-19 02:47:17 INFO  TaskSetManager:54 - Starting task 4.0 in stage 6.0 (TID 313, hadoop17.cusp.nyu.edu, executor 5, partition 4, PROCESS_LOCAL, 8321 bytes)
2021-05-19 02:47:17 INFO  TaskSetManager:54 - Starting task 5.0 in stage 6.0 (TID 314, hadoop17.cusp.nyu.edu, executor 5, partition 5, PROCESS_LOCAL, 8321 bytes)
2021-05-19 02:47:17 INFO  TaskSetManager:54 - Starting task 6.0 in stage 6.0 (TID 315, hadoop17.cusp.nyu.edu, executor 5, partition 6, PROCESS_LOCAL, 8321 bytes)
2021-05-19 02:47:17 INFO  TaskSetManager:54 - Starting task 7.0 in stage 6.0 (TID 316, hadoop17.cusp.nyu.edu, executor 5, partition 7, PROCESS_LOCAL, 8321 bytes)
2021-05-19 02:47:17 INFO  BlockManagerInfo:54 - Added broadcast_11_piece0 in memory on hadoop17.cusp.nyu.edu:39842 (size: 14.1 KB, free: 365.6 MB)
2021-05-19 02:47:17 INFO  CodeGenerator:54 - Code generated in 19.972226 ms
2021-05-19 02:47:18 INFO  TaskSetManager:54 - Finished task 7.0 in stage 6.0 (TID 316) in 518 ms on hadoop17.cusp.nyu.edu (executor 5) (1/8)
2021-05-19 02:47:18 INFO  TaskSetManager:54 - Finished task 6.0 in stage 6.0 (TID 315) in 536 ms on hadoop17.cusp.nyu.edu (executor 5) (2/8)
2021-05-19 02:47:18 INFO  TaskSetManager:54 - Finished task 3.0 in stage 6.0 (TID 312) in 539 ms on hadoop17.cusp.nyu.edu (executor 5) (3/8)
2021-05-19 02:47:18 INFO  TaskSetManager:54 - Finished task 0.0 in stage 6.0 (TID 309) in 544 ms on hadoop17.cusp.nyu.edu (executor 5) (4/8)
2021-05-19 02:47:18 INFO  TaskSetManager:54 - Finished task 1.0 in stage 6.0 (TID 310) in 543 ms on hadoop17.cusp.nyu.edu (executor 5) (5/8)
2021-05-19 02:47:18 INFO  TaskSetManager:54 - Finished task 2.0 in stage 6.0 (TID 311) in 542 ms on hadoop17.cusp.nyu.edu (executor 5) (6/8)
2021-05-19 02:47:18 INFO  TaskSetManager:54 - Finished task 5.0 in stage 6.0 (TID 314) in 542 ms on hadoop17.cusp.nyu.edu (executor 5) (7/8)
2021-05-19 02:47:18 INFO  TaskSetManager:54 - Finished task 4.0 in stage 6.0 (TID 313) in 542 ms on hadoop17.cusp.nyu.edu (executor 5) (8/8)
2021-05-19 02:47:18 INFO  YarnClusterScheduler:54 - Removed TaskSet 6.0, whose tasks have all completed, from pool 
2021-05-19 02:47:18 INFO  DAGScheduler:54 - ResultStage 6 (run at ThreadPoolExecutor.java:1149) finished in 0.569 s
2021-05-19 02:47:18 INFO  DAGScheduler:54 - Job 5 finished: run at ThreadPoolExecutor.java:1149, took 0.581228 s
2021-05-19 02:47:18 INFO  CodeGenerator:54 - Code generated in 14.364773 ms
2021-05-19 02:47:18 INFO  MemoryStore:54 - Block broadcast_12 stored as values in memory (estimated size 4.0 MB, free 361.9 MB)
2021-05-19 02:47:18 INFO  MemoryStore:54 - Block broadcast_12_piece0 stored as bytes in memory (estimated size 580.1 KB, free 361.3 MB)
2021-05-19 02:47:18 INFO  BlockManagerInfo:54 - Added broadcast_12_piece0 in memory on hadoop02.cusp.nyu.edu:49352 (size: 580.1 KB, free: 365.7 MB)
2021-05-19 02:47:18 INFO  SparkContext:54 - Created broadcast 12 from run at ThreadPoolExecutor.java:1149
2021-05-19 02:47:18 INFO  CodeGenerator:54 - Code generated in 38.973408 ms
2021-05-19 02:47:18 INFO  MemoryStore:54 - Block broadcast_13 stored as values in memory (estimated size 332.8 KB, free 361.0 MB)
2021-05-19 02:47:18 INFO  MemoryStore:54 - Block broadcast_13_piece0 stored as bytes in memory (estimated size 33.4 KB, free 361.0 MB)
2021-05-19 02:47:18 INFO  BlockManagerInfo:54 - Added broadcast_13_piece0 in memory on hadoop02.cusp.nyu.edu:49352 (size: 33.4 KB, free: 365.7 MB)
2021-05-19 02:47:18 INFO  SparkContext:54 - Created broadcast 13 from csv at NativeMethodAccessorImpl.java:0
2021-05-19 02:47:18 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 134217728 bytes, open cost is considered as scanning 4194304 bytes.
2021-05-19 02:47:18 INFO  ContextCleaner:54 - Cleaned accumulator 222
2021-05-19 02:47:18 INFO  ContextCleaner:54 - Cleaned accumulator 232
2021-05-19 02:47:18 INFO  ContextCleaner:54 - Cleaned accumulator 238
2021-05-19 02:47:18 INFO  ContextCleaner:54 - Cleaned accumulator 234
2021-05-19 02:47:18 INFO  ContextCleaner:54 - Cleaned accumulator 223
2021-05-19 02:47:18 INFO  ContextCleaner:54 - Cleaned accumulator 227
2021-05-19 02:47:18 INFO  ContextCleaner:54 - Cleaned accumulator 221
2021-05-19 02:47:18 INFO  ContextCleaner:54 - Cleaned accumulator 220
2021-05-19 02:47:18 INFO  ContextCleaner:54 - Cleaned accumulator 228
2021-05-19 02:47:18 INFO  ContextCleaner:54 - Cleaned accumulator 230
2021-05-19 02:47:18 INFO  ContextCleaner:54 - Cleaned accumulator 218
2021-05-19 02:47:18 INFO  ContextCleaner:54 - Cleaned accumulator 242
2021-05-19 02:47:18 INFO  ContextCleaner:54 - Cleaned accumulator 225
2021-05-19 02:47:18 INFO  ContextCleaner:54 - Cleaned accumulator 226
2021-05-19 02:47:18 INFO  ContextCleaner:54 - Cleaned accumulator 219
2021-05-19 02:47:18 INFO  ContextCleaner:54 - Cleaned accumulator 224
2021-05-19 02:47:18 INFO  ContextCleaner:54 - Cleaned accumulator 239
2021-05-19 02:47:18 INFO  ContextCleaner:54 - Cleaned accumulator 229
2021-05-19 02:47:18 INFO  ContextCleaner:54 - Cleaned accumulator 197
2021-05-19 02:47:18 INFO  ContextCleaner:54 - Cleaned accumulator 241
2021-05-19 02:47:18 INFO  ContextCleaner:54 - Cleaned accumulator 198
2021-05-19 02:47:18 INFO  ContextCleaner:54 - Cleaned accumulator 233
2021-05-19 02:47:18 INFO  ContextCleaner:54 - Cleaned accumulator 240
2021-05-19 02:47:18 INFO  BlockManagerInfo:54 - Removed broadcast_11_piece0 on hadoop02.cusp.nyu.edu:49352 in memory (size: 14.1 KB, free: 365.7 MB)
2021-05-19 02:47:18 INFO  BlockManagerInfo:54 - Removed broadcast_11_piece0 on hadoop17.cusp.nyu.edu:39842 in memory (size: 14.1 KB, free: 365.6 MB)
2021-05-19 02:47:18 INFO  ContextCleaner:54 - Cleaned accumulator 235
2021-05-19 02:47:18 INFO  ContextCleaner:54 - Cleaned accumulator 236
2021-05-19 02:47:18 INFO  ContextCleaner:54 - Cleaned accumulator 231
2021-05-19 02:47:18 INFO  ContextCleaner:54 - Cleaned accumulator 237
2021-05-19 02:47:18 INFO  CodeGenerator:54 - Code generated in 22.311378 ms
2021-05-19 02:47:18 INFO  SparkContext:54 - Starting job: csv at NativeMethodAccessorImpl.java:0
2021-05-19 02:47:18 INFO  DAGScheduler:54 - Registering RDD 50 (csv at NativeMethodAccessorImpl.java:0)
2021-05-19 02:47:18 INFO  DAGScheduler:54 - Got job 6 (csv at NativeMethodAccessorImpl.java:0) with 200 output partitions
2021-05-19 02:47:18 INFO  DAGScheduler:54 - Final stage: ResultStage 8 (csv at NativeMethodAccessorImpl.java:0)
2021-05-19 02:47:18 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 7)
2021-05-19 02:47:18 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 7)
2021-05-19 02:47:18 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 7 (MapPartitionsRDD[50] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
2021-05-19 02:47:18 INFO  MemoryStore:54 - Block broadcast_14 stored as values in memory (estimated size 51.4 KB, free 361.0 MB)
2021-05-19 02:47:18 INFO  MemoryStore:54 - Block broadcast_14_piece0 stored as bytes in memory (estimated size 22.9 KB, free 360.9 MB)
2021-05-19 02:47:18 INFO  BlockManagerInfo:54 - Added broadcast_14_piece0 in memory on hadoop02.cusp.nyu.edu:49352 (size: 22.9 KB, free: 365.6 MB)
2021-05-19 02:47:18 INFO  SparkContext:54 - Created broadcast 14 from broadcast at DAGScheduler.scala:1161
2021-05-19 02:47:18 INFO  DAGScheduler:54 - Submitting 70 missing tasks from ShuffleMapStage 7 (MapPartitionsRDD[50] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
2021-05-19 02:47:18 INFO  YarnClusterScheduler:54 - Adding task set 7.0 with 70 tasks
2021-05-19 02:47:18 INFO  TaskSetManager:54 - Starting task 0.0 in stage 7.0 (TID 317, hadoop06.cusp.nyu.edu, executor 4, partition 0, NODE_LOCAL, 8331 bytes)
2021-05-19 02:47:18 INFO  TaskSetManager:54 - Starting task 1.0 in stage 7.0 (TID 318, hadoop17.cusp.nyu.edu, executor 5, partition 1, NODE_LOCAL, 8331 bytes)
2021-05-19 02:47:18 INFO  TaskSetManager:54 - Starting task 4.0 in stage 7.0 (TID 319, hadoop13.cusp.nyu.edu, executor 1, partition 4, NODE_LOCAL, 8331 bytes)
2021-05-19 02:47:18 INFO  TaskSetManager:54 - Starting task 6.0 in stage 7.0 (TID 320, hadoop18.cusp.nyu.edu, executor 2, partition 6, NODE_LOCAL, 8331 bytes)
2021-05-19 02:47:18 INFO  TaskSetManager:54 - Starting task 2.0 in stage 7.0 (TID 321, hadoop06.cusp.nyu.edu, executor 4, partition 2, NODE_LOCAL, 8331 bytes)
2021-05-19 02:47:18 INFO  TaskSetManager:54 - Starting task 3.0 in stage 7.0 (TID 322, hadoop17.cusp.nyu.edu, executor 5, partition 3, NODE_LOCAL, 8331 bytes)
2021-05-19 02:47:18 INFO  TaskSetManager:54 - Starting task 5.0 in stage 7.0 (TID 323, hadoop13.cusp.nyu.edu, executor 1, partition 5, NODE_LOCAL, 8331 bytes)
2021-05-19 02:47:18 INFO  TaskSetManager:54 - Starting task 13.0 in stage 7.0 (TID 324, hadoop18.cusp.nyu.edu, executor 2, partition 13, NODE_LOCAL, 8331 bytes)
2021-05-19 02:47:18 INFO  TaskSetManager:54 - Starting task 7.0 in stage 7.0 (TID 325, hadoop06.cusp.nyu.edu, executor 4, partition 7, NODE_LOCAL, 8331 bytes)
2021-05-19 02:47:18 INFO  TaskSetManager:54 - Starting task 9.0 in stage 7.0 (TID 326, hadoop17.cusp.nyu.edu, executor 5, partition 9, NODE_LOCAL, 8331 bytes)
2021-05-19 02:47:18 INFO  TaskSetManager:54 - Starting task 14.0 in stage 7.0 (TID 327, hadoop13.cusp.nyu.edu, executor 1, partition 14, NODE_LOCAL, 8331 bytes)
2021-05-19 02:47:18 INFO  TaskSetManager:54 - Starting task 15.0 in stage 7.0 (TID 328, hadoop18.cusp.nyu.edu, executor 2, partition 15, NODE_LOCAL, 8331 bytes)
2021-05-19 02:47:18 INFO  TaskSetManager:54 - Starting task 17.0 in stage 7.0 (TID 329, hadoop06.cusp.nyu.edu, executor 4, partition 17, NODE_LOCAL, 8331 bytes)
2021-05-19 02:47:18 INFO  TaskSetManager:54 - Starting task 10.0 in stage 7.0 (TID 330, hadoop17.cusp.nyu.edu, executor 5, partition 10, NODE_LOCAL, 8331 bytes)
2021-05-19 02:47:18 INFO  TaskSetManager:54 - Starting task 20.0 in stage 7.0 (TID 331, hadoop13.cusp.nyu.edu, executor 1, partition 20, NODE_LOCAL, 8331 bytes)
2021-05-19 02:47:18 INFO  TaskSetManager:54 - Starting task 16.0 in stage 7.0 (TID 332, hadoop18.cusp.nyu.edu, executor 2, partition 16, NODE_LOCAL, 8331 bytes)
2021-05-19 02:47:18 INFO  TaskSetManager:54 - Starting task 18.0 in stage 7.0 (TID 333, hadoop06.cusp.nyu.edu, executor 4, partition 18, NODE_LOCAL, 8331 bytes)
2021-05-19 02:47:18 INFO  TaskSetManager:54 - Starting task 30.0 in stage 7.0 (TID 334, hadoop17.cusp.nyu.edu, executor 5, partition 30, NODE_LOCAL, 8331 bytes)
2021-05-19 02:47:18 INFO  TaskSetManager:54 - Starting task 23.0 in stage 7.0 (TID 335, hadoop13.cusp.nyu.edu, executor 1, partition 23, NODE_LOCAL, 8331 bytes)
2021-05-19 02:47:18 INFO  TaskSetManager:54 - Starting task 26.0 in stage 7.0 (TID 336, hadoop18.cusp.nyu.edu, executor 2, partition 26, NODE_LOCAL, 8331 bytes)
2021-05-19 02:47:18 INFO  TaskSetManager:54 - Starting task 25.0 in stage 7.0 (TID 337, hadoop06.cusp.nyu.edu, executor 4, partition 25, NODE_LOCAL, 8331 bytes)
2021-05-19 02:47:18 INFO  TaskSetManager:54 - Starting task 32.0 in stage 7.0 (TID 338, hadoop17.cusp.nyu.edu, executor 5, partition 32, NODE_LOCAL, 8331 bytes)
2021-05-19 02:47:18 INFO  TaskSetManager:54 - Starting task 34.0 in stage 7.0 (TID 339, hadoop13.cusp.nyu.edu, executor 1, partition 34, NODE_LOCAL, 8331 bytes)
2021-05-19 02:47:18 INFO  TaskSetManager:54 - Starting task 27.0 in stage 7.0 (TID 340, hadoop18.cusp.nyu.edu, executor 2, partition 27, NODE_LOCAL, 8331 bytes)
2021-05-19 02:47:18 INFO  TaskSetManager:54 - Starting task 33.0 in stage 7.0 (TID 341, hadoop06.cusp.nyu.edu, executor 4, partition 33, NODE_LOCAL, 8331 bytes)
2021-05-19 02:47:18 INFO  TaskSetManager:54 - Starting task 40.0 in stage 7.0 (TID 342, hadoop17.cusp.nyu.edu, executor 5, partition 40, NODE_LOCAL, 8331 bytes)
2021-05-19 02:47:18 INFO  TaskSetManager:54 - Starting task 41.0 in stage 7.0 (TID 343, hadoop13.cusp.nyu.edu, executor 1, partition 41, NODE_LOCAL, 8331 bytes)
2021-05-19 02:47:18 INFO  TaskSetManager:54 - Starting task 31.0 in stage 7.0 (TID 344, hadoop18.cusp.nyu.edu, executor 2, partition 31, NODE_LOCAL, 8331 bytes)
2021-05-19 02:47:18 INFO  TaskSetManager:54 - Starting task 36.0 in stage 7.0 (TID 345, hadoop06.cusp.nyu.edu, executor 4, partition 36, NODE_LOCAL, 8331 bytes)
2021-05-19 02:47:18 INFO  TaskSetManager:54 - Starting task 43.0 in stage 7.0 (TID 346, hadoop17.cusp.nyu.edu, executor 5, partition 43, NODE_LOCAL, 8331 bytes)
2021-05-19 02:47:18 INFO  TaskSetManager:54 - Starting task 52.0 in stage 7.0 (TID 347, hadoop13.cusp.nyu.edu, executor 1, partition 52, NODE_LOCAL, 8436 bytes)
2021-05-19 02:47:18 INFO  TaskSetManager:54 - Starting task 35.0 in stage 7.0 (TID 348, hadoop18.cusp.nyu.edu, executor 2, partition 35, NODE_LOCAL, 8331 bytes)
2021-05-19 02:47:18 INFO  TaskSetManager:54 - Starting task 39.0 in stage 7.0 (TID 349, hadoop06.cusp.nyu.edu, executor 4, partition 39, NODE_LOCAL, 8331 bytes)
2021-05-19 02:47:18 INFO  TaskSetManager:54 - Starting task 44.0 in stage 7.0 (TID 350, hadoop17.cusp.nyu.edu, executor 5, partition 44, NODE_LOCAL, 8331 bytes)
2021-05-19 02:47:18 INFO  TaskSetManager:54 - Starting task 38.0 in stage 7.0 (TID 351, hadoop18.cusp.nyu.edu, executor 2, partition 38, NODE_LOCAL, 8331 bytes)
2021-05-19 02:47:18 INFO  TaskSetManager:54 - Starting task 47.0 in stage 7.0 (TID 352, hadoop06.cusp.nyu.edu, executor 4, partition 47, NODE_LOCAL, 8331 bytes)
2021-05-19 02:47:18 INFO  TaskSetManager:54 - Starting task 45.0 in stage 7.0 (TID 353, hadoop17.cusp.nyu.edu, executor 5, partition 45, NODE_LOCAL, 8331 bytes)
2021-05-19 02:47:18 INFO  TaskSetManager:54 - Starting task 51.0 in stage 7.0 (TID 354, hadoop18.cusp.nyu.edu, executor 2, partition 51, NODE_LOCAL, 8436 bytes)
2021-05-19 02:47:19 INFO  BlockManagerInfo:54 - Added broadcast_14_piece0 in memory on hadoop17.cusp.nyu.edu:39842 (size: 22.9 KB, free: 365.6 MB)
2021-05-19 02:47:19 INFO  BlockManagerInfo:54 - Added broadcast_14_piece0 in memory on hadoop06.cusp.nyu.edu:53410 (size: 22.9 KB, free: 366.3 MB)
2021-05-19 02:47:19 INFO  BlockManagerInfo:54 - Added broadcast_14_piece0 in memory on hadoop13.cusp.nyu.edu:32809 (size: 22.9 KB, free: 366.3 MB)
2021-05-19 02:47:19 INFO  BlockManagerInfo:54 - Added broadcast_14_piece0 in memory on hadoop18.cusp.nyu.edu:37819 (size: 22.9 KB, free: 366.3 MB)
2021-05-19 02:47:19 INFO  BlockManagerInfo:54 - Added broadcast_12_piece0 in memory on hadoop17.cusp.nyu.edu:39842 (size: 580.1 KB, free: 365.0 MB)
2021-05-19 02:47:19 INFO  BlockManagerInfo:54 - Added broadcast_12_piece0 in memory on hadoop06.cusp.nyu.edu:53410 (size: 580.1 KB, free: 365.7 MB)
2021-05-19 02:47:19 INFO  BlockManagerInfo:54 - Added broadcast_12_piece0 in memory on hadoop13.cusp.nyu.edu:32809 (size: 580.1 KB, free: 365.7 MB)
2021-05-19 02:47:19 INFO  BlockManagerInfo:54 - Added broadcast_12_piece0 in memory on hadoop18.cusp.nyu.edu:37819 (size: 580.1 KB, free: 365.7 MB)
2021-05-19 02:47:19 INFO  BlockManagerInfo:54 - Added broadcast_13_piece0 in memory on hadoop17.cusp.nyu.edu:39842 (size: 33.4 KB, free: 365.0 MB)
2021-05-19 02:47:20 INFO  BlockManagerInfo:54 - Added broadcast_13_piece0 in memory on hadoop06.cusp.nyu.edu:53410 (size: 33.4 KB, free: 365.7 MB)
2021-05-19 02:47:20 INFO  BlockManagerInfo:54 - Added broadcast_13_piece0 in memory on hadoop13.cusp.nyu.edu:32809 (size: 33.4 KB, free: 365.7 MB)
2021-05-19 02:47:20 INFO  BlockManagerInfo:54 - Added broadcast_13_piece0 in memory on hadoop18.cusp.nyu.edu:37819 (size: 33.4 KB, free: 365.7 MB)
2021-05-19 02:47:22 INFO  TaskSetManager:54 - Starting task 8.0 in stage 7.0 (TID 355, hadoop04.cusp.nyu.edu, executor 3, partition 8, RACK_LOCAL, 8331 bytes)
2021-05-19 02:47:22 INFO  TaskSetManager:54 - Starting task 11.0 in stage 7.0 (TID 356, hadoop13.cusp.nyu.edu, executor 1, partition 11, RACK_LOCAL, 8331 bytes)
2021-05-19 02:47:22 INFO  TaskSetManager:54 - Starting task 12.0 in stage 7.0 (TID 357, hadoop04.cusp.nyu.edu, executor 3, partition 12, RACK_LOCAL, 8331 bytes)
2021-05-19 02:47:22 INFO  TaskSetManager:54 - Starting task 19.0 in stage 7.0 (TID 358, hadoop13.cusp.nyu.edu, executor 1, partition 19, RACK_LOCAL, 8331 bytes)
2021-05-19 02:47:22 INFO  TaskSetManager:54 - Starting task 21.0 in stage 7.0 (TID 359, hadoop04.cusp.nyu.edu, executor 3, partition 21, RACK_LOCAL, 8331 bytes)
2021-05-19 02:47:22 INFO  TaskSetManager:54 - Starting task 22.0 in stage 7.0 (TID 360, hadoop04.cusp.nyu.edu, executor 3, partition 22, RACK_LOCAL, 8331 bytes)
2021-05-19 02:47:22 INFO  TaskSetManager:54 - Starting task 24.0 in stage 7.0 (TID 361, hadoop04.cusp.nyu.edu, executor 3, partition 24, RACK_LOCAL, 8331 bytes)
2021-05-19 02:47:22 INFO  TaskSetManager:54 - Starting task 28.0 in stage 7.0 (TID 362, hadoop04.cusp.nyu.edu, executor 3, partition 28, RACK_LOCAL, 8331 bytes)
2021-05-19 02:47:22 INFO  TaskSetManager:54 - Starting task 29.0 in stage 7.0 (TID 363, hadoop04.cusp.nyu.edu, executor 3, partition 29, RACK_LOCAL, 8331 bytes)
2021-05-19 02:47:22 INFO  TaskSetManager:54 - Starting task 37.0 in stage 7.0 (TID 364, hadoop04.cusp.nyu.edu, executor 3, partition 37, RACK_LOCAL, 8331 bytes)
2021-05-19 02:47:22 INFO  TaskSetManager:54 - Starting task 42.0 in stage 7.0 (TID 365, hadoop04.cusp.nyu.edu, executor 3, partition 42, RACK_LOCAL, 8331 bytes)
2021-05-19 02:47:22 INFO  TaskSetManager:54 - Starting task 46.0 in stage 7.0 (TID 366, hadoop04.cusp.nyu.edu, executor 3, partition 46, RACK_LOCAL, 8331 bytes)
2021-05-19 02:47:22 INFO  BlockManagerInfo:54 - Added broadcast_14_piece0 in memory on hadoop04.cusp.nyu.edu:41664 (size: 22.9 KB, free: 366.3 MB)
2021-05-19 02:47:22 INFO  BlockManagerInfo:54 - Added broadcast_12_piece0 in memory on hadoop04.cusp.nyu.edu:41664 (size: 580.1 KB, free: 365.7 MB)
2021-05-19 02:47:23 INFO  BlockManagerInfo:54 - Added broadcast_13_piece0 in memory on hadoop04.cusp.nyu.edu:41664 (size: 33.4 KB, free: 365.7 MB)
2021-05-19 02:47:28 INFO  YarnSchedulerBackend$YarnDriverEndpoint:54 - Disabling executor 5.
2021-05-19 02:47:28 INFO  DAGScheduler:54 - Executor lost: 5 (epoch 1)
2021-05-19 02:47:28 INFO  BlockManagerMasterEndpoint:54 - Trying to remove executor 5 from BlockManagerMaster.
2021-05-19 02:47:28 WARN  BlockManagerMasterEndpoint:66 - No more replicas available for rdd_29_3 !
2021-05-19 02:47:28 WARN  BlockManagerMasterEndpoint:66 - No more replicas available for rdd_29_5 !
2021-05-19 02:47:28 WARN  BlockManagerMasterEndpoint:66 - No more replicas available for rdd_29_2 !
2021-05-19 02:47:28 WARN  BlockManagerMasterEndpoint:66 - No more replicas available for rdd_29_4 !
2021-05-19 02:47:28 WARN  BlockManagerMasterEndpoint:66 - No more replicas available for rdd_29_1 !
2021-05-19 02:47:28 WARN  BlockManagerMasterEndpoint:66 - No more replicas available for rdd_29_6 !
2021-05-19 02:47:28 WARN  BlockManagerMasterEndpoint:66 - No more replicas available for rdd_29_7 !
2021-05-19 02:47:28 WARN  BlockManagerMasterEndpoint:66 - No more replicas available for rdd_29_0 !
2021-05-19 02:47:28 INFO  BlockManagerMasterEndpoint:54 - Removing block manager BlockManagerId(5, hadoop17.cusp.nyu.edu, 39842, None)
2021-05-19 02:47:28 INFO  BlockManagerMaster:54 - Removed 5 successfully in removeExecutor
2021-05-19 02:47:28 INFO  YarnAllocator:54 - Completed container container_e10_1609183734776_5900_02_000006 on host: hadoop17.cusp.nyu.edu (state: COMPLETE, exit status: -104)
2021-05-19 02:47:28 WARN  YarnAllocator:66 - Container killed by YARN for exceeding memory limits.  1.5 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:47:28 WARN  YarnSchedulerBackend$YarnSchedulerEndpoint:66 - Requesting driver to remove executor 5 for reason Container killed by YARN for exceeding memory limits.  1.5 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:47:29 ERROR YarnClusterScheduler:70 - Lost executor 5 on hadoop17.cusp.nyu.edu: Container killed by YARN for exceeding memory limits.  1.5 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:47:29 WARN  TaskSetManager:66 - Lost task 43.0 in stage 7.0 (TID 346, hadoop17.cusp.nyu.edu, executor 5): ExecutorLostFailure (executor 5 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  1.5 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:47:29 WARN  TaskSetManager:66 - Lost task 3.0 in stage 7.0 (TID 322, hadoop17.cusp.nyu.edu, executor 5): ExecutorLostFailure (executor 5 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  1.5 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:47:29 WARN  TaskSetManager:66 - Lost task 30.0 in stage 7.0 (TID 334, hadoop17.cusp.nyu.edu, executor 5): ExecutorLostFailure (executor 5 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  1.5 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:47:29 WARN  TaskSetManager:66 - Lost task 1.0 in stage 7.0 (TID 318, hadoop17.cusp.nyu.edu, executor 5): ExecutorLostFailure (executor 5 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  1.5 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:47:29 WARN  TaskSetManager:66 - Lost task 10.0 in stage 7.0 (TID 330, hadoop17.cusp.nyu.edu, executor 5): ExecutorLostFailure (executor 5 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  1.5 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:47:29 WARN  TaskSetManager:66 - Lost task 40.0 in stage 7.0 (TID 342, hadoop17.cusp.nyu.edu, executor 5): ExecutorLostFailure (executor 5 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  1.5 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:47:29 WARN  TaskSetManager:66 - Lost task 44.0 in stage 7.0 (TID 350, hadoop17.cusp.nyu.edu, executor 5): ExecutorLostFailure (executor 5 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  1.5 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:47:29 WARN  TaskSetManager:66 - Lost task 45.0 in stage 7.0 (TID 353, hadoop17.cusp.nyu.edu, executor 5): ExecutorLostFailure (executor 5 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  1.5 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:47:29 WARN  TaskSetManager:66 - Lost task 9.0 in stage 7.0 (TID 326, hadoop17.cusp.nyu.edu, executor 5): ExecutorLostFailure (executor 5 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  1.5 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:47:29 WARN  TaskSetManager:66 - Lost task 32.0 in stage 7.0 (TID 338, hadoop17.cusp.nyu.edu, executor 5): ExecutorLostFailure (executor 5 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  1.5 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:47:29 INFO  BlockManagerMasterEndpoint:54 - Trying to remove executor 5 from BlockManagerMaster.
2021-05-19 02:47:29 INFO  BlockManagerMaster:54 - Removal of executor 5 requested
2021-05-19 02:47:29 INFO  YarnSchedulerBackend$YarnDriverEndpoint:54 - Asked to remove non-existent executor 5
2021-05-19 02:47:31 INFO  TaskSetManager:54 - Starting task 9.1 in stage 7.0 (TID 367, hadoop13.cusp.nyu.edu, executor 1, partition 9, NODE_LOCAL, 8331 bytes)
2021-05-19 02:47:31 INFO  TaskSetManager:54 - Finished task 52.0 in stage 7.0 (TID 347) in 12186 ms on hadoop13.cusp.nyu.edu (executor 1) (1/70)
2021-05-19 02:47:31 INFO  TaskSetManager:54 - Starting task 32.1 in stage 7.0 (TID 368, hadoop18.cusp.nyu.edu, executor 2, partition 32, NODE_LOCAL, 8331 bytes)
2021-05-19 02:47:31 INFO  TaskSetManager:54 - Finished task 51.0 in stage 7.0 (TID 354) in 12241 ms on hadoop18.cusp.nyu.edu (executor 2) (2/70)
2021-05-19 02:47:31 INFO  YarnAllocator:54 - Will request 1 executor container(s), each with 10 core(s) and 1408 MB memory (including 384 MB of overhead)
2021-05-19 02:47:31 INFO  YarnAllocator:54 - Submitted 1 unlocalized container requests.
2021-05-19 02:47:32 INFO  YarnAllocator:54 - Launching container container_e10_1609183734776_5900_02_000007 on host hadoop06.cusp.nyu.edu for executor with ID 6
2021-05-19 02:47:32 INFO  YarnAllocator:54 - Received 1 containers from YARN, launching executors on 1 of them.
2021-05-19 02:47:32 INFO  YarnAllocator:54 - Completed container container_e10_1609183734776_5900_02_000003 on host: hadoop18.cusp.nyu.edu (state: COMPLETE, exit status: -104)
2021-05-19 02:47:32 WARN  YarnAllocator:66 - Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:47:32 WARN  YarnSchedulerBackend$YarnSchedulerEndpoint:66 - Requesting driver to remove executor 2 for reason Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:47:32 INFO  ContainerManagementProtocolProxy:81 - yarn.client.max-cached-nodemanagers-proxies : 0
2021-05-19 02:47:32 ERROR YarnClusterScheduler:70 - Lost executor 2 on hadoop18.cusp.nyu.edu: Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:47:32 INFO  YarnAllocator:54 - Completed container container_e10_1609183734776_5900_02_000005 on host: hadoop06.cusp.nyu.edu (state: COMPLETE, exit status: -104)
2021-05-19 02:47:32 WARN  YarnAllocator:66 - Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:47:32 WARN  TaskSetManager:66 - Lost task 27.0 in stage 7.0 (TID 340, hadoop18.cusp.nyu.edu, executor 2): ExecutorLostFailure (executor 2 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:47:32 WARN  YarnSchedulerBackend$YarnSchedulerEndpoint:66 - Requesting driver to remove executor 4 for reason Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:47:32 WARN  TaskSetManager:66 - Lost task 15.0 in stage 7.0 (TID 328, hadoop18.cusp.nyu.edu, executor 2): ExecutorLostFailure (executor 2 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:47:32 WARN  TaskSetManager:66 - Lost task 26.0 in stage 7.0 (TID 336, hadoop18.cusp.nyu.edu, executor 2): ExecutorLostFailure (executor 2 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:47:32 WARN  TaskSetManager:66 - Lost task 35.0 in stage 7.0 (TID 348, hadoop18.cusp.nyu.edu, executor 2): ExecutorLostFailure (executor 2 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:47:32 WARN  TaskSetManager:66 - Lost task 13.0 in stage 7.0 (TID 324, hadoop18.cusp.nyu.edu, executor 2): ExecutorLostFailure (executor 2 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:47:32 WARN  TaskSetManager:66 - Lost task 38.0 in stage 7.0 (TID 351, hadoop18.cusp.nyu.edu, executor 2): ExecutorLostFailure (executor 2 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:47:32 WARN  TaskSetManager:66 - Lost task 16.0 in stage 7.0 (TID 332, hadoop18.cusp.nyu.edu, executor 2): ExecutorLostFailure (executor 2 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:47:32 WARN  TaskSetManager:66 - Lost task 32.1 in stage 7.0 (TID 368, hadoop18.cusp.nyu.edu, executor 2): ExecutorLostFailure (executor 2 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:47:32 WARN  TaskSetManager:66 - Lost task 31.0 in stage 7.0 (TID 344, hadoop18.cusp.nyu.edu, executor 2): ExecutorLostFailure (executor 2 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:47:32 WARN  TaskSetManager:66 - Lost task 6.0 in stage 7.0 (TID 320, hadoop18.cusp.nyu.edu, executor 2): ExecutorLostFailure (executor 2 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:47:32 INFO  ContainerManagementProtocolProxy:260 - Opening proxy : hadoop06.cusp.nyu.edu:8041
2021-05-19 02:47:32 INFO  DAGScheduler:54 - Executor lost: 2 (epoch 1)
2021-05-19 02:47:32 ERROR YarnClusterScheduler:70 - Lost executor 4 on hadoop06.cusp.nyu.edu: Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:47:32 WARN  TaskSetManager:66 - Lost task 39.0 in stage 7.0 (TID 349, hadoop06.cusp.nyu.edu, executor 4): ExecutorLostFailure (executor 4 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:47:32 INFO  BlockManagerMasterEndpoint:54 - Trying to remove executor 2 from BlockManagerMaster.
2021-05-19 02:47:32 INFO  BlockManagerMasterEndpoint:54 - Removing block manager BlockManagerId(2, hadoop18.cusp.nyu.edu, 37819, None)
2021-05-19 02:47:32 WARN  TaskSetManager:66 - Lost task 47.0 in stage 7.0 (TID 352, hadoop06.cusp.nyu.edu, executor 4): ExecutorLostFailure (executor 4 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:47:32 INFO  BlockManagerMaster:54 - Removed 2 successfully in removeExecutor
2021-05-19 02:47:32 WARN  TaskSetManager:66 - Lost task 7.0 in stage 7.0 (TID 325, hadoop06.cusp.nyu.edu, executor 4): ExecutorLostFailure (executor 4 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:47:32 WARN  TaskSetManager:66 - Lost task 25.0 in stage 7.0 (TID 337, hadoop06.cusp.nyu.edu, executor 4): ExecutorLostFailure (executor 4 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:47:32 WARN  TaskSetManager:66 - Lost task 36.0 in stage 7.0 (TID 345, hadoop06.cusp.nyu.edu, executor 4): ExecutorLostFailure (executor 4 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:47:32 WARN  TaskSetManager:66 - Lost task 2.0 in stage 7.0 (TID 321, hadoop06.cusp.nyu.edu, executor 4): ExecutorLostFailure (executor 4 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:47:32 WARN  TaskSetManager:66 - Lost task 18.0 in stage 7.0 (TID 333, hadoop06.cusp.nyu.edu, executor 4): ExecutorLostFailure (executor 4 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:47:32 WARN  TaskSetManager:66 - Lost task 33.0 in stage 7.0 (TID 341, hadoop06.cusp.nyu.edu, executor 4): ExecutorLostFailure (executor 4 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:47:32 WARN  TaskSetManager:66 - Lost task 0.0 in stage 7.0 (TID 317, hadoop06.cusp.nyu.edu, executor 4): ExecutorLostFailure (executor 4 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:47:32 WARN  TaskSetManager:66 - Lost task 17.0 in stage 7.0 (TID 329, hadoop06.cusp.nyu.edu, executor 4): ExecutorLostFailure (executor 4 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:47:32 INFO  DAGScheduler:54 - Executor lost: 4 (epoch 1)
2021-05-19 02:47:32 INFO  BlockManagerMasterEndpoint:54 - Trying to remove executor 4 from BlockManagerMaster.
2021-05-19 02:47:32 INFO  BlockManagerMasterEndpoint:54 - Removing block manager BlockManagerId(4, hadoop06.cusp.nyu.edu, 53410, None)
2021-05-19 02:47:32 INFO  BlockManagerMaster:54 - Removed 4 successfully in removeExecutor
2021-05-19 02:47:32 WARN  TransportChannelHandler:78 - Exception in connection from /192.168.72.176:38350
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileDispatcherImpl.read0(Native Method)
	at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)
	at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:223)
	at sun.nio.ch.IOUtil.read(IOUtil.java:192)
	at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:380)
	at io.netty.buffer.PooledUnsafeDirectByteBuf.setBytes(PooledUnsafeDirectByteBuf.java:288)
	at io.netty.buffer.AbstractByteBuf.writeBytes(AbstractByteBuf.java:1106)
	at io.netty.channel.socket.nio.NioSocketChannel.doReadBytes(NioSocketChannel.java:343)
	at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:123)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:645)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:580)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:497)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:459)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
2021-05-19 02:47:32 INFO  TaskSetManager:54 - Starting task 26.1 in stage 7.0 (TID 369, hadoop13.cusp.nyu.edu, executor 1, partition 26, NODE_LOCAL, 8331 bytes)
2021-05-19 02:47:32 INFO  TaskSetManager:54 - Finished task 20.0 in stage 7.0 (TID 331) in 13412 ms on hadoop13.cusp.nyu.edu (executor 1) (3/70)
2021-05-19 02:47:32 INFO  TaskSetManager:54 - Starting task 43.1 in stage 7.0 (TID 370, hadoop13.cusp.nyu.edu, executor 1, partition 43, NODE_LOCAL, 8331 bytes)
2021-05-19 02:47:32 INFO  TaskSetManager:54 - Finished task 34.0 in stage 7.0 (TID 339) in 13453 ms on hadoop13.cusp.nyu.edu (executor 1) (4/70)
2021-05-19 02:47:32 INFO  TaskSetManager:54 - Finished task 23.0 in stage 7.0 (TID 335) in 13680 ms on hadoop13.cusp.nyu.edu (executor 1) (5/70)
2021-05-19 02:47:33 INFO  TaskSetManager:54 - Finished task 41.0 in stage 7.0 (TID 343) in 14097 ms on hadoop13.cusp.nyu.edu (executor 1) (6/70)
2021-05-19 02:47:33 INFO  TaskSetManager:54 - Finished task 4.0 in stage 7.0 (TID 319) in 14164 ms on hadoop13.cusp.nyu.edu (executor 1) (7/70)
2021-05-19 02:47:33 INFO  TaskSetManager:54 - Finished task 14.0 in stage 7.0 (TID 327) in 14365 ms on hadoop13.cusp.nyu.edu (executor 1) (8/70)
2021-05-19 02:47:33 INFO  TaskSetManager:54 - Finished task 5.0 in stage 7.0 (TID 323) in 14375 ms on hadoop13.cusp.nyu.edu (executor 1) (9/70)
2021-05-19 02:47:33 INFO  TaskSetManager:54 - Finished task 11.0 in stage 7.0 (TID 356) in 11493 ms on hadoop13.cusp.nyu.edu (executor 1) (10/70)
2021-05-19 02:47:34 INFO  YarnSchedulerBackend$YarnDriverEndpoint:54 - Disabling executor 1.
2021-05-19 02:47:34 INFO  DAGScheduler:54 - Executor lost: 1 (epoch 1)
2021-05-19 02:47:34 INFO  BlockManagerMasterEndpoint:54 - Trying to remove executor 1 from BlockManagerMaster.
2021-05-19 02:47:34 INFO  BlockManagerMasterEndpoint:54 - Removing block manager BlockManagerId(1, hadoop13.cusp.nyu.edu, 32809, None)
2021-05-19 02:47:34 INFO  YarnAllocator:54 - Will request 2 executor container(s), each with 10 core(s) and 1408 MB memory (including 384 MB of overhead)
2021-05-19 02:47:34 INFO  BlockManagerMaster:54 - Removed 1 successfully in removeExecutor
2021-05-19 02:47:34 INFO  YarnAllocator:54 - Submitted 2 unlocalized container requests.
2021-05-19 02:47:34 INFO  YarnAllocator:54 - Completed container container_e10_1609183734776_5900_02_000002 on host: hadoop13.cusp.nyu.edu (state: COMPLETE, exit status: -104)
2021-05-19 02:47:34 WARN  YarnAllocator:66 - Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:47:34 WARN  YarnSchedulerBackend$YarnSchedulerEndpoint:66 - Requesting driver to remove executor 1 for reason Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:47:34 ERROR YarnClusterScheduler:70 - Lost executor 1 on hadoop13.cusp.nyu.edu: Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:47:34 WARN  TaskSetManager:66 - Lost task 9.1 in stage 7.0 (TID 367, hadoop13.cusp.nyu.edu, executor 1): ExecutorLostFailure (executor 1 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:47:34 WARN  TaskSetManager:66 - Lost task 19.0 in stage 7.0 (TID 358, hadoop13.cusp.nyu.edu, executor 1): ExecutorLostFailure (executor 1 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:47:34 WARN  TaskSetManager:66 - Lost task 43.1 in stage 7.0 (TID 370, hadoop13.cusp.nyu.edu, executor 1): ExecutorLostFailure (executor 1 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:47:34 WARN  TaskSetManager:66 - Lost task 26.1 in stage 7.0 (TID 369, hadoop13.cusp.nyu.edu, executor 1): ExecutorLostFailure (executor 1 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:47:34 INFO  BlockManagerMasterEndpoint:54 - Trying to remove executor 1 from BlockManagerMaster.
2021-05-19 02:47:34 INFO  BlockManagerMaster:54 - Removal of executor 1 requested
2021-05-19 02:47:34 INFO  YarnSchedulerBackend$YarnDriverEndpoint:54 - Asked to remove non-existent executor 1
2021-05-19 02:47:34 INFO  YarnAllocator:54 - Will request 1 executor container(s), each with 10 core(s) and 1408 MB memory (including 384 MB of overhead)
2021-05-19 02:47:34 INFO  YarnAllocator:54 - Submitted 1 unlocalized container requests.
2021-05-19 02:47:34 INFO  YarnAllocator:54 - Launching container container_e10_1609183734776_5900_02_000008 on host hadoop13.cusp.nyu.edu for executor with ID 7
2021-05-19 02:47:34 INFO  YarnAllocator:54 - Launching container container_e10_1609183734776_5900_02_000009 on host hadoop18.cusp.nyu.edu for executor with ID 8
2021-05-19 02:47:34 INFO  YarnAllocator:54 - Launching container container_e10_1609183734776_5900_02_000010 on host hadoop17.cusp.nyu.edu for executor with ID 9
2021-05-19 02:47:34 INFO  YarnAllocator:54 - Received 3 containers from YARN, launching executors on 3 of them.
2021-05-19 02:47:34 INFO  ContainerManagementProtocolProxy:81 - yarn.client.max-cached-nodemanagers-proxies : 0
2021-05-19 02:47:34 INFO  ContainerManagementProtocolProxy:81 - yarn.client.max-cached-nodemanagers-proxies : 0
2021-05-19 02:47:34 INFO  ContainerManagementProtocolProxy:81 - yarn.client.max-cached-nodemanagers-proxies : 0
2021-05-19 02:47:34 INFO  ContainerManagementProtocolProxy:260 - Opening proxy : hadoop13.cusp.nyu.edu:8041
2021-05-19 02:47:34 INFO  ContainerManagementProtocolProxy:260 - Opening proxy : hadoop17.cusp.nyu.edu:8041
2021-05-19 02:47:34 INFO  ContainerManagementProtocolProxy:260 - Opening proxy : hadoop18.cusp.nyu.edu:8041
2021-05-19 02:47:35 INFO  YarnSchedulerBackend$YarnDriverEndpoint:54 - Registered executor NettyRpcEndpointRef(spark-client://Executor) (192.168.72.176:38426) with ID 6
2021-05-19 02:47:35 INFO  TaskSetManager:54 - Starting task 17.1 in stage 7.0 (TID 371, hadoop06.cusp.nyu.edu, executor 6, partition 17, NODE_LOCAL, 8331 bytes)
2021-05-19 02:47:35 INFO  TaskSetManager:54 - Starting task 0.1 in stage 7.0 (TID 372, hadoop06.cusp.nyu.edu, executor 6, partition 0, NODE_LOCAL, 8331 bytes)
2021-05-19 02:47:35 INFO  TaskSetManager:54 - Starting task 33.1 in stage 7.0 (TID 373, hadoop06.cusp.nyu.edu, executor 6, partition 33, NODE_LOCAL, 8331 bytes)
2021-05-19 02:47:35 INFO  TaskSetManager:54 - Starting task 18.1 in stage 7.0 (TID 374, hadoop06.cusp.nyu.edu, executor 6, partition 18, NODE_LOCAL, 8331 bytes)
2021-05-19 02:47:35 INFO  TaskSetManager:54 - Starting task 2.1 in stage 7.0 (TID 375, hadoop06.cusp.nyu.edu, executor 6, partition 2, NODE_LOCAL, 8331 bytes)
2021-05-19 02:47:35 INFO  TaskSetManager:54 - Starting task 36.1 in stage 7.0 (TID 376, hadoop06.cusp.nyu.edu, executor 6, partition 36, NODE_LOCAL, 8331 bytes)
2021-05-19 02:47:35 INFO  TaskSetManager:54 - Starting task 25.1 in stage 7.0 (TID 377, hadoop06.cusp.nyu.edu, executor 6, partition 25, NODE_LOCAL, 8331 bytes)
2021-05-19 02:47:35 INFO  TaskSetManager:54 - Starting task 7.1 in stage 7.0 (TID 378, hadoop06.cusp.nyu.edu, executor 6, partition 7, NODE_LOCAL, 8331 bytes)
2021-05-19 02:47:35 INFO  TaskSetManager:54 - Starting task 47.1 in stage 7.0 (TID 379, hadoop06.cusp.nyu.edu, executor 6, partition 47, NODE_LOCAL, 8331 bytes)
2021-05-19 02:47:35 INFO  TaskSetManager:54 - Starting task 39.1 in stage 7.0 (TID 380, hadoop06.cusp.nyu.edu, executor 6, partition 39, NODE_LOCAL, 8331 bytes)
2021-05-19 02:47:35 INFO  BlockManagerMasterEndpoint:54 - Registering block manager hadoop06.cusp.nyu.edu:34178 with 366.3 MB RAM, BlockManagerId(6, hadoop06.cusp.nyu.edu, 34178, None)
2021-05-19 02:47:36 INFO  BlockManagerInfo:54 - Added broadcast_14_piece0 in memory on hadoop06.cusp.nyu.edu:34178 (size: 22.9 KB, free: 366.3 MB)
2021-05-19 02:47:36 INFO  TaskSetManager:54 - Finished task 21.0 in stage 7.0 (TID 359) in 14470 ms on hadoop04.cusp.nyu.edu (executor 3) (11/70)
2021-05-19 02:47:36 INFO  TaskSetManager:54 - Finished task 46.0 in stage 7.0 (TID 366) in 14624 ms on hadoop04.cusp.nyu.edu (executor 3) (12/70)
2021-05-19 02:47:37 INFO  YarnSchedulerBackend$YarnDriverEndpoint:54 - Disabling executor 3.
2021-05-19 02:47:37 INFO  DAGScheduler:54 - Executor lost: 3 (epoch 1)
2021-05-19 02:47:37 INFO  BlockManagerMasterEndpoint:54 - Trying to remove executor 3 from BlockManagerMaster.
2021-05-19 02:47:37 INFO  BlockManagerMasterEndpoint:54 - Removing block manager BlockManagerId(3, hadoop04.cusp.nyu.edu, 41664, None)
2021-05-19 02:47:37 INFO  BlockManagerMaster:54 - Removed 3 successfully in removeExecutor
2021-05-19 02:47:37 INFO  YarnAllocator:54 - Completed container container_e10_1609183734776_5900_02_000004 on host: hadoop04.cusp.nyu.edu (state: COMPLETE, exit status: -104)
2021-05-19 02:47:37 WARN  YarnAllocator:66 - Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:47:37 WARN  YarnSchedulerBackend$YarnSchedulerEndpoint:66 - Requesting driver to remove executor 3 for reason Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:47:37 ERROR YarnClusterScheduler:70 - Lost executor 3 on hadoop04.cusp.nyu.edu: Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:47:37 WARN  TaskSetManager:66 - Lost task 37.0 in stage 7.0 (TID 364, hadoop04.cusp.nyu.edu, executor 3): ExecutorLostFailure (executor 3 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:47:37 WARN  TaskSetManager:66 - Lost task 8.0 in stage 7.0 (TID 355, hadoop04.cusp.nyu.edu, executor 3): ExecutorLostFailure (executor 3 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:47:37 WARN  TaskSetManager:66 - Lost task 24.0 in stage 7.0 (TID 361, hadoop04.cusp.nyu.edu, executor 3): ExecutorLostFailure (executor 3 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:47:37 WARN  TaskSetManager:66 - Lost task 22.0 in stage 7.0 (TID 360, hadoop04.cusp.nyu.edu, executor 3): ExecutorLostFailure (executor 3 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:47:37 WARN  TaskSetManager:66 - Lost task 29.0 in stage 7.0 (TID 363, hadoop04.cusp.nyu.edu, executor 3): ExecutorLostFailure (executor 3 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:47:37 WARN  TaskSetManager:66 - Lost task 12.0 in stage 7.0 (TID 357, hadoop04.cusp.nyu.edu, executor 3): ExecutorLostFailure (executor 3 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:47:37 WARN  TaskSetManager:66 - Lost task 28.0 in stage 7.0 (TID 362, hadoop04.cusp.nyu.edu, executor 3): ExecutorLostFailure (executor 3 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:47:37 WARN  TaskSetManager:66 - Lost task 42.0 in stage 7.0 (TID 365, hadoop04.cusp.nyu.edu, executor 3): ExecutorLostFailure (executor 3 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:47:37 INFO  BlockManagerMaster:54 - Removal of executor 3 requested
2021-05-19 02:47:37 INFO  BlockManagerMasterEndpoint:54 - Trying to remove executor 3 from BlockManagerMaster.
2021-05-19 02:47:37 INFO  YarnSchedulerBackend$YarnDriverEndpoint:54 - Asked to remove non-existent executor 3
2021-05-19 02:47:37 INFO  BlockManagerInfo:54 - Added broadcast_12_piece0 in memory on hadoop06.cusp.nyu.edu:34178 (size: 580.1 KB, free: 365.7 MB)
2021-05-19 02:47:38 INFO  YarnSchedulerBackend$YarnDriverEndpoint:54 - Registered executor NettyRpcEndpointRef(spark-client://Executor) (192.168.72.183:57759) with ID 7
2021-05-19 02:47:38 INFO  TaskSetManager:54 - Starting task 26.2 in stage 7.0 (TID 381, hadoop13.cusp.nyu.edu, executor 7, partition 26, NODE_LOCAL, 8331 bytes)
2021-05-19 02:47:38 INFO  TaskSetManager:54 - Starting task 43.2 in stage 7.0 (TID 382, hadoop13.cusp.nyu.edu, executor 7, partition 43, NODE_LOCAL, 8331 bytes)
2021-05-19 02:47:38 INFO  TaskSetManager:54 - Starting task 9.2 in stage 7.0 (TID 383, hadoop13.cusp.nyu.edu, executor 7, partition 9, NODE_LOCAL, 8331 bytes)
2021-05-19 02:47:38 INFO  YarnSchedulerBackend$YarnDriverEndpoint:54 - Registered executor NettyRpcEndpointRef(spark-client://Executor) (192.168.72.187:44000) with ID 9
2021-05-19 02:47:38 INFO  TaskSetManager:54 - Starting task 32.2 in stage 7.0 (TID 384, hadoop17.cusp.nyu.edu, executor 9, partition 32, NODE_LOCAL, 8331 bytes)
2021-05-19 02:47:38 INFO  TaskSetManager:54 - Starting task 16.1 in stage 7.0 (TID 385, hadoop17.cusp.nyu.edu, executor 9, partition 16, NODE_LOCAL, 8331 bytes)
2021-05-19 02:47:38 INFO  TaskSetManager:54 - Starting task 15.1 in stage 7.0 (TID 386, hadoop17.cusp.nyu.edu, executor 9, partition 15, NODE_LOCAL, 8331 bytes)
2021-05-19 02:47:38 INFO  TaskSetManager:54 - Starting task 45.1 in stage 7.0 (TID 387, hadoop17.cusp.nyu.edu, executor 9, partition 45, NODE_LOCAL, 8331 bytes)
2021-05-19 02:47:38 INFO  TaskSetManager:54 - Starting task 44.1 in stage 7.0 (TID 388, hadoop17.cusp.nyu.edu, executor 9, partition 44, NODE_LOCAL, 8331 bytes)
2021-05-19 02:47:38 INFO  TaskSetManager:54 - Starting task 40.1 in stage 7.0 (TID 389, hadoop17.cusp.nyu.edu, executor 9, partition 40, NODE_LOCAL, 8331 bytes)
2021-05-19 02:47:38 INFO  TaskSetManager:54 - Starting task 10.1 in stage 7.0 (TID 390, hadoop17.cusp.nyu.edu, executor 9, partition 10, NODE_LOCAL, 8331 bytes)
2021-05-19 02:47:38 INFO  TaskSetManager:54 - Starting task 1.1 in stage 7.0 (TID 391, hadoop17.cusp.nyu.edu, executor 9, partition 1, NODE_LOCAL, 8331 bytes)
2021-05-19 02:47:38 INFO  TaskSetManager:54 - Starting task 30.1 in stage 7.0 (TID 392, hadoop17.cusp.nyu.edu, executor 9, partition 30, NODE_LOCAL, 8331 bytes)
2021-05-19 02:47:38 INFO  TaskSetManager:54 - Starting task 3.1 in stage 7.0 (TID 393, hadoop17.cusp.nyu.edu, executor 9, partition 3, NODE_LOCAL, 8331 bytes)
2021-05-19 02:47:38 INFO  BlockManagerMasterEndpoint:54 - Registering block manager hadoop13.cusp.nyu.edu:44397 with 366.3 MB RAM, BlockManagerId(7, hadoop13.cusp.nyu.edu, 44397, None)
2021-05-19 02:47:38 INFO  YarnSchedulerBackend$YarnDriverEndpoint:54 - Registered executor NettyRpcEndpointRef(spark-client://Executor) (192.168.72.188:41859) with ID 8
2021-05-19 02:47:38 INFO  TaskSetManager:54 - Starting task 6.1 in stage 7.0 (TID 394, hadoop18.cusp.nyu.edu, executor 8, partition 6, NODE_LOCAL, 8331 bytes)
2021-05-19 02:47:38 INFO  TaskSetManager:54 - Starting task 31.1 in stage 7.0 (TID 395, hadoop18.cusp.nyu.edu, executor 8, partition 31, NODE_LOCAL, 8331 bytes)
2021-05-19 02:47:38 INFO  TaskSetManager:54 - Starting task 38.1 in stage 7.0 (TID 396, hadoop18.cusp.nyu.edu, executor 8, partition 38, NODE_LOCAL, 8331 bytes)
2021-05-19 02:47:38 INFO  TaskSetManager:54 - Starting task 13.1 in stage 7.0 (TID 397, hadoop18.cusp.nyu.edu, executor 8, partition 13, NODE_LOCAL, 8331 bytes)
2021-05-19 02:47:38 INFO  TaskSetManager:54 - Starting task 35.1 in stage 7.0 (TID 398, hadoop18.cusp.nyu.edu, executor 8, partition 35, NODE_LOCAL, 8331 bytes)
2021-05-19 02:47:38 INFO  TaskSetManager:54 - Starting task 27.1 in stage 7.0 (TID 399, hadoop18.cusp.nyu.edu, executor 8, partition 27, NODE_LOCAL, 8331 bytes)
2021-05-19 02:47:38 INFO  TaskSetManager:54 - Starting task 53.0 in stage 7.0 (TID 400, hadoop18.cusp.nyu.edu, executor 8, partition 53, NODE_LOCAL, 8436 bytes)
2021-05-19 02:47:38 INFO  TaskSetManager:54 - Starting task 58.0 in stage 7.0 (TID 401, hadoop18.cusp.nyu.edu, executor 8, partition 58, NODE_LOCAL, 8436 bytes)
2021-05-19 02:47:38 INFO  TaskSetManager:54 - Starting task 60.0 in stage 7.0 (TID 402, hadoop18.cusp.nyu.edu, executor 8, partition 60, NODE_LOCAL, 8436 bytes)
2021-05-19 02:47:38 INFO  TaskSetManager:54 - Starting task 62.0 in stage 7.0 (TID 403, hadoop18.cusp.nyu.edu, executor 8, partition 62, NODE_LOCAL, 8436 bytes)
2021-05-19 02:47:38 INFO  BlockManagerMasterEndpoint:54 - Registering block manager hadoop17.cusp.nyu.edu:58642 with 366.3 MB RAM, BlockManagerId(9, hadoop17.cusp.nyu.edu, 58642, None)
2021-05-19 02:47:38 INFO  BlockManagerMasterEndpoint:54 - Registering block manager hadoop18.cusp.nyu.edu:38463 with 366.3 MB RAM, BlockManagerId(8, hadoop18.cusp.nyu.edu, 38463, None)
2021-05-19 02:47:38 INFO  BlockManagerInfo:54 - Added broadcast_14_piece0 in memory on hadoop13.cusp.nyu.edu:44397 (size: 22.9 KB, free: 366.3 MB)
2021-05-19 02:47:39 INFO  BlockManagerInfo:54 - Added broadcast_14_piece0 in memory on hadoop17.cusp.nyu.edu:58642 (size: 22.9 KB, free: 366.3 MB)
2021-05-19 02:47:39 INFO  BlockManagerInfo:54 - Added broadcast_13_piece0 in memory on hadoop06.cusp.nyu.edu:34178 (size: 33.4 KB, free: 365.7 MB)
2021-05-19 02:47:39 INFO  BlockManagerInfo:54 - Added broadcast_14_piece0 in memory on hadoop18.cusp.nyu.edu:38463 (size: 22.9 KB, free: 366.3 MB)
2021-05-19 02:47:40 INFO  YarnAllocator:54 - Will request 1 executor container(s), each with 10 core(s) and 1408 MB memory (including 384 MB of overhead)
2021-05-19 02:47:40 INFO  YarnAllocator:54 - Submitted 1 unlocalized container requests.
2021-05-19 02:47:40 INFO  YarnAllocator:54 - Launching container container_e10_1609183734776_5900_02_000011 on host hadoop04.cusp.nyu.edu for executor with ID 10
2021-05-19 02:47:40 INFO  YarnAllocator:54 - Received 1 containers from YARN, launching executors on 1 of them.
2021-05-19 02:47:40 INFO  ContainerManagementProtocolProxy:81 - yarn.client.max-cached-nodemanagers-proxies : 0
2021-05-19 02:47:40 INFO  ContainerManagementProtocolProxy:260 - Opening proxy : hadoop04.cusp.nyu.edu:8041
2021-05-19 02:47:40 INFO  BlockManagerInfo:54 - Added broadcast_12_piece0 in memory on hadoop13.cusp.nyu.edu:44397 (size: 580.1 KB, free: 365.7 MB)
2021-05-19 02:47:40 INFO  BlockManagerInfo:54 - Added broadcast_12_piece0 in memory on hadoop17.cusp.nyu.edu:58642 (size: 580.1 KB, free: 365.7 MB)
2021-05-19 02:47:40 INFO  BlockManagerInfo:54 - Added broadcast_12_piece0 in memory on hadoop18.cusp.nyu.edu:38463 (size: 580.1 KB, free: 365.7 MB)
2021-05-19 02:47:41 INFO  BlockManagerInfo:54 - Added broadcast_13_piece0 in memory on hadoop13.cusp.nyu.edu:44397 (size: 33.4 KB, free: 365.7 MB)
2021-05-19 02:47:42 INFO  BlockManagerInfo:54 - Added broadcast_13_piece0 in memory on hadoop17.cusp.nyu.edu:58642 (size: 33.4 KB, free: 365.7 MB)
2021-05-19 02:47:42 INFO  TaskSetManager:54 - Starting task 42.1 in stage 7.0 (TID 404, hadoop13.cusp.nyu.edu, executor 7, partition 42, RACK_LOCAL, 8331 bytes)
2021-05-19 02:47:42 INFO  TaskSetManager:54 - Starting task 28.1 in stage 7.0 (TID 405, hadoop13.cusp.nyu.edu, executor 7, partition 28, RACK_LOCAL, 8331 bytes)
2021-05-19 02:47:42 INFO  TaskSetManager:54 - Starting task 12.1 in stage 7.0 (TID 406, hadoop13.cusp.nyu.edu, executor 7, partition 12, RACK_LOCAL, 8331 bytes)
2021-05-19 02:47:42 INFO  TaskSetManager:54 - Starting task 29.1 in stage 7.0 (TID 407, hadoop13.cusp.nyu.edu, executor 7, partition 29, RACK_LOCAL, 8331 bytes)
2021-05-19 02:47:42 INFO  TaskSetManager:54 - Starting task 22.1 in stage 7.0 (TID 408, hadoop13.cusp.nyu.edu, executor 7, partition 22, RACK_LOCAL, 8331 bytes)
2021-05-19 02:47:42 INFO  TaskSetManager:54 - Starting task 24.1 in stage 7.0 (TID 409, hadoop13.cusp.nyu.edu, executor 7, partition 24, RACK_LOCAL, 8331 bytes)
2021-05-19 02:47:42 INFO  TaskSetManager:54 - Starting task 8.1 in stage 7.0 (TID 410, hadoop13.cusp.nyu.edu, executor 7, partition 8, RACK_LOCAL, 8331 bytes)
2021-05-19 02:47:42 INFO  BlockManagerInfo:54 - Added broadcast_13_piece0 in memory on hadoop18.cusp.nyu.edu:38463 (size: 33.4 KB, free: 365.7 MB)
2021-05-19 02:47:43 INFO  YarnSchedulerBackend$YarnDriverEndpoint:54 - Registered executor NettyRpcEndpointRef(spark-client://Executor) (192.168.72.174:43487) with ID 10
2021-05-19 02:47:43 INFO  TaskSetManager:54 - Starting task 37.1 in stage 7.0 (TID 411, hadoop04.cusp.nyu.edu, executor 10, partition 37, RACK_LOCAL, 8331 bytes)
2021-05-19 02:47:43 INFO  TaskSetManager:54 - Starting task 19.1 in stage 7.0 (TID 412, hadoop04.cusp.nyu.edu, executor 10, partition 19, RACK_LOCAL, 8331 bytes)
2021-05-19 02:47:43 INFO  TaskSetManager:54 - Starting task 48.0 in stage 7.0 (TID 413, hadoop04.cusp.nyu.edu, executor 10, partition 48, RACK_LOCAL, 8331 bytes)
2021-05-19 02:47:43 INFO  TaskSetManager:54 - Starting task 49.0 in stage 7.0 (TID 414, hadoop04.cusp.nyu.edu, executor 10, partition 49, RACK_LOCAL, 8436 bytes)
2021-05-19 02:47:43 INFO  TaskSetManager:54 - Starting task 50.0 in stage 7.0 (TID 415, hadoop04.cusp.nyu.edu, executor 10, partition 50, RACK_LOCAL, 8436 bytes)
2021-05-19 02:47:43 INFO  TaskSetManager:54 - Starting task 54.0 in stage 7.0 (TID 416, hadoop04.cusp.nyu.edu, executor 10, partition 54, RACK_LOCAL, 8436 bytes)
2021-05-19 02:47:43 INFO  TaskSetManager:54 - Starting task 55.0 in stage 7.0 (TID 417, hadoop04.cusp.nyu.edu, executor 10, partition 55, RACK_LOCAL, 8436 bytes)
2021-05-19 02:47:43 INFO  TaskSetManager:54 - Starting task 56.0 in stage 7.0 (TID 418, hadoop04.cusp.nyu.edu, executor 10, partition 56, RACK_LOCAL, 8436 bytes)
2021-05-19 02:47:43 INFO  TaskSetManager:54 - Starting task 57.0 in stage 7.0 (TID 419, hadoop04.cusp.nyu.edu, executor 10, partition 57, RACK_LOCAL, 8436 bytes)
2021-05-19 02:47:43 INFO  TaskSetManager:54 - Starting task 59.0 in stage 7.0 (TID 420, hadoop04.cusp.nyu.edu, executor 10, partition 59, RACK_LOCAL, 8436 bytes)
2021-05-19 02:47:44 INFO  BlockManagerMasterEndpoint:54 - Registering block manager hadoop04.cusp.nyu.edu:35739 with 366.3 MB RAM, BlockManagerId(10, hadoop04.cusp.nyu.edu, 35739, None)
2021-05-19 02:47:44 INFO  BlockManagerInfo:54 - Added broadcast_14_piece0 in memory on hadoop04.cusp.nyu.edu:35739 (size: 22.9 KB, free: 366.3 MB)
2021-05-19 02:47:46 INFO  BlockManagerInfo:54 - Added broadcast_12_piece0 in memory on hadoop04.cusp.nyu.edu:35739 (size: 580.1 KB, free: 365.7 MB)
2021-05-19 02:47:47 INFO  BlockManagerInfo:54 - Added broadcast_13_piece0 in memory on hadoop04.cusp.nyu.edu:35739 (size: 33.4 KB, free: 365.7 MB)
2021-05-19 02:47:51 INFO  YarnSchedulerBackend$YarnDriverEndpoint:54 - Disabling executor 6.
2021-05-19 02:47:51 INFO  DAGScheduler:54 - Executor lost: 6 (epoch 1)
2021-05-19 02:47:51 INFO  BlockManagerMasterEndpoint:54 - Trying to remove executor 6 from BlockManagerMaster.
2021-05-19 02:47:51 INFO  BlockManagerMasterEndpoint:54 - Removing block manager BlockManagerId(6, hadoop06.cusp.nyu.edu, 34178, None)
2021-05-19 02:47:51 INFO  BlockManagerMaster:54 - Removed 6 successfully in removeExecutor
2021-05-19 02:47:51 INFO  YarnAllocator:54 - Completed container container_e10_1609183734776_5900_02_000007 on host: hadoop06.cusp.nyu.edu (state: COMPLETE, exit status: -104)
2021-05-19 02:47:51 WARN  YarnAllocator:66 - Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:47:51 WARN  YarnSchedulerBackend$YarnSchedulerEndpoint:66 - Requesting driver to remove executor 6 for reason Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:47:51 ERROR YarnClusterScheduler:70 - Lost executor 6 on hadoop06.cusp.nyu.edu: Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:47:51 WARN  TaskSetManager:66 - Lost task 33.1 in stage 7.0 (TID 373, hadoop06.cusp.nyu.edu, executor 6): ExecutorLostFailure (executor 6 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:47:51 WARN  TaskSetManager:66 - Lost task 36.1 in stage 7.0 (TID 376, hadoop06.cusp.nyu.edu, executor 6): ExecutorLostFailure (executor 6 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:47:51 WARN  TaskSetManager:66 - Lost task 47.1 in stage 7.0 (TID 379, hadoop06.cusp.nyu.edu, executor 6): ExecutorLostFailure (executor 6 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:47:51 WARN  TaskSetManager:66 - Lost task 7.1 in stage 7.0 (TID 378, hadoop06.cusp.nyu.edu, executor 6): ExecutorLostFailure (executor 6 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:47:51 WARN  TaskSetManager:66 - Lost task 0.1 in stage 7.0 (TID 372, hadoop06.cusp.nyu.edu, executor 6): ExecutorLostFailure (executor 6 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:47:51 WARN  TaskSetManager:66 - Lost task 2.1 in stage 7.0 (TID 375, hadoop06.cusp.nyu.edu, executor 6): ExecutorLostFailure (executor 6 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:47:51 WARN  TaskSetManager:66 - Lost task 25.1 in stage 7.0 (TID 377, hadoop06.cusp.nyu.edu, executor 6): ExecutorLostFailure (executor 6 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:47:51 WARN  TaskSetManager:66 - Lost task 39.1 in stage 7.0 (TID 380, hadoop06.cusp.nyu.edu, executor 6): ExecutorLostFailure (executor 6 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:47:51 WARN  TaskSetManager:66 - Lost task 17.1 in stage 7.0 (TID 371, hadoop06.cusp.nyu.edu, executor 6): ExecutorLostFailure (executor 6 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:47:51 WARN  TaskSetManager:66 - Lost task 18.1 in stage 7.0 (TID 374, hadoop06.cusp.nyu.edu, executor 6): ExecutorLostFailure (executor 6 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:47:51 INFO  BlockManagerMaster:54 - Removal of executor 6 requested
2021-05-19 02:47:51 INFO  YarnSchedulerBackend$YarnDriverEndpoint:54 - Asked to remove non-existent executor 6
2021-05-19 02:47:51 INFO  BlockManagerMasterEndpoint:54 - Trying to remove executor 6 from BlockManagerMaster.
2021-05-19 02:47:53 INFO  TaskSetManager:54 - Starting task 47.2 in stage 7.0 (TID 421, hadoop18.cusp.nyu.edu, executor 8, partition 47, NODE_LOCAL, 8331 bytes)
2021-05-19 02:47:53 INFO  TaskSetManager:54 - Finished task 62.0 in stage 7.0 (TID 403) in 14743 ms on hadoop18.cusp.nyu.edu (executor 8) (13/70)
2021-05-19 02:47:54 INFO  YarnAllocator:54 - Will request 1 executor container(s), each with 10 core(s) and 1408 MB memory (including 384 MB of overhead)
2021-05-19 02:47:54 INFO  YarnAllocator:54 - Submitted 1 unlocalized container requests.
2021-05-19 02:47:54 INFO  YarnAllocator:54 - Completed container container_e10_1609183734776_5900_02_000009 on host: hadoop18.cusp.nyu.edu (state: COMPLETE, exit status: -104)
2021-05-19 02:47:54 WARN  YarnAllocator:66 - Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:47:54 WARN  YarnSchedulerBackend$YarnSchedulerEndpoint:66 - Requesting driver to remove executor 8 for reason Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:47:54 ERROR YarnClusterScheduler:70 - Lost executor 8 on hadoop18.cusp.nyu.edu: Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:47:54 WARN  TaskSetManager:66 - Lost task 53.0 in stage 7.0 (TID 400, hadoop18.cusp.nyu.edu, executor 8): ExecutorLostFailure (executor 8 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:47:54 WARN  TaskSetManager:66 - Lost task 6.1 in stage 7.0 (TID 394, hadoop18.cusp.nyu.edu, executor 8): ExecutorLostFailure (executor 8 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:47:54 WARN  TaskSetManager:66 - Lost task 47.2 in stage 7.0 (TID 421, hadoop18.cusp.nyu.edu, executor 8): ExecutorLostFailure (executor 8 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:47:54 WARN  TaskSetManager:66 - Lost task 13.1 in stage 7.0 (TID 397, hadoop18.cusp.nyu.edu, executor 8): ExecutorLostFailure (executor 8 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:47:54 WARN  TaskSetManager:66 - Lost task 38.1 in stage 7.0 (TID 396, hadoop18.cusp.nyu.edu, executor 8): ExecutorLostFailure (executor 8 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:47:54 WARN  TaskSetManager:66 - Lost task 27.1 in stage 7.0 (TID 399, hadoop18.cusp.nyu.edu, executor 8): ExecutorLostFailure (executor 8 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:47:54 WARN  TaskSetManager:66 - Lost task 60.0 in stage 7.0 (TID 402, hadoop18.cusp.nyu.edu, executor 8): ExecutorLostFailure (executor 8 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:47:54 WARN  TaskSetManager:66 - Lost task 58.0 in stage 7.0 (TID 401, hadoop18.cusp.nyu.edu, executor 8): ExecutorLostFailure (executor 8 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:47:54 WARN  TaskSetManager:66 - Lost task 31.1 in stage 7.0 (TID 395, hadoop18.cusp.nyu.edu, executor 8): ExecutorLostFailure (executor 8 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:47:54 WARN  TaskSetManager:66 - Lost task 35.1 in stage 7.0 (TID 398, hadoop18.cusp.nyu.edu, executor 8): ExecutorLostFailure (executor 8 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:47:54 INFO  DAGScheduler:54 - Executor lost: 8 (epoch 1)
2021-05-19 02:47:54 INFO  BlockManagerMasterEndpoint:54 - Trying to remove executor 8 from BlockManagerMaster.
2021-05-19 02:47:54 INFO  BlockManagerMasterEndpoint:54 - Removing block manager BlockManagerId(8, hadoop18.cusp.nyu.edu, 38463, None)
2021-05-19 02:47:54 INFO  BlockManagerMaster:54 - Removed 8 successfully in removeExecutor
2021-05-19 02:47:54 INFO  YarnAllocator:54 - Will request 1 executor container(s), each with 10 core(s) and 1408 MB memory (including 384 MB of overhead)
2021-05-19 02:47:54 INFO  YarnAllocator:54 - Submitted 1 unlocalized container requests.
2021-05-19 02:47:54 INFO  YarnAllocator:54 - Launching container container_e10_1609183734776_5900_02_000012 on host hadoop18.cusp.nyu.edu for executor with ID 11
2021-05-19 02:47:54 INFO  YarnAllocator:54 - Received 1 containers from YARN, launching executors on 1 of them.
2021-05-19 02:47:54 INFO  ContainerManagementProtocolProxy:81 - yarn.client.max-cached-nodemanagers-proxies : 0
2021-05-19 02:47:54 INFO  ContainerManagementProtocolProxy:260 - Opening proxy : hadoop18.cusp.nyu.edu:8041
2021-05-19 02:47:54 INFO  AMRMClientImpl:360 - Received new token for : hadoop05.cusp.nyu.edu:8041
2021-05-19 02:47:54 INFO  YarnAllocator:54 - Launching container container_e10_1609183734776_5900_02_000013 on host hadoop06.cusp.nyu.edu for executor with ID 12
2021-05-19 02:47:54 INFO  YarnAllocator:54 - Received 2 containers from YARN, launching executors on 1 of them.
2021-05-19 02:47:54 INFO  ContainerManagementProtocolProxy:81 - yarn.client.max-cached-nodemanagers-proxies : 0
2021-05-19 02:47:54 INFO  ContainerManagementProtocolProxy:260 - Opening proxy : hadoop06.cusp.nyu.edu:8041
2021-05-19 02:47:56 INFO  YarnSchedulerBackend$YarnDriverEndpoint:54 - Disabling executor 7.
2021-05-19 02:47:56 INFO  DAGScheduler:54 - Executor lost: 7 (epoch 1)
2021-05-19 02:47:56 INFO  BlockManagerMasterEndpoint:54 - Trying to remove executor 7 from BlockManagerMaster.
2021-05-19 02:47:56 INFO  BlockManagerMasterEndpoint:54 - Removing block manager BlockManagerId(7, hadoop13.cusp.nyu.edu, 44397, None)
2021-05-19 02:47:56 INFO  BlockManagerMaster:54 - Removed 7 successfully in removeExecutor
2021-05-19 02:47:56 INFO  YarnAllocator:54 - Received 1 containers from YARN, launching executors on 0 of them.
2021-05-19 02:47:56 INFO  YarnAllocator:54 - Completed container container_e10_1609183734776_5900_02_000008 on host: hadoop13.cusp.nyu.edu (state: COMPLETE, exit status: -104)
2021-05-19 02:47:56 WARN  YarnAllocator:66 - Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:47:56 WARN  YarnSchedulerBackend$YarnSchedulerEndpoint:66 - Requesting driver to remove executor 7 for reason Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:47:56 ERROR YarnClusterScheduler:70 - Lost executor 7 on hadoop13.cusp.nyu.edu: Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:47:56 WARN  TaskSetManager:66 - Lost task 12.1 in stage 7.0 (TID 406, hadoop13.cusp.nyu.edu, executor 7): ExecutorLostFailure (executor 7 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:47:56 WARN  TaskSetManager:66 - Lost task 24.1 in stage 7.0 (TID 409, hadoop13.cusp.nyu.edu, executor 7): ExecutorLostFailure (executor 7 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:47:56 WARN  TaskSetManager:66 - Lost task 43.2 in stage 7.0 (TID 382, hadoop13.cusp.nyu.edu, executor 7): ExecutorLostFailure (executor 7 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:47:56 WARN  TaskSetManager:66 - Lost task 28.1 in stage 7.0 (TID 405, hadoop13.cusp.nyu.edu, executor 7): ExecutorLostFailure (executor 7 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:47:56 WARN  TaskSetManager:66 - Lost task 22.1 in stage 7.0 (TID 408, hadoop13.cusp.nyu.edu, executor 7): ExecutorLostFailure (executor 7 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:47:56 WARN  TaskSetManager:66 - Lost task 26.2 in stage 7.0 (TID 381, hadoop13.cusp.nyu.edu, executor 7): ExecutorLostFailure (executor 7 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:47:56 WARN  TaskSetManager:66 - Lost task 9.2 in stage 7.0 (TID 383, hadoop13.cusp.nyu.edu, executor 7): ExecutorLostFailure (executor 7 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:47:56 WARN  TaskSetManager:66 - Lost task 8.1 in stage 7.0 (TID 410, hadoop13.cusp.nyu.edu, executor 7): ExecutorLostFailure (executor 7 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:47:56 WARN  TaskSetManager:66 - Lost task 42.1 in stage 7.0 (TID 404, hadoop13.cusp.nyu.edu, executor 7): ExecutorLostFailure (executor 7 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:47:56 WARN  TaskSetManager:66 - Lost task 29.1 in stage 7.0 (TID 407, hadoop13.cusp.nyu.edu, executor 7): ExecutorLostFailure (executor 7 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:47:56 INFO  BlockManagerMasterEndpoint:54 - Trying to remove executor 7 from BlockManagerMaster.
2021-05-19 02:47:56 INFO  BlockManagerMaster:54 - Removal of executor 7 requested
2021-05-19 02:47:56 INFO  YarnSchedulerBackend$YarnDriverEndpoint:54 - Asked to remove non-existent executor 7
2021-05-19 02:47:56 INFO  YarnSchedulerBackend$YarnDriverEndpoint:54 - Disabling executor 9.
2021-05-19 02:47:56 INFO  DAGScheduler:54 - Executor lost: 9 (epoch 1)
2021-05-19 02:47:56 INFO  YarnAllocator:54 - Will request 1 executor container(s), each with 10 core(s) and 1408 MB memory (including 384 MB of overhead)
2021-05-19 02:47:56 INFO  BlockManagerMasterEndpoint:54 - Trying to remove executor 9 from BlockManagerMaster.
2021-05-19 02:47:56 INFO  YarnAllocator:54 - Submitted 1 unlocalized container requests.
2021-05-19 02:47:56 INFO  BlockManagerMasterEndpoint:54 - Removing block manager BlockManagerId(9, hadoop17.cusp.nyu.edu, 58642, None)
2021-05-19 02:47:56 INFO  BlockManagerMaster:54 - Removed 9 successfully in removeExecutor
2021-05-19 02:47:56 INFO  YarnAllocator:54 - Completed container container_e10_1609183734776_5900_02_000010 on host: hadoop17.cusp.nyu.edu (state: COMPLETE, exit status: -104)
2021-05-19 02:47:56 WARN  YarnAllocator:66 - Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:47:56 WARN  YarnSchedulerBackend$YarnSchedulerEndpoint:66 - Requesting driver to remove executor 9 for reason Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:47:56 ERROR YarnClusterScheduler:70 - Lost executor 9 on hadoop17.cusp.nyu.edu: Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:47:56 WARN  TaskSetManager:66 - Lost task 1.1 in stage 7.0 (TID 391, hadoop17.cusp.nyu.edu, executor 9): ExecutorLostFailure (executor 9 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:47:56 WARN  TaskSetManager:66 - Lost task 16.1 in stage 7.0 (TID 385, hadoop17.cusp.nyu.edu, executor 9): ExecutorLostFailure (executor 9 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:47:56 WARN  TaskSetManager:66 - Lost task 44.1 in stage 7.0 (TID 388, hadoop17.cusp.nyu.edu, executor 9): ExecutorLostFailure (executor 9 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:47:56 WARN  TaskSetManager:66 - Lost task 45.1 in stage 7.0 (TID 387, hadoop17.cusp.nyu.edu, executor 9): ExecutorLostFailure (executor 9 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:47:56 WARN  TaskSetManager:66 - Lost task 10.1 in stage 7.0 (TID 390, hadoop17.cusp.nyu.edu, executor 9): ExecutorLostFailure (executor 9 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:47:56 WARN  TaskSetManager:66 - Lost task 3.1 in stage 7.0 (TID 393, hadoop17.cusp.nyu.edu, executor 9): ExecutorLostFailure (executor 9 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:47:56 WARN  TaskSetManager:66 - Lost task 32.2 in stage 7.0 (TID 384, hadoop17.cusp.nyu.edu, executor 9): ExecutorLostFailure (executor 9 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:47:56 WARN  TaskSetManager:66 - Lost task 30.1 in stage 7.0 (TID 392, hadoop17.cusp.nyu.edu, executor 9): ExecutorLostFailure (executor 9 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:47:56 WARN  TaskSetManager:66 - Lost task 15.1 in stage 7.0 (TID 386, hadoop17.cusp.nyu.edu, executor 9): ExecutorLostFailure (executor 9 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:47:56 WARN  TaskSetManager:66 - Lost task 40.1 in stage 7.0 (TID 389, hadoop17.cusp.nyu.edu, executor 9): ExecutorLostFailure (executor 9 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:47:56 INFO  BlockManagerMasterEndpoint:54 - Trying to remove executor 9 from BlockManagerMaster.
2021-05-19 02:47:56 INFO  BlockManagerMaster:54 - Removal of executor 9 requested
2021-05-19 02:47:56 INFO  YarnSchedulerBackend$YarnDriverEndpoint:54 - Asked to remove non-existent executor 9
2021-05-19 02:47:56 INFO  YarnAllocator:54 - Will request 1 executor container(s), each with 10 core(s) and 1408 MB memory (including 384 MB of overhead)
2021-05-19 02:47:56 INFO  YarnAllocator:54 - Submitted 1 unlocalized container requests.
2021-05-19 02:47:56 INFO  YarnAllocator:54 - Launching container container_e10_1609183734776_5900_02_000016 on host hadoop13.cusp.nyu.edu for executor with ID 13
2021-05-19 02:47:56 INFO  YarnAllocator:54 - Received 1 containers from YARN, launching executors on 1 of them.
2021-05-19 02:47:56 INFO  ContainerManagementProtocolProxy:81 - yarn.client.max-cached-nodemanagers-proxies : 0
2021-05-19 02:47:56 INFO  ContainerManagementProtocolProxy:260 - Opening proxy : hadoop13.cusp.nyu.edu:8041
2021-05-19 02:47:57 INFO  YarnAllocator:54 - Launching container container_e10_1609183734776_5900_02_000017 on host hadoop17.cusp.nyu.edu for executor with ID 14
2021-05-19 02:47:57 INFO  YarnAllocator:54 - Received 2 containers from YARN, launching executors on 1 of them.
2021-05-19 02:47:57 INFO  ContainerManagementProtocolProxy:81 - yarn.client.max-cached-nodemanagers-proxies : 0
2021-05-19 02:47:57 INFO  ContainerManagementProtocolProxy:260 - Opening proxy : hadoop17.cusp.nyu.edu:8041
2021-05-19 02:47:57 INFO  YarnSchedulerBackend$YarnDriverEndpoint:54 - Registered executor NettyRpcEndpointRef(spark-client://Executor) (192.168.72.188:41908) with ID 11
2021-05-19 02:47:57 INFO  TaskSetManager:54 - Starting task 15.2 in stage 7.0 (TID 422, hadoop18.cusp.nyu.edu, executor 11, partition 15, NODE_LOCAL, 8331 bytes)
2021-05-19 02:47:57 INFO  TaskSetManager:54 - Starting task 32.3 in stage 7.0 (TID 423, hadoop18.cusp.nyu.edu, executor 11, partition 32, NODE_LOCAL, 8331 bytes)
2021-05-19 02:47:57 INFO  TaskSetManager:54 - Starting task 16.2 in stage 7.0 (TID 424, hadoop18.cusp.nyu.edu, executor 11, partition 16, NODE_LOCAL, 8331 bytes)
2021-05-19 02:47:57 INFO  TaskSetManager:54 - Starting task 26.3 in stage 7.0 (TID 425, hadoop18.cusp.nyu.edu, executor 11, partition 26, NODE_LOCAL, 8331 bytes)
2021-05-19 02:47:57 INFO  TaskSetManager:54 - Starting task 35.2 in stage 7.0 (TID 426, hadoop18.cusp.nyu.edu, executor 11, partition 35, NODE_LOCAL, 8331 bytes)
2021-05-19 02:47:57 INFO  TaskSetManager:54 - Starting task 31.2 in stage 7.0 (TID 427, hadoop18.cusp.nyu.edu, executor 11, partition 31, NODE_LOCAL, 8331 bytes)
2021-05-19 02:47:57 INFO  TaskSetManager:54 - Starting task 58.1 in stage 7.0 (TID 428, hadoop18.cusp.nyu.edu, executor 11, partition 58, NODE_LOCAL, 8436 bytes)
2021-05-19 02:47:57 INFO  TaskSetManager:54 - Starting task 60.1 in stage 7.0 (TID 429, hadoop18.cusp.nyu.edu, executor 11, partition 60, NODE_LOCAL, 8436 bytes)
2021-05-19 02:47:57 INFO  TaskSetManager:54 - Starting task 27.2 in stage 7.0 (TID 430, hadoop18.cusp.nyu.edu, executor 11, partition 27, NODE_LOCAL, 8331 bytes)
2021-05-19 02:47:57 INFO  TaskSetManager:54 - Starting task 38.2 in stage 7.0 (TID 431, hadoop18.cusp.nyu.edu, executor 11, partition 38, NODE_LOCAL, 8331 bytes)
2021-05-19 02:47:57 INFO  YarnSchedulerBackend$YarnDriverEndpoint:54 - Registered executor NettyRpcEndpointRef(spark-client://Executor) (192.168.72.176:38488) with ID 12
2021-05-19 02:47:57 INFO  TaskSetManager:54 - Starting task 47.3 in stage 7.0 (TID 432, hadoop06.cusp.nyu.edu, executor 12, partition 47, NODE_LOCAL, 8331 bytes)
2021-05-19 02:47:57 INFO  TaskSetManager:54 - Starting task 18.2 in stage 7.0 (TID 433, hadoop06.cusp.nyu.edu, executor 12, partition 18, NODE_LOCAL, 8331 bytes)
2021-05-19 02:47:57 INFO  TaskSetManager:54 - Starting task 17.2 in stage 7.0 (TID 434, hadoop06.cusp.nyu.edu, executor 12, partition 17, NODE_LOCAL, 8331 bytes)
2021-05-19 02:47:57 INFO  TaskSetManager:54 - Starting task 39.2 in stage 7.0 (TID 435, hadoop06.cusp.nyu.edu, executor 12, partition 39, NODE_LOCAL, 8331 bytes)
2021-05-19 02:47:57 INFO  TaskSetManager:54 - Starting task 25.2 in stage 7.0 (TID 436, hadoop06.cusp.nyu.edu, executor 12, partition 25, NODE_LOCAL, 8331 bytes)
2021-05-19 02:47:57 INFO  TaskSetManager:54 - Starting task 2.2 in stage 7.0 (TID 437, hadoop06.cusp.nyu.edu, executor 12, partition 2, NODE_LOCAL, 8331 bytes)
2021-05-19 02:47:57 INFO  TaskSetManager:54 - Starting task 0.2 in stage 7.0 (TID 438, hadoop06.cusp.nyu.edu, executor 12, partition 0, NODE_LOCAL, 8331 bytes)
2021-05-19 02:47:57 INFO  TaskSetManager:54 - Starting task 7.2 in stage 7.0 (TID 439, hadoop06.cusp.nyu.edu, executor 12, partition 7, NODE_LOCAL, 8331 bytes)
2021-05-19 02:47:57 INFO  TaskSetManager:54 - Starting task 36.2 in stage 7.0 (TID 440, hadoop06.cusp.nyu.edu, executor 12, partition 36, NODE_LOCAL, 8331 bytes)
2021-05-19 02:47:57 INFO  TaskSetManager:54 - Starting task 33.2 in stage 7.0 (TID 441, hadoop06.cusp.nyu.edu, executor 12, partition 33, NODE_LOCAL, 8331 bytes)
2021-05-19 02:47:58 INFO  BlockManagerMasterEndpoint:54 - Registering block manager hadoop18.cusp.nyu.edu:38556 with 366.3 MB RAM, BlockManagerId(11, hadoop18.cusp.nyu.edu, 38556, None)
2021-05-19 02:47:58 INFO  BlockManagerMasterEndpoint:54 - Registering block manager hadoop06.cusp.nyu.edu:44467 with 366.3 MB RAM, BlockManagerId(12, hadoop06.cusp.nyu.edu, 44467, None)
2021-05-19 02:47:58 INFO  BlockManagerInfo:54 - Added broadcast_14_piece0 in memory on hadoop18.cusp.nyu.edu:38556 (size: 22.9 KB, free: 366.3 MB)
2021-05-19 02:47:58 INFO  BlockManagerInfo:54 - Added broadcast_14_piece0 in memory on hadoop06.cusp.nyu.edu:44467 (size: 22.9 KB, free: 366.3 MB)
2021-05-19 02:47:58 INFO  TaskSetManager:54 - Finished task 55.0 in stage 7.0 (TID 417) in 14927 ms on hadoop04.cusp.nyu.edu (executor 10) (14/70)
2021-05-19 02:47:59 INFO  TaskSetManager:54 - Finished task 56.0 in stage 7.0 (TID 418) in 15731 ms on hadoop04.cusp.nyu.edu (executor 10) (15/70)
2021-05-19 02:48:00 INFO  BlockManagerInfo:54 - Added broadcast_12_piece0 in memory on hadoop06.cusp.nyu.edu:44467 (size: 580.1 KB, free: 365.7 MB)
2021-05-19 02:48:00 INFO  BlockManagerInfo:54 - Added broadcast_12_piece0 in memory on hadoop18.cusp.nyu.edu:38556 (size: 580.1 KB, free: 365.7 MB)
2021-05-19 02:48:00 INFO  TaskSetManager:54 - Finished task 57.0 in stage 7.0 (TID 419) in 16204 ms on hadoop04.cusp.nyu.edu (executor 10) (16/70)
2021-05-19 02:48:00 INFO  TaskSetManager:54 - Finished task 59.0 in stage 7.0 (TID 420) in 16241 ms on hadoop04.cusp.nyu.edu (executor 10) (17/70)
2021-05-19 02:48:00 INFO  TaskSetManager:54 - Finished task 49.0 in stage 7.0 (TID 414) in 16284 ms on hadoop04.cusp.nyu.edu (executor 10) (18/70)
2021-05-19 02:48:00 INFO  TaskSetManager:54 - Finished task 54.0 in stage 7.0 (TID 416) in 16287 ms on hadoop04.cusp.nyu.edu (executor 10) (19/70)
2021-05-19 02:48:00 INFO  TaskSetManager:54 - Finished task 50.0 in stage 7.0 (TID 415) in 16308 ms on hadoop04.cusp.nyu.edu (executor 10) (20/70)
2021-05-19 02:48:00 INFO  YarnSchedulerBackend$YarnDriverEndpoint:54 - Registered executor NettyRpcEndpointRef(spark-client://Executor) (192.168.72.183:57810) with ID 13
2021-05-19 02:48:00 INFO  TaskSetManager:54 - Starting task 9.3 in stage 7.0 (TID 442, hadoop13.cusp.nyu.edu, executor 13, partition 9, NODE_LOCAL, 8331 bytes)
2021-05-19 02:48:00 INFO  TaskSetManager:54 - Starting task 43.3 in stage 7.0 (TID 443, hadoop13.cusp.nyu.edu, executor 13, partition 43, NODE_LOCAL, 8331 bytes)
2021-05-19 02:48:00 INFO  AMRMClientImpl:360 - Received new token for : hadoop09.cusp.nyu.edu:8041
2021-05-19 02:48:00 INFO  YarnAllocator:54 - Received 1 containers from YARN, launching executors on 0 of them.
2021-05-19 02:48:00 INFO  BlockManagerMasterEndpoint:54 - Registering block manager hadoop13.cusp.nyu.edu:43962 with 366.3 MB RAM, BlockManagerId(13, hadoop13.cusp.nyu.edu, 43962, None)
2021-05-19 02:48:00 INFO  YarnSchedulerBackend$YarnDriverEndpoint:54 - Registered executor NettyRpcEndpointRef(spark-client://Executor) (192.168.72.187:44056) with ID 14
2021-05-19 02:48:00 INFO  TaskSetManager:54 - Starting task 40.2 in stage 7.0 (TID 444, hadoop17.cusp.nyu.edu, executor 14, partition 40, NODE_LOCAL, 8331 bytes)
2021-05-19 02:48:00 INFO  TaskSetManager:54 - Starting task 30.2 in stage 7.0 (TID 445, hadoop17.cusp.nyu.edu, executor 14, partition 30, NODE_LOCAL, 8331 bytes)
2021-05-19 02:48:00 INFO  TaskSetManager:54 - Starting task 3.2 in stage 7.0 (TID 446, hadoop17.cusp.nyu.edu, executor 14, partition 3, NODE_LOCAL, 8331 bytes)
2021-05-19 02:48:00 INFO  TaskSetManager:54 - Starting task 10.2 in stage 7.0 (TID 447, hadoop17.cusp.nyu.edu, executor 14, partition 10, NODE_LOCAL, 8331 bytes)
2021-05-19 02:48:00 INFO  TaskSetManager:54 - Starting task 45.2 in stage 7.0 (TID 448, hadoop17.cusp.nyu.edu, executor 14, partition 45, NODE_LOCAL, 8331 bytes)
2021-05-19 02:48:00 INFO  TaskSetManager:54 - Starting task 44.2 in stage 7.0 (TID 449, hadoop17.cusp.nyu.edu, executor 14, partition 44, NODE_LOCAL, 8331 bytes)
2021-05-19 02:48:00 INFO  TaskSetManager:54 - Starting task 1.2 in stage 7.0 (TID 450, hadoop17.cusp.nyu.edu, executor 14, partition 1, NODE_LOCAL, 8331 bytes)
2021-05-19 02:48:00 INFO  TaskSetManager:54 - Starting task 61.0 in stage 7.0 (TID 451, hadoop17.cusp.nyu.edu, executor 14, partition 61, NODE_LOCAL, 8436 bytes)
2021-05-19 02:48:00 INFO  TaskSetManager:54 - Starting task 64.0 in stage 7.0 (TID 452, hadoop17.cusp.nyu.edu, executor 14, partition 64, NODE_LOCAL, 8541 bytes)
2021-05-19 02:48:00 INFO  TaskSetManager:54 - Starting task 69.0 in stage 7.0 (TID 453, hadoop17.cusp.nyu.edu, executor 14, partition 69, NODE_LOCAL, 8541 bytes)
2021-05-19 02:48:00 INFO  BlockManagerInfo:54 - Added broadcast_14_piece0 in memory on hadoop13.cusp.nyu.edu:43962 (size: 22.9 KB, free: 366.3 MB)
2021-05-19 02:48:00 INFO  BlockManagerMasterEndpoint:54 - Registering block manager hadoop17.cusp.nyu.edu:44528 with 366.3 MB RAM, BlockManagerId(14, hadoop17.cusp.nyu.edu, 44528, None)
2021-05-19 02:48:01 INFO  BlockManagerInfo:54 - Added broadcast_14_piece0 in memory on hadoop17.cusp.nyu.edu:44528 (size: 22.9 KB, free: 366.3 MB)
2021-05-19 02:48:01 INFO  BlockManagerInfo:54 - Added broadcast_13_piece0 in memory on hadoop06.cusp.nyu.edu:44467 (size: 33.4 KB, free: 365.7 MB)
2021-05-19 02:48:01 INFO  TaskSetManager:54 - Finished task 37.1 in stage 7.0 (TID 411) in 17495 ms on hadoop04.cusp.nyu.edu (executor 10) (21/70)
2021-05-19 02:48:01 INFO  BlockManagerInfo:54 - Added broadcast_13_piece0 in memory on hadoop18.cusp.nyu.edu:38556 (size: 33.4 KB, free: 365.7 MB)
2021-05-19 02:48:01 INFO  TaskSetManager:54 - Finished task 48.0 in stage 7.0 (TID 413) in 17599 ms on hadoop04.cusp.nyu.edu (executor 10) (22/70)
2021-05-19 02:48:02 INFO  YarnSchedulerBackend$YarnDriverEndpoint:54 - Disabling executor 10.
2021-05-19 02:48:02 INFO  DAGScheduler:54 - Executor lost: 10 (epoch 1)
2021-05-19 02:48:02 INFO  BlockManagerMasterEndpoint:54 - Trying to remove executor 10 from BlockManagerMaster.
2021-05-19 02:48:02 INFO  BlockManagerMasterEndpoint:54 - Removing block manager BlockManagerId(10, hadoop04.cusp.nyu.edu, 35739, None)
2021-05-19 02:48:02 INFO  BlockManagerMaster:54 - Removed 10 successfully in removeExecutor
2021-05-19 02:48:02 INFO  YarnAllocator:54 - Completed container container_e10_1609183734776_5900_02_000011 on host: hadoop04.cusp.nyu.edu (state: COMPLETE, exit status: -104)
2021-05-19 02:48:02 WARN  YarnAllocator:66 - Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:48:02 WARN  YarnSchedulerBackend$YarnSchedulerEndpoint:66 - Requesting driver to remove executor 10 for reason Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:48:02 ERROR YarnClusterScheduler:70 - Lost executor 10 on hadoop04.cusp.nyu.edu: Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:48:02 WARN  TaskSetManager:66 - Lost task 19.1 in stage 7.0 (TID 412, hadoop04.cusp.nyu.edu, executor 10): ExecutorLostFailure (executor 10 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:48:02 INFO  BlockManagerMaster:54 - Removal of executor 10 requested
2021-05-19 02:48:02 INFO  BlockManagerMasterEndpoint:54 - Trying to remove executor 10 from BlockManagerMaster.
2021-05-19 02:48:02 INFO  YarnSchedulerBackend$YarnDriverEndpoint:54 - Asked to remove non-existent executor 10
2021-05-19 02:48:02 INFO  BlockManagerInfo:54 - Added broadcast_12_piece0 in memory on hadoop13.cusp.nyu.edu:43962 (size: 580.1 KB, free: 365.7 MB)
2021-05-19 02:48:03 INFO  BlockManagerInfo:54 - Added broadcast_12_piece0 in memory on hadoop17.cusp.nyu.edu:44528 (size: 580.1 KB, free: 365.7 MB)
2021-05-19 02:48:03 INFO  BlockManagerInfo:54 - Added broadcast_13_piece0 in memory on hadoop13.cusp.nyu.edu:43962 (size: 33.4 KB, free: 365.7 MB)
2021-05-19 02:48:04 INFO  TaskSetManager:54 - Starting task 19.2 in stage 7.0 (TID 454, hadoop13.cusp.nyu.edu, executor 13, partition 19, RACK_LOCAL, 8331 bytes)
2021-05-19 02:48:04 INFO  TaskSetManager:54 - Starting task 29.2 in stage 7.0 (TID 455, hadoop13.cusp.nyu.edu, executor 13, partition 29, RACK_LOCAL, 8331 bytes)
2021-05-19 02:48:04 INFO  TaskSetManager:54 - Starting task 42.2 in stage 7.0 (TID 456, hadoop13.cusp.nyu.edu, executor 13, partition 42, RACK_LOCAL, 8331 bytes)
2021-05-19 02:48:04 INFO  TaskSetManager:54 - Starting task 8.2 in stage 7.0 (TID 457, hadoop13.cusp.nyu.edu, executor 13, partition 8, RACK_LOCAL, 8331 bytes)
2021-05-19 02:48:04 INFO  TaskSetManager:54 - Starting task 22.2 in stage 7.0 (TID 458, hadoop13.cusp.nyu.edu, executor 13, partition 22, RACK_LOCAL, 8331 bytes)
2021-05-19 02:48:04 INFO  TaskSetManager:54 - Starting task 28.2 in stage 7.0 (TID 459, hadoop13.cusp.nyu.edu, executor 13, partition 28, RACK_LOCAL, 8331 bytes)
2021-05-19 02:48:04 INFO  TaskSetManager:54 - Starting task 24.2 in stage 7.0 (TID 460, hadoop13.cusp.nyu.edu, executor 13, partition 24, RACK_LOCAL, 8331 bytes)
2021-05-19 02:48:04 INFO  TaskSetManager:54 - Starting task 12.2 in stage 7.0 (TID 461, hadoop13.cusp.nyu.edu, executor 13, partition 12, RACK_LOCAL, 8331 bytes)
2021-05-19 02:48:04 INFO  BlockManagerInfo:54 - Added broadcast_13_piece0 in memory on hadoop17.cusp.nyu.edu:44528 (size: 33.4 KB, free: 365.7 MB)
2021-05-19 02:48:05 INFO  YarnAllocator:54 - Will request 1 executor container(s), each with 10 core(s) and 1408 MB memory (including 384 MB of overhead)
2021-05-19 02:48:05 INFO  YarnAllocator:54 - Submitted 1 unlocalized container requests.
2021-05-19 02:48:05 INFO  YarnAllocator:54 - Launching container container_e10_1609183734776_5900_02_000020 on host hadoop04.cusp.nyu.edu for executor with ID 15
2021-05-19 02:48:05 INFO  YarnAllocator:54 - Received 1 containers from YARN, launching executors on 1 of them.
2021-05-19 02:48:05 INFO  ContainerManagementProtocolProxy:81 - yarn.client.max-cached-nodemanagers-proxies : 0
2021-05-19 02:48:05 INFO  ContainerManagementProtocolProxy:260 - Opening proxy : hadoop04.cusp.nyu.edu:8041
2021-05-19 02:48:08 INFO  YarnSchedulerBackend$YarnDriverEndpoint:54 - Registered executor NettyRpcEndpointRef(spark-client://Executor) (192.168.72.174:43544) with ID 15
2021-05-19 02:48:08 INFO  TaskSetManager:54 - Starting task 13.2 in stage 7.0 (TID 462, hadoop04.cusp.nyu.edu, executor 15, partition 13, RACK_LOCAL, 8331 bytes)
2021-05-19 02:48:08 INFO  TaskSetManager:54 - Starting task 6.2 in stage 7.0 (TID 463, hadoop04.cusp.nyu.edu, executor 15, partition 6, RACK_LOCAL, 8331 bytes)
2021-05-19 02:48:08 INFO  TaskSetManager:54 - Starting task 53.1 in stage 7.0 (TID 464, hadoop04.cusp.nyu.edu, executor 15, partition 53, RACK_LOCAL, 8436 bytes)
2021-05-19 02:48:08 INFO  TaskSetManager:54 - Starting task 63.0 in stage 7.0 (TID 465, hadoop04.cusp.nyu.edu, executor 15, partition 63, RACK_LOCAL, 8541 bytes)
2021-05-19 02:48:08 INFO  TaskSetManager:54 - Starting task 65.0 in stage 7.0 (TID 466, hadoop04.cusp.nyu.edu, executor 15, partition 65, RACK_LOCAL, 8541 bytes)
2021-05-19 02:48:08 INFO  TaskSetManager:54 - Starting task 66.0 in stage 7.0 (TID 467, hadoop04.cusp.nyu.edu, executor 15, partition 66, RACK_LOCAL, 8541 bytes)
2021-05-19 02:48:08 INFO  TaskSetManager:54 - Starting task 67.0 in stage 7.0 (TID 468, hadoop04.cusp.nyu.edu, executor 15, partition 67, RACK_LOCAL, 8541 bytes)
2021-05-19 02:48:08 INFO  TaskSetManager:54 - Starting task 68.0 in stage 7.0 (TID 469, hadoop04.cusp.nyu.edu, executor 15, partition 68, RACK_LOCAL, 8541 bytes)
2021-05-19 02:48:09 INFO  BlockManagerMasterEndpoint:54 - Registering block manager hadoop04.cusp.nyu.edu:38347 with 366.3 MB RAM, BlockManagerId(15, hadoop04.cusp.nyu.edu, 38347, None)
2021-05-19 02:48:09 INFO  BlockManagerInfo:54 - Added broadcast_14_piece0 in memory on hadoop04.cusp.nyu.edu:38347 (size: 22.9 KB, free: 366.3 MB)
2021-05-19 02:48:11 INFO  BlockManagerInfo:54 - Added broadcast_12_piece0 in memory on hadoop04.cusp.nyu.edu:38347 (size: 580.1 KB, free: 365.7 MB)
2021-05-19 02:48:12 INFO  BlockManagerInfo:54 - Added broadcast_13_piece0 in memory on hadoop04.cusp.nyu.edu:38347 (size: 33.4 KB, free: 365.7 MB)
2021-05-19 02:48:13 INFO  TaskSetManager:54 - Finished task 60.1 in stage 7.0 (TID 429) in 15979 ms on hadoop18.cusp.nyu.edu (executor 11) (23/70)
2021-05-19 02:48:13 INFO  TaskSetManager:54 - Finished task 58.1 in stage 7.0 (TID 428) in 15981 ms on hadoop18.cusp.nyu.edu (executor 11) (24/70)
2021-05-19 02:48:14 INFO  TaskSetManager:54 - Finished task 31.2 in stage 7.0 (TID 427) in 16835 ms on hadoop18.cusp.nyu.edu (executor 11) (25/70)
2021-05-19 02:48:14 INFO  TaskSetManager:54 - Finished task 15.2 in stage 7.0 (TID 422) in 16955 ms on hadoop18.cusp.nyu.edu (executor 11) (26/70)
2021-05-19 02:48:15 INFO  TaskSetManager:54 - Finished task 16.2 in stage 7.0 (TID 424) in 17633 ms on hadoop18.cusp.nyu.edu (executor 11) (27/70)
2021-05-19 02:48:15 INFO  TaskSetManager:54 - Finished task 38.2 in stage 7.0 (TID 431) in 17632 ms on hadoop18.cusp.nyu.edu (executor 11) (28/70)
2021-05-19 02:48:15 INFO  TaskSetManager:54 - Finished task 27.2 in stage 7.0 (TID 430) in 17877 ms on hadoop18.cusp.nyu.edu (executor 11) (29/70)
2021-05-19 02:48:15 INFO  TaskSetManager:54 - Finished task 35.2 in stage 7.0 (TID 426) in 17891 ms on hadoop18.cusp.nyu.edu (executor 11) (30/70)
2021-05-19 02:48:16 INFO  YarnSchedulerBackend$YarnDriverEndpoint:54 - Disabling executor 12.
2021-05-19 02:48:16 INFO  DAGScheduler:54 - Executor lost: 12 (epoch 1)
2021-05-19 02:48:16 INFO  BlockManagerMasterEndpoint:54 - Trying to remove executor 12 from BlockManagerMaster.
2021-05-19 02:48:16 INFO  BlockManagerMasterEndpoint:54 - Removing block manager BlockManagerId(12, hadoop06.cusp.nyu.edu, 44467, None)
2021-05-19 02:48:16 INFO  BlockManagerMaster:54 - Removed 12 successfully in removeExecutor
2021-05-19 02:48:16 INFO  YarnAllocator:54 - Completed container container_e10_1609183734776_5900_02_000012 on host: hadoop18.cusp.nyu.edu (state: COMPLETE, exit status: -104)
2021-05-19 02:48:16 WARN  YarnAllocator:66 - Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:48:16 INFO  YarnAllocator:54 - Completed container container_e10_1609183734776_5900_02_000013 on host: hadoop06.cusp.nyu.edu (state: COMPLETE, exit status: -104)
2021-05-19 02:48:16 WARN  YarnSchedulerBackend$YarnSchedulerEndpoint:66 - Requesting driver to remove executor 11 for reason Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:48:16 WARN  YarnAllocator:66 - Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:48:16 ERROR YarnClusterScheduler:70 - Lost executor 11 on hadoop18.cusp.nyu.edu: Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:48:16 WARN  YarnSchedulerBackend$YarnSchedulerEndpoint:66 - Requesting driver to remove executor 12 for reason Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:48:16 WARN  TaskSetManager:66 - Lost task 32.3 in stage 7.0 (TID 423, hadoop18.cusp.nyu.edu, executor 11): ExecutorLostFailure (executor 11 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:48:16 ERROR TaskSetManager:70 - Task 32 in stage 7.0 failed 4 times; aborting job
2021-05-19 02:48:16 WARN  TaskSetManager:66 - Lost task 26.3 in stage 7.0 (TID 425, hadoop18.cusp.nyu.edu, executor 11): ExecutorLostFailure (executor 11 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:48:16 ERROR YarnClusterScheduler:70 - Lost executor 12 on hadoop06.cusp.nyu.edu: Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:48:16 WARN  TaskSetManager:66 - Lost task 18.2 in stage 7.0 (TID 433, hadoop06.cusp.nyu.edu, executor 12): ExecutorLostFailure (executor 12 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:48:16 WARN  TaskSetManager:66 - Lost task 25.2 in stage 7.0 (TID 436, hadoop06.cusp.nyu.edu, executor 12): ExecutorLostFailure (executor 12 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:48:16 WARN  TaskSetManager:66 - Lost task 7.2 in stage 7.0 (TID 439, hadoop06.cusp.nyu.edu, executor 12): ExecutorLostFailure (executor 12 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:48:16 WARN  TaskSetManager:66 - Lost task 0.2 in stage 7.0 (TID 438, hadoop06.cusp.nyu.edu, executor 12): ExecutorLostFailure (executor 12 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:48:16 WARN  TaskSetManager:66 - Lost task 33.2 in stage 7.0 (TID 441, hadoop06.cusp.nyu.edu, executor 12): ExecutorLostFailure (executor 12 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:48:16 WARN  TaskSetManager:66 - Lost task 47.3 in stage 7.0 (TID 432, hadoop06.cusp.nyu.edu, executor 12): ExecutorLostFailure (executor 12 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:48:16 WARN  TaskSetManager:66 - Lost task 39.2 in stage 7.0 (TID 435, hadoop06.cusp.nyu.edu, executor 12): ExecutorLostFailure (executor 12 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:48:16 WARN  TaskSetManager:66 - Lost task 2.2 in stage 7.0 (TID 437, hadoop06.cusp.nyu.edu, executor 12): ExecutorLostFailure (executor 12 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:48:16 WARN  TaskSetManager:66 - Lost task 36.2 in stage 7.0 (TID 440, hadoop06.cusp.nyu.edu, executor 12): ExecutorLostFailure (executor 12 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:48:16 WARN  TaskSetManager:66 - Lost task 17.2 in stage 7.0 (TID 434, hadoop06.cusp.nyu.edu, executor 12): ExecutorLostFailure (executor 12 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:48:16 INFO  BlockManagerMaster:54 - Removal of executor 12 requested
2021-05-19 02:48:16 INFO  BlockManagerMasterEndpoint:54 - Trying to remove executor 12 from BlockManagerMaster.
2021-05-19 02:48:16 INFO  YarnSchedulerBackend$YarnDriverEndpoint:54 - Asked to remove non-existent executor 12
2021-05-19 02:48:16 INFO  YarnClusterScheduler:54 - Cancelling stage 7
2021-05-19 02:48:16 INFO  YarnClusterScheduler:54 - Killing all running tasks in stage 7: Stage cancelled
2021-05-19 02:48:16 INFO  YarnClusterScheduler:54 - Stage 7 was cancelled
2021-05-19 02:48:16 INFO  DAGScheduler:54 - ShuffleMapStage 7 (csv at NativeMethodAccessorImpl.java:0) failed in 57.333 s due to Job aborted due to stage failure: Task 32 in stage 7.0 failed 4 times, most recent failure: Lost task 32.3 in stage 7.0 (TID 423, hadoop18.cusp.nyu.edu, executor 11): ExecutorLostFailure (executor 11 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
Driver stacktrace:
2021-05-19 02:48:16 INFO  DAGScheduler:54 - Executor lost: 11 (epoch 1)
2021-05-19 02:48:16 INFO  DAGScheduler:54 - Job 6 failed: csv at NativeMethodAccessorImpl.java:0, took 57.352034 s
2021-05-19 02:48:16 INFO  BlockManagerMasterEndpoint:54 - Trying to remove executor 11 from BlockManagerMaster.
2021-05-19 02:48:16 INFO  BlockManagerMasterEndpoint:54 - Removing block manager BlockManagerId(11, hadoop18.cusp.nyu.edu, 38556, None)
2021-05-19 02:48:16 INFO  BlockManagerMaster:54 - Removed 11 successfully in removeExecutor
2021-05-19 02:48:16 ERROR FileFormatWriter:91 - Aborting job 3f1962f0-562c-4ac6-ba50-20adf3499f0f.
org.apache.spark.SparkException: Job aborted due to stage failure: Task 32 in stage 7.0 failed 4 times, most recent failure: Lost task 32.3 in stage 7.0 (TID 423, hadoop18.cusp.nyu.edu, executor 11): ExecutorLostFailure (executor 11 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1887)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1875)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1874)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1874)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:926)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2108)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2057)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2046)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:737)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2061)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2082)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2101)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2126)
	at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:945)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:363)
	at org.apache.spark.rdd.RDD.collect(RDD.scala:944)
	at org.apache.spark.RangePartitioner$.sketch(Partitioner.scala:309)
	at org.apache.spark.RangePartitioner.<init>(Partitioner.scala:171)
	at org.apache.spark.sql.execution.exchange.ShuffleExchangeExec$.prepareShuffleDependency(ShuffleExchangeExec.scala:224)
	at org.apache.spark.sql.execution.exchange.ShuffleExchangeExec.prepareShuffleDependency(ShuffleExchangeExec.scala:91)
	at org.apache.spark.sql.execution.exchange.ShuffleExchangeExec$$anonfun$doExecute$1.apply(ShuffleExchangeExec.scala:128)
	at org.apache.spark.sql.execution.exchange.ShuffleExchangeExec$$anonfun$doExecute$1.apply(ShuffleExchangeExec.scala:119)
	at org.apache.spark.sql.catalyst.errors.package$.attachTree(package.scala:52)
	at org.apache.spark.sql.execution.exchange.ShuffleExchangeExec.doExecute(ShuffleExchangeExec.scala:119)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)
	at org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)
	at org.apache.spark.sql.execution.InputAdapter.inputRDDs(WholeStageCodegenExec.scala:374)
	at org.apache.spark.sql.execution.SortExec.inputRDDs(SortExec.scala:121)
	at org.apache.spark.sql.execution.WholeStageCodegenExec.doExecute(WholeStageCodegenExec.scala:610)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)
	at org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)
	at org.apache.spark.sql.execution.columnar.CachedRDDBuilder.buildBuffers(InMemoryRelation.scala:89)
	at org.apache.spark.sql.execution.columnar.CachedRDDBuilder.cachedColumnBuffers(InMemoryRelation.scala:59)
	at org.apache.spark.sql.execution.columnar.InMemoryTableScanExec.filteredCachedBatches(InMemoryTableScanExec.scala:276)
	at org.apache.spark.sql.execution.columnar.InMemoryTableScanExec.inputRDD$lzycompute(InMemoryTableScanExec.scala:105)
	at org.apache.spark.sql.execution.columnar.InMemoryTableScanExec.inputRDD(InMemoryTableScanExec.scala:104)
	at org.apache.spark.sql.execution.columnar.InMemoryTableScanExec.doExecute(InMemoryTableScanExec.scala:310)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)
	at org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)
	at org.apache.spark.sql.execution.InputAdapter.inputRDDs(WholeStageCodegenExec.scala:374)
	at org.apache.spark.sql.execution.FilterExec.inputRDDs(basicPhysicalOperators.scala:121)
	at org.apache.spark.sql.execution.ProjectExec.inputRDDs(basicPhysicalOperators.scala:41)
	at org.apache.spark.sql.execution.WholeStageCodegenExec.doExecute(WholeStageCodegenExec.scala:610)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)
	at org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)
	at org.apache.spark.sql.execution.CoalesceExec.doExecute(basicPhysicalOperators.scala:597)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)
	at org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:143)
	at org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand.run(InsertIntoHadoopFsRelationCommand.scala:159)
	at org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult$lzycompute(commands.scala:104)
	at org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult(commands.scala:102)
	at org.apache.spark.sql.execution.command.DataWritingCommandExec.doExecute(commands.scala:122)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)
	at org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)
	at org.apache.spark.sql.execution.QueryExecution.toRdd$lzycompute(QueryExecution.scala:80)
	at org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:80)
	at org.apache.spark.sql.DataFrameWriter$$anonfun$runCommand$1.apply(DataFrameWriter.scala:668)
	at org.apache.spark.sql.DataFrameWriter$$anonfun$runCommand$1.apply(DataFrameWriter.scala:668)
	at org.apache.spark.sql.execution.SQLExecution$$anonfun$withNewExecutionId$1.apply(SQLExecution.scala:78)
	at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:125)
	at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:73)
	at org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:668)
	at org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:276)
	at org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:270)
	at org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:228)
	at org.apache.spark.sql.DataFrameWriter.csv(DataFrameWriter.scala:656)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:282)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.GatewayConnection.run(GatewayConnection.java:238)
	at java.lang.Thread.run(Thread.java:748)
2021-05-19 02:48:16 WARN  TaskSetManager:66 - Lost task 29.2 in stage 7.0 (TID 455, hadoop13.cusp.nyu.edu, executor 13): TaskKilled (Stage cancelled)
2021-05-19 02:48:16 WARN  TaskSetManager:66 - Lost task 28.2 in stage 7.0 (TID 459, hadoop13.cusp.nyu.edu, executor 13): TaskKilled (Stage cancelled)
2021-05-19 02:48:16 WARN  TaskSetManager:66 - Lost task 43.3 in stage 7.0 (TID 443, hadoop13.cusp.nyu.edu, executor 13): TaskKilled (Stage cancelled)
2021-05-19 02:48:16 WARN  TaskSetManager:66 - Lost task 9.3 in stage 7.0 (TID 442, hadoop13.cusp.nyu.edu, executor 13): TaskKilled (Stage cancelled)
2021-05-19 02:48:16 WARN  TaskSetManager:66 - Lost task 19.2 in stage 7.0 (TID 454, hadoop13.cusp.nyu.edu, executor 13): TaskKilled (Stage cancelled)
2021-05-19 02:48:16 WARN  TaskSetManager:66 - Lost task 24.2 in stage 7.0 (TID 460, hadoop13.cusp.nyu.edu, executor 13): TaskKilled (Stage cancelled)
2021-05-19 02:48:16 WARN  TaskSetManager:66 - Lost task 8.2 in stage 7.0 (TID 457, hadoop13.cusp.nyu.edu, executor 13): TaskKilled (Stage cancelled)
2021-05-19 02:48:16 WARN  TaskSetManager:66 - Lost task 42.2 in stage 7.0 (TID 456, hadoop13.cusp.nyu.edu, executor 13): TaskKilled (Stage cancelled)
2021-05-19 02:48:16 WARN  TaskSetManager:66 - Lost task 12.2 in stage 7.0 (TID 461, hadoop13.cusp.nyu.edu, executor 13): TaskKilled (Stage cancelled)
2021-05-19 02:48:16 WARN  TaskSetManager:66 - Lost task 64.0 in stage 7.0 (TID 452, hadoop17.cusp.nyu.edu, executor 14): TaskKilled (Stage cancelled)
2021-05-19 02:48:16 WARN  TaskSetManager:66 - Lost task 10.2 in stage 7.0 (TID 447, hadoop17.cusp.nyu.edu, executor 14): TaskKilled (Stage cancelled)
2021-05-19 02:48:16 WARN  TaskSetManager:66 - Lost task 69.0 in stage 7.0 (TID 453, hadoop17.cusp.nyu.edu, executor 14): TaskKilled (Stage cancelled)
2021-05-19 02:48:16 WARN  TaskSetManager:66 - Lost task 61.0 in stage 7.0 (TID 451, hadoop17.cusp.nyu.edu, executor 14): TaskKilled (Stage cancelled)
2021-05-19 02:48:16 WARN  TaskSetManager:66 - Lost task 1.2 in stage 7.0 (TID 450, hadoop17.cusp.nyu.edu, executor 14): TaskKilled (Stage cancelled)
2021-05-19 02:48:16 WARN  TaskSetManager:66 - Lost task 30.2 in stage 7.0 (TID 445, hadoop17.cusp.nyu.edu, executor 14): TaskKilled (Stage cancelled)
2021-05-19 02:48:16 WARN  TaskSetManager:66 - Lost task 44.2 in stage 7.0 (TID 449, hadoop17.cusp.nyu.edu, executor 14): TaskKilled (Stage cancelled)
2021-05-19 02:48:16 WARN  TaskSetManager:66 - Lost task 40.2 in stage 7.0 (TID 444, hadoop17.cusp.nyu.edu, executor 14): TaskKilled (Stage cancelled)
2021-05-19 02:48:16 WARN  TaskSetManager:66 - Lost task 3.2 in stage 7.0 (TID 446, hadoop17.cusp.nyu.edu, executor 14): TaskKilled (Stage cancelled)
2021-05-19 02:48:16 WARN  TaskSetManager:66 - Lost task 45.2 in stage 7.0 (TID 448, hadoop17.cusp.nyu.edu, executor 14): TaskKilled (Stage cancelled)
2021-05-19 02:48:16 WARN  TaskSetManager:66 - Lost task 22.2 in stage 7.0 (TID 458, hadoop13.cusp.nyu.edu, executor 13): TaskKilled (Stage cancelled)
2021-05-19 02:48:16 WARN  TaskSetManager:66 - Lost task 6.2 in stage 7.0 (TID 463, hadoop04.cusp.nyu.edu, executor 15): TaskKilled (Stage cancelled)
2021-05-19 02:48:16 WARN  TaskSetManager:66 - Lost task 65.0 in stage 7.0 (TID 466, hadoop04.cusp.nyu.edu, executor 15): TaskKilled (Stage cancelled)
2021-05-19 02:48:16 WARN  TaskSetManager:66 - Lost task 67.0 in stage 7.0 (TID 468, hadoop04.cusp.nyu.edu, executor 15): TaskKilled (Stage cancelled)
2021-05-19 02:48:16 WARN  TaskSetManager:66 - Lost task 66.0 in stage 7.0 (TID 467, hadoop04.cusp.nyu.edu, executor 15): TaskKilled (Stage cancelled)
2021-05-19 02:48:16 WARN  TaskSetManager:66 - Lost task 13.2 in stage 7.0 (TID 462, hadoop04.cusp.nyu.edu, executor 15): TaskKilled (Stage cancelled)
2021-05-19 02:48:16 WARN  TaskSetManager:66 - Lost task 63.0 in stage 7.0 (TID 465, hadoop04.cusp.nyu.edu, executor 15): TaskKilled (Stage cancelled)
2021-05-19 02:48:16 INFO  YarnClusterScheduler:54 - Removed TaskSet 7.0, whose tasks have all completed, from pool 
2021-05-19 02:48:16 WARN  TaskSetManager:66 - Lost task 53.1 in stage 7.0 (TID 464, hadoop04.cusp.nyu.edu, executor 15): TaskKilled (Stage cancelled)
2021-05-19 02:48:16 INFO  YarnClusterScheduler:54 - Removed TaskSet 7.0, whose tasks have all completed, from pool 
2021-05-19 02:48:16 WARN  TaskSetManager:66 - Lost task 68.0 in stage 7.0 (TID 469, hadoop04.cusp.nyu.edu, executor 15): TaskKilled (Stage cancelled)
2021-05-19 02:48:16 INFO  YarnClusterScheduler:54 - Removed TaskSet 7.0, whose tasks have all completed, from pool 
2021-05-19 02:48:16 WARN  TransportChannelHandler:78 - Exception in connection from /192.168.72.188:41908
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileDispatcherImpl.read0(Native Method)
	at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)
	at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:223)
	at sun.nio.ch.IOUtil.read(IOUtil.java:192)
	at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:380)
	at io.netty.buffer.PooledUnsafeDirectByteBuf.setBytes(PooledUnsafeDirectByteBuf.java:288)
	at io.netty.buffer.AbstractByteBuf.writeBytes(AbstractByteBuf.java:1106)
	at io.netty.channel.socket.nio.NioSocketChannel.doReadBytes(NioSocketChannel.java:343)
	at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:123)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:645)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:580)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:497)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:459)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
Traceback (most recent call last):
  File "BDM_HW4.py", line 93, in <module>
    main(sc, spark)
  File "BDM_HW4.py", line 86, in main
    mode='overwrite', header=True)
  File "/localhome/cdp/yarn/nm/usercache/catherine.ng60/appcache/application_1609183734776_5900/container_e10_1609183734776_5900_02_000001/pyspark.zip/pyspark/sql/readwriter.py", line 929, in csv
  File "/localhome/cdp/yarn/nm/usercache/catherine.ng60/appcache/application_1609183734776_5900/container_e10_1609183734776_5900_02_000001/py4j-0.10.7-src.zip/py4j/java_gateway.py", line 1257, in __call__
  File "/localhome/cdp/yarn/nm/usercache/catherine.ng60/appcache/application_1609183734776_5900/container_e10_1609183734776_5900_02_000001/pyspark.zip/pyspark/sql/utils.py", line 63, in deco
  File "/localhome/cdp/yarn/nm/usercache/catherine.ng60/appcache/application_1609183734776_5900/container_e10_1609183734776_5900_02_000001/py4j-0.10.7-src.zip/py4j/protocol.py", line 328, in get_return_value
py4j.protocol.Py4JJavaError: An error occurred while calling o179.csv.
: org.apache.spark.SparkException: Job aborted.
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:196)
	at org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand.run(InsertIntoHadoopFsRelationCommand.scala:159)
	at org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult$lzycompute(commands.scala:104)
	at org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult(commands.scala:102)
	at org.apache.spark.sql.execution.command.DataWritingCommandExec.doExecute(commands.scala:122)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)
	at org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)
	at org.apache.spark.sql.execution.QueryExecution.toRdd$lzycompute(QueryExecution.scala:80)
	at org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:80)
	at org.apache.spark.sql.DataFrameWriter$$anonfun$runCommand$1.apply(DataFrameWriter.scala:668)
	at org.apache.spark.sql.DataFrameWriter$$anonfun$runCommand$1.apply(DataFrameWriter.scala:668)
	at org.apache.spark.sql.execution.SQLExecution$$anonfun$withNewExecutionId$1.apply(SQLExecution.scala:78)
	at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:125)
	at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:73)
	at org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:668)
	at org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:276)
	at org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:270)
	at org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:228)
	at org.apache.spark.sql.DataFrameWriter.csv(DataFrameWriter.scala:656)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:282)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.GatewayConnection.run(GatewayConnection.java:238)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.spark.SparkException: Job aborted due to stage failure: Task 32 in stage 7.0 failed 4 times, most recent failure: Lost task 32.3 in stage 7.0 (TID 423, hadoop18.cusp.nyu.edu, executor 11): ExecutorLostFailure (executor 11 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1887)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1875)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1874)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1874)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:926)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2108)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2057)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2046)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:737)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2061)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2082)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2101)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2126)
	at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:945)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:363)
	at org.apache.spark.rdd.RDD.collect(RDD.scala:944)
	at org.apache.spark.RangePartitioner$.sketch(Partitioner.scala:309)
	at org.apache.spark.RangePartitioner.<init>(Partitioner.scala:171)
	at org.apache.spark.sql.execution.exchange.ShuffleExchangeExec$.prepareShuffleDependency(ShuffleExchangeExec.scala:224)
	at org.apache.spark.sql.execution.exchange.ShuffleExchangeExec.prepareShuffleDependency(ShuffleExchangeExec.scala:91)
	at org.apache.spark.sql.execution.exchange.ShuffleExchangeExec$$anonfun$doExecute$1.apply(ShuffleExchangeExec.scala:128)
	at org.apache.spark.sql.execution.exchange.ShuffleExchangeExec$$anonfun$doExecute$1.apply(ShuffleExchangeExec.scala:119)
	at org.apache.spark.sql.catalyst.errors.package$.attachTree(package.scala:52)
	at org.apache.spark.sql.execution.exchange.ShuffleExchangeExec.doExecute(ShuffleExchangeExec.scala:119)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)
	at org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)
	at org.apache.spark.sql.execution.InputAdapter.inputRDDs(WholeStageCodegenExec.scala:374)
	at org.apache.spark.sql.execution.SortExec.inputRDDs(SortExec.scala:121)
	at org.apache.spark.sql.execution.WholeStageCodegenExec.doExecute(WholeStageCodegenExec.scala:610)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)
	at org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)
	at org.apache.spark.sql.execution.columnar.CachedRDDBuilder.buildBuffers(InMemoryRelation.scala:89)
	at org.apache.spark.sql.execution.columnar.CachedRDDBuilder.cachedColumnBuffers(InMemoryRelation.scala:59)
	at org.apache.spark.sql.execution.columnar.InMemoryTableScanExec.filteredCachedBatches(InMemoryTableScanExec.scala:276)
	at org.apache.spark.sql.execution.columnar.InMemoryTableScanExec.inputRDD$lzycompute(InMemoryTableScanExec.scala:105)
	at org.apache.spark.sql.execution.columnar.InMemoryTableScanExec.inputRDD(InMemoryTableScanExec.scala:104)
	at org.apache.spark.sql.execution.columnar.InMemoryTableScanExec.doExecute(InMemoryTableScanExec.scala:310)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)
	at org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)
	at org.apache.spark.sql.execution.InputAdapter.inputRDDs(WholeStageCodegenExec.scala:374)
	at org.apache.spark.sql.execution.FilterExec.inputRDDs(basicPhysicalOperators.scala:121)
	at org.apache.spark.sql.execution.ProjectExec.inputRDDs(basicPhysicalOperators.scala:41)
	at org.apache.spark.sql.execution.WholeStageCodegenExec.doExecute(WholeStageCodegenExec.scala:610)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)
	at org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)
	at org.apache.spark.sql.execution.CoalesceExec.doExecute(basicPhysicalOperators.scala:597)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)
	at org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:143)
	... 33 more

2021-05-19 02:48:16 ERROR ApplicationMaster:70 - User application exited with status 1
2021-05-19 02:48:16 INFO  ApplicationMaster:54 - Final app status: FAILED, exitCode: 1, (reason: User application exited with status 1)
2021-05-19 02:48:16 INFO  SparkContext:54 - Invoking stop() from shutdown hook
2021-05-19 02:48:16 INFO  AbstractConnector:318 - Stopped Spark@337c3ed2{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2021-05-19 02:48:16 INFO  SparkUI:54 - Stopped Spark web UI at http://hadoop02.cusp.nyu.edu:53810
2021-05-19 02:48:16 INFO  YarnAllocator:54 - Driver requested a total number of 0 executor(s).
2021-05-19 02:48:16 INFO  YarnClusterSchedulerBackend:54 - Shutting down all executors
2021-05-19 02:48:16 INFO  YarnSchedulerBackend$YarnDriverEndpoint:54 - Asking each executor to shut down
2021-05-19 02:48:16 INFO  SchedulerExtensionServices:54 - Stopping SchedulerExtensionServices
(serviceOption=None,
 services=List(),
 started=false)
2021-05-19 02:48:16 INFO  MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!
2021-05-19 02:48:16 INFO  MemoryStore:54 - MemoryStore cleared
2021-05-19 02:48:16 INFO  BlockManager:54 - BlockManager stopped
2021-05-19 02:48:16 INFO  BlockManagerMaster:54 - BlockManagerMaster stopped
2021-05-19 02:48:16 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!
2021-05-19 02:48:16 INFO  SparkContext:54 - Successfully stopped SparkContext
2021-05-19 02:48:16 INFO  ApplicationMaster:54 - Unregistering ApplicationMaster with FAILED (diag message: User application exited with status 1)
2021-05-19 02:48:16 INFO  AMRMClientImpl:382 - Waiting for application to be successfully unregistered.
2021-05-19 02:48:17 INFO  ApplicationMaster:54 - Deleting staging directory hdfs://NameService1/user/catherine.ng60/.sparkStaging/application_1609183734776_5900
2021-05-19 02:48:17 INFO  ShutdownHookManager:54 - Shutdown hook called
2021-05-19 02:48:17 INFO  ShutdownHookManager:54 - Deleting directory /localhome/cdp/yarn/nm/usercache/catherine.ng60/appcache/application_1609183734776_5900/spark-7e513736-a52e-41ae-b728-cb39016e4d02
2021-05-19 02:48:17 INFO  ShutdownHookManager:54 - Deleting directory /localhome/cdp/yarn/nm/usercache/catherine.ng60/appcache/application_1609183734776_5900/spark-7e513736-a52e-41ae-b728-cb39016e4d02/pyspark-c1e867e4-6428-478b-b6b7-e1d74c771a83

End of LogType:stdout
***********************************************************************


End of LogType:prelaunch.err
******************************************************************************

Container: container_e10_1609183734776_5900_01_000015 on hadoop02.cusp.nyu.edu_8041
LogAggregationType: AGGREGATED
===================================================================================
LogType:prelaunch.out
LogLastModifiedTime:Wed May 19 02:48:18 -0400 2021
LogLength:70
LogContents:
Setting up env variables
Setting up job resources
Launching container

End of LogType:prelaunch.out
******************************************************************************

Container: container_e10_1609183734776_5900_01_000015 on hadoop02.cusp.nyu.edu_8041
LogAggregationType: AGGREGATED
===================================================================================
LogType:stderr
LogLastModifiedTime:Wed May 19 02:48:18 -0400 2021
LogLength:529
LogContents:
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/localhome/cdp/yarn/nm/filecache/25/spark-jars-2.4.0-hadoop2.7.jar/slf4j-log4j12-1.7.16.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-6.1.0-1.cdh6.1.0.p0.770702/jars/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]

End of LogType:stderr
***********************************************************************

Container: container_e10_1609183734776_5900_01_000015 on hadoop02.cusp.nyu.edu_8041
LogAggregationType: AGGREGATED
===================================================================================
LogType:stdout
LogLastModifiedTime:Wed May 19 02:48:18 -0400 2021
LogLength:8329
LogContents:
2021-05-19 02:46:34 INFO  CoarseGrainedExecutorBackend:2566 - Started daemon with process name: 17463@hadoop02.cusp.nyu.edu
2021-05-19 02:46:35 INFO  SignalUtils:54 - Registered signal handler for TERM
2021-05-19 02:46:35 INFO  SignalUtils:54 - Registered signal handler for HUP
2021-05-19 02:46:35 INFO  SignalUtils:54 - Registered signal handler for INT
2021-05-19 02:46:35 INFO  SecurityManager:54 - Changing view acls to: catherine.ng60
2021-05-19 02:46:35 INFO  SecurityManager:54 - Changing modify acls to: catherine.ng60
2021-05-19 02:46:35 INFO  SecurityManager:54 - Changing view acls groups to: 
2021-05-19 02:46:35 INFO  SecurityManager:54 - Changing modify acls groups to: 
2021-05-19 02:46:35 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(catherine.ng60); groups with view permissions: Set(); users  with modify permissions: Set(catherine.ng60); groups with modify permissions: Set()
2021-05-19 02:46:36 INFO  TransportClientFactory:267 - Successfully created connection to hadoop05.cusp.nyu.edu/192.168.72.175:47481 after 101 ms (0 ms spent in bootstraps)
2021-05-19 02:46:36 INFO  SecurityManager:54 - Changing view acls to: catherine.ng60
2021-05-19 02:46:36 INFO  SecurityManager:54 - Changing modify acls to: catherine.ng60
2021-05-19 02:46:36 INFO  SecurityManager:54 - Changing view acls groups to: 
2021-05-19 02:46:36 INFO  SecurityManager:54 - Changing modify acls groups to: 
2021-05-19 02:46:36 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(catherine.ng60); groups with view permissions: Set(); users  with modify permissions: Set(catherine.ng60); groups with modify permissions: Set()
2021-05-19 02:46:36 INFO  TransportClientFactory:267 - Successfully created connection to hadoop05.cusp.nyu.edu/192.168.72.175:47481 after 3 ms (0 ms spent in bootstraps)
2021-05-19 02:46:36 INFO  DiskBlockManager:54 - Created local directory at /localhome/cdp/yarn/nm/usercache/catherine.ng60/appcache/application_1609183734776_5900/blockmgr-5ae3c7f9-5ddd-421b-919b-8801646c054d
2021-05-19 02:46:36 INFO  MemoryStore:54 - MemoryStore started with capacity 366.3 MB
2021-05-19 02:46:37 INFO  CoarseGrainedExecutorBackend:54 - Connecting to driver: spark://CoarseGrainedScheduler@hadoop05.cusp.nyu.edu:47481
2021-05-19 02:46:37 INFO  CoarseGrainedExecutorBackend:54 - Successfully registered with driver
2021-05-19 02:46:37 INFO  Executor:54 - Starting executor ID 12 on host hadoop02.cusp.nyu.edu
2021-05-19 02:46:37 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 43020.
2021-05-19 02:46:37 INFO  NettyBlockTransferService:54 - Server created on hadoop02.cusp.nyu.edu:43020
2021-05-19 02:46:37 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2021-05-19 02:46:37 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(12, hadoop02.cusp.nyu.edu, 43020, None)
2021-05-19 02:46:37 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(12, hadoop02.cusp.nyu.edu, 43020, None)
2021-05-19 02:46:37 INFO  BlockManager:54 - external shuffle service port = 7337
2021-05-19 02:46:37 INFO  BlockManager:54 - Registering executor with local external shuffle service.
2021-05-19 02:46:37 INFO  TransportClientFactory:267 - Successfully created connection to hadoop02.cusp.nyu.edu/192.168.72.172:7337 after 3 ms (0 ms spent in bootstraps)
2021-05-19 02:46:37 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(12, hadoop02.cusp.nyu.edu, 43020, None)
2021-05-19 02:46:37 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 435
2021-05-19 02:46:37 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 436
2021-05-19 02:46:37 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 437
2021-05-19 02:46:37 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 438
2021-05-19 02:46:37 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 439
2021-05-19 02:46:37 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 440
2021-05-19 02:46:37 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 441
2021-05-19 02:46:37 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 442
2021-05-19 02:46:37 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 443
2021-05-19 02:46:37 INFO  Executor:54 - Running task 11.2 in stage 7.0 (TID 438)
2021-05-19 02:46:37 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 444
2021-05-19 02:46:37 INFO  Executor:54 - Running task 47.1 in stage 7.0 (TID 439)
2021-05-19 02:46:37 INFO  Executor:54 - Running task 6.2 in stage 7.0 (TID 442)
2021-05-19 02:46:37 INFO  Executor:54 - Running task 34.3 in stage 7.0 (TID 435)
2021-05-19 02:46:37 INFO  Executor:54 - Running task 2.2 in stage 7.0 (TID 440)
2021-05-19 02:46:37 INFO  Executor:54 - Running task 14.3 in stage 7.0 (TID 436)
2021-05-19 02:46:37 INFO  Executor:54 - Running task 26.2 in stage 7.0 (TID 437)
2021-05-19 02:46:37 INFO  Executor:54 - Running task 17.1 in stage 7.0 (TID 441)
2021-05-19 02:46:37 INFO  Executor:54 - Running task 37.3 in stage 7.0 (TID 444)
2021-05-19 02:46:37 INFO  Executor:54 - Running task 8.2 in stage 7.0 (TID 443)
2021-05-19 02:46:37 INFO  MapOutputTrackerWorker:54 - Updating epoch to 1 and clearing cache
2021-05-19 02:46:37 INFO  TorrentBroadcast:54 - Started reading broadcast variable 14
2021-05-19 02:46:37 INFO  TransportClientFactory:267 - Successfully created connection to hadoop05.cusp.nyu.edu/192.168.72.175:36982 after 3 ms (0 ms spent in bootstraps)
2021-05-19 02:46:37 INFO  MemoryStore:54 - Block broadcast_14_piece0 stored as bytes in memory (estimated size 22.9 KB, free 366.3 MB)
2021-05-19 02:46:37 INFO  TorrentBroadcast:54 - Reading broadcast variable 14 took 117 ms
2021-05-19 02:46:38 INFO  MemoryStore:54 - Block broadcast_14 stored as values in memory (estimated size 51.5 KB, free 366.2 MB)
2021-05-19 02:46:39 INFO  CodeGenerator:54 - Code generated in 410.61102 ms
2021-05-19 02:46:39 INFO  TorrentBroadcast:54 - Started reading broadcast variable 12
2021-05-19 02:46:39 INFO  MemoryStore:54 - Block broadcast_12_piece0 stored as bytes in memory (estimated size 580.1 KB, free 365.7 MB)
2021-05-19 02:46:39 INFO  TorrentBroadcast:54 - Reading broadcast variable 12 took 34 ms
2021-05-19 02:46:39 INFO  MemoryStore:54 - Block broadcast_12 stored as values in memory (estimated size 5.0 MB, free 360.7 MB)
2021-05-19 02:46:39 INFO  CodeGenerator:54 - Code generated in 27.493699 ms
2021-05-19 02:46:39 INFO  Executor:54 - Executor is trying to kill task 26.2 in stage 7.0 (TID 437), reason: Stage cancelled
2021-05-19 02:46:39 INFO  Executor:54 - Executor is trying to kill task 11.2 in stage 7.0 (TID 438), reason: Stage cancelled
2021-05-19 02:46:39 INFO  Executor:54 - Executor is trying to kill task 37.3 in stage 7.0 (TID 444), reason: Stage cancelled
2021-05-19 02:46:39 INFO  Executor:54 - Executor is trying to kill task 47.1 in stage 7.0 (TID 439), reason: Stage cancelled
2021-05-19 02:46:39 INFO  Executor:54 - Executor is trying to kill task 2.2 in stage 7.0 (TID 440), reason: Stage cancelled
2021-05-19 02:46:39 INFO  Executor:54 - Executor is trying to kill task 17.1 in stage 7.0 (TID 441), reason: Stage cancelled
2021-05-19 02:46:39 INFO  Executor:54 - Executor is trying to kill task 6.2 in stage 7.0 (TID 442), reason: Stage cancelled
2021-05-19 02:46:39 INFO  Executor:54 - Executor is trying to kill task 8.2 in stage 7.0 (TID 443), reason: Stage cancelled
2021-05-19 02:46:39 INFO  Executor:54 - Executor is trying to kill task 34.3 in stage 7.0 (TID 435), reason: Stage cancelled
2021-05-19 02:46:39 INFO  Executor:54 - Executor is trying to kill task 14.3 in stage 7.0 (TID 436), reason: Stage cancelled
2021-05-19 02:46:40 INFO  CoarseGrainedExecutorBackend:54 - Driver commanded a shutdown
2021-05-19 02:46:40 INFO  MemoryStore:54 - MemoryStore cleared
2021-05-19 02:46:40 INFO  BlockManager:54 - BlockManager stopped
2021-05-19 02:46:40 INFO  ShutdownHookManager:54 - Shutdown hook called
2021-05-19 02:46:40 INFO  ShutdownHookManager:54 - Deleting directory /localhome/cdp/yarn/nm/usercache/catherine.ng60/appcache/application_1609183734776_5900/spark-787edef9-a866-4e12-8fb9-8dcc7f944c09

End of LogType:stdout
***********************************************************************

Container: container_e10_1609183734776_5900_01_000007 on hadoop02.cusp.nyu.edu_8041
LogAggregationType: AGGREGATED
===================================================================================
LogType:container-localizer-syslog
LogLastModifiedTime:Wed May 19 02:48:18 -0400 2021
LogLength:506
LogContents:
2021-05-19 02:46:10,535 INFO [main] org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ContainerLocalizer: Disk Validator: yarn.nodemanager.disk-validator is loaded.
2021-05-19 02:46:11,865 WARN [ContainerLocalizer Downloader] org.apache.hadoop.ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ipc.StandbyException): Operation category READ is not supported in state standby. Visit https://s.apache.org/sbnn-error

End of LogType:container-localizer-syslog
*******************************************************************************************


End of LogType:prelaunch.err
******************************************************************************

Container: container_e10_1609183734776_5900_01_000007 on hadoop02.cusp.nyu.edu_8041
LogAggregationType: AGGREGATED
===================================================================================
LogType:prelaunch.out
LogLastModifiedTime:Wed May 19 02:48:18 -0400 2021
LogLength:70
LogContents:
Setting up env variables
Setting up job resources
Launching container

End of LogType:prelaunch.out
******************************************************************************

Container: container_e10_1609183734776_5900_01_000007 on hadoop02.cusp.nyu.edu_8041
LogAggregationType: AGGREGATED
===================================================================================
LogType:stderr
LogLastModifiedTime:Wed May 19 02:48:18 -0400 2021
LogLength:529
LogContents:
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/localhome/cdp/yarn/nm/filecache/25/spark-jars-2.4.0-hadoop2.7.jar/slf4j-log4j12-1.7.16.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-6.1.0-1.cdh6.1.0.p0.770702/jars/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]

End of LogType:stderr
***********************************************************************

Container: container_e10_1609183734776_5900_01_000007 on hadoop02.cusp.nyu.edu_8041
LogAggregationType: AGGREGATED
===================================================================================
LogType:stdout
LogLastModifiedTime:Wed May 19 02:48:18 -0400 2021
LogLength:20347
LogContents:
2021-05-19 02:46:13 INFO  CoarseGrainedExecutorBackend:2566 - Started daemon with process name: 17189@hadoop02.cusp.nyu.edu
2021-05-19 02:46:13 INFO  SignalUtils:54 - Registered signal handler for TERM
2021-05-19 02:46:13 INFO  SignalUtils:54 - Registered signal handler for HUP
2021-05-19 02:46:13 INFO  SignalUtils:54 - Registered signal handler for INT
2021-05-19 02:46:14 INFO  SecurityManager:54 - Changing view acls to: catherine.ng60
2021-05-19 02:46:14 INFO  SecurityManager:54 - Changing modify acls to: catherine.ng60
2021-05-19 02:46:14 INFO  SecurityManager:54 - Changing view acls groups to: 
2021-05-19 02:46:14 INFO  SecurityManager:54 - Changing modify acls groups to: 
2021-05-19 02:46:14 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(catherine.ng60); groups with view permissions: Set(); users  with modify permissions: Set(catherine.ng60); groups with modify permissions: Set()
2021-05-19 02:46:14 INFO  TransportClientFactory:267 - Successfully created connection to hadoop05.cusp.nyu.edu/192.168.72.175:47481 after 97 ms (0 ms spent in bootstraps)
2021-05-19 02:46:14 INFO  SecurityManager:54 - Changing view acls to: catherine.ng60
2021-05-19 02:46:14 INFO  SecurityManager:54 - Changing modify acls to: catherine.ng60
2021-05-19 02:46:14 INFO  SecurityManager:54 - Changing view acls groups to: 
2021-05-19 02:46:14 INFO  SecurityManager:54 - Changing modify acls groups to: 
2021-05-19 02:46:14 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(catherine.ng60); groups with view permissions: Set(); users  with modify permissions: Set(catherine.ng60); groups with modify permissions: Set()
2021-05-19 02:46:15 INFO  TransportClientFactory:267 - Successfully created connection to hadoop05.cusp.nyu.edu/192.168.72.175:47481 after 4 ms (0 ms spent in bootstraps)
2021-05-19 02:46:15 INFO  DiskBlockManager:54 - Created local directory at /localhome/cdp/yarn/nm/usercache/catherine.ng60/appcache/application_1609183734776_5900/blockmgr-9e22d640-5156-4a34-8397-ecbe191917c5
2021-05-19 02:46:15 INFO  MemoryStore:54 - MemoryStore started with capacity 366.3 MB
2021-05-19 02:46:15 INFO  CoarseGrainedExecutorBackend:54 - Connecting to driver: spark://CoarseGrainedScheduler@hadoop05.cusp.nyu.edu:47481
2021-05-19 02:46:15 INFO  CoarseGrainedExecutorBackend:54 - Successfully registered with driver
2021-05-19 02:46:15 INFO  Executor:54 - Starting executor ID 6 on host hadoop02.cusp.nyu.edu
2021-05-19 02:46:15 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 45477.
2021-05-19 02:46:15 INFO  NettyBlockTransferService:54 - Server created on hadoop02.cusp.nyu.edu:45477
2021-05-19 02:46:15 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2021-05-19 02:46:15 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(6, hadoop02.cusp.nyu.edu, 45477, None)
2021-05-19 02:46:15 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(6, hadoop02.cusp.nyu.edu, 45477, None)
2021-05-19 02:46:15 INFO  BlockManager:54 - external shuffle service port = 7337
2021-05-19 02:46:15 INFO  BlockManager:54 - Registering executor with local external shuffle service.
2021-05-19 02:46:15 INFO  TransportClientFactory:267 - Successfully created connection to hadoop02.cusp.nyu.edu/192.168.72.172:7337 after 3 ms (0 ms spent in bootstraps)
2021-05-19 02:46:15 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(6, hadoop02.cusp.nyu.edu, 45477, None)
2021-05-19 02:46:15 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 387
2021-05-19 02:46:15 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 388
2021-05-19 02:46:15 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 389
2021-05-19 02:46:15 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 390
2021-05-19 02:46:15 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 391
2021-05-19 02:46:15 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 392
2021-05-19 02:46:15 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 393
2021-05-19 02:46:15 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 394
2021-05-19 02:46:15 INFO  Executor:54 - Running task 14.1 in stage 7.0 (TID 387)
2021-05-19 02:46:15 INFO  Executor:54 - Running task 8.1 in stage 7.0 (TID 388)
2021-05-19 02:46:15 INFO  Executor:54 - Running task 26.0 in stage 7.0 (TID 394)
2021-05-19 02:46:15 INFO  Executor:54 - Running task 2.1 in stage 7.0 (TID 392)
2021-05-19 02:46:15 INFO  Executor:54 - Running task 17.0 in stage 7.0 (TID 393)
2021-05-19 02:46:15 INFO  Executor:54 - Running task 6.1 in stage 7.0 (TID 390)
2021-05-19 02:46:15 INFO  Executor:54 - Running task 11.1 in stage 7.0 (TID 389)
2021-05-19 02:46:15 INFO  Executor:54 - Running task 45.1 in stage 7.0 (TID 391)
2021-05-19 02:46:15 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 395
2021-05-19 02:46:15 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 396
2021-05-19 02:46:15 INFO  Executor:54 - Running task 47.0 in stage 7.0 (TID 395)
2021-05-19 02:46:15 INFO  Executor:54 - Running task 49.0 in stage 7.0 (TID 396)
2021-05-19 02:46:15 INFO  MapOutputTrackerWorker:54 - Updating epoch to 1 and clearing cache
2021-05-19 02:46:15 INFO  TorrentBroadcast:54 - Started reading broadcast variable 14
2021-05-19 02:46:15 INFO  TransportClientFactory:267 - Successfully created connection to hadoop07.cusp.nyu.edu/192.168.72.177:35847 after 2 ms (0 ms spent in bootstraps)
2021-05-19 02:46:16 INFO  MemoryStore:54 - Block broadcast_14_piece0 stored as bytes in memory (estimated size 22.9 KB, free 366.3 MB)
2021-05-19 02:46:16 INFO  TorrentBroadcast:54 - Reading broadcast variable 14 took 168 ms
2021-05-19 02:46:16 INFO  MemoryStore:54 - Block broadcast_14 stored as values in memory (estimated size 51.5 KB, free 366.2 MB)
2021-05-19 02:46:17 INFO  CodeGenerator:54 - Code generated in 411.085344 ms
2021-05-19 02:46:17 INFO  TorrentBroadcast:54 - Started reading broadcast variable 12
2021-05-19 02:46:17 INFO  MemoryStore:54 - Block broadcast_12_piece0 stored as bytes in memory (estimated size 580.1 KB, free 365.7 MB)
2021-05-19 02:46:17 INFO  TorrentBroadcast:54 - Reading broadcast variable 12 took 34 ms
2021-05-19 02:46:17 INFO  MemoryStore:54 - Block broadcast_12 stored as values in memory (estimated size 5.0 MB, free 360.7 MB)
2021-05-19 02:46:18 INFO  CodeGenerator:54 - Code generated in 35.960279 ms
2021-05-19 02:46:18 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00026, range: 0-134217728, partition values: [empty row]
2021-05-19 02:46:18 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00011, range: 0-134217728, partition values: [empty row]
2021-05-19 02:46:18 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00014, range: 0-134217728, partition values: [empty row]
2021-05-19 02:46:18 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00006, range: 0-134217728, partition values: [empty row]
2021-05-19 02:46:18 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00017, range: 0-134217728, partition values: [empty row]
2021-05-19 02:46:18 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00002, range: 0-134217728, partition values: [empty row]
2021-05-19 02:46:18 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00008, range: 0-134217728, partition values: [empty row]
2021-05-19 02:46:18 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00047, range: 0-134217728, partition values: [empty row]
2021-05-19 02:46:18 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00008, range: 134217728-179381693, partition values: [empty row]
2021-05-19 02:46:18 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00045, range: 0-134217728, partition values: [empty row]
2021-05-19 02:46:19 INFO  CodeGenerator:54 - Code generated in 59.961475 ms
2021-05-19 02:46:19 INFO  TorrentBroadcast:54 - Started reading broadcast variable 13
2021-05-19 02:46:19 INFO  TransportClientFactory:267 - Successfully created connection to hadoop05.cusp.nyu.edu/192.168.72.175:36982 after 6 ms (0 ms spent in bootstraps)
2021-05-19 02:46:19 INFO  MemoryStore:54 - Block broadcast_13_piece0 stored as bytes in memory (estimated size 33.4 KB, free 360.6 MB)
2021-05-19 02:46:19 INFO  CodeGenerator:54 - Code generated in 66.742044 ms
2021-05-19 02:46:19 INFO  TorrentBroadcast:54 - Reading broadcast variable 13 took 46 ms
2021-05-19 02:46:19 INFO  CodeGenerator:54 - Code generated in 63.871253 ms
2021-05-19 02:46:19 INFO  CodeGenerator:54 - Code generated in 53.646829 ms
2021-05-19 02:46:19 INFO  CodeGenerator:54 - Code generated in 37.422802 ms
2021-05-19 02:46:19 INFO  MemoryStore:54 - Block broadcast_13 stored as values in memory (estimated size 506.4 KB, free 360.1 MB)
2021-05-19 02:46:20 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: 226-223@627-wgt-z2k, 2018-12-31T00:00:00-05:00, [0,0,0,0,2,0,0]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: 226-223@627-wgt-z2k
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00002
2021-05-19 02:46:20 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: 237-224@627-rwx-wtv, 2018-12-31T00:00:00-05:00, [1,0,12,14,0,4,4]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: 237-224@627-rwx-wtv
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00006
2021-05-19 02:46:20 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: 238-222@627-s8g-tqf, 2018-12-31T00:00:00-05:00, [0,2,2,4,2,2,2]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: 238-222@627-s8g-tqf
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00011
2021-05-19 02:46:20 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: 22n-224@627-wc7-qfz, 2018-12-31T00:00:00-05:00, [4,2,14,28,22,22,26]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: 22n-224@627-wc7-qfz
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00008
2021-05-19 02:46:20 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: 222-222@627-wgb-qxq, 2019-01-07T00:00:00-05:00, [408,482,574,546,236,93,103]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: 222-222@627-wgb-qxq
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00014
2021-05-19 02:46:20 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: 222-222@627-vsg-8n5, 2020-05-04T00:00:00-04:00, [3,1,2,2,5,3,2]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: 222-222@627-vsg-8n5
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00047
2021-05-19 02:46:20 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: 22r-222@627-vvk-swk, 2019-11-18T00:00:00-05:00, [7,32,20,27,42,29,34]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: 22r-222@627-vvk-swk
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00045
2021-05-19 02:46:20 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: 22h-223@627-s84-6hq, 2019-08-05T00:00:00-04:00, [2,2,0,2,1,3,1]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: 22h-223@627-s84-6hq
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00026
2021-05-19 02:46:20 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: 227-224@627-s6m-yn5, 2020-06-15T00:00:00-04:00, [1,1,4,4,3,1,6]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: 227-224@627-s6m-yn5
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00017
2021-05-19 02:46:21 INFO  CodeGenerator:54 - Code generated in 20.437768 ms
2021-05-19 02:46:21 INFO  CodeGenerator:54 - Code generated in 43.129115 ms
2021-05-19 02:46:21 INFO  CodeGenerator:54 - Code generated in 26.863925 ms
2021-05-19 02:46:22 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:46:22 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:46:22 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:46:22 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:46:22 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:46:22 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:46:22 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:46:22 INFO  CodeGenerator:54 - Code generated in 38.557109 ms
2021-05-19 02:46:22 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:46:22 INFO  CodeGenerator:54 - Code generated in 26.930723 ms
2021-05-19 02:46:22 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:46:22 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:46:22 INFO  CodeGenerator:54 - Code generated in 23.712286 ms
2021-05-19 02:46:22 INFO  CodeGenerator:54 - Code generated in 19.530481 ms
2021-05-19 02:46:23 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00002, range: 134217728-179368669, partition values: [empty row]
2021-05-19 02:46:31 INFO  PythonUDFRunner:54 - Times: total = 13495, boot = 760, init = 2567, finish = 10168
2021-05-19 02:46:32 INFO  CodeGenerator:54 - Code generated in 27.58156 ms
2021-05-19 02:46:32 INFO  PythonUDFRunner:54 - Times: total = 13982, boot = 719, init = 2623, finish = 10640
2021-05-19 02:46:32 INFO  PythonUDFRunner:54 - Times: total = 14041, boot = 738, init = 2602, finish = 10701
2021-05-19 02:46:32 INFO  PythonUDFRunner:54 - Times: total = 14097, boot = 750, init = 2596, finish = 10751
2021-05-19 02:46:32 INFO  Executor:54 - Finished task 49.0 in stage 7.0 (TID 396). 4313 bytes result sent to driver
2021-05-19 02:46:32 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 427
2021-05-19 02:46:32 INFO  Executor:54 - Running task 37.2 in stage 7.0 (TID 427)
2021-05-19 02:46:32 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00037, range: 0-134217728, partition values: [empty row]
2021-05-19 02:46:32 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: zzy-222@627-wf8-59f, 2019-07-08T00:00:00-04:00, [0,5,1,0,6,2,4]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: zzy-222@627-wf8-59f
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00037
2021-05-19 02:46:32 INFO  PythonUDFRunner:54 - Times: total = 14444, boot = 690, init = 2648, finish = 11106
2021-05-19 02:46:32 INFO  PythonUDFRunner:54 - Times: total = 14503, boot = 699, init = 2639, finish = 11165
2021-05-19 02:46:32 ERROR CoarseGrainedExecutorBackend:43 - RECEIVED SIGNAL TERM
2021-05-19 02:46:32 INFO  DiskBlockManager:54 - Shutdown hook called
2021-05-19 02:46:32 INFO  ShutdownHookManager:54 - Shutdown hook called
2021-05-19 02:46:32 INFO  ShutdownHookManager:54 - Deleting directory /localhome/cdp/yarn/nm/usercache/catherine.ng60/appcache/application_1609183734776_5900/spark-89e22740-8d3c-4fef-a496-3ee91c034ec7
2021-05-19 02:46:33 ERROR TaskContextImpl:91 - Error in TaskCompletionListener
java.io.IOException: Filesystem closed
	at org.apache.hadoop.hdfs.DFSClient.checkOpen(DFSClient.java:808)
	at org.apache.hadoop.hdfs.DFSInputStream.close(DFSInputStream.java:710)
	at java.io.FilterInputStream.close(FilterInputStream.java:181)
	at org.apache.hadoop.util.LineReader.close(LineReader.java:150)
	at org.apache.hadoop.mapreduce.lib.input.LineRecordReader.close(LineRecordReader.java:231)
	at org.apache.spark.sql.execution.datasources.RecordReaderIterator.close(RecordReaderIterator.scala:62)
	at org.apache.spark.sql.execution.datasources.HadoopFileLinesReader.close(HadoopFileLinesReader.scala:73)
	at org.apache.spark.sql.execution.datasources.csv.TextInputCSVDataSource$$anonfun$4$$anonfun$apply$2.apply(CSVDataSource.scala:200)
	at org.apache.spark.sql.execution.datasources.csv.TextInputCSVDataSource$$anonfun$4$$anonfun$apply$2.apply(CSVDataSource.scala:200)
	at org.apache.spark.TaskContext$$anon$1.onTaskCompletion(TaskContext.scala:131)
	at org.apache.spark.TaskContextImpl$$anonfun$markTaskCompleted$1.apply(TaskContextImpl.scala:117)
	at org.apache.spark.TaskContextImpl$$anonfun$markTaskCompleted$1.apply(TaskContextImpl.scala:117)
	at org.apache.spark.TaskContextImpl$$anonfun$invokeListeners$1.apply(TaskContextImpl.scala:130)
	at org.apache.spark.TaskContextImpl$$anonfun$invokeListeners$1.apply(TaskContextImpl.scala:128)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.TaskContextImpl.invokeListeners(TaskContextImpl.scala:128)
	at org.apache.spark.TaskContextImpl.markTaskCompleted(TaskContextImpl.scala:116)
	at org.apache.spark.scheduler.Task.run(Task.scala:131)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:402)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:408)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)

End of LogType:stdout
***********************************************************************


End of LogType:prelaunch.err
******************************************************************************

Container: container_e10_1609183734776_5900_02_000004 on hadoop04.cusp.nyu.edu_8041
LogAggregationType: AGGREGATED
===================================================================================
LogType:prelaunch.out
LogLastModifiedTime:Wed May 19 02:48:18 -0400 2021
LogLength:70
LogContents:
Setting up env variables
Setting up job resources
Launching container

End of LogType:prelaunch.out
******************************************************************************

Container: container_e10_1609183734776_5900_02_000004 on hadoop04.cusp.nyu.edu_8041
LogAggregationType: AGGREGATED
===================================================================================
LogType:stderr
LogLastModifiedTime:Wed May 19 02:48:18 -0400 2021
LogLength:529
LogContents:
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/localhome/cdp/yarn/nm/filecache/26/spark-jars-2.4.0-hadoop2.7.jar/slf4j-log4j12-1.7.16.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-6.1.0-1.cdh6.1.0.p0.770702/jars/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]

End of LogType:stderr
***********************************************************************

Container: container_e10_1609183734776_5900_02_000004 on hadoop04.cusp.nyu.edu_8041
LogAggregationType: AGGREGATED
===================================================================================
LogType:stdout
LogLastModifiedTime:Wed May 19 02:48:18 -0400 2021
LogLength:31722
LogContents:
2021-05-19 02:46:52 INFO  CoarseGrainedExecutorBackend:2566 - Started daemon with process name: 21900@hadoop04.cusp.nyu.edu
2021-05-19 02:46:52 INFO  SignalUtils:54 - Registered signal handler for TERM
2021-05-19 02:46:52 INFO  SignalUtils:54 - Registered signal handler for HUP
2021-05-19 02:46:52 INFO  SignalUtils:54 - Registered signal handler for INT
2021-05-19 02:46:53 INFO  SecurityManager:54 - Changing view acls to: catherine.ng60
2021-05-19 02:46:53 INFO  SecurityManager:54 - Changing modify acls to: catherine.ng60
2021-05-19 02:46:53 INFO  SecurityManager:54 - Changing view acls groups to: 
2021-05-19 02:46:53 INFO  SecurityManager:54 - Changing modify acls groups to: 
2021-05-19 02:46:53 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(catherine.ng60); groups with view permissions: Set(); users  with modify permissions: Set(catherine.ng60); groups with modify permissions: Set()
2021-05-19 02:46:54 INFO  TransportClientFactory:267 - Successfully created connection to hadoop02.cusp.nyu.edu/192.168.72.172:60108 after 106 ms (0 ms spent in bootstraps)
2021-05-19 02:46:54 INFO  SecurityManager:54 - Changing view acls to: catherine.ng60
2021-05-19 02:46:54 INFO  SecurityManager:54 - Changing modify acls to: catherine.ng60
2021-05-19 02:46:54 INFO  SecurityManager:54 - Changing view acls groups to: 
2021-05-19 02:46:54 INFO  SecurityManager:54 - Changing modify acls groups to: 
2021-05-19 02:46:54 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(catherine.ng60); groups with view permissions: Set(); users  with modify permissions: Set(catherine.ng60); groups with modify permissions: Set()
2021-05-19 02:46:54 INFO  TransportClientFactory:267 - Successfully created connection to hadoop02.cusp.nyu.edu/192.168.72.172:60108 after 4 ms (0 ms spent in bootstraps)
2021-05-19 02:46:54 INFO  DiskBlockManager:54 - Created local directory at /localhome/cdp/yarn/nm/usercache/catherine.ng60/appcache/application_1609183734776_5900/blockmgr-37d7638d-0785-4219-bf4e-6a2acf6da832
2021-05-19 02:46:55 INFO  MemoryStore:54 - MemoryStore started with capacity 366.3 MB
2021-05-19 02:46:55 INFO  CoarseGrainedExecutorBackend:54 - Connecting to driver: spark://CoarseGrainedScheduler@hadoop02.cusp.nyu.edu:60108
2021-05-19 02:46:55 INFO  CoarseGrainedExecutorBackend:54 - Successfully registered with driver
2021-05-19 02:46:55 INFO  Executor:54 - Starting executor ID 3 on host hadoop04.cusp.nyu.edu
2021-05-19 02:46:55 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 41664.
2021-05-19 02:46:55 INFO  NettyBlockTransferService:54 - Server created on hadoop04.cusp.nyu.edu:41664
2021-05-19 02:46:55 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2021-05-19 02:46:55 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(3, hadoop04.cusp.nyu.edu, 41664, None)
2021-05-19 02:46:55 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(3, hadoop04.cusp.nyu.edu, 41664, None)
2021-05-19 02:46:55 INFO  BlockManager:54 - external shuffle service port = 7337
2021-05-19 02:46:55 INFO  BlockManager:54 - Registering executor with local external shuffle service.
2021-05-19 02:46:55 INFO  TransportClientFactory:267 - Successfully created connection to hadoop04.cusp.nyu.edu/192.168.72.174:7337 after 3 ms (0 ms spent in bootstraps)
2021-05-19 02:46:55 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(3, hadoop04.cusp.nyu.edu, 41664, None)
2021-05-19 02:47:04 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 2
2021-05-19 02:47:04 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 7
2021-05-19 02:47:04 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 12
2021-05-19 02:47:04 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 17
2021-05-19 02:47:04 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 22
2021-05-19 02:47:04 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 27
2021-05-19 02:47:04 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 32
2021-05-19 02:47:04 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 37
2021-05-19 02:47:04 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 42
2021-05-19 02:47:04 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 47
2021-05-19 02:47:04 INFO  Executor:54 - Running task 31.0 in stage 1.0 (TID 32)
2021-05-19 02:47:04 INFO  Executor:54 - Running task 26.0 in stage 1.0 (TID 27)
2021-05-19 02:47:04 INFO  Executor:54 - Running task 11.0 in stage 1.0 (TID 12)
2021-05-19 02:47:04 INFO  Executor:54 - Running task 21.0 in stage 1.0 (TID 22)
2021-05-19 02:47:04 INFO  Executor:54 - Running task 16.0 in stage 1.0 (TID 17)
2021-05-19 02:47:04 INFO  Executor:54 - Running task 41.0 in stage 1.0 (TID 42)
2021-05-19 02:47:04 INFO  Executor:54 - Running task 36.0 in stage 1.0 (TID 37)
2021-05-19 02:47:04 INFO  Executor:54 - Running task 46.0 in stage 1.0 (TID 47)
2021-05-19 02:47:04 INFO  Executor:54 - Running task 1.0 in stage 1.0 (TID 2)
2021-05-19 02:47:04 INFO  Executor:54 - Running task 6.0 in stage 1.0 (TID 7)
2021-05-19 02:47:05 INFO  TorrentBroadcast:54 - Started reading broadcast variable 3
2021-05-19 02:47:05 INFO  TransportClientFactory:267 - Successfully created connection to hadoop02.cusp.nyu.edu/192.168.72.172:49352 after 6 ms (0 ms spent in bootstraps)
2021-05-19 02:47:05 INFO  MemoryStore:54 - Block broadcast_3_piece0 stored as bytes in memory (estimated size 35.0 KB, free 366.3 MB)
2021-05-19 02:47:05 INFO  TorrentBroadcast:54 - Reading broadcast variable 3 took 157 ms
2021-05-19 02:47:05 INFO  MemoryStore:54 - Block broadcast_3 stored as values in memory (estimated size 129.0 KB, free 366.1 MB)
2021-05-19 02:47:07 INFO  Executor:54 - Finished task 6.0 in stage 1.0 (TID 7). 1492 bytes result sent to driver
2021-05-19 02:47:07 INFO  Executor:54 - Finished task 11.0 in stage 1.0 (TID 12). 1492 bytes result sent to driver
2021-05-19 02:47:07 INFO  Executor:54 - Finished task 31.0 in stage 1.0 (TID 32). 1492 bytes result sent to driver
2021-05-19 02:47:07 INFO  Executor:54 - Finished task 21.0 in stage 1.0 (TID 22). 1492 bytes result sent to driver
2021-05-19 02:47:07 INFO  Executor:54 - Finished task 26.0 in stage 1.0 (TID 27). 1492 bytes result sent to driver
2021-05-19 02:47:07 INFO  Executor:54 - Finished task 46.0 in stage 1.0 (TID 47). 1492 bytes result sent to driver
2021-05-19 02:47:07 INFO  Executor:54 - Finished task 36.0 in stage 1.0 (TID 37). 1492 bytes result sent to driver
2021-05-19 02:47:07 INFO  Executor:54 - Finished task 1.0 in stage 1.0 (TID 2). 1492 bytes result sent to driver
2021-05-19 02:47:07 INFO  Executor:54 - Finished task 41.0 in stage 1.0 (TID 42). 1492 bytes result sent to driver
2021-05-19 02:47:07 INFO  Executor:54 - Finished task 16.0 in stage 1.0 (TID 17). 1492 bytes result sent to driver
2021-05-19 02:47:08 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 54
2021-05-19 02:47:08 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 59
2021-05-19 02:47:08 INFO  Executor:54 - Running task 3.0 in stage 2.0 (TID 54)
2021-05-19 02:47:08 INFO  Executor:54 - Running task 8.0 in stage 2.0 (TID 59)
2021-05-19 02:47:08 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 64
2021-05-19 02:47:08 INFO  Executor:54 - Running task 13.0 in stage 2.0 (TID 64)
2021-05-19 02:47:08 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 69
2021-05-19 02:47:08 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 74
2021-05-19 02:47:08 INFO  Executor:54 - Running task 18.0 in stage 2.0 (TID 69)
2021-05-19 02:47:08 INFO  Executor:54 - Running task 23.0 in stage 2.0 (TID 74)
2021-05-19 02:47:08 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 79
2021-05-19 02:47:08 INFO  Executor:54 - Running task 28.0 in stage 2.0 (TID 79)
2021-05-19 02:47:08 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 84
2021-05-19 02:47:08 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 89
2021-05-19 02:47:08 INFO  Executor:54 - Running task 33.0 in stage 2.0 (TID 84)
2021-05-19 02:47:08 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 94
2021-05-19 02:47:08 INFO  Executor:54 - Running task 38.0 in stage 2.0 (TID 89)
2021-05-19 02:47:08 INFO  Executor:54 - Running task 43.0 in stage 2.0 (TID 94)
2021-05-19 02:47:08 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 99
2021-05-19 02:47:08 INFO  Executor:54 - Running task 48.0 in stage 2.0 (TID 99)
2021-05-19 02:47:08 INFO  TorrentBroadcast:54 - Started reading broadcast variable 4
2021-05-19 02:47:08 INFO  MemoryStore:54 - Block broadcast_4_piece0 stored as bytes in memory (estimated size 35.0 KB, free 366.1 MB)
2021-05-19 02:47:08 INFO  TorrentBroadcast:54 - Reading broadcast variable 4 took 22 ms
2021-05-19 02:47:08 INFO  MemoryStore:54 - Block broadcast_4 stored as values in memory (estimated size 129.0 KB, free 366.0 MB)
2021-05-19 02:47:08 INFO  Executor:54 - Finished task 13.0 in stage 2.0 (TID 64). 1449 bytes result sent to driver
2021-05-19 02:47:08 INFO  Executor:54 - Finished task 23.0 in stage 2.0 (TID 74). 1449 bytes result sent to driver
2021-05-19 02:47:08 INFO  Executor:54 - Finished task 28.0 in stage 2.0 (TID 79). 1449 bytes result sent to driver
2021-05-19 02:47:08 INFO  Executor:54 - Finished task 33.0 in stage 2.0 (TID 84). 1449 bytes result sent to driver
2021-05-19 02:47:08 INFO  Executor:54 - Finished task 43.0 in stage 2.0 (TID 94). 1449 bytes result sent to driver
2021-05-19 02:47:08 INFO  Executor:54 - Finished task 48.0 in stage 2.0 (TID 99). 1449 bytes result sent to driver
2021-05-19 02:47:08 INFO  Executor:54 - Finished task 8.0 in stage 2.0 (TID 59). 1449 bytes result sent to driver
2021-05-19 02:47:08 INFO  Executor:54 - Finished task 18.0 in stage 2.0 (TID 69). 1449 bytes result sent to driver
2021-05-19 02:47:08 INFO  Executor:54 - Finished task 3.0 in stage 2.0 (TID 54). 1449 bytes result sent to driver
2021-05-19 02:47:08 INFO  Executor:54 - Finished task 38.0 in stage 2.0 (TID 89). 1449 bytes result sent to driver
2021-05-19 02:47:14 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 118
2021-05-19 02:47:14 INFO  Executor:54 - Running task 0.0 in stage 5.0 (TID 118)
2021-05-19 02:47:14 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 123
2021-05-19 02:47:14 INFO  Executor:54 - Running task 6.0 in stage 5.0 (TID 123)
2021-05-19 02:47:14 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 127
2021-05-19 02:47:14 INFO  Executor:54 - Running task 10.0 in stage 5.0 (TID 127)
2021-05-19 02:47:14 INFO  MapOutputTrackerWorker:54 - Updating epoch to 1 and clearing cache
2021-05-19 02:47:14 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 131
2021-05-19 02:47:14 INFO  Executor:54 - Running task 14.0 in stage 5.0 (TID 131)
2021-05-19 02:47:14 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 135
2021-05-19 02:47:14 INFO  Executor:54 - Running task 19.0 in stage 5.0 (TID 135)
2021-05-19 02:47:14 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 139
2021-05-19 02:47:14 INFO  TorrentBroadcast:54 - Started reading broadcast variable 10
2021-05-19 02:47:14 INFO  Executor:54 - Running task 23.0 in stage 5.0 (TID 139)
2021-05-19 02:47:14 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 143
2021-05-19 02:47:14 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 147
2021-05-19 02:47:14 INFO  Executor:54 - Running task 28.0 in stage 5.0 (TID 143)
2021-05-19 02:47:14 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 151
2021-05-19 02:47:14 INFO  Executor:54 - Running task 32.0 in stage 5.0 (TID 147)
2021-05-19 02:47:14 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 155
2021-05-19 02:47:14 INFO  Executor:54 - Running task 37.0 in stage 5.0 (TID 151)
2021-05-19 02:47:14 INFO  Executor:54 - Running task 41.0 in stage 5.0 (TID 155)
2021-05-19 02:47:14 INFO  MemoryStore:54 - Block broadcast_10_piece0 stored as bytes in memory (estimated size 20.4 KB, free 366.3 MB)
2021-05-19 02:47:14 INFO  TorrentBroadcast:54 - Reading broadcast variable 10 took 33 ms
2021-05-19 02:47:14 INFO  MemoryStore:54 - Block broadcast_10 stored as values in memory (estimated size 40.9 KB, free 366.2 MB)
2021-05-19 02:47:14 INFO  MapOutputTrackerWorker:54 - Don't have map outputs for shuffle 0, fetching them
2021-05-19 02:47:14 INFO  MapOutputTrackerWorker:54 - Don't have map outputs for shuffle 0, fetching them
2021-05-19 02:47:14 INFO  MapOutputTrackerWorker:54 - Don't have map outputs for shuffle 0, fetching them
2021-05-19 02:47:14 INFO  MapOutputTrackerWorker:54 - Don't have map outputs for shuffle 0, fetching them
2021-05-19 02:47:14 INFO  MapOutputTrackerWorker:54 - Don't have map outputs for shuffle 0, fetching them
2021-05-19 02:47:14 INFO  MapOutputTrackerWorker:54 - Don't have map outputs for shuffle 0, fetching them
2021-05-19 02:47:14 INFO  MapOutputTrackerWorker:54 - Don't have map outputs for shuffle 0, fetching them
2021-05-19 02:47:14 INFO  MapOutputTrackerWorker:54 - Don't have map outputs for shuffle 0, fetching them
2021-05-19 02:47:14 INFO  MapOutputTrackerWorker:54 - Don't have map outputs for shuffle 0, fetching them
2021-05-19 02:47:14 INFO  MapOutputTrackerWorker:54 - Don't have map outputs for shuffle 0, fetching them
2021-05-19 02:47:14 INFO  MapOutputTrackerWorker:54 - Doing the fetch; tracker endpoint = NettyRpcEndpointRef(spark://MapOutputTracker@hadoop02.cusp.nyu.edu:60108)
2021-05-19 02:47:14 INFO  MapOutputTrackerWorker:54 - Got the output locations
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 11 ms
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 11 ms
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 12 ms
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 11 ms
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 10 ms
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 10 ms
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 11 ms
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 15 ms
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 16 ms
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 17 ms
2021-05-19 02:47:15 INFO  CodeGenerator:54 - Code generated in 386.340812 ms
2021-05-19 02:47:15 INFO  CodeGenerator:54 - Code generated in 38.7218 ms
2021-05-19 02:47:15 INFO  CodeGenerator:54 - Code generated in 34.443346 ms
2021-05-19 02:47:15 INFO  CodeGenerator:54 - Code generated in 32.179015 ms
2021-05-19 02:47:15 INFO  Executor:54 - Finished task 37.0 in stage 5.0 (TID 151). 3776 bytes result sent to driver
2021-05-19 02:47:15 INFO  Executor:54 - Finished task 32.0 in stage 5.0 (TID 147). 3776 bytes result sent to driver
2021-05-19 02:47:15 INFO  Executor:54 - Finished task 10.0 in stage 5.0 (TID 127). 3776 bytes result sent to driver
2021-05-19 02:47:15 INFO  Executor:54 - Finished task 14.0 in stage 5.0 (TID 131). 3776 bytes result sent to driver
2021-05-19 02:47:15 INFO  Executor:54 - Finished task 23.0 in stage 5.0 (TID 139). 3776 bytes result sent to driver
2021-05-19 02:47:15 INFO  Executor:54 - Finished task 0.0 in stage 5.0 (TID 118). 3776 bytes result sent to driver
2021-05-19 02:47:15 INFO  Executor:54 - Finished task 19.0 in stage 5.0 (TID 135). 3776 bytes result sent to driver
2021-05-19 02:47:15 INFO  Executor:54 - Finished task 28.0 in stage 5.0 (TID 143). 3776 bytes result sent to driver
2021-05-19 02:47:15 INFO  Executor:54 - Finished task 41.0 in stage 5.0 (TID 155). 3819 bytes result sent to driver
2021-05-19 02:47:15 INFO  Executor:54 - Finished task 6.0 in stage 5.0 (TID 123). 3819 bytes result sent to driver
2021-05-19 02:47:22 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 355
2021-05-19 02:47:22 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 357
2021-05-19 02:47:22 INFO  Executor:54 - Running task 8.0 in stage 7.0 (TID 355)
2021-05-19 02:47:22 INFO  Executor:54 - Running task 12.0 in stage 7.0 (TID 357)
2021-05-19 02:47:22 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 359
2021-05-19 02:47:22 INFO  Executor:54 - Running task 21.0 in stage 7.0 (TID 359)
2021-05-19 02:47:22 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 360
2021-05-19 02:47:22 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 361
2021-05-19 02:47:22 INFO  Executor:54 - Running task 22.0 in stage 7.0 (TID 360)
2021-05-19 02:47:22 INFO  Executor:54 - Running task 24.0 in stage 7.0 (TID 361)
2021-05-19 02:47:22 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 362
2021-05-19 02:47:22 INFO  Executor:54 - Running task 28.0 in stage 7.0 (TID 362)
2021-05-19 02:47:22 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 363
2021-05-19 02:47:22 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 364
2021-05-19 02:47:22 INFO  Executor:54 - Running task 29.0 in stage 7.0 (TID 363)
2021-05-19 02:47:22 INFO  Executor:54 - Running task 37.0 in stage 7.0 (TID 364)
2021-05-19 02:47:22 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 365
2021-05-19 02:47:22 INFO  Executor:54 - Running task 42.0 in stage 7.0 (TID 365)
2021-05-19 02:47:22 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 366
2021-05-19 02:47:22 INFO  Executor:54 - Running task 46.0 in stage 7.0 (TID 366)
2021-05-19 02:47:22 INFO  TorrentBroadcast:54 - Started reading broadcast variable 14
2021-05-19 02:47:22 INFO  TransportClientFactory:267 - Successfully created connection to hadoop06.cusp.nyu.edu/192.168.72.176:53410 after 5 ms (0 ms spent in bootstraps)
2021-05-19 02:47:22 INFO  MemoryStore:54 - Block broadcast_14_piece0 stored as bytes in memory (estimated size 22.9 KB, free 366.3 MB)
2021-05-19 02:47:22 INFO  TorrentBroadcast:54 - Reading broadcast variable 14 took 131 ms
2021-05-19 02:47:22 INFO  MemoryStore:54 - Block broadcast_14 stored as values in memory (estimated size 51.4 KB, free 366.2 MB)
2021-05-19 02:47:22 INFO  CodeGenerator:54 - Code generated in 61.137431 ms
2021-05-19 02:47:22 INFO  TorrentBroadcast:54 - Started reading broadcast variable 12
2021-05-19 02:47:22 INFO  MemoryStore:54 - Block broadcast_12_piece0 stored as bytes in memory (estimated size 580.1 KB, free 365.7 MB)
2021-05-19 02:47:22 INFO  TorrentBroadcast:54 - Reading broadcast variable 12 took 27 ms
2021-05-19 02:47:22 INFO  MemoryStore:54 - Block broadcast_12 stored as values in memory (estimated size 5.0 MB, free 360.7 MB)
2021-05-19 02:47:22 INFO  CodeGenerator:54 - Code generated in 18.103965 ms
2021-05-19 02:47:23 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00024, range: 0-134217728, partition values: [empty row]
2021-05-19 02:47:23 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00022, range: 0-134217728, partition values: [empty row]
2021-05-19 02:47:23 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00042, range: 0-134217728, partition values: [empty row]
2021-05-19 02:47:23 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00028, range: 0-134217728, partition values: [empty row]
2021-05-19 02:47:23 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00037, range: 0-134217728, partition values: [empty row]
2021-05-19 02:47:23 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00008, range: 0-134217728, partition values: [empty row]
2021-05-19 02:47:23 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00046, range: 0-134217728, partition values: [empty row]
2021-05-19 02:47:23 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00012, range: 0-134217728, partition values: [empty row]
2021-05-19 02:47:23 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00021, range: 0-134217728, partition values: [empty row]
2021-05-19 02:47:23 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00029, range: 0-134217728, partition values: [empty row]
2021-05-19 02:47:23 INFO  CodeGenerator:54 - Code generated in 72.026137 ms
2021-05-19 02:47:23 INFO  TorrentBroadcast:54 - Started reading broadcast variable 13
2021-05-19 02:47:23 INFO  TransportClientFactory:267 - Successfully created connection to hadoop18.cusp.nyu.edu/192.168.72.188:37819 after 4 ms (0 ms spent in bootstraps)
2021-05-19 02:47:23 INFO  CodeGenerator:54 - Code generated in 72.785083 ms
2021-05-19 02:47:23 INFO  MemoryStore:54 - Block broadcast_13_piece0 stored as bytes in memory (estimated size 33.4 KB, free 360.6 MB)
2021-05-19 02:47:23 INFO  TorrentBroadcast:54 - Reading broadcast variable 13 took 93 ms
2021-05-19 02:47:23 INFO  CodeGenerator:54 - Code generated in 47.563379 ms
2021-05-19 02:47:23 INFO  CodeGenerator:54 - Code generated in 86.141879 ms
2021-05-19 02:47:23 INFO  CodeGenerator:54 - Code generated in 23.86057 ms
2021-05-19 02:47:23 INFO  MemoryStore:54 - Block broadcast_13 stored as values in memory (estimated size 506.4 KB, free 360.1 MB)
2021-05-19 02:47:24 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: 233-222@627-s6b-5s5, 2018-12-31T00:00:00-05:00, [38,44,50,44,70,36,32]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: 233-222@627-s6b-5s5
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00021
2021-05-19 02:47:24 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: zzy-222@627-s93-26k, 2019-12-02T00:00:00-05:00, [4,6,9,13,8,11,4]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: zzy-222@627-s93-26k
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00029
2021-05-19 02:47:24 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: zzw-226@627-wc7-49z, 2019-02-11T00:00:00-05:00, [26,15,15,20,33,6,11]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: zzw-226@627-wc7-49z
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00022
2021-05-19 02:47:24 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: 22j-222@627-wc7-8jv, 2019-05-13T00:00:00-04:00, [1,1,0,2,2,4,1]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: 22j-222@627-wc7-8jv
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00028
2021-05-19 02:47:24 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: 22f-222@627-s8x-c5z, 2020-10-26T00:00:00-04:00, [1,0,0,0,0,0,0]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: 22f-222@627-s8x-c5z
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00042
2021-05-19 02:47:24 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: 22p-222@627-s5x-c3q, 2018-12-31T00:00:00-05:00, [3,2,4,4,4,6,0]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: 22p-222@627-s5x-c3q
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00012
2021-05-19 02:47:24 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: 224-222@627-s8r-975, 2019-12-02T00:00:00-05:00, [15,24,17,27,24,13,21]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: 224-222@627-s8r-975
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00024
2021-05-19 02:47:24 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: 22h-223@627-s96-73q, 2019-10-07T00:00:00-04:00, [5,3,1,1,5,1,3]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: 22h-223@627-s96-73q
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00046
2021-05-19 02:47:24 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: 22n-224@627-wc7-qfz, 2018-12-31T00:00:00-05:00, [4,2,14,28,22,22,26]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: 22n-224@627-wc7-qfz
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00008
2021-05-19 02:47:24 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: zzy-222@627-wf8-59f, 2019-07-08T00:00:00-04:00, [0,5,1,0,6,2,4]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: zzy-222@627-wf8-59f
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00037
2021-05-19 02:47:25 INFO  CodeGenerator:54 - Code generated in 22.861412 ms
2021-05-19 02:47:25 INFO  CodeGenerator:54 - Code generated in 26.764578 ms
2021-05-19 02:47:25 INFO  CodeGenerator:54 - Code generated in 24.156299 ms
2021-05-19 02:47:25 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:47:25 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:47:25 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:47:25 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:47:25 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:47:25 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:47:25 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:47:25 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:47:25 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:47:25 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:47:25 INFO  CodeGenerator:54 - Code generated in 37.990416 ms
2021-05-19 02:47:25 INFO  CodeGenerator:54 - Code generated in 55.632613 ms
2021-05-19 02:47:25 INFO  CodeGenerator:54 - Code generated in 19.711186 ms
2021-05-19 02:47:26 INFO  CodeGenerator:54 - Code generated in 22.566681 ms
2021-05-19 02:47:35 INFO  PythonUDFRunner:54 - Times: total = 13187, boot = 789, init = 1284, finish = 11114
2021-05-19 02:47:36 INFO  PythonUDFRunner:54 - Times: total = 13477, boot = 756, init = 1319, finish = 11402
2021-05-19 02:47:36 INFO  CodeGenerator:54 - Code generated in 24.011768 ms
2021-05-19 02:47:36 INFO  PythonUDFRunner:54 - Times: total = 13606, boot = 777, init = 1303, finish = 11526
2021-05-19 02:47:36 INFO  PythonUDFRunner:54 - Times: total = 13772, boot = 746, init = 1321, finish = 11705
2021-05-19 02:47:36 INFO  PythonUDFRunner:54 - Times: total = 13799, boot = 765, init = 1315, finish = 11719
2021-05-19 02:47:36 INFO  PythonUDFRunner:54 - Times: total = 13840, boot = 736, init = 1338, finish = 11766
2021-05-19 02:47:36 INFO  PythonUDFRunner:54 - Times: total = 13842, boot = 702, init = 1372, finish = 11768
2021-05-19 02:47:36 INFO  Executor:54 - Finished task 21.0 in stage 7.0 (TID 359). 4270 bytes result sent to driver
2021-05-19 02:47:36 INFO  PythonUDFRunner:54 - Times: total = 13897, boot = 799, init = 1279, finish = 11819
2021-05-19 02:47:36 INFO  Executor:54 - Finished task 46.0 in stage 7.0 (TID 366). 4270 bytes result sent to driver
2021-05-19 02:47:36 INFO  PythonUDFRunner:54 - Times: total = 14092, boot = 714, init = 1367, finish = 12011
2021-05-19 02:47:36 ERROR CoarseGrainedExecutorBackend:43 - RECEIVED SIGNAL TERM
2021-05-19 02:47:36 INFO  DiskBlockManager:54 - Shutdown hook called
2021-05-19 02:47:36 INFO  ShutdownHookManager:54 - Shutdown hook called
2021-05-19 02:47:36 INFO  ShutdownHookManager:54 - Deleting directory /localhome/cdp/yarn/nm/usercache/catherine.ng60/appcache/application_1609183734776_5900/spark-0bff7cce-a51f-4a1c-b01e-3c8da6c4e1f9
2021-05-19 02:47:36 INFO  PythonUDFRunner:54 - Times: total = 14197, boot = 726, init = 1347, finish = 12124

End of LogType:stdout
***********************************************************************


End of LogType:prelaunch.err
******************************************************************************

Container: container_e10_1609183734776_5900_02_000020 on hadoop04.cusp.nyu.edu_8041
LogAggregationType: AGGREGATED
===================================================================================
LogType:prelaunch.out
LogLastModifiedTime:Wed May 19 02:48:18 -0400 2021
LogLength:70
LogContents:
Setting up env variables
Setting up job resources
Launching container

End of LogType:prelaunch.out
******************************************************************************

Container: container_e10_1609183734776_5900_02_000020 on hadoop04.cusp.nyu.edu_8041
LogAggregationType: AGGREGATED
===================================================================================
LogType:stderr
LogLastModifiedTime:Wed May 19 02:48:18 -0400 2021
LogLength:529
LogContents:
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/localhome/cdp/yarn/nm/filecache/26/spark-jars-2.4.0-hadoop2.7.jar/slf4j-log4j12-1.7.16.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-6.1.0-1.cdh6.1.0.p0.770702/jars/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]

End of LogType:stderr
***********************************************************************

Container: container_e10_1609183734776_5900_02_000020 on hadoop04.cusp.nyu.edu_8041
LogAggregationType: AGGREGATED
===================================================================================
LogType:stdout
LogLastModifiedTime:Wed May 19 02:48:18 -0400 2021
LogLength:15031
LogContents:
2021-05-19 02:48:06 INFO  CoarseGrainedExecutorBackend:2566 - Started daemon with process name: 22718@hadoop04.cusp.nyu.edu
2021-05-19 02:48:06 INFO  SignalUtils:54 - Registered signal handler for TERM
2021-05-19 02:48:06 INFO  SignalUtils:54 - Registered signal handler for HUP
2021-05-19 02:48:06 INFO  SignalUtils:54 - Registered signal handler for INT
2021-05-19 02:48:07 INFO  SecurityManager:54 - Changing view acls to: catherine.ng60
2021-05-19 02:48:07 INFO  SecurityManager:54 - Changing modify acls to: catherine.ng60
2021-05-19 02:48:07 INFO  SecurityManager:54 - Changing view acls groups to: 
2021-05-19 02:48:07 INFO  SecurityManager:54 - Changing modify acls groups to: 
2021-05-19 02:48:07 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(catherine.ng60); groups with view permissions: Set(); users  with modify permissions: Set(catherine.ng60); groups with modify permissions: Set()
2021-05-19 02:48:08 INFO  TransportClientFactory:267 - Successfully created connection to hadoop02.cusp.nyu.edu/192.168.72.172:60108 after 105 ms (0 ms spent in bootstraps)
2021-05-19 02:48:08 INFO  SecurityManager:54 - Changing view acls to: catherine.ng60
2021-05-19 02:48:08 INFO  SecurityManager:54 - Changing modify acls to: catherine.ng60
2021-05-19 02:48:08 INFO  SecurityManager:54 - Changing view acls groups to: 
2021-05-19 02:48:08 INFO  SecurityManager:54 - Changing modify acls groups to: 
2021-05-19 02:48:08 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(catherine.ng60); groups with view permissions: Set(); users  with modify permissions: Set(catherine.ng60); groups with modify permissions: Set()
2021-05-19 02:48:08 INFO  TransportClientFactory:267 - Successfully created connection to hadoop02.cusp.nyu.edu/192.168.72.172:60108 after 4 ms (0 ms spent in bootstraps)
2021-05-19 02:48:08 INFO  DiskBlockManager:54 - Created local directory at /localhome/cdp/yarn/nm/usercache/catherine.ng60/appcache/application_1609183734776_5900/blockmgr-00a549eb-74bf-4120-b3cc-f4a9ea6a7bbb
2021-05-19 02:48:08 INFO  MemoryStore:54 - MemoryStore started with capacity 366.3 MB
2021-05-19 02:48:08 INFO  CoarseGrainedExecutorBackend:54 - Connecting to driver: spark://CoarseGrainedScheduler@hadoop02.cusp.nyu.edu:60108
2021-05-19 02:48:08 INFO  CoarseGrainedExecutorBackend:54 - Successfully registered with driver
2021-05-19 02:48:08 INFO  Executor:54 - Starting executor ID 15 on host hadoop04.cusp.nyu.edu
2021-05-19 02:48:08 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 38347.
2021-05-19 02:48:08 INFO  NettyBlockTransferService:54 - Server created on hadoop04.cusp.nyu.edu:38347
2021-05-19 02:48:08 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2021-05-19 02:48:08 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(15, hadoop04.cusp.nyu.edu, 38347, None)
2021-05-19 02:48:09 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(15, hadoop04.cusp.nyu.edu, 38347, None)
2021-05-19 02:48:09 INFO  BlockManager:54 - external shuffle service port = 7337
2021-05-19 02:48:09 INFO  BlockManager:54 - Registering executor with local external shuffle service.
2021-05-19 02:48:09 INFO  TransportClientFactory:267 - Successfully created connection to hadoop04.cusp.nyu.edu/192.168.72.174:7337 after 3 ms (0 ms spent in bootstraps)
2021-05-19 02:48:09 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(15, hadoop04.cusp.nyu.edu, 38347, None)
2021-05-19 02:48:09 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 462
2021-05-19 02:48:09 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 463
2021-05-19 02:48:09 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 464
2021-05-19 02:48:09 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 465
2021-05-19 02:48:09 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 466
2021-05-19 02:48:09 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 467
2021-05-19 02:48:09 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 468
2021-05-19 02:48:09 INFO  Executor:54 - Running task 13.2 in stage 7.0 (TID 462)
2021-05-19 02:48:09 INFO  Executor:54 - Running task 53.1 in stage 7.0 (TID 464)
2021-05-19 02:48:09 INFO  Executor:54 - Running task 6.2 in stage 7.0 (TID 463)
2021-05-19 02:48:09 INFO  Executor:54 - Running task 65.0 in stage 7.0 (TID 466)
2021-05-19 02:48:09 INFO  Executor:54 - Running task 66.0 in stage 7.0 (TID 467)
2021-05-19 02:48:09 INFO  Executor:54 - Running task 63.0 in stage 7.0 (TID 465)
2021-05-19 02:48:09 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 469
2021-05-19 02:48:09 INFO  Executor:54 - Running task 67.0 in stage 7.0 (TID 468)
2021-05-19 02:48:09 INFO  Executor:54 - Running task 68.0 in stage 7.0 (TID 469)
2021-05-19 02:48:09 INFO  MapOutputTrackerWorker:54 - Updating epoch to 1 and clearing cache
2021-05-19 02:48:09 INFO  TorrentBroadcast:54 - Started reading broadcast variable 14
2021-05-19 02:48:09 INFO  TransportClientFactory:267 - Successfully created connection to hadoop06.cusp.nyu.edu/192.168.72.176:44467 after 2 ms (0 ms spent in bootstraps)
2021-05-19 02:48:09 INFO  MemoryStore:54 - Block broadcast_14_piece0 stored as bytes in memory (estimated size 22.9 KB, free 366.3 MB)
2021-05-19 02:48:09 INFO  TorrentBroadcast:54 - Reading broadcast variable 14 took 140 ms
2021-05-19 02:48:09 INFO  MemoryStore:54 - Block broadcast_14 stored as values in memory (estimated size 51.4 KB, free 366.2 MB)
2021-05-19 02:48:11 INFO  CodeGenerator:54 - Code generated in 336.986853 ms
2021-05-19 02:48:11 INFO  TorrentBroadcast:54 - Started reading broadcast variable 12
2021-05-19 02:48:11 INFO  TransportClientFactory:267 - Successfully created connection to hadoop13.cusp.nyu.edu/192.168.72.183:43962 after 5 ms (0 ms spent in bootstraps)
2021-05-19 02:48:11 INFO  MemoryStore:54 - Block broadcast_12_piece0 stored as bytes in memory (estimated size 580.1 KB, free 365.7 MB)
2021-05-19 02:48:11 INFO  TorrentBroadcast:54 - Reading broadcast variable 12 took 69 ms
2021-05-19 02:48:11 INFO  MemoryStore:54 - Block broadcast_12 stored as values in memory (estimated size 5.0 MB, free 360.7 MB)
2021-05-19 02:48:11 INFO  CodeGenerator:54 - Code generated in 36.0456 ms
2021-05-19 02:48:12 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00018, range: 134217728-174220852, partition values: [empty row]
2021-05-19 02:48:12 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00041, range: 134217728-175666719, partition values: [empty row]
2021-05-19 02:48:12 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00034, range: 134217728-174985204, partition values: [empty row]
2021-05-19 02:48:12 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00031, range: 134217728-176028743, partition values: [empty row]
2021-05-19 02:48:12 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00026, range: 134217728-178435909, partition values: [empty row]
2021-05-19 02:48:12 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00006, range: 0-134217728, partition values: [empty row]
2021-05-19 02:48:12 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00013, range: 0-134217728, partition values: [empty row]
2021-05-19 02:48:12 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00039, range: 134217728-175562757, partition values: [empty row]
2021-05-19 02:48:12 INFO  CodeGenerator:54 - Code generated in 48.262282 ms
2021-05-19 02:48:12 INFO  TorrentBroadcast:54 - Started reading broadcast variable 13
2021-05-19 02:48:12 INFO  TransportClientFactory:267 - Successfully created connection to hadoop17.cusp.nyu.edu/192.168.72.187:44528 after 5 ms (0 ms spent in bootstraps)
2021-05-19 02:48:12 INFO  CodeGenerator:54 - Code generated in 49.997455 ms
2021-05-19 02:48:12 INFO  CodeGenerator:54 - Code generated in 31.792656 ms
2021-05-19 02:48:12 INFO  CodeGenerator:54 - Code generated in 43.844881 ms
2021-05-19 02:48:12 INFO  CodeGenerator:54 - Code generated in 22.774261 ms
2021-05-19 02:48:12 INFO  MemoryStore:54 - Block broadcast_13_piece0 stored as bytes in memory (estimated size 33.4 KB, free 360.6 MB)
2021-05-19 02:48:12 INFO  TorrentBroadcast:54 - Reading broadcast variable 13 took 314 ms
2021-05-19 02:48:12 INFO  MemoryStore:54 - Block broadcast_13 stored as values in memory (estimated size 506.4 KB, free 360.1 MB)
2021-05-19 02:48:14 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: 237-224@627-rwx-wtv, 2018-12-31T00:00:00-05:00, [1,0,12,14,0,4,4]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: 237-224@627-rwx-wtv
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00006
2021-05-19 02:48:14 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: 23b-222@627-wh4-vxq, 2019-01-07T00:00:00-05:00, [10,12,10,16,2,4,3]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: 23b-222@627-wh4-vxq
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00013
2021-05-19 02:48:15 INFO  CodeGenerator:54 - Code generated in 17.337248 ms
2021-05-19 02:48:15 INFO  CodeGenerator:54 - Code generated in 18.093357 ms
2021-05-19 02:48:15 INFO  CodeGenerator:54 - Code generated in 22.0313 ms
2021-05-19 02:48:15 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:48:15 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:48:15 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:48:15 INFO  CodeGenerator:54 - Code generated in 58.041061 ms
2021-05-19 02:48:15 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:48:15 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:48:15 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:48:15 INFO  CodeGenerator:54 - Code generated in 32.810463 ms
2021-05-19 02:48:15 INFO  CodeGenerator:54 - Code generated in 14.776 ms
2021-05-19 02:48:15 INFO  CodeGenerator:54 - Code generated in 18.10184 ms
2021-05-19 02:48:16 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:48:16 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00045, range: 134217728-174154361, partition values: [empty row]
2021-05-19 02:48:16 INFO  Executor:54 - Executor is trying to kill task 65.0 in stage 7.0 (TID 466), reason: Stage cancelled
2021-05-19 02:48:16 INFO  Executor:54 - Executor is trying to kill task 66.0 in stage 7.0 (TID 467), reason: Stage cancelled
2021-05-19 02:48:16 INFO  Executor:54 - Executor is trying to kill task 67.0 in stage 7.0 (TID 468), reason: Stage cancelled
2021-05-19 02:48:16 INFO  Executor:54 - Executor is trying to kill task 68.0 in stage 7.0 (TID 469), reason: Stage cancelled
2021-05-19 02:48:16 INFO  Executor:54 - Executor is trying to kill task 13.2 in stage 7.0 (TID 462), reason: Stage cancelled
2021-05-19 02:48:16 INFO  Executor:54 - Executor is trying to kill task 6.2 in stage 7.0 (TID 463), reason: Stage cancelled
2021-05-19 02:48:16 INFO  Executor:54 - Executor is trying to kill task 53.1 in stage 7.0 (TID 464), reason: Stage cancelled
2021-05-19 02:48:16 INFO  Executor:54 - Executor is trying to kill task 63.0 in stage 7.0 (TID 465), reason: Stage cancelled
2021-05-19 02:48:16 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:48:16 INFO  Executor:54 - Executor killed task 65.0 in stage 7.0 (TID 466), reason: Stage cancelled
2021-05-19 02:48:16 INFO  Executor:54 - Executor killed task 6.2 in stage 7.0 (TID 463), reason: Stage cancelled
2021-05-19 02:48:16 INFO  Executor:54 - Executor killed task 68.0 in stage 7.0 (TID 469), reason: Stage cancelled
2021-05-19 02:48:16 INFO  Executor:54 - Executor killed task 66.0 in stage 7.0 (TID 467), reason: Stage cancelled
2021-05-19 02:48:16 INFO  Executor:54 - Executor killed task 53.1 in stage 7.0 (TID 464), reason: Stage cancelled
2021-05-19 02:48:16 INFO  Executor:54 - Executor killed task 67.0 in stage 7.0 (TID 468), reason: Stage cancelled
2021-05-19 02:48:16 INFO  Executor:54 - Executor killed task 63.0 in stage 7.0 (TID 465), reason: Stage cancelled
2021-05-19 02:48:16 INFO  Executor:54 - Executor killed task 13.2 in stage 7.0 (TID 462), reason: Stage cancelled
2021-05-19 02:48:16 INFO  CoarseGrainedExecutorBackend:54 - Driver commanded a shutdown
2021-05-19 02:48:16 INFO  MemoryStore:54 - MemoryStore cleared
2021-05-19 02:48:16 INFO  BlockManager:54 - BlockManager stopped
2021-05-19 02:48:16 INFO  ShutdownHookManager:54 - Shutdown hook called
2021-05-19 02:48:16 INFO  ShutdownHookManager:54 - Deleting directory /localhome/cdp/yarn/nm/usercache/catherine.ng60/appcache/application_1609183734776_5900/spark-64c7245b-89f4-42df-aeff-54fa87731bde

End of LogType:stdout
***********************************************************************

Container: container_e10_1609183734776_5900_01_000014 on hadoop04.cusp.nyu.edu_8041
LogAggregationType: AGGREGATED
===================================================================================
LogType:container-localizer-syslog
LogLastModifiedTime:Wed May 19 02:48:18 -0400 2021
LogLength:506
LogContents:
2021-05-19 02:46:33,436 INFO [main] org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ContainerLocalizer: Disk Validator: yarn.nodemanager.disk-validator is loaded.
2021-05-19 02:46:34,733 WARN [ContainerLocalizer Downloader] org.apache.hadoop.ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ipc.StandbyException): Operation category READ is not supported in state standby. Visit https://s.apache.org/sbnn-error

End of LogType:container-localizer-syslog
*******************************************************************************************


End of LogType:prelaunch.err
******************************************************************************

Container: container_e10_1609183734776_5900_01_000014 on hadoop04.cusp.nyu.edu_8041
LogAggregationType: AGGREGATED
===================================================================================
LogType:prelaunch.out
LogLastModifiedTime:Wed May 19 02:48:18 -0400 2021
LogLength:70
LogContents:
Setting up env variables
Setting up job resources
Launching container

End of LogType:prelaunch.out
******************************************************************************

Container: container_e10_1609183734776_5900_01_000014 on hadoop04.cusp.nyu.edu_8041
LogAggregationType: AGGREGATED
===================================================================================
LogType:stderr
LogLastModifiedTime:Wed May 19 02:48:18 -0400 2021
LogLength:529
LogContents:
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/localhome/cdp/yarn/nm/filecache/26/spark-jars-2.4.0-hadoop2.7.jar/slf4j-log4j12-1.7.16.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-6.1.0-1.cdh6.1.0.p0.770702/jars/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]

End of LogType:stderr
***********************************************************************

Container: container_e10_1609183734776_5900_01_000014 on hadoop04.cusp.nyu.edu_8041
LogAggregationType: AGGREGATED
===================================================================================
LogType:stdout
LogLastModifiedTime:Wed May 19 02:48:18 -0400 2021
LogLength:3959
LogContents:
2021-05-19 02:46:36 INFO  CoarseGrainedExecutorBackend:2566 - Started daemon with process name: 21675@hadoop04.cusp.nyu.edu
2021-05-19 02:46:36 INFO  SignalUtils:54 - Registered signal handler for TERM
2021-05-19 02:46:36 INFO  SignalUtils:54 - Registered signal handler for HUP
2021-05-19 02:46:36 INFO  SignalUtils:54 - Registered signal handler for INT
2021-05-19 02:46:37 INFO  SecurityManager:54 - Changing view acls to: catherine.ng60
2021-05-19 02:46:37 INFO  SecurityManager:54 - Changing modify acls to: catherine.ng60
2021-05-19 02:46:37 INFO  SecurityManager:54 - Changing view acls groups to: 
2021-05-19 02:46:37 INFO  SecurityManager:54 - Changing modify acls groups to: 
2021-05-19 02:46:37 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(catherine.ng60); groups with view permissions: Set(); users  with modify permissions: Set(catherine.ng60); groups with modify permissions: Set()
2021-05-19 02:46:37 INFO  TransportClientFactory:267 - Successfully created connection to hadoop05.cusp.nyu.edu/192.168.72.175:47481 after 113 ms (0 ms spent in bootstraps)
2021-05-19 02:46:37 INFO  SecurityManager:54 - Changing view acls to: catherine.ng60
2021-05-19 02:46:37 INFO  SecurityManager:54 - Changing modify acls to: catherine.ng60
2021-05-19 02:46:37 INFO  SecurityManager:54 - Changing view acls groups to: 
2021-05-19 02:46:37 INFO  SecurityManager:54 - Changing modify acls groups to: 
2021-05-19 02:46:37 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(catherine.ng60); groups with view permissions: Set(); users  with modify permissions: Set(catherine.ng60); groups with modify permissions: Set()
2021-05-19 02:46:38 INFO  TransportClientFactory:267 - Successfully created connection to hadoop05.cusp.nyu.edu/192.168.72.175:47481 after 4 ms (0 ms spent in bootstraps)
2021-05-19 02:46:38 INFO  DiskBlockManager:54 - Created local directory at /localhome/cdp/yarn/nm/usercache/catherine.ng60/appcache/application_1609183734776_5900/blockmgr-3b40cde5-642b-4c5b-b666-eeb12441ff95
2021-05-19 02:46:38 INFO  MemoryStore:54 - MemoryStore started with capacity 366.3 MB
2021-05-19 02:46:38 INFO  CoarseGrainedExecutorBackend:54 - Connecting to driver: spark://CoarseGrainedScheduler@hadoop05.cusp.nyu.edu:47481
2021-05-19 02:46:38 INFO  CoarseGrainedExecutorBackend:54 - Successfully registered with driver
2021-05-19 02:46:38 INFO  Executor:54 - Starting executor ID 11 on host hadoop04.cusp.nyu.edu
2021-05-19 02:46:38 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 36965.
2021-05-19 02:46:38 INFO  NettyBlockTransferService:54 - Server created on hadoop04.cusp.nyu.edu:36965
2021-05-19 02:46:38 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2021-05-19 02:46:38 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(11, hadoop04.cusp.nyu.edu, 36965, None)
2021-05-19 02:46:38 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(11, hadoop04.cusp.nyu.edu, 36965, None)
2021-05-19 02:46:38 INFO  BlockManager:54 - external shuffle service port = 7337
2021-05-19 02:46:38 INFO  BlockManager:54 - Registering executor with local external shuffle service.
2021-05-19 02:46:38 INFO  TransportClientFactory:267 - Successfully created connection to hadoop04.cusp.nyu.edu/192.168.72.174:7337 after 3 ms (0 ms spent in bootstraps)
2021-05-19 02:46:38 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(11, hadoop04.cusp.nyu.edu, 36965, None)
2021-05-19 02:46:40 INFO  CoarseGrainedExecutorBackend:54 - Driver commanded a shutdown
2021-05-19 02:46:40 INFO  MemoryStore:54 - MemoryStore cleared
2021-05-19 02:46:40 INFO  BlockManager:54 - BlockManager stopped
2021-05-19 02:46:40 INFO  ShutdownHookManager:54 - Shutdown hook called

End of LogType:stdout
***********************************************************************


End of LogType:prelaunch.err
******************************************************************************

Container: container_e10_1609183734776_5900_02_000011 on hadoop04.cusp.nyu.edu_8041
LogAggregationType: AGGREGATED
===================================================================================
LogType:prelaunch.out
LogLastModifiedTime:Wed May 19 02:48:18 -0400 2021
LogLength:70
LogContents:
Setting up env variables
Setting up job resources
Launching container

End of LogType:prelaunch.out
******************************************************************************

Container: container_e10_1609183734776_5900_02_000011 on hadoop04.cusp.nyu.edu_8041
LogAggregationType: AGGREGATED
===================================================================================
LogType:stderr
LogLastModifiedTime:Wed May 19 02:48:18 -0400 2021
LogLength:529
LogContents:
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/localhome/cdp/yarn/nm/filecache/26/spark-jars-2.4.0-hadoop2.7.jar/slf4j-log4j12-1.7.16.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-6.1.0-1.cdh6.1.0.p0.770702/jars/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]

End of LogType:stderr
***********************************************************************

Container: container_e10_1609183734776_5900_02_000011 on hadoop04.cusp.nyu.edu_8041
LogAggregationType: AGGREGATED
===================================================================================
LogType:stdout
LogLastModifiedTime:Wed May 19 02:48:18 -0400 2021
LogLength:17885
LogContents:
2021-05-19 02:47:41 INFO  CoarseGrainedExecutorBackend:2566 - Started daemon with process name: 22327@hadoop04.cusp.nyu.edu
2021-05-19 02:47:41 INFO  SignalUtils:54 - Registered signal handler for TERM
2021-05-19 02:47:41 INFO  SignalUtils:54 - Registered signal handler for HUP
2021-05-19 02:47:41 INFO  SignalUtils:54 - Registered signal handler for INT
2021-05-19 02:47:42 INFO  SecurityManager:54 - Changing view acls to: catherine.ng60
2021-05-19 02:47:42 INFO  SecurityManager:54 - Changing modify acls to: catherine.ng60
2021-05-19 02:47:42 INFO  SecurityManager:54 - Changing view acls groups to: 
2021-05-19 02:47:42 INFO  SecurityManager:54 - Changing modify acls groups to: 
2021-05-19 02:47:42 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(catherine.ng60); groups with view permissions: Set(); users  with modify permissions: Set(catherine.ng60); groups with modify permissions: Set()
2021-05-19 02:47:43 INFO  TransportClientFactory:267 - Successfully created connection to hadoop02.cusp.nyu.edu/192.168.72.172:60108 after 105 ms (0 ms spent in bootstraps)
2021-05-19 02:47:43 INFO  SecurityManager:54 - Changing view acls to: catherine.ng60
2021-05-19 02:47:43 INFO  SecurityManager:54 - Changing modify acls to: catherine.ng60
2021-05-19 02:47:43 INFO  SecurityManager:54 - Changing view acls groups to: 
2021-05-19 02:47:43 INFO  SecurityManager:54 - Changing modify acls groups to: 
2021-05-19 02:47:43 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(catherine.ng60); groups with view permissions: Set(); users  with modify permissions: Set(catherine.ng60); groups with modify permissions: Set()
2021-05-19 02:47:43 INFO  TransportClientFactory:267 - Successfully created connection to hadoop02.cusp.nyu.edu/192.168.72.172:60108 after 4 ms (0 ms spent in bootstraps)
2021-05-19 02:47:43 INFO  DiskBlockManager:54 - Created local directory at /localhome/cdp/yarn/nm/usercache/catherine.ng60/appcache/application_1609183734776_5900/blockmgr-73131710-3a3f-4ea0-9bbd-260dc668f025
2021-05-19 02:47:43 INFO  MemoryStore:54 - MemoryStore started with capacity 366.3 MB
2021-05-19 02:47:43 INFO  CoarseGrainedExecutorBackend:54 - Connecting to driver: spark://CoarseGrainedScheduler@hadoop02.cusp.nyu.edu:60108
2021-05-19 02:47:43 INFO  CoarseGrainedExecutorBackend:54 - Successfully registered with driver
2021-05-19 02:47:43 INFO  Executor:54 - Starting executor ID 10 on host hadoop04.cusp.nyu.edu
2021-05-19 02:47:44 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 35739.
2021-05-19 02:47:44 INFO  NettyBlockTransferService:54 - Server created on hadoop04.cusp.nyu.edu:35739
2021-05-19 02:47:44 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2021-05-19 02:47:44 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(10, hadoop04.cusp.nyu.edu, 35739, None)
2021-05-19 02:47:44 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(10, hadoop04.cusp.nyu.edu, 35739, None)
2021-05-19 02:47:44 INFO  BlockManager:54 - external shuffle service port = 7337
2021-05-19 02:47:44 INFO  BlockManager:54 - Registering executor with local external shuffle service.
2021-05-19 02:47:44 INFO  TransportClientFactory:267 - Successfully created connection to hadoop04.cusp.nyu.edu/192.168.72.174:7337 after 3 ms (0 ms spent in bootstraps)
2021-05-19 02:47:44 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(10, hadoop04.cusp.nyu.edu, 35739, None)
2021-05-19 02:47:44 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 411
2021-05-19 02:47:44 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 412
2021-05-19 02:47:44 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 413
2021-05-19 02:47:44 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 414
2021-05-19 02:47:44 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 415
2021-05-19 02:47:44 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 416
2021-05-19 02:47:44 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 417
2021-05-19 02:47:44 INFO  Executor:54 - Running task 54.0 in stage 7.0 (TID 416)
2021-05-19 02:47:44 INFO  Executor:54 - Running task 48.0 in stage 7.0 (TID 413)
2021-05-19 02:47:44 INFO  Executor:54 - Running task 19.1 in stage 7.0 (TID 412)
2021-05-19 02:47:44 INFO  Executor:54 - Running task 49.0 in stage 7.0 (TID 414)
2021-05-19 02:47:44 INFO  Executor:54 - Running task 50.0 in stage 7.0 (TID 415)
2021-05-19 02:47:44 INFO  Executor:54 - Running task 37.1 in stage 7.0 (TID 411)
2021-05-19 02:47:44 INFO  Executor:54 - Running task 55.0 in stage 7.0 (TID 417)
2021-05-19 02:47:44 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 418
2021-05-19 02:47:44 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 419
2021-05-19 02:47:44 INFO  Executor:54 - Running task 56.0 in stage 7.0 (TID 418)
2021-05-19 02:47:44 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 420
2021-05-19 02:47:44 INFO  Executor:54 - Running task 57.0 in stage 7.0 (TID 419)
2021-05-19 02:47:44 INFO  Executor:54 - Running task 59.0 in stage 7.0 (TID 420)
2021-05-19 02:47:44 INFO  MapOutputTrackerWorker:54 - Updating epoch to 1 and clearing cache
2021-05-19 02:47:44 INFO  TorrentBroadcast:54 - Started reading broadcast variable 14
2021-05-19 02:47:44 INFO  TransportClientFactory:267 - Successfully created connection to hadoop02.cusp.nyu.edu/192.168.72.172:49352 after 3 ms (0 ms spent in bootstraps)
2021-05-19 02:47:44 INFO  MemoryStore:54 - Block broadcast_14_piece0 stored as bytes in memory (estimated size 22.9 KB, free 366.3 MB)
2021-05-19 02:47:44 INFO  TorrentBroadcast:54 - Reading broadcast variable 14 took 130 ms
2021-05-19 02:47:44 INFO  MemoryStore:54 - Block broadcast_14 stored as values in memory (estimated size 51.4 KB, free 366.2 MB)
2021-05-19 02:47:46 INFO  CodeGenerator:54 - Code generated in 338.640515 ms
2021-05-19 02:47:46 INFO  TorrentBroadcast:54 - Started reading broadcast variable 12
2021-05-19 02:47:46 INFO  MemoryStore:54 - Block broadcast_12_piece0 stored as bytes in memory (estimated size 580.1 KB, free 365.7 MB)
2021-05-19 02:47:46 INFO  TorrentBroadcast:54 - Reading broadcast variable 12 took 35 ms
2021-05-19 02:47:46 INFO  MemoryStore:54 - Block broadcast_12 stored as values in memory (estimated size 5.0 MB, free 360.7 MB)
2021-05-19 02:47:46 INFO  CodeGenerator:54 - Code generated in 29.289673 ms
2021-05-19 02:47:47 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00011, range: 134217728-177020723, partition values: [empty row]
2021-05-19 02:47:47 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00028, range: 134217728-177133478, partition values: [empty row]
2021-05-19 02:47:47 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00019, range: 0-134217728, partition values: [empty row]
2021-05-19 02:47:47 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00022, range: 134217728-177544240, partition values: [empty row]
2021-05-19 02:47:47 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00010, range: 134217728-179164944, partition values: [empty row]
2021-05-19 02:47:47 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00037, range: 0-134217728, partition values: [empty row]
2021-05-19 02:47:47 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00040, range: 134217728-177901153, partition values: [empty row]
2021-05-19 02:47:47 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00032, range: 134217728-177884607, partition values: [empty row]
2021-05-19 02:47:47 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00008, range: 134217728-179381693, partition values: [empty row]
2021-05-19 02:47:47 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00048, range: 0-134217728, partition values: [empty row]
2021-05-19 02:47:47 INFO  CodeGenerator:54 - Code generated in 30.62421 ms
2021-05-19 02:47:47 INFO  TorrentBroadcast:54 - Started reading broadcast variable 13
2021-05-19 02:47:47 INFO  TransportClientFactory:267 - Successfully created connection to hadoop13.cusp.nyu.edu/192.168.72.183:44397 after 5 ms (0 ms spent in bootstraps)
2021-05-19 02:47:47 INFO  MemoryStore:54 - Block broadcast_13_piece0 stored as bytes in memory (estimated size 33.4 KB, free 360.6 MB)
2021-05-19 02:47:47 INFO  TorrentBroadcast:54 - Reading broadcast variable 13 took 68 ms
2021-05-19 02:47:47 INFO  CodeGenerator:54 - Code generated in 63.200349 ms
2021-05-19 02:47:47 INFO  CodeGenerator:54 - Code generated in 33.276078 ms
2021-05-19 02:47:47 INFO  MemoryStore:54 - Block broadcast_13 stored as values in memory (estimated size 506.4 KB, free 360.1 MB)
2021-05-19 02:47:47 INFO  CodeGenerator:54 - Code generated in 73.056623 ms
2021-05-19 02:47:47 INFO  CodeGenerator:54 - Code generated in 26.085299 ms
2021-05-19 02:47:49 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: zzy-222@627-wf8-59f, 2019-07-08T00:00:00-04:00, [0,5,1,0,6,2,4]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: zzy-222@627-wf8-59f
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00037
2021-05-19 02:47:49 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: 22g-222@627-rw8-nwk, 2020-10-12T00:00:00-04:00, [4,5,3,6,3,16,7]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: 22g-222@627-rw8-nwk
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00048
2021-05-19 02:47:49 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: 22c-222@627-vv6-vvf, 2019-12-16T00:00:00-05:00, [0,0,0,0,1,0,0]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: 22c-222@627-vv6-vvf
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00019
2021-05-19 02:47:50 INFO  CodeGenerator:54 - Code generated in 18.083264 ms
2021-05-19 02:47:50 INFO  CodeGenerator:54 - Code generated in 25.008424 ms
2021-05-19 02:47:50 INFO  CodeGenerator:54 - Code generated in 27.338692 ms
2021-05-19 02:47:50 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:47:50 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:47:50 INFO  CodeGenerator:54 - Code generated in 44.095164 ms
2021-05-19 02:47:50 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:47:50 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:47:50 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:47:50 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:47:50 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:47:50 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:47:50 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:47:50 INFO  CodeGenerator:54 - Code generated in 30.219332 ms
2021-05-19 02:47:50 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:47:50 INFO  CodeGenerator:54 - Code generated in 20.788837 ms
2021-05-19 02:47:50 INFO  CodeGenerator:54 - Code generated in 21.995075 ms
2021-05-19 02:47:51 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00002, range: 134217728-179368669, partition values: [empty row]
2021-05-19 02:47:51 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00017, range: 134217728-176909385, partition values: [empty row]
2021-05-19 02:47:51 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00015, range: 134217728-177898804, partition values: [empty row]
2021-05-19 02:47:51 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00023, range: 134217728-177753533, partition values: [empty row]
2021-05-19 02:47:51 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00042, range: 134217728-177070408, partition values: [empty row]
2021-05-19 02:47:51 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00014, range: 134217728-177434121, partition values: [empty row]
2021-05-19 02:47:51 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00003, range: 134217728-178774105, partition values: [empty row]
2021-05-19 02:47:58 INFO  PythonUDFRunner:54 - Times: total = 11608, boot = 751, init = 2410, finish = 8447
2021-05-19 02:47:58 INFO  CodeGenerator:54 - Code generated in 31.893024 ms
2021-05-19 02:47:58 INFO  Executor:54 - Finished task 55.0 in stage 7.0 (TID 417). 4313 bytes result sent to driver
2021-05-19 02:47:58 INFO  PythonUDFRunner:54 - Times: total = 12326, boot = 719, init = 2442, finish = 9165
2021-05-19 02:47:59 INFO  PythonUDFRunner:54 - Times: total = 12390, boot = 710, init = 2446, finish = 9234
2021-05-19 02:47:59 INFO  PythonUDFRunner:54 - Times: total = 12494, boot = 772, init = 2387, finish = 9335
2021-05-19 02:47:59 INFO  PythonUDFRunner:54 - Times: total = 12500, boot = 700, init = 2464, finish = 9336
2021-05-19 02:47:59 INFO  PythonUDFRunner:54 - Times: total = 12582, boot = 741, init = 2419, finish = 9422
2021-05-19 02:47:59 INFO  PythonUDFRunner:54 - Times: total = 12821, boot = 679, init = 2482, finish = 9660
2021-05-19 02:47:59 INFO  Executor:54 - Finished task 56.0 in stage 7.0 (TID 418). 4270 bytes result sent to driver
2021-05-19 02:48:00 INFO  Executor:54 - Finished task 57.0 in stage 7.0 (TID 419). 4270 bytes result sent to driver
2021-05-19 02:48:00 INFO  Executor:54 - Finished task 59.0 in stage 7.0 (TID 420). 4313 bytes result sent to driver
2021-05-19 02:48:00 INFO  Executor:54 - Finished task 49.0 in stage 7.0 (TID 414). 4313 bytes result sent to driver
2021-05-19 02:48:00 INFO  Executor:54 - Finished task 54.0 in stage 7.0 (TID 416). 4270 bytes result sent to driver
2021-05-19 02:48:00 INFO  Executor:54 - Finished task 50.0 in stage 7.0 (TID 415). 4313 bytes result sent to driver
2021-05-19 02:48:01 INFO  PythonUDFRunner:54 - Times: total = 14474, boot = 729, init = 2439, finish = 11306
2021-05-19 02:48:01 INFO  PythonUDFRunner:54 - Times: total = 14578, boot = 761, init = 2412, finish = 11405
2021-05-19 02:48:01 INFO  Executor:54 - Finished task 37.1 in stage 7.0 (TID 411). 4270 bytes result sent to driver
2021-05-19 02:48:01 INFO  PythonUDFRunner:54 - Times: total = 14862, boot = 691, init = 2485, finish = 11686
2021-05-19 02:48:01 INFO  Executor:54 - Finished task 48.0 in stage 7.0 (TID 413). 4270 bytes result sent to driver
2021-05-19 02:48:01 ERROR CoarseGrainedExecutorBackend:43 - RECEIVED SIGNAL TERM
2021-05-19 02:48:01 INFO  DiskBlockManager:54 - Shutdown hook called
2021-05-19 02:48:01 INFO  ShutdownHookManager:54 - Shutdown hook called
2021-05-19 02:48:01 INFO  ShutdownHookManager:54 - Deleting directory /localhome/cdp/yarn/nm/usercache/catherine.ng60/appcache/application_1609183734776_5900/spark-d2467597-a3f0-4d89-8b33-a8ffd137b853

End of LogType:stdout
***********************************************************************

Container: container_e10_1609183734776_5900_01_000001 on hadoop05.cusp.nyu.edu_8041
LogAggregationType: AGGREGATED
===================================================================================
LogType:container-localizer-syslog
LogLastModifiedTime:Wed May 19 02:48:17 -0400 2021
LogLength:506
LogContents:
2021-05-19 02:45:16,445 INFO [main] org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ContainerLocalizer: Disk Validator: yarn.nodemanager.disk-validator is loaded.
2021-05-19 02:45:17,750 WARN [ContainerLocalizer Downloader] org.apache.hadoop.ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ipc.StandbyException): Operation category READ is not supported in state standby. Visit https://s.apache.org/sbnn-error

End of LogType:container-localizer-syslog
*******************************************************************************************


End of LogType:prelaunch.err
******************************************************************************

Container: container_e10_1609183734776_5900_01_000001 on hadoop05.cusp.nyu.edu_8041
LogAggregationType: AGGREGATED
===================================================================================
LogType:prelaunch.out
LogLastModifiedTime:Wed May 19 02:48:17 -0400 2021
LogLength:70
LogContents:
Setting up env variables
Setting up job resources
Launching container

End of LogType:prelaunch.out
******************************************************************************

Container: container_e10_1609183734776_5900_01_000001 on hadoop05.cusp.nyu.edu_8041
LogAggregationType: AGGREGATED
===================================================================================
LogType:stderr
LogLastModifiedTime:Wed May 19 02:48:17 -0400 2021
LogLength:529
LogContents:
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/localhome/cdp/yarn/nm/filecache/23/spark-jars-2.4.0-hadoop2.7.jar/slf4j-log4j12-1.7.16.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-6.1.0-1.cdh6.1.0.p0.770702/jars/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]

End of LogType:stderr
***********************************************************************

Container: container_e10_1609183734776_5900_01_000001 on hadoop05.cusp.nyu.edu_8041
LogAggregationType: AGGREGATED
===================================================================================
LogType:stdout
LogLastModifiedTime:Wed May 19 02:48:17 -0400 2021
LogLength:299367
LogContents:
2021-05-19 02:45:19 INFO  SignalUtils:54 - Registered signal handler for TERM
2021-05-19 02:45:19 INFO  SignalUtils:54 - Registered signal handler for HUP
2021-05-19 02:45:19 INFO  SignalUtils:54 - Registered signal handler for INT
2021-05-19 02:45:19 INFO  SecurityManager:54 - Changing view acls to: catherine.ng60
2021-05-19 02:45:19 INFO  SecurityManager:54 - Changing modify acls to: catherine.ng60
2021-05-19 02:45:19 INFO  SecurityManager:54 - Changing view acls groups to: 
2021-05-19 02:45:19 INFO  SecurityManager:54 - Changing modify acls groups to: 
2021-05-19 02:45:19 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(catherine.ng60); groups with view permissions: Set(); users  with modify permissions: Set(catherine.ng60); groups with modify permissions: Set()
2021-05-19 02:45:20 INFO  ApplicationMaster:54 - Preparing Local resources
2021-05-19 02:45:21 INFO  ApplicationMaster:54 - ApplicationAttemptId: appattempt_1609183734776_5900_000001
2021-05-19 02:45:21 INFO  ApplicationMaster:54 - Starting the user application in a separate Thread
2021-05-19 02:45:21 INFO  ApplicationMaster:54 - Waiting for spark context initialization...
2021-05-19 02:45:22 INFO  SparkContext:54 - Running Spark version 2.4.0
2021-05-19 02:45:22 INFO  SparkContext:54 - Submitted application: BDM_HW4.py
2021-05-19 02:45:22 INFO  SecurityManager:54 - Changing view acls to: catherine.ng60
2021-05-19 02:45:22 INFO  SecurityManager:54 - Changing modify acls to: catherine.ng60
2021-05-19 02:45:22 INFO  SecurityManager:54 - Changing view acls groups to: 
2021-05-19 02:45:22 INFO  SecurityManager:54 - Changing modify acls groups to: 
2021-05-19 02:45:22 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(catherine.ng60); groups with view permissions: Set(); users  with modify permissions: Set(catherine.ng60); groups with modify permissions: Set()
2021-05-19 02:45:23 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 47481.
2021-05-19 02:45:23 INFO  SparkEnv:54 - Registering MapOutputTracker
2021-05-19 02:45:23 INFO  SparkEnv:54 - Registering BlockManagerMaster
2021-05-19 02:45:23 INFO  BlockManagerMasterEndpoint:54 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2021-05-19 02:45:23 INFO  BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up
2021-05-19 02:45:23 INFO  DiskBlockManager:54 - Created local directory at /localhome/cdp/yarn/nm/usercache/catherine.ng60/appcache/application_1609183734776_5900/blockmgr-d54e442d-6184-41f1-b2d7-f0ab2f454c6a
2021-05-19 02:45:23 INFO  MemoryStore:54 - MemoryStore started with capacity 366.3 MB
2021-05-19 02:45:23 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2021-05-19 02:45:23 INFO  log:192 - Logging initialized @5208ms
2021-05-19 02:45:23 INFO  JettyUtils:54 - Adding filter org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter to /jobs, /jobs/json, /jobs/job, /jobs/job/json, /stages, /stages/json, /stages/stage, /stages/stage/json, /stages/pool, /stages/pool/json, /storage, /storage/json, /storage/rdd, /storage/rdd/json, /environment, /environment/json, /executors, /executors/json, /executors/threadDump, /executors/threadDump/json, /static, /, /api, /jobs/job/kill, /stages/stage/kill.
2021-05-19 02:45:23 INFO  Server:351 - jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2021-05-19 02:45:23 INFO  Server:419 - Started @5450ms
2021-05-19 02:45:23 INFO  AbstractConnector:278 - Started ServerConnector@42198ffd{HTTP/1.1,[http/1.1]}{0.0.0.0:59983}
2021-05-19 02:45:23 INFO  Utils:54 - Successfully started service 'SparkUI' on port 59983.
2021-05-19 02:45:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@14dda17d{/jobs,null,AVAILABLE,@Spark}
2021-05-19 02:45:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7803eb2d{/jobs/json,null,AVAILABLE,@Spark}
2021-05-19 02:45:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4cae1e25{/jobs/job,null,AVAILABLE,@Spark}
2021-05-19 02:45:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@58eb6641{/jobs/job/json,null,AVAILABLE,@Spark}
2021-05-19 02:45:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3fd6a4f2{/stages,null,AVAILABLE,@Spark}
2021-05-19 02:45:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@335da1b{/stages/json,null,AVAILABLE,@Spark}
2021-05-19 02:45:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@47e330e8{/stages/stage,null,AVAILABLE,@Spark}
2021-05-19 02:45:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@630aacbb{/stages/stage/json,null,AVAILABLE,@Spark}
2021-05-19 02:45:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3d30b442{/stages/pool,null,AVAILABLE,@Spark}
2021-05-19 02:45:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@35f82488{/stages/pool/json,null,AVAILABLE,@Spark}
2021-05-19 02:45:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@69f5f15f{/storage,null,AVAILABLE,@Spark}
2021-05-19 02:45:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5facf7ae{/storage/json,null,AVAILABLE,@Spark}
2021-05-19 02:45:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6786dabd{/storage/rdd,null,AVAILABLE,@Spark}
2021-05-19 02:45:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@13ae6ea1{/storage/rdd/json,null,AVAILABLE,@Spark}
2021-05-19 02:45:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@55970a82{/environment,null,AVAILABLE,@Spark}
2021-05-19 02:45:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6d3e8619{/environment/json,null,AVAILABLE,@Spark}
2021-05-19 02:45:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3c3cea31{/executors,null,AVAILABLE,@Spark}
2021-05-19 02:45:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5c075071{/executors/json,null,AVAILABLE,@Spark}
2021-05-19 02:45:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@31a99269{/executors/threadDump,null,AVAILABLE,@Spark}
2021-05-19 02:45:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@283ec40b{/executors/threadDump/json,null,AVAILABLE,@Spark}
2021-05-19 02:45:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7388ce5f{/static,null,AVAILABLE,@Spark}
2021-05-19 02:45:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1790fc79{/,null,AVAILABLE,@Spark}
2021-05-19 02:45:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3863698{/api,null,AVAILABLE,@Spark}
2021-05-19 02:45:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4bde2ce4{/jobs/job/kill,null,AVAILABLE,@Spark}
2021-05-19 02:45:23 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3a637f5f{/stages/stage/kill,null,AVAILABLE,@Spark}
2021-05-19 02:45:23 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://hadoop05.cusp.nyu.edu:59983
2021-05-19 02:45:23 INFO  YarnClusterScheduler:54 - Created YarnClusterScheduler
2021-05-19 02:45:23 INFO  SchedulerExtensionServices:54 - Starting Yarn extension services with app application_1609183734776_5900 and attemptId Some(appattempt_1609183734776_5900_000001)
2021-05-19 02:45:23 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 36982.
2021-05-19 02:45:23 INFO  NettyBlockTransferService:54 - Server created on hadoop05.cusp.nyu.edu:36982
2021-05-19 02:45:23 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2021-05-19 02:45:23 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, hadoop05.cusp.nyu.edu, 36982, None)
2021-05-19 02:45:23 INFO  BlockManagerMasterEndpoint:54 - Registering block manager hadoop05.cusp.nyu.edu:36982 with 366.3 MB RAM, BlockManagerId(driver, hadoop05.cusp.nyu.edu, 36982, None)
2021-05-19 02:45:23 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, hadoop05.cusp.nyu.edu, 36982, None)
2021-05-19 02:45:23 INFO  BlockManager:54 - external shuffle service port = 7337
2021-05-19 02:45:23 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(driver, hadoop05.cusp.nyu.edu, 36982, None)
2021-05-19 02:45:24 INFO  JettyUtils:54 - Adding filter org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter to /metrics/json.
2021-05-19 02:45:24 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7861a1b1{/metrics/json,null,AVAILABLE,@Spark}
2021-05-19 02:45:24 INFO  EventLoggingListener:54 - Logging events to hdfs://NameService1/user/spark/applicationHistory/application_1609183734776_5900_1
2021-05-19 02:45:24 INFO  YarnRMClient:54 - Registering the ApplicationMaster
2021-05-19 02:45:24 INFO  ApplicationMaster:54 - 
===============================================================================
YARN executor launch context:
  env:
    CLASSPATH -> {{HADOOP_COMMON_HOME}}/../../../CDH/lib/hive/lib/datanucleus-core-4.1.6.jar:{{HADOOP_COMMON_HOME}}/../../../CDH/lib/hive/lib/datanucleus-api-jdo-4.2.1.jar:{{HADOOP_COMMON_HOME}}/../../../CDH/lib/hive/lib/datanucleus-rdbms-4.1.7.jar<CPS>{{PWD}}<CPS>{{PWD}}/__spark_conf__<CPS>{{PWD}}/__spark_libs__/*<CPS>$HADOOP_CLIENT_CONF_DIR<CPS>$HADOOP_COMMON_HOME/*<CPS>$HADOOP_COMMON_HOME/lib/*<CPS>$HADOOP_HDFS_HOME/*<CPS>$HADOOP_HDFS_HOME/lib/*<CPS>$HADOOP_YARN_HOME/*<CPS>$HADOOP_YARN_HOME/lib/*<CPS>$HADOOP_CLIENT_CONF_DIR<CPS>$PWD/mr-framework/*<CPS>$MR2_CLASSPATH<CPS>/etc/hadoop/conf:{{HADOOP_COMMON_HOME}}/../../../CDH-6.1.0-1.cdh6.1.0.p0.770702/lib/hadoop/libexec/../../hadoop/lib/*:{{HADOOP_COMMON_HOME}}/../../../CDH-6.1.0-1.cdh6.1.0.p0.770702/lib/hadoop/libexec/../../hadoop/.//*:{{HADOOP_COMMON_HOME}}/../../../CDH-6.1.0-1.cdh6.1.0.p0.770702/lib/hadoop/libexec/../../hadoop-hdfs/./:{{HADOOP_COMMON_HOME}}/../../../CDH-6.1.0-1.cdh6.1.0.p0.770702/lib/hadoop/libexec/../../hadoop-hdfs/lib/*:{{HADOOP_COMMON_HOME}}/../../../CDH-6.1.0-1.cdh6.1.0.p0.770702/lib/hadoop/libexec/../../hadoop-hdfs/.//*:{{HADOOP_COMMON_HOME}}/../../../CDH/lib/hadoop-mapreduce/.//*:{{HADOOP_COMMON_HOME}}/../../../CDH-6.1.0-1.cdh6.1.0.p0.770702/lib/hadoop/libexec/../../hadoop-yarn/lib/*:{{HADOOP_COMMON_HOME}}/../../../CDH-6.1.0-1.cdh6.1.0.p0.770702/lib/hadoop/libexec/../../hadoop-yarn/.//*<CPS>{{PWD}}/__spark_conf__/__hadoop_conf__
    SPARK_DIST_CLASSPATH -> /etc/hadoop/conf:/opt/cloudera/parcels/CDH-6.1.0-1.cdh6.1.0.p0.770702/lib/hadoop/libexec/../../hadoop/lib/*:/opt/cloudera/parcels/CDH-6.1.0-1.cdh6.1.0.p0.770702/lib/hadoop/libexec/../../hadoop/.//*:/opt/cloudera/parcels/CDH-6.1.0-1.cdh6.1.0.p0.770702/lib/hadoop/libexec/../../hadoop-hdfs/./:/opt/cloudera/parcels/CDH-6.1.0-1.cdh6.1.0.p0.770702/lib/hadoop/libexec/../../hadoop-hdfs/lib/*:/opt/cloudera/parcels/CDH-6.1.0-1.cdh6.1.0.p0.770702/lib/hadoop/libexec/../../hadoop-hdfs/.//*:/opt/cloudera/parcels/CDH/lib/hadoop-mapreduce/.//*:/opt/cloudera/parcels/CDH-6.1.0-1.cdh6.1.0.p0.770702/lib/hadoop/libexec/../../hadoop-yarn/lib/*:/opt/cloudera/parcels/CDH-6.1.0-1.cdh6.1.0.p0.770702/lib/hadoop/libexec/../../hadoop-yarn/.//*
    SPARK_YARN_STAGING_DIR -> hdfs://NameService1/user/catherine.ng60/.sparkStaging/application_1609183734776_5900
    SPARK_USER -> catherine.ng60
    PYTHONPATH -> {{PWD}}/pyspark.zip<CPS>{{PWD}}/py4j-0.10.7-src.zip

  command:
    LD_LIBRARY_PATH=\"{{HADOOP_COMMON_HOME}}/../../../CDH/lib/hadoop/lib/native:$LD_LIBRARY_PATH\" \ 
      {{JAVA_HOME}}/bin/java \ 
      -server \ 
      -Xmx1024m \ 
      -Djava.io.tmpdir={{PWD}}/tmp \ 
      '-Dspark.driver.port=47481' \ 
      '-Dspark.authenticate=false' \ 
      '-Dspark.shuffle.service.port=7337' \ 
      '-Dspark.ui.port=0' \ 
      -Dspark.yarn.app.container.log.dir=<LOG_DIR> \ 
      -XX:OnOutOfMemoryError='kill %p' \ 
      org.apache.spark.executor.CoarseGrainedExecutorBackend \ 
      --driver-url \ 
      spark://CoarseGrainedScheduler@hadoop05.cusp.nyu.edu:47481 \ 
      --executor-id \ 
      <executorId> \ 
      --hostname \ 
      <hostname> \ 
      --cores \ 
      10 \ 
      --app-id \ 
      application_1609183734776_5900 \ 
      --user-class-path \ 
      file:$PWD/__app__.jar \ 
      1><LOG_DIR>/stdout \ 
      2><LOG_DIR>/stderr

  resources:
    pyspark.zip -> resource { scheme: "hdfs" host: "NameService1" port: -1 file: "/user/catherine.ng60/.sparkStaging/application_1609183734776_5900/pyspark.zip" } size: 589244 timestamp: 1621406712809 type: FILE visibility: PRIVATE
    py4j-0.10.7-src.zip -> resource { scheme: "hdfs" host: "NameService1" port: -1 file: "/user/catherine.ng60/.sparkStaging/application_1609183734776_5900/py4j-0.10.7-src.zip" } size: 42437 timestamp: 1621406712851 type: FILE visibility: PRIVATE
    __spark_libs__ -> resource { scheme: "hdfs" host: "NameService1" port: -1 file: "/lib/spark-jars-2.4.0-hadoop2.7.jar" } size: 212061339 timestamp: 1550568561625 type: ARCHIVE visibility: PUBLIC
    __spark_conf__ -> resource { scheme: "hdfs" host: "NameService1" port: -1 file: "/user/catherine.ng60/.sparkStaging/application_1609183734776_5900/__spark_conf__.zip" } size: 145535 timestamp: 1621406713019 type: ARCHIVE visibility: PRIVATE

===============================================================================
2021-05-19 02:45:24 INFO  YarnAllocator:54 - Will request 5 executor container(s), each with 10 core(s) and 1408 MB memory (including 384 MB of overhead)
2021-05-19 02:45:24 INFO  YarnSchedulerBackend$YarnSchedulerEndpoint:54 - ApplicationMaster registered as NettyRpcEndpointRef(spark://YarnAM@hadoop05.cusp.nyu.edu:47481)
2021-05-19 02:45:24 INFO  YarnAllocator:54 - Submitted 5 unlocalized container requests.
2021-05-19 02:45:24 INFO  ApplicationMaster:54 - Started progress reporter thread with (heartbeat : 3000, initial allocation : 200) intervals
2021-05-19 02:45:25 INFO  AMRMClientImpl:360 - Received new token for : hadoop07.cusp.nyu.edu:8041
2021-05-19 02:45:25 INFO  AMRMClientImpl:360 - Received new token for : hadoop20.cusp.nyu.edu:8041
2021-05-19 02:45:25 INFO  AMRMClientImpl:360 - Received new token for : hadoop09.cusp.nyu.edu:8041
2021-05-19 02:45:25 INFO  AMRMClientImpl:360 - Received new token for : hadoop08.cusp.nyu.edu:8041
2021-05-19 02:45:25 INFO  AMRMClientImpl:360 - Received new token for : hadoop10.cusp.nyu.edu:8041
2021-05-19 02:45:25 INFO  YarnAllocator:54 - Launching container container_e10_1609183734776_5900_01_000002 on host hadoop09.cusp.nyu.edu for executor with ID 1
2021-05-19 02:45:25 INFO  YarnAllocator:54 - Launching container container_e10_1609183734776_5900_01_000003 on host hadoop10.cusp.nyu.edu for executor with ID 2
2021-05-19 02:45:25 INFO  YarnAllocator:54 - Launching container container_e10_1609183734776_5900_01_000004 on host hadoop07.cusp.nyu.edu for executor with ID 3
2021-05-19 02:45:25 INFO  YarnAllocator:54 - Launching container container_e10_1609183734776_5900_01_000005 on host hadoop20.cusp.nyu.edu for executor with ID 4
2021-05-19 02:45:25 INFO  YarnAllocator:54 - Launching container container_e10_1609183734776_5900_01_000006 on host hadoop08.cusp.nyu.edu for executor with ID 5
2021-05-19 02:45:25 INFO  YarnAllocator:54 - Received 5 containers from YARN, launching executors on 5 of them.
2021-05-19 02:45:25 INFO  ContainerManagementProtocolProxy:81 - yarn.client.max-cached-nodemanagers-proxies : 0
2021-05-19 02:45:25 INFO  ContainerManagementProtocolProxy:81 - yarn.client.max-cached-nodemanagers-proxies : 0
2021-05-19 02:45:25 INFO  ContainerManagementProtocolProxy:81 - yarn.client.max-cached-nodemanagers-proxies : 0
2021-05-19 02:45:25 INFO  ContainerManagementProtocolProxy:81 - yarn.client.max-cached-nodemanagers-proxies : 0
2021-05-19 02:45:25 INFO  ContainerManagementProtocolProxy:81 - yarn.client.max-cached-nodemanagers-proxies : 0
2021-05-19 02:45:25 INFO  ContainerManagementProtocolProxy:260 - Opening proxy : hadoop10.cusp.nyu.edu:8041
2021-05-19 02:45:25 INFO  ContainerManagementProtocolProxy:260 - Opening proxy : hadoop08.cusp.nyu.edu:8041
2021-05-19 02:45:25 INFO  ContainerManagementProtocolProxy:260 - Opening proxy : hadoop09.cusp.nyu.edu:8041
2021-05-19 02:45:25 INFO  ContainerManagementProtocolProxy:260 - Opening proxy : hadoop20.cusp.nyu.edu:8041
2021-05-19 02:45:25 INFO  ContainerManagementProtocolProxy:260 - Opening proxy : hadoop07.cusp.nyu.edu:8041
2021-05-19 02:45:32 INFO  YarnSchedulerBackend$YarnDriverEndpoint:54 - Registered executor NettyRpcEndpointRef(spark-client://Executor) (192.168.72.177:37542) with ID 3
2021-05-19 02:45:32 INFO  YarnSchedulerBackend$YarnDriverEndpoint:54 - Registered executor NettyRpcEndpointRef(spark-client://Executor) (192.168.72.179:34802) with ID 1
2021-05-19 02:45:32 INFO  YarnSchedulerBackend$YarnDriverEndpoint:54 - Registered executor NettyRpcEndpointRef(spark-client://Executor) (192.168.72.178:41880) with ID 5
2021-05-19 02:45:32 INFO  YarnSchedulerBackend$YarnDriverEndpoint:54 - Registered executor NettyRpcEndpointRef(spark-client://Executor) (192.168.72.180:39670) with ID 2
2021-05-19 02:45:32 INFO  YarnSchedulerBackend$YarnDriverEndpoint:54 - Registered executor NettyRpcEndpointRef(spark-client://Executor) (192.168.72.190:45953) with ID 4
2021-05-19 02:45:32 INFO  YarnClusterSchedulerBackend:54 - SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.8
2021-05-19 02:45:32 INFO  YarnClusterScheduler:54 - YarnClusterScheduler.postStartHook done
2021-05-19 02:45:32 INFO  BlockManagerMasterEndpoint:54 - Registering block manager hadoop07.cusp.nyu.edu:57060 with 366.3 MB RAM, BlockManagerId(3, hadoop07.cusp.nyu.edu, 57060, None)
2021-05-19 02:45:32 INFO  BlockManagerMasterEndpoint:54 - Registering block manager hadoop10.cusp.nyu.edu:51710 with 366.3 MB RAM, BlockManagerId(2, hadoop10.cusp.nyu.edu, 51710, None)
2021-05-19 02:45:32 INFO  BlockManagerMasterEndpoint:54 - Registering block manager hadoop09.cusp.nyu.edu:44190 with 366.3 MB RAM, BlockManagerId(1, hadoop09.cusp.nyu.edu, 44190, None)
2021-05-19 02:45:32 INFO  BlockManagerMasterEndpoint:54 - Registering block manager hadoop08.cusp.nyu.edu:54817 with 366.3 MB RAM, BlockManagerId(5, hadoop08.cusp.nyu.edu, 54817, None)
2021-05-19 02:45:32 INFO  BlockManagerMasterEndpoint:54 - Registering block manager hadoop20.cusp.nyu.edu:55825 with 366.3 MB RAM, BlockManagerId(4, hadoop20.cusp.nyu.edu, 55825, None)
2021-05-19 02:45:32 INFO  SharedState:54 - loading hive config file: file:/localhome/cdp/yarn/nm/usercache/catherine.ng60/filecache/125/__spark_conf__.zip/__hadoop_conf__/hive-site.xml
2021-05-19 02:45:32 INFO  SharedState:54 - spark.sql.warehouse.dir is not set, but hive.metastore.warehouse.dir is set. Setting spark.sql.warehouse.dir to the value of hive.metastore.warehouse.dir ('/user/hive/warehouse').
2021-05-19 02:45:32 INFO  SharedState:54 - Warehouse path is '/user/hive/warehouse'.
2021-05-19 02:45:32 INFO  JettyUtils:54 - Adding filter org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter to /SQL.
2021-05-19 02:45:32 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@31c054ee{/SQL,null,AVAILABLE,@Spark}
2021-05-19 02:45:32 INFO  JettyUtils:54 - Adding filter org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter to /SQL/json.
2021-05-19 02:45:32 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@cfd65dc{/SQL/json,null,AVAILABLE,@Spark}
2021-05-19 02:45:32 INFO  JettyUtils:54 - Adding filter org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter to /SQL/execution.
2021-05-19 02:45:32 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@790bd2c7{/SQL/execution,null,AVAILABLE,@Spark}
2021-05-19 02:45:32 INFO  JettyUtils:54 - Adding filter org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter to /SQL/execution/json.
2021-05-19 02:45:32 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@923cfdb{/SQL/execution/json,null,AVAILABLE,@Spark}
2021-05-19 02:45:32 INFO  JettyUtils:54 - Adding filter org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter to /static/sql.
2021-05-19 02:45:32 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1451c9c5{/static/sql,null,AVAILABLE,@Spark}
2021-05-19 02:45:33 INFO  StateStoreCoordinatorRef:54 - Registered StateStoreCoordinator endpoint
2021-05-19 02:45:36 INFO  FileSourceStrategy:54 - Pruning directories with: 
2021-05-19 02:45:36 INFO  FileSourceStrategy:54 - Post-Scan Filters: (length(trim(value#0, None)) > 0)
2021-05-19 02:45:36 INFO  FileSourceStrategy:54 - Output Data Schema: struct<value: string>
2021-05-19 02:45:36 INFO  FileSourceScanExec:54 - Pushed Filters: 
2021-05-19 02:45:37 INFO  CodeGenerator:54 - Code generated in 350.077781 ms
2021-05-19 02:45:37 INFO  CodeGenerator:54 - Code generated in 42.231254 ms
2021-05-19 02:45:37 INFO  MemoryStore:54 - Block broadcast_0 stored as values in memory (estimated size 332.8 KB, free 366.0 MB)
2021-05-19 02:45:38 INFO  MemoryStore:54 - Block broadcast_0_piece0 stored as bytes in memory (estimated size 33.4 KB, free 365.9 MB)
2021-05-19 02:45:38 INFO  BlockManagerInfo:54 - Added broadcast_0_piece0 in memory on hadoop05.cusp.nyu.edu:36982 (size: 33.4 KB, free: 366.3 MB)
2021-05-19 02:45:38 INFO  SparkContext:54 - Created broadcast 0 from csv at NativeMethodAccessorImpl.java:0
2021-05-19 02:45:38 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2021-05-19 02:45:38 INFO  SparkContext:54 - Starting job: csv at NativeMethodAccessorImpl.java:0
2021-05-19 02:45:38 INFO  DAGScheduler:54 - Got job 0 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
2021-05-19 02:45:38 INFO  DAGScheduler:54 - Final stage: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0)
2021-05-19 02:45:38 INFO  DAGScheduler:54 - Parents of final stage: List()
2021-05-19 02:45:38 INFO  DAGScheduler:54 - Missing parents: List()
2021-05-19 02:45:38 INFO  DAGScheduler:54 - Submitting ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
2021-05-19 02:45:38 INFO  MemoryStore:54 - Block broadcast_1 stored as values in memory (estimated size 8.8 KB, free 365.9 MB)
2021-05-19 02:45:38 INFO  MemoryStore:54 - Block broadcast_1_piece0 stored as bytes in memory (estimated size 4.5 KB, free 365.9 MB)
2021-05-19 02:45:38 INFO  BlockManagerInfo:54 - Added broadcast_1_piece0 in memory on hadoop05.cusp.nyu.edu:36982 (size: 4.5 KB, free: 366.3 MB)
2021-05-19 02:45:38 INFO  SparkContext:54 - Created broadcast 1 from broadcast at DAGScheduler.scala:1161
2021-05-19 02:45:38 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
2021-05-19 02:45:38 INFO  YarnClusterScheduler:54 - Adding task set 0.0 with 1 tasks
2021-05-19 02:45:38 INFO  TaskSetManager:54 - Starting task 0.0 in stage 0.0 (TID 0, hadoop08.cusp.nyu.edu, executor 5, partition 0, NODE_LOCAL, 8321 bytes)
2021-05-19 02:45:38 INFO  BlockManagerInfo:54 - Added broadcast_1_piece0 in memory on hadoop08.cusp.nyu.edu:54817 (size: 4.5 KB, free: 366.3 MB)
2021-05-19 02:45:40 INFO  BlockManagerInfo:54 - Added broadcast_0_piece0 in memory on hadoop08.cusp.nyu.edu:54817 (size: 33.4 KB, free: 366.3 MB)
2021-05-19 02:45:41 INFO  TaskSetManager:54 - Finished task 0.0 in stage 0.0 (TID 0) in 2850 ms on hadoop08.cusp.nyu.edu (executor 5) (1/1)
2021-05-19 02:45:41 INFO  YarnClusterScheduler:54 - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2021-05-19 02:45:41 INFO  DAGScheduler:54 - ResultStage 0 (csv at NativeMethodAccessorImpl.java:0) finished in 3.159 s
2021-05-19 02:45:41 INFO  DAGScheduler:54 - Job 0 finished: csv at NativeMethodAccessorImpl.java:0, took 3.232190 s
2021-05-19 02:45:41 INFO  FileSourceStrategy:54 - Pruning directories with: 
2021-05-19 02:45:41 INFO  FileSourceStrategy:54 - Post-Scan Filters: 
2021-05-19 02:45:41 INFO  FileSourceStrategy:54 - Output Data Schema: struct<value: string>
2021-05-19 02:45:41 INFO  FileSourceScanExec:54 - Pushed Filters: 
2021-05-19 02:45:41 INFO  CodeGenerator:54 - Code generated in 20.336297 ms
2021-05-19 02:45:41 INFO  MemoryStore:54 - Block broadcast_2 stored as values in memory (estimated size 332.8 KB, free 365.6 MB)
2021-05-19 02:45:41 INFO  MemoryStore:54 - Block broadcast_2_piece0 stored as bytes in memory (estimated size 33.4 KB, free 365.6 MB)
2021-05-19 02:45:41 INFO  BlockManagerInfo:54 - Added broadcast_2_piece0 in memory on hadoop05.cusp.nyu.edu:36982 (size: 33.4 KB, free: 366.2 MB)
2021-05-19 02:45:41 INFO  SparkContext:54 - Created broadcast 2 from csv at NativeMethodAccessorImpl.java:0
2021-05-19 02:45:41 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2021-05-19 02:45:41 INFO  InMemoryFileIndex:54 - Listing leaf files and directories in parallel under: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/_SUCCESS, hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00000, hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00001, hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00002, hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00003, hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00004, hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00005, hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00006, hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00007, hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00008, hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00009, hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00010, hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00011, hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00012, hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00013, hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00014, hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00015, hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00016, hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00017, hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00018, hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00019, hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00020, hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00021, hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00022, hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00023, hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00024, hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00025, hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00026, hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00027, hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00028, hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00029, hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00030, hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00031, hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00032, hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00033, hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00034, hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00035, hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00036, hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00037, hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00038, hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00039, hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00040, hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00041, hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00042, hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00043, hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00044, hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00045, hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00046, hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00047, hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00048
2021-05-19 02:45:42 INFO  SparkContext:54 - Starting job: csv at NativeMethodAccessorImpl.java:0
2021-05-19 02:45:42 INFO  DAGScheduler:54 - Got job 1 (csv at NativeMethodAccessorImpl.java:0) with 50 output partitions
2021-05-19 02:45:42 INFO  DAGScheduler:54 - Final stage: ResultStage 1 (csv at NativeMethodAccessorImpl.java:0)
2021-05-19 02:45:42 INFO  DAGScheduler:54 - Parents of final stage: List()
2021-05-19 02:45:42 INFO  DAGScheduler:54 - Missing parents: List()
2021-05-19 02:45:42 INFO  DAGScheduler:54 - Submitting ResultStage 1 (MapPartitionsRDD[11] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
2021-05-19 02:45:42 INFO  MemoryStore:54 - Block broadcast_3 stored as values in memory (estimated size 129.0 KB, free 365.4 MB)
2021-05-19 02:45:42 INFO  MemoryStore:54 - Block broadcast_3_piece0 stored as bytes in memory (estimated size 35.0 KB, free 365.4 MB)
2021-05-19 02:45:42 INFO  BlockManagerInfo:54 - Added broadcast_3_piece0 in memory on hadoop05.cusp.nyu.edu:36982 (size: 35.0 KB, free: 366.2 MB)
2021-05-19 02:45:42 INFO  SparkContext:54 - Created broadcast 3 from broadcast at DAGScheduler.scala:1161
2021-05-19 02:45:42 INFO  DAGScheduler:54 - Submitting 50 missing tasks from ResultStage 1 (MapPartitionsRDD[11] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
2021-05-19 02:45:42 INFO  YarnClusterScheduler:54 - Adding task set 1.0 with 50 tasks
2021-05-19 02:45:42 INFO  TaskSetManager:54 - Starting task 0.0 in stage 1.0 (TID 1, hadoop08.cusp.nyu.edu, executor 5, partition 0, PROCESS_LOCAL, 7786 bytes)
2021-05-19 02:45:42 INFO  TaskSetManager:54 - Starting task 1.0 in stage 1.0 (TID 2, hadoop07.cusp.nyu.edu, executor 3, partition 1, PROCESS_LOCAL, 7788 bytes)
2021-05-19 02:45:42 INFO  TaskSetManager:54 - Starting task 2.0 in stage 1.0 (TID 3, hadoop09.cusp.nyu.edu, executor 1, partition 2, PROCESS_LOCAL, 7788 bytes)
2021-05-19 02:45:42 INFO  TaskSetManager:54 - Starting task 3.0 in stage 1.0 (TID 4, hadoop10.cusp.nyu.edu, executor 2, partition 3, PROCESS_LOCAL, 7788 bytes)
2021-05-19 02:45:42 INFO  TaskSetManager:54 - Starting task 4.0 in stage 1.0 (TID 5, hadoop20.cusp.nyu.edu, executor 4, partition 4, PROCESS_LOCAL, 7788 bytes)
2021-05-19 02:45:42 INFO  TaskSetManager:54 - Starting task 5.0 in stage 1.0 (TID 6, hadoop08.cusp.nyu.edu, executor 5, partition 5, PROCESS_LOCAL, 7788 bytes)
2021-05-19 02:45:42 INFO  TaskSetManager:54 - Starting task 6.0 in stage 1.0 (TID 7, hadoop07.cusp.nyu.edu, executor 3, partition 6, PROCESS_LOCAL, 7788 bytes)
2021-05-19 02:45:42 INFO  TaskSetManager:54 - Starting task 7.0 in stage 1.0 (TID 8, hadoop09.cusp.nyu.edu, executor 1, partition 7, PROCESS_LOCAL, 7788 bytes)
2021-05-19 02:45:42 INFO  TaskSetManager:54 - Starting task 8.0 in stage 1.0 (TID 9, hadoop10.cusp.nyu.edu, executor 2, partition 8, PROCESS_LOCAL, 7788 bytes)
2021-05-19 02:45:42 INFO  TaskSetManager:54 - Starting task 9.0 in stage 1.0 (TID 10, hadoop20.cusp.nyu.edu, executor 4, partition 9, PROCESS_LOCAL, 7788 bytes)
2021-05-19 02:45:42 INFO  TaskSetManager:54 - Starting task 10.0 in stage 1.0 (TID 11, hadoop08.cusp.nyu.edu, executor 5, partition 10, PROCESS_LOCAL, 7788 bytes)
2021-05-19 02:45:42 INFO  TaskSetManager:54 - Starting task 11.0 in stage 1.0 (TID 12, hadoop07.cusp.nyu.edu, executor 3, partition 11, PROCESS_LOCAL, 7788 bytes)
2021-05-19 02:45:42 INFO  TaskSetManager:54 - Starting task 12.0 in stage 1.0 (TID 13, hadoop09.cusp.nyu.edu, executor 1, partition 12, PROCESS_LOCAL, 7788 bytes)
2021-05-19 02:45:42 INFO  TaskSetManager:54 - Starting task 13.0 in stage 1.0 (TID 14, hadoop10.cusp.nyu.edu, executor 2, partition 13, PROCESS_LOCAL, 7788 bytes)
2021-05-19 02:45:42 INFO  TaskSetManager:54 - Starting task 14.0 in stage 1.0 (TID 15, hadoop20.cusp.nyu.edu, executor 4, partition 14, PROCESS_LOCAL, 7788 bytes)
2021-05-19 02:45:42 INFO  TaskSetManager:54 - Starting task 15.0 in stage 1.0 (TID 16, hadoop08.cusp.nyu.edu, executor 5, partition 15, PROCESS_LOCAL, 7788 bytes)
2021-05-19 02:45:42 INFO  TaskSetManager:54 - Starting task 16.0 in stage 1.0 (TID 17, hadoop07.cusp.nyu.edu, executor 3, partition 16, PROCESS_LOCAL, 7788 bytes)
2021-05-19 02:45:42 INFO  TaskSetManager:54 - Starting task 17.0 in stage 1.0 (TID 18, hadoop09.cusp.nyu.edu, executor 1, partition 17, PROCESS_LOCAL, 7788 bytes)
2021-05-19 02:45:42 INFO  TaskSetManager:54 - Starting task 18.0 in stage 1.0 (TID 19, hadoop10.cusp.nyu.edu, executor 2, partition 18, PROCESS_LOCAL, 7788 bytes)
2021-05-19 02:45:42 INFO  TaskSetManager:54 - Starting task 19.0 in stage 1.0 (TID 20, hadoop20.cusp.nyu.edu, executor 4, partition 19, PROCESS_LOCAL, 7788 bytes)
2021-05-19 02:45:42 INFO  TaskSetManager:54 - Starting task 20.0 in stage 1.0 (TID 21, hadoop08.cusp.nyu.edu, executor 5, partition 20, PROCESS_LOCAL, 7788 bytes)
2021-05-19 02:45:42 INFO  TaskSetManager:54 - Starting task 21.0 in stage 1.0 (TID 22, hadoop07.cusp.nyu.edu, executor 3, partition 21, PROCESS_LOCAL, 7788 bytes)
2021-05-19 02:45:42 INFO  TaskSetManager:54 - Starting task 22.0 in stage 1.0 (TID 23, hadoop09.cusp.nyu.edu, executor 1, partition 22, PROCESS_LOCAL, 7788 bytes)
2021-05-19 02:45:42 INFO  TaskSetManager:54 - Starting task 23.0 in stage 1.0 (TID 24, hadoop10.cusp.nyu.edu, executor 2, partition 23, PROCESS_LOCAL, 7788 bytes)
2021-05-19 02:45:42 INFO  TaskSetManager:54 - Starting task 24.0 in stage 1.0 (TID 25, hadoop20.cusp.nyu.edu, executor 4, partition 24, PROCESS_LOCAL, 7788 bytes)
2021-05-19 02:45:42 INFO  TaskSetManager:54 - Starting task 25.0 in stage 1.0 (TID 26, hadoop08.cusp.nyu.edu, executor 5, partition 25, PROCESS_LOCAL, 7788 bytes)
2021-05-19 02:45:42 INFO  TaskSetManager:54 - Starting task 26.0 in stage 1.0 (TID 27, hadoop07.cusp.nyu.edu, executor 3, partition 26, PROCESS_LOCAL, 7788 bytes)
2021-05-19 02:45:42 INFO  TaskSetManager:54 - Starting task 27.0 in stage 1.0 (TID 28, hadoop09.cusp.nyu.edu, executor 1, partition 27, PROCESS_LOCAL, 7788 bytes)
2021-05-19 02:45:42 INFO  TaskSetManager:54 - Starting task 28.0 in stage 1.0 (TID 29, hadoop10.cusp.nyu.edu, executor 2, partition 28, PROCESS_LOCAL, 7788 bytes)
2021-05-19 02:45:42 INFO  TaskSetManager:54 - Starting task 29.0 in stage 1.0 (TID 30, hadoop20.cusp.nyu.edu, executor 4, partition 29, PROCESS_LOCAL, 7788 bytes)
2021-05-19 02:45:42 INFO  TaskSetManager:54 - Starting task 30.0 in stage 1.0 (TID 31, hadoop08.cusp.nyu.edu, executor 5, partition 30, PROCESS_LOCAL, 7788 bytes)
2021-05-19 02:45:42 INFO  TaskSetManager:54 - Starting task 31.0 in stage 1.0 (TID 32, hadoop07.cusp.nyu.edu, executor 3, partition 31, PROCESS_LOCAL, 7788 bytes)
2021-05-19 02:45:42 INFO  TaskSetManager:54 - Starting task 32.0 in stage 1.0 (TID 33, hadoop09.cusp.nyu.edu, executor 1, partition 32, PROCESS_LOCAL, 7788 bytes)
2021-05-19 02:45:42 INFO  TaskSetManager:54 - Starting task 33.0 in stage 1.0 (TID 34, hadoop10.cusp.nyu.edu, executor 2, partition 33, PROCESS_LOCAL, 7788 bytes)
2021-05-19 02:45:42 INFO  TaskSetManager:54 - Starting task 34.0 in stage 1.0 (TID 35, hadoop20.cusp.nyu.edu, executor 4, partition 34, PROCESS_LOCAL, 7788 bytes)
2021-05-19 02:45:42 INFO  TaskSetManager:54 - Starting task 35.0 in stage 1.0 (TID 36, hadoop08.cusp.nyu.edu, executor 5, partition 35, PROCESS_LOCAL, 7788 bytes)
2021-05-19 02:45:42 INFO  TaskSetManager:54 - Starting task 36.0 in stage 1.0 (TID 37, hadoop07.cusp.nyu.edu, executor 3, partition 36, PROCESS_LOCAL, 7788 bytes)
2021-05-19 02:45:42 INFO  TaskSetManager:54 - Starting task 37.0 in stage 1.0 (TID 38, hadoop09.cusp.nyu.edu, executor 1, partition 37, PROCESS_LOCAL, 7788 bytes)
2021-05-19 02:45:42 INFO  TaskSetManager:54 - Starting task 38.0 in stage 1.0 (TID 39, hadoop10.cusp.nyu.edu, executor 2, partition 38, PROCESS_LOCAL, 7788 bytes)
2021-05-19 02:45:42 INFO  TaskSetManager:54 - Starting task 39.0 in stage 1.0 (TID 40, hadoop20.cusp.nyu.edu, executor 4, partition 39, PROCESS_LOCAL, 7788 bytes)
2021-05-19 02:45:42 INFO  TaskSetManager:54 - Starting task 40.0 in stage 1.0 (TID 41, hadoop08.cusp.nyu.edu, executor 5, partition 40, PROCESS_LOCAL, 7788 bytes)
2021-05-19 02:45:42 INFO  TaskSetManager:54 - Starting task 41.0 in stage 1.0 (TID 42, hadoop07.cusp.nyu.edu, executor 3, partition 41, PROCESS_LOCAL, 7788 bytes)
2021-05-19 02:45:42 INFO  TaskSetManager:54 - Starting task 42.0 in stage 1.0 (TID 43, hadoop09.cusp.nyu.edu, executor 1, partition 42, PROCESS_LOCAL, 7788 bytes)
2021-05-19 02:45:42 INFO  TaskSetManager:54 - Starting task 43.0 in stage 1.0 (TID 44, hadoop10.cusp.nyu.edu, executor 2, partition 43, PROCESS_LOCAL, 7788 bytes)
2021-05-19 02:45:42 INFO  TaskSetManager:54 - Starting task 44.0 in stage 1.0 (TID 45, hadoop20.cusp.nyu.edu, executor 4, partition 44, PROCESS_LOCAL, 7788 bytes)
2021-05-19 02:45:42 INFO  TaskSetManager:54 - Starting task 45.0 in stage 1.0 (TID 46, hadoop08.cusp.nyu.edu, executor 5, partition 45, PROCESS_LOCAL, 7788 bytes)
2021-05-19 02:45:42 INFO  TaskSetManager:54 - Starting task 46.0 in stage 1.0 (TID 47, hadoop07.cusp.nyu.edu, executor 3, partition 46, PROCESS_LOCAL, 7788 bytes)
2021-05-19 02:45:42 INFO  TaskSetManager:54 - Starting task 47.0 in stage 1.0 (TID 48, hadoop09.cusp.nyu.edu, executor 1, partition 47, PROCESS_LOCAL, 7788 bytes)
2021-05-19 02:45:42 INFO  TaskSetManager:54 - Starting task 48.0 in stage 1.0 (TID 49, hadoop10.cusp.nyu.edu, executor 2, partition 48, PROCESS_LOCAL, 7788 bytes)
2021-05-19 02:45:42 INFO  TaskSetManager:54 - Starting task 49.0 in stage 1.0 (TID 50, hadoop20.cusp.nyu.edu, executor 4, partition 49, PROCESS_LOCAL, 7788 bytes)
2021-05-19 02:45:42 INFO  BlockManagerInfo:54 - Added broadcast_3_piece0 in memory on hadoop08.cusp.nyu.edu:54817 (size: 35.0 KB, free: 366.2 MB)
2021-05-19 02:45:42 INFO  TaskSetManager:54 - Finished task 0.0 in stage 1.0 (TID 1) in 824 ms on hadoop08.cusp.nyu.edu (executor 5) (1/50)
2021-05-19 02:45:42 INFO  TaskSetManager:54 - Finished task 10.0 in stage 1.0 (TID 11) in 779 ms on hadoop08.cusp.nyu.edu (executor 5) (2/50)
2021-05-19 02:45:42 INFO  TaskSetManager:54 - Finished task 40.0 in stage 1.0 (TID 41) in 643 ms on hadoop08.cusp.nyu.edu (executor 5) (3/50)
2021-05-19 02:45:42 INFO  TaskSetManager:54 - Finished task 35.0 in stage 1.0 (TID 36) in 661 ms on hadoop08.cusp.nyu.edu (executor 5) (4/50)
2021-05-19 02:45:42 INFO  TaskSetManager:54 - Finished task 45.0 in stage 1.0 (TID 46) in 628 ms on hadoop08.cusp.nyu.edu (executor 5) (5/50)
2021-05-19 02:45:42 INFO  TaskSetManager:54 - Finished task 20.0 in stage 1.0 (TID 21) in 733 ms on hadoop08.cusp.nyu.edu (executor 5) (6/50)
2021-05-19 02:45:42 INFO  TaskSetManager:54 - Finished task 5.0 in stage 1.0 (TID 6) in 813 ms on hadoop08.cusp.nyu.edu (executor 5) (7/50)
2021-05-19 02:45:42 INFO  TaskSetManager:54 - Finished task 15.0 in stage 1.0 (TID 16) in 757 ms on hadoop08.cusp.nyu.edu (executor 5) (8/50)
2021-05-19 02:45:42 INFO  TaskSetManager:54 - Finished task 30.0 in stage 1.0 (TID 31) in 687 ms on hadoop08.cusp.nyu.edu (executor 5) (9/50)
2021-05-19 02:45:42 INFO  TaskSetManager:54 - Finished task 25.0 in stage 1.0 (TID 26) in 714 ms on hadoop08.cusp.nyu.edu (executor 5) (10/50)
2021-05-19 02:45:43 INFO  BlockManagerInfo:54 - Added broadcast_3_piece0 in memory on hadoop10.cusp.nyu.edu:51710 (size: 35.0 KB, free: 366.3 MB)
2021-05-19 02:45:43 INFO  BlockManagerInfo:54 - Added broadcast_3_piece0 in memory on hadoop07.cusp.nyu.edu:57060 (size: 35.0 KB, free: 366.3 MB)
2021-05-19 02:45:43 INFO  BlockManagerInfo:54 - Added broadcast_3_piece0 in memory on hadoop20.cusp.nyu.edu:55825 (size: 35.0 KB, free: 366.3 MB)
2021-05-19 02:45:43 INFO  BlockManagerInfo:54 - Added broadcast_3_piece0 in memory on hadoop09.cusp.nyu.edu:44190 (size: 35.0 KB, free: 366.3 MB)
2021-05-19 02:45:44 INFO  TaskSetManager:54 - Finished task 28.0 in stage 1.0 (TID 29) in 2715 ms on hadoop10.cusp.nyu.edu (executor 2) (11/50)
2021-05-19 02:45:44 INFO  TaskSetManager:54 - Finished task 18.0 in stage 1.0 (TID 19) in 2766 ms on hadoop10.cusp.nyu.edu (executor 2) (12/50)
2021-05-19 02:45:44 INFO  TaskSetManager:54 - Finished task 23.0 in stage 1.0 (TID 24) in 2741 ms on hadoop10.cusp.nyu.edu (executor 2) (13/50)
2021-05-19 02:45:44 INFO  TaskSetManager:54 - Finished task 43.0 in stage 1.0 (TID 44) in 2660 ms on hadoop10.cusp.nyu.edu (executor 2) (14/50)
2021-05-19 02:45:44 INFO  TaskSetManager:54 - Finished task 13.0 in stage 1.0 (TID 14) in 2790 ms on hadoop10.cusp.nyu.edu (executor 2) (15/50)
2021-05-19 02:45:44 INFO  TaskSetManager:54 - Finished task 48.0 in stage 1.0 (TID 49) in 2646 ms on hadoop10.cusp.nyu.edu (executor 2) (16/50)
2021-05-19 02:45:44 INFO  TaskSetManager:54 - Finished task 38.0 in stage 1.0 (TID 39) in 2681 ms on hadoop10.cusp.nyu.edu (executor 2) (17/50)
2021-05-19 02:45:44 INFO  TaskSetManager:54 - Finished task 33.0 in stage 1.0 (TID 34) in 2698 ms on hadoop10.cusp.nyu.edu (executor 2) (18/50)
2021-05-19 02:45:44 INFO  TaskSetManager:54 - Finished task 3.0 in stage 1.0 (TID 4) in 2853 ms on hadoop10.cusp.nyu.edu (executor 2) (19/50)
2021-05-19 02:45:44 INFO  TaskSetManager:54 - Finished task 8.0 in stage 1.0 (TID 9) in 2830 ms on hadoop10.cusp.nyu.edu (executor 2) (20/50)
2021-05-19 02:45:45 INFO  TaskSetManager:54 - Finished task 1.0 in stage 1.0 (TID 2) in 2925 ms on hadoop07.cusp.nyu.edu (executor 3) (21/50)
2021-05-19 02:45:45 INFO  TaskSetManager:54 - Finished task 11.0 in stage 1.0 (TID 12) in 2859 ms on hadoop07.cusp.nyu.edu (executor 3) (22/50)
2021-05-19 02:45:45 INFO  TaskSetManager:54 - Finished task 41.0 in stage 1.0 (TID 42) in 2729 ms on hadoop07.cusp.nyu.edu (executor 3) (23/50)
2021-05-19 02:45:45 INFO  TaskSetManager:54 - Finished task 46.0 in stage 1.0 (TID 47) in 2713 ms on hadoop07.cusp.nyu.edu (executor 3) (24/50)
2021-05-19 02:45:45 INFO  TaskSetManager:54 - Finished task 21.0 in stage 1.0 (TID 22) in 2817 ms on hadoop07.cusp.nyu.edu (executor 3) (25/50)
2021-05-19 02:45:45 INFO  TaskSetManager:54 - Finished task 31.0 in stage 1.0 (TID 32) in 2768 ms on hadoop07.cusp.nyu.edu (executor 3) (26/50)
2021-05-19 02:45:45 INFO  TaskSetManager:54 - Finished task 6.0 in stage 1.0 (TID 7) in 2900 ms on hadoop07.cusp.nyu.edu (executor 3) (27/50)
2021-05-19 02:45:45 INFO  TaskSetManager:54 - Finished task 16.0 in stage 1.0 (TID 17) in 2844 ms on hadoop07.cusp.nyu.edu (executor 3) (28/50)
2021-05-19 02:45:45 INFO  TaskSetManager:54 - Finished task 26.0 in stage 1.0 (TID 27) in 2797 ms on hadoop07.cusp.nyu.edu (executor 3) (29/50)
2021-05-19 02:45:45 INFO  TaskSetManager:54 - Finished task 36.0 in stage 1.0 (TID 37) in 2803 ms on hadoop07.cusp.nyu.edu (executor 3) (30/50)
2021-05-19 02:45:45 INFO  TaskSetManager:54 - Finished task 34.0 in stage 1.0 (TID 35) in 2831 ms on hadoop20.cusp.nyu.edu (executor 4) (31/50)
2021-05-19 02:45:45 INFO  TaskSetManager:54 - Finished task 9.0 in stage 1.0 (TID 10) in 2958 ms on hadoop20.cusp.nyu.edu (executor 4) (32/50)
2021-05-19 02:45:45 INFO  TaskSetManager:54 - Finished task 29.0 in stage 1.0 (TID 30) in 2859 ms on hadoop20.cusp.nyu.edu (executor 4) (33/50)
2021-05-19 02:45:45 INFO  TaskSetManager:54 - Finished task 39.0 in stage 1.0 (TID 40) in 2820 ms on hadoop20.cusp.nyu.edu (executor 4) (34/50)
2021-05-19 02:45:45 INFO  TaskSetManager:54 - Finished task 44.0 in stage 1.0 (TID 45) in 2804 ms on hadoop20.cusp.nyu.edu (executor 4) (35/50)
2021-05-19 02:45:45 INFO  TaskSetManager:54 - Finished task 19.0 in stage 1.0 (TID 20) in 2911 ms on hadoop20.cusp.nyu.edu (executor 4) (36/50)
2021-05-19 02:45:45 INFO  TaskSetManager:54 - Finished task 14.0 in stage 1.0 (TID 15) in 2935 ms on hadoop20.cusp.nyu.edu (executor 4) (37/50)
2021-05-19 02:45:45 INFO  TaskSetManager:54 - Finished task 4.0 in stage 1.0 (TID 5) in 2996 ms on hadoop20.cusp.nyu.edu (executor 4) (38/50)
2021-05-19 02:45:45 INFO  TaskSetManager:54 - Finished task 49.0 in stage 1.0 (TID 50) in 2795 ms on hadoop20.cusp.nyu.edu (executor 4) (39/50)
2021-05-19 02:45:45 INFO  TaskSetManager:54 - Finished task 24.0 in stage 1.0 (TID 25) in 2891 ms on hadoop20.cusp.nyu.edu (executor 4) (40/50)
2021-05-19 02:45:45 INFO  ContextCleaner:54 - Cleaned accumulator 13
2021-05-19 02:45:45 INFO  ContextCleaner:54 - Cleaned accumulator 15
2021-05-19 02:45:45 INFO  ContextCleaner:54 - Cleaned accumulator 30
2021-05-19 02:45:45 INFO  ContextCleaner:54 - Cleaned accumulator 32
2021-05-19 02:45:45 INFO  ContextCleaner:54 - Cleaned accumulator 9
2021-05-19 02:45:45 INFO  ContextCleaner:54 - Cleaned accumulator 34
2021-05-19 02:45:45 INFO  ContextCleaner:54 - Cleaned accumulator 5
2021-05-19 02:45:45 INFO  ContextCleaner:54 - Cleaned accumulator 20
2021-05-19 02:45:45 INFO  ContextCleaner:54 - Cleaned accumulator 22
2021-05-19 02:45:45 INFO  ContextCleaner:54 - Cleaned accumulator 4
2021-05-19 02:45:45 INFO  ContextCleaner:54 - Cleaned accumulator 7
2021-05-19 02:45:45 INFO  TaskSetManager:54 - Finished task 37.0 in stage 1.0 (TID 38) in 2873 ms on hadoop09.cusp.nyu.edu (executor 1) (41/50)
2021-05-19 02:45:45 INFO  TaskSetManager:54 - Finished task 17.0 in stage 1.0 (TID 18) in 2964 ms on hadoop09.cusp.nyu.edu (executor 1) (42/50)
2021-05-19 02:45:45 INFO  TaskSetManager:54 - Finished task 42.0 in stage 1.0 (TID 43) in 2856 ms on hadoop09.cusp.nyu.edu (executor 1) (43/50)
2021-05-19 02:45:45 INFO  BlockManagerInfo:54 - Removed broadcast_0_piece0 on hadoop05.cusp.nyu.edu:36982 in memory (size: 33.4 KB, free: 366.2 MB)
2021-05-19 02:45:45 INFO  TaskSetManager:54 - Finished task 7.0 in stage 1.0 (TID 8) in 3024 ms on hadoop09.cusp.nyu.edu (executor 1) (44/50)
2021-05-19 02:45:45 INFO  TaskSetManager:54 - Finished task 22.0 in stage 1.0 (TID 23) in 2945 ms on hadoop09.cusp.nyu.edu (executor 1) (45/50)
2021-05-19 02:45:45 INFO  TaskSetManager:54 - Finished task 27.0 in stage 1.0 (TID 28) in 2923 ms on hadoop09.cusp.nyu.edu (executor 1) (46/50)
2021-05-19 02:45:45 INFO  TaskSetManager:54 - Finished task 12.0 in stage 1.0 (TID 13) in 2993 ms on hadoop09.cusp.nyu.edu (executor 1) (47/50)
2021-05-19 02:45:45 INFO  TaskSetManager:54 - Finished task 2.0 in stage 1.0 (TID 3) in 3061 ms on hadoop09.cusp.nyu.edu (executor 1) (48/50)
2021-05-19 02:45:45 INFO  TaskSetManager:54 - Finished task 47.0 in stage 1.0 (TID 48) in 2851 ms on hadoop09.cusp.nyu.edu (executor 1) (49/50)
2021-05-19 02:45:45 INFO  TaskSetManager:54 - Finished task 32.0 in stage 1.0 (TID 33) in 2903 ms on hadoop09.cusp.nyu.edu (executor 1) (50/50)
2021-05-19 02:45:45 INFO  YarnClusterScheduler:54 - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2021-05-19 02:45:45 INFO  DAGScheduler:54 - ResultStage 1 (csv at NativeMethodAccessorImpl.java:0) finished in 3.147 s
2021-05-19 02:45:45 INFO  DAGScheduler:54 - Job 1 finished: csv at NativeMethodAccessorImpl.java:0, took 3.170300 s
2021-05-19 02:45:45 INFO  BlockManagerInfo:54 - Removed broadcast_0_piece0 on hadoop08.cusp.nyu.edu:54817 in memory (size: 33.4 KB, free: 366.3 MB)
2021-05-19 02:45:45 INFO  ContextCleaner:54 - Cleaned accumulator 18
2021-05-19 02:45:45 INFO  ContextCleaner:54 - Cleaned accumulator 3
2021-05-19 02:45:45 INFO  BlockManagerInfo:54 - Removed broadcast_1_piece0 on hadoop05.cusp.nyu.edu:36982 in memory (size: 4.5 KB, free: 366.2 MB)
2021-05-19 02:45:45 INFO  BlockManagerInfo:54 - Removed broadcast_1_piece0 on hadoop08.cusp.nyu.edu:54817 in memory (size: 4.5 KB, free: 366.3 MB)
2021-05-19 02:45:45 INFO  ContextCleaner:54 - Cleaned accumulator 11
2021-05-19 02:45:45 INFO  ContextCleaner:54 - Cleaned accumulator 35
2021-05-19 02:45:45 INFO  ContextCleaner:54 - Cleaned accumulator 28
2021-05-19 02:45:45 INFO  ContextCleaner:54 - Cleaned accumulator 6
2021-05-19 02:45:45 INFO  ContextCleaner:54 - Cleaned accumulator 8
2021-05-19 02:45:45 INFO  ContextCleaner:54 - Cleaned accumulator 25
2021-05-19 02:45:45 INFO  BlockManagerInfo:54 - Removed broadcast_2_piece0 on hadoop05.cusp.nyu.edu:36982 in memory (size: 33.4 KB, free: 366.3 MB)
2021-05-19 02:45:45 INFO  InMemoryFileIndex:54 - Listing leaf files and directories in parallel under: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00000, hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00001, hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00002, hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00003, hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00004, hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00005, hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00006, hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00007, hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00008, hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00009, hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00010, hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00011, hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00012, hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00013, hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00014, hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00015, hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00016, hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00017, hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00018, hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00019, hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00020, hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00021, hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00022, hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00023, hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00024, hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00025, hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00026, hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00027, hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00028, hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00029, hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00030, hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00031, hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00032, hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00033, hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00034, hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00035, hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00036, hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00037, hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00038, hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00039, hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00040, hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00041, hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00042, hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00043, hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00044, hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00045, hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00046, hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00047, hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00048
2021-05-19 02:45:45 INFO  ContextCleaner:54 - Cleaned accumulator 10
2021-05-19 02:45:45 INFO  ContextCleaner:54 - Cleaned accumulator 1
2021-05-19 02:45:45 INFO  ContextCleaner:54 - Cleaned accumulator 17
2021-05-19 02:45:45 INFO  ContextCleaner:54 - Cleaned accumulator 14
2021-05-19 02:45:45 INFO  ContextCleaner:54 - Cleaned accumulator 31
2021-05-19 02:45:45 INFO  ContextCleaner:54 - Cleaned accumulator 33
2021-05-19 02:45:45 INFO  ContextCleaner:54 - Cleaned accumulator 24
2021-05-19 02:45:45 INFO  ContextCleaner:54 - Cleaned accumulator 16
2021-05-19 02:45:45 INFO  ContextCleaner:54 - Cleaned accumulator 19
2021-05-19 02:45:45 INFO  ContextCleaner:54 - Cleaned accumulator 26
2021-05-19 02:45:45 INFO  ContextCleaner:54 - Cleaned accumulator 36
2021-05-19 02:45:45 INFO  ContextCleaner:54 - Cleaned accumulator 27
2021-05-19 02:45:45 INFO  ContextCleaner:54 - Cleaned accumulator 29
2021-05-19 02:45:45 INFO  ContextCleaner:54 - Cleaned accumulator 2
2021-05-19 02:45:45 INFO  ContextCleaner:54 - Cleaned accumulator 21
2021-05-19 02:45:45 INFO  ContextCleaner:54 - Cleaned accumulator 12
2021-05-19 02:45:45 INFO  ContextCleaner:54 - Cleaned accumulator 23
2021-05-19 02:45:45 INFO  SparkContext:54 - Starting job: csv at NativeMethodAccessorImpl.java:0
2021-05-19 02:45:45 INFO  DAGScheduler:54 - Got job 2 (csv at NativeMethodAccessorImpl.java:0) with 49 output partitions
2021-05-19 02:45:45 INFO  DAGScheduler:54 - Final stage: ResultStage 2 (csv at NativeMethodAccessorImpl.java:0)
2021-05-19 02:45:45 INFO  DAGScheduler:54 - Parents of final stage: List()
2021-05-19 02:45:45 INFO  DAGScheduler:54 - Missing parents: List()
2021-05-19 02:45:45 INFO  DAGScheduler:54 - Submitting ResultStage 2 (MapPartitionsRDD[14] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
2021-05-19 02:45:45 INFO  MemoryStore:54 - Block broadcast_4 stored as values in memory (estimated size 129.0 KB, free 366.0 MB)
2021-05-19 02:45:45 INFO  MemoryStore:54 - Block broadcast_4_piece0 stored as bytes in memory (estimated size 35.0 KB, free 366.0 MB)
2021-05-19 02:45:45 INFO  BlockManagerInfo:54 - Added broadcast_4_piece0 in memory on hadoop05.cusp.nyu.edu:36982 (size: 35.0 KB, free: 366.2 MB)
2021-05-19 02:45:45 INFO  SparkContext:54 - Created broadcast 4 from broadcast at DAGScheduler.scala:1161
2021-05-19 02:45:45 INFO  DAGScheduler:54 - Submitting 49 missing tasks from ResultStage 2 (MapPartitionsRDD[14] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
2021-05-19 02:45:45 INFO  YarnClusterScheduler:54 - Adding task set 2.0 with 49 tasks
2021-05-19 02:45:45 INFO  TaskSetManager:54 - Starting task 0.0 in stage 2.0 (TID 51, hadoop09.cusp.nyu.edu, executor 1, partition 0, PROCESS_LOCAL, 7788 bytes)
2021-05-19 02:45:45 INFO  TaskSetManager:54 - Starting task 1.0 in stage 2.0 (TID 52, hadoop20.cusp.nyu.edu, executor 4, partition 1, PROCESS_LOCAL, 7788 bytes)
2021-05-19 02:45:45 INFO  TaskSetManager:54 - Starting task 2.0 in stage 2.0 (TID 53, hadoop10.cusp.nyu.edu, executor 2, partition 2, PROCESS_LOCAL, 7788 bytes)
2021-05-19 02:45:45 INFO  TaskSetManager:54 - Starting task 3.0 in stage 2.0 (TID 54, hadoop08.cusp.nyu.edu, executor 5, partition 3, PROCESS_LOCAL, 7788 bytes)
2021-05-19 02:45:45 INFO  TaskSetManager:54 - Starting task 4.0 in stage 2.0 (TID 55, hadoop07.cusp.nyu.edu, executor 3, partition 4, PROCESS_LOCAL, 7788 bytes)
2021-05-19 02:45:45 INFO  TaskSetManager:54 - Starting task 5.0 in stage 2.0 (TID 56, hadoop09.cusp.nyu.edu, executor 1, partition 5, PROCESS_LOCAL, 7788 bytes)
2021-05-19 02:45:45 INFO  TaskSetManager:54 - Starting task 6.0 in stage 2.0 (TID 57, hadoop20.cusp.nyu.edu, executor 4, partition 6, PROCESS_LOCAL, 7788 bytes)
2021-05-19 02:45:45 INFO  TaskSetManager:54 - Starting task 7.0 in stage 2.0 (TID 58, hadoop10.cusp.nyu.edu, executor 2, partition 7, PROCESS_LOCAL, 7788 bytes)
2021-05-19 02:45:45 INFO  TaskSetManager:54 - Starting task 8.0 in stage 2.0 (TID 59, hadoop08.cusp.nyu.edu, executor 5, partition 8, PROCESS_LOCAL, 7788 bytes)
2021-05-19 02:45:45 INFO  TaskSetManager:54 - Starting task 9.0 in stage 2.0 (TID 60, hadoop07.cusp.nyu.edu, executor 3, partition 9, PROCESS_LOCAL, 7788 bytes)
2021-05-19 02:45:45 INFO  TaskSetManager:54 - Starting task 10.0 in stage 2.0 (TID 61, hadoop09.cusp.nyu.edu, executor 1, partition 10, PROCESS_LOCAL, 7788 bytes)
2021-05-19 02:45:45 INFO  TaskSetManager:54 - Starting task 11.0 in stage 2.0 (TID 62, hadoop20.cusp.nyu.edu, executor 4, partition 11, PROCESS_LOCAL, 7788 bytes)
2021-05-19 02:45:45 INFO  TaskSetManager:54 - Starting task 12.0 in stage 2.0 (TID 63, hadoop10.cusp.nyu.edu, executor 2, partition 12, PROCESS_LOCAL, 7788 bytes)
2021-05-19 02:45:45 INFO  TaskSetManager:54 - Starting task 13.0 in stage 2.0 (TID 64, hadoop08.cusp.nyu.edu, executor 5, partition 13, PROCESS_LOCAL, 7788 bytes)
2021-05-19 02:45:45 INFO  TaskSetManager:54 - Starting task 14.0 in stage 2.0 (TID 65, hadoop07.cusp.nyu.edu, executor 3, partition 14, PROCESS_LOCAL, 7788 bytes)
2021-05-19 02:45:45 INFO  TaskSetManager:54 - Starting task 15.0 in stage 2.0 (TID 66, hadoop09.cusp.nyu.edu, executor 1, partition 15, PROCESS_LOCAL, 7788 bytes)
2021-05-19 02:45:45 INFO  TaskSetManager:54 - Starting task 16.0 in stage 2.0 (TID 67, hadoop20.cusp.nyu.edu, executor 4, partition 16, PROCESS_LOCAL, 7788 bytes)
2021-05-19 02:45:45 INFO  TaskSetManager:54 - Starting task 17.0 in stage 2.0 (TID 68, hadoop10.cusp.nyu.edu, executor 2, partition 17, PROCESS_LOCAL, 7788 bytes)
2021-05-19 02:45:45 INFO  TaskSetManager:54 - Starting task 18.0 in stage 2.0 (TID 69, hadoop08.cusp.nyu.edu, executor 5, partition 18, PROCESS_LOCAL, 7788 bytes)
2021-05-19 02:45:45 INFO  TaskSetManager:54 - Starting task 19.0 in stage 2.0 (TID 70, hadoop07.cusp.nyu.edu, executor 3, partition 19, PROCESS_LOCAL, 7788 bytes)
2021-05-19 02:45:45 INFO  TaskSetManager:54 - Starting task 20.0 in stage 2.0 (TID 71, hadoop09.cusp.nyu.edu, executor 1, partition 20, PROCESS_LOCAL, 7788 bytes)
2021-05-19 02:45:45 INFO  TaskSetManager:54 - Starting task 21.0 in stage 2.0 (TID 72, hadoop20.cusp.nyu.edu, executor 4, partition 21, PROCESS_LOCAL, 7788 bytes)
2021-05-19 02:45:45 INFO  TaskSetManager:54 - Starting task 22.0 in stage 2.0 (TID 73, hadoop10.cusp.nyu.edu, executor 2, partition 22, PROCESS_LOCAL, 7788 bytes)
2021-05-19 02:45:45 INFO  TaskSetManager:54 - Starting task 23.0 in stage 2.0 (TID 74, hadoop08.cusp.nyu.edu, executor 5, partition 23, PROCESS_LOCAL, 7788 bytes)
2021-05-19 02:45:45 INFO  TaskSetManager:54 - Starting task 24.0 in stage 2.0 (TID 75, hadoop07.cusp.nyu.edu, executor 3, partition 24, PROCESS_LOCAL, 7788 bytes)
2021-05-19 02:45:45 INFO  TaskSetManager:54 - Starting task 25.0 in stage 2.0 (TID 76, hadoop09.cusp.nyu.edu, executor 1, partition 25, PROCESS_LOCAL, 7788 bytes)
2021-05-19 02:45:45 INFO  TaskSetManager:54 - Starting task 26.0 in stage 2.0 (TID 77, hadoop20.cusp.nyu.edu, executor 4, partition 26, PROCESS_LOCAL, 7788 bytes)
2021-05-19 02:45:45 INFO  TaskSetManager:54 - Starting task 27.0 in stage 2.0 (TID 78, hadoop10.cusp.nyu.edu, executor 2, partition 27, PROCESS_LOCAL, 7788 bytes)
2021-05-19 02:45:45 INFO  TaskSetManager:54 - Starting task 28.0 in stage 2.0 (TID 79, hadoop08.cusp.nyu.edu, executor 5, partition 28, PROCESS_LOCAL, 7788 bytes)
2021-05-19 02:45:45 INFO  TaskSetManager:54 - Starting task 29.0 in stage 2.0 (TID 80, hadoop07.cusp.nyu.edu, executor 3, partition 29, PROCESS_LOCAL, 7788 bytes)
2021-05-19 02:45:45 INFO  TaskSetManager:54 - Starting task 30.0 in stage 2.0 (TID 81, hadoop09.cusp.nyu.edu, executor 1, partition 30, PROCESS_LOCAL, 7788 bytes)
2021-05-19 02:45:45 INFO  TaskSetManager:54 - Starting task 31.0 in stage 2.0 (TID 82, hadoop20.cusp.nyu.edu, executor 4, partition 31, PROCESS_LOCAL, 7788 bytes)
2021-05-19 02:45:45 INFO  TaskSetManager:54 - Starting task 32.0 in stage 2.0 (TID 83, hadoop10.cusp.nyu.edu, executor 2, partition 32, PROCESS_LOCAL, 7788 bytes)
2021-05-19 02:45:45 INFO  TaskSetManager:54 - Starting task 33.0 in stage 2.0 (TID 84, hadoop08.cusp.nyu.edu, executor 5, partition 33, PROCESS_LOCAL, 7788 bytes)
2021-05-19 02:45:45 INFO  TaskSetManager:54 - Starting task 34.0 in stage 2.0 (TID 85, hadoop07.cusp.nyu.edu, executor 3, partition 34, PROCESS_LOCAL, 7788 bytes)
2021-05-19 02:45:45 INFO  TaskSetManager:54 - Starting task 35.0 in stage 2.0 (TID 86, hadoop09.cusp.nyu.edu, executor 1, partition 35, PROCESS_LOCAL, 7788 bytes)
2021-05-19 02:45:45 INFO  TaskSetManager:54 - Starting task 36.0 in stage 2.0 (TID 87, hadoop20.cusp.nyu.edu, executor 4, partition 36, PROCESS_LOCAL, 7788 bytes)
2021-05-19 02:45:45 INFO  TaskSetManager:54 - Starting task 37.0 in stage 2.0 (TID 88, hadoop10.cusp.nyu.edu, executor 2, partition 37, PROCESS_LOCAL, 7788 bytes)
2021-05-19 02:45:45 INFO  TaskSetManager:54 - Starting task 38.0 in stage 2.0 (TID 89, hadoop08.cusp.nyu.edu, executor 5, partition 38, PROCESS_LOCAL, 7788 bytes)
2021-05-19 02:45:45 INFO  TaskSetManager:54 - Starting task 39.0 in stage 2.0 (TID 90, hadoop07.cusp.nyu.edu, executor 3, partition 39, PROCESS_LOCAL, 7788 bytes)
2021-05-19 02:45:45 INFO  TaskSetManager:54 - Starting task 40.0 in stage 2.0 (TID 91, hadoop09.cusp.nyu.edu, executor 1, partition 40, PROCESS_LOCAL, 7788 bytes)
2021-05-19 02:45:45 INFO  TaskSetManager:54 - Starting task 41.0 in stage 2.0 (TID 92, hadoop20.cusp.nyu.edu, executor 4, partition 41, PROCESS_LOCAL, 7788 bytes)
2021-05-19 02:45:45 INFO  TaskSetManager:54 - Starting task 42.0 in stage 2.0 (TID 93, hadoop10.cusp.nyu.edu, executor 2, partition 42, PROCESS_LOCAL, 7788 bytes)
2021-05-19 02:45:45 INFO  TaskSetManager:54 - Starting task 43.0 in stage 2.0 (TID 94, hadoop08.cusp.nyu.edu, executor 5, partition 43, PROCESS_LOCAL, 7788 bytes)
2021-05-19 02:45:45 INFO  TaskSetManager:54 - Starting task 44.0 in stage 2.0 (TID 95, hadoop07.cusp.nyu.edu, executor 3, partition 44, PROCESS_LOCAL, 7788 bytes)
2021-05-19 02:45:45 INFO  TaskSetManager:54 - Starting task 45.0 in stage 2.0 (TID 96, hadoop09.cusp.nyu.edu, executor 1, partition 45, PROCESS_LOCAL, 7788 bytes)
2021-05-19 02:45:45 INFO  TaskSetManager:54 - Starting task 46.0 in stage 2.0 (TID 97, hadoop20.cusp.nyu.edu, executor 4, partition 46, PROCESS_LOCAL, 7788 bytes)
2021-05-19 02:45:45 INFO  TaskSetManager:54 - Starting task 47.0 in stage 2.0 (TID 98, hadoop10.cusp.nyu.edu, executor 2, partition 47, PROCESS_LOCAL, 7788 bytes)
2021-05-19 02:45:45 INFO  TaskSetManager:54 - Starting task 48.0 in stage 2.0 (TID 99, hadoop08.cusp.nyu.edu, executor 5, partition 48, PROCESS_LOCAL, 7788 bytes)
2021-05-19 02:45:45 INFO  BlockManagerInfo:54 - Added broadcast_4_piece0 in memory on hadoop08.cusp.nyu.edu:54817 (size: 35.0 KB, free: 366.2 MB)
2021-05-19 02:45:45 INFO  BlockManagerInfo:54 - Added broadcast_4_piece0 in memory on hadoop10.cusp.nyu.edu:51710 (size: 35.0 KB, free: 366.2 MB)
2021-05-19 02:45:45 INFO  BlockManagerInfo:54 - Added broadcast_4_piece0 in memory on hadoop09.cusp.nyu.edu:44190 (size: 35.0 KB, free: 366.2 MB)
2021-05-19 02:45:45 INFO  BlockManagerInfo:54 - Added broadcast_4_piece0 in memory on hadoop20.cusp.nyu.edu:55825 (size: 35.0 KB, free: 366.2 MB)
2021-05-19 02:45:45 INFO  BlockManagerInfo:54 - Added broadcast_4_piece0 in memory on hadoop07.cusp.nyu.edu:57060 (size: 35.0 KB, free: 366.2 MB)
2021-05-19 02:45:45 INFO  TaskSetManager:54 - Finished task 7.0 in stage 2.0 (TID 58) in 299 ms on hadoop10.cusp.nyu.edu (executor 2) (1/49)
2021-05-19 02:45:45 INFO  TaskSetManager:54 - Finished task 10.0 in stage 2.0 (TID 61) in 299 ms on hadoop09.cusp.nyu.edu (executor 1) (2/49)
2021-05-19 02:45:45 INFO  TaskSetManager:54 - Finished task 11.0 in stage 2.0 (TID 62) in 331 ms on hadoop20.cusp.nyu.edu (executor 4) (3/49)
2021-05-19 02:45:45 INFO  TaskSetManager:54 - Finished task 24.0 in stage 2.0 (TID 75) in 295 ms on hadoop07.cusp.nyu.edu (executor 3) (4/49)
2021-05-19 02:45:45 INFO  TaskSetManager:54 - Finished task 3.0 in stage 2.0 (TID 54) in 416 ms on hadoop08.cusp.nyu.edu (executor 5) (5/49)
2021-05-19 02:45:45 INFO  TaskSetManager:54 - Finished task 39.0 in stage 2.0 (TID 90) in 313 ms on hadoop07.cusp.nyu.edu (executor 3) (6/49)
2021-05-19 02:45:45 INFO  TaskSetManager:54 - Finished task 29.0 in stage 2.0 (TID 80) in 345 ms on hadoop07.cusp.nyu.edu (executor 3) (7/49)
2021-05-19 02:45:45 INFO  TaskSetManager:54 - Finished task 34.0 in stage 2.0 (TID 85) in 333 ms on hadoop07.cusp.nyu.edu (executor 3) (8/49)
2021-05-19 02:45:45 INFO  TaskSetManager:54 - Finished task 4.0 in stage 2.0 (TID 55) in 425 ms on hadoop07.cusp.nyu.edu (executor 3) (9/49)
2021-05-19 02:45:45 INFO  TaskSetManager:54 - Finished task 38.0 in stage 2.0 (TID 89) in 325 ms on hadoop08.cusp.nyu.edu (executor 5) (10/49)
2021-05-19 02:45:45 INFO  TaskSetManager:54 - Finished task 9.0 in stage 2.0 (TID 60) in 410 ms on hadoop07.cusp.nyu.edu (executor 3) (11/49)
2021-05-19 02:45:45 INFO  TaskSetManager:54 - Finished task 44.0 in stage 2.0 (TID 95) in 311 ms on hadoop07.cusp.nyu.edu (executor 3) (12/49)
2021-05-19 02:45:45 INFO  TaskSetManager:54 - Finished task 19.0 in stage 2.0 (TID 70) in 383 ms on hadoop07.cusp.nyu.edu (executor 3) (13/49)
2021-05-19 02:45:45 INFO  TaskSetManager:54 - Finished task 14.0 in stage 2.0 (TID 65) in 401 ms on hadoop07.cusp.nyu.edu (executor 3) (14/49)
2021-05-19 02:45:45 INFO  TaskSetManager:54 - Finished task 13.0 in stage 2.0 (TID 64) in 404 ms on hadoop08.cusp.nyu.edu (executor 5) (15/49)
2021-05-19 02:45:45 INFO  TaskSetManager:54 - Finished task 48.0 in stage 2.0 (TID 99) in 305 ms on hadoop08.cusp.nyu.edu (executor 5) (16/49)
2021-05-19 02:45:45 INFO  TaskSetManager:54 - Finished task 43.0 in stage 2.0 (TID 94) in 327 ms on hadoop08.cusp.nyu.edu (executor 5) (17/49)
2021-05-19 02:45:45 INFO  TaskSetManager:54 - Finished task 28.0 in stage 2.0 (TID 79) in 375 ms on hadoop08.cusp.nyu.edu (executor 5) (18/49)
2021-05-19 02:45:45 INFO  TaskSetManager:54 - Finished task 33.0 in stage 2.0 (TID 84) in 369 ms on hadoop08.cusp.nyu.edu (executor 5) (19/49)
2021-05-19 02:45:45 INFO  TaskSetManager:54 - Finished task 18.0 in stage 2.0 (TID 69) in 423 ms on hadoop08.cusp.nyu.edu (executor 5) (20/49)
2021-05-19 02:45:45 INFO  TaskSetManager:54 - Finished task 23.0 in stage 2.0 (TID 74) in 409 ms on hadoop08.cusp.nyu.edu (executor 5) (21/49)
2021-05-19 02:45:45 INFO  TaskSetManager:54 - Finished task 8.0 in stage 2.0 (TID 59) in 454 ms on hadoop08.cusp.nyu.edu (executor 5) (22/49)
2021-05-19 02:45:45 INFO  TaskSetManager:54 - Finished task 17.0 in stage 2.0 (TID 68) in 432 ms on hadoop10.cusp.nyu.edu (executor 2) (23/49)
2021-05-19 02:45:45 INFO  TaskSetManager:54 - Finished task 32.0 in stage 2.0 (TID 83) in 389 ms on hadoop10.cusp.nyu.edu (executor 2) (24/49)
2021-05-19 02:45:45 INFO  TaskSetManager:54 - Finished task 42.0 in stage 2.0 (TID 93) in 363 ms on hadoop10.cusp.nyu.edu (executor 2) (25/49)
2021-05-19 02:45:45 INFO  TaskSetManager:54 - Finished task 2.0 in stage 2.0 (TID 53) in 482 ms on hadoop10.cusp.nyu.edu (executor 2) (26/49)
2021-05-19 02:45:45 INFO  TaskSetManager:54 - Finished task 12.0 in stage 2.0 (TID 63) in 451 ms on hadoop10.cusp.nyu.edu (executor 2) (27/49)
2021-05-19 02:45:45 INFO  TaskSetManager:54 - Finished task 47.0 in stage 2.0 (TID 98) in 351 ms on hadoop10.cusp.nyu.edu (executor 2) (28/49)
2021-05-19 02:45:45 INFO  TaskSetManager:54 - Finished task 22.0 in stage 2.0 (TID 73) in 423 ms on hadoop10.cusp.nyu.edu (executor 2) (29/49)
2021-05-19 02:45:45 INFO  TaskSetManager:54 - Finished task 37.0 in stage 2.0 (TID 88) in 380 ms on hadoop10.cusp.nyu.edu (executor 2) (30/49)
2021-05-19 02:45:45 INFO  TaskSetManager:54 - Finished task 27.0 in stage 2.0 (TID 78) in 411 ms on hadoop10.cusp.nyu.edu (executor 2) (31/49)
2021-05-19 02:45:45 INFO  TaskSetManager:54 - Finished task 5.0 in stage 2.0 (TID 56) in 491 ms on hadoop09.cusp.nyu.edu (executor 1) (32/49)
2021-05-19 02:45:45 INFO  TaskSetManager:54 - Finished task 20.0 in stage 2.0 (TID 71) in 446 ms on hadoop09.cusp.nyu.edu (executor 1) (33/49)
2021-05-19 02:45:45 INFO  TaskSetManager:54 - Finished task 40.0 in stage 2.0 (TID 91) in 398 ms on hadoop09.cusp.nyu.edu (executor 1) (34/49)
2021-05-19 02:45:45 INFO  TaskSetManager:54 - Finished task 35.0 in stage 2.0 (TID 86) in 413 ms on hadoop09.cusp.nyu.edu (executor 1) (35/49)
2021-05-19 02:45:45 INFO  TaskSetManager:54 - Finished task 15.0 in stage 2.0 (TID 66) in 472 ms on hadoop09.cusp.nyu.edu (executor 1) (36/49)
2021-05-19 02:45:45 INFO  TaskSetManager:54 - Finished task 0.0 in stage 2.0 (TID 51) in 531 ms on hadoop09.cusp.nyu.edu (executor 1) (37/49)
2021-05-19 02:45:45 INFO  TaskSetManager:54 - Finished task 6.0 in stage 2.0 (TID 57) in 506 ms on hadoop20.cusp.nyu.edu (executor 4) (38/49)
2021-05-19 02:45:45 INFO  TaskSetManager:54 - Finished task 25.0 in stage 2.0 (TID 76) in 453 ms on hadoop09.cusp.nyu.edu (executor 1) (39/49)
2021-05-19 02:45:45 INFO  TaskSetManager:54 - Finished task 45.0 in stage 2.0 (TID 96) in 397 ms on hadoop09.cusp.nyu.edu (executor 1) (40/49)
2021-05-19 02:45:45 INFO  TaskSetManager:54 - Finished task 30.0 in stage 2.0 (TID 81) in 439 ms on hadoop09.cusp.nyu.edu (executor 1) (41/49)
2021-05-19 02:45:45 INFO  TaskSetManager:54 - Finished task 31.0 in stage 2.0 (TID 82) in 454 ms on hadoop20.cusp.nyu.edu (executor 4) (42/49)
2021-05-19 02:45:45 INFO  TaskSetManager:54 - Finished task 41.0 in stage 2.0 (TID 92) in 427 ms on hadoop20.cusp.nyu.edu (executor 4) (43/49)
2021-05-19 02:45:46 INFO  TaskSetManager:54 - Finished task 26.0 in stage 2.0 (TID 77) in 475 ms on hadoop20.cusp.nyu.edu (executor 4) (44/49)
2021-05-19 02:45:46 INFO  TaskSetManager:54 - Finished task 36.0 in stage 2.0 (TID 87) in 446 ms on hadoop20.cusp.nyu.edu (executor 4) (45/49)
2021-05-19 02:45:46 INFO  TaskSetManager:54 - Finished task 1.0 in stage 2.0 (TID 52) in 555 ms on hadoop20.cusp.nyu.edu (executor 4) (46/49)
2021-05-19 02:45:46 INFO  TaskSetManager:54 - Finished task 46.0 in stage 2.0 (TID 97) in 422 ms on hadoop20.cusp.nyu.edu (executor 4) (47/49)
2021-05-19 02:45:46 INFO  TaskSetManager:54 - Finished task 16.0 in stage 2.0 (TID 67) in 516 ms on hadoop20.cusp.nyu.edu (executor 4) (48/49)
2021-05-19 02:45:46 INFO  TaskSetManager:54 - Finished task 21.0 in stage 2.0 (TID 72) in 502 ms on hadoop20.cusp.nyu.edu (executor 4) (49/49)
2021-05-19 02:45:46 INFO  YarnClusterScheduler:54 - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2021-05-19 02:45:46 INFO  DAGScheduler:54 - ResultStage 2 (csv at NativeMethodAccessorImpl.java:0) finished in 0.628 s
2021-05-19 02:45:46 INFO  DAGScheduler:54 - Job 2 finished: csv at NativeMethodAccessorImpl.java:0, took 0.639346 s
2021-05-19 02:45:46 INFO  ContextCleaner:54 - Cleaned accumulator 43
2021-05-19 02:45:46 INFO  ContextCleaner:54 - Cleaned accumulator 44
2021-05-19 02:45:46 INFO  ContextCleaner:54 - Cleaned accumulator 47
2021-05-19 02:45:46 INFO  ContextCleaner:54 - Cleaned accumulator 65
2021-05-19 02:45:46 INFO  ContextCleaner:54 - Cleaned accumulator 86
2021-05-19 02:45:46 INFO  ContextCleaner:54 - Cleaned accumulator 37
2021-05-19 02:45:46 INFO  BlockManagerInfo:54 - Removed broadcast_3_piece0 on hadoop05.cusp.nyu.edu:36982 in memory (size: 35.0 KB, free: 366.3 MB)
2021-05-19 02:45:46 INFO  BlockManagerInfo:54 - Removed broadcast_3_piece0 on hadoop08.cusp.nyu.edu:54817 in memory (size: 35.0 KB, free: 366.3 MB)
2021-05-19 02:45:46 INFO  BlockManagerInfo:54 - Removed broadcast_3_piece0 on hadoop10.cusp.nyu.edu:51710 in memory (size: 35.0 KB, free: 366.3 MB)
2021-05-19 02:45:46 INFO  BlockManagerInfo:54 - Removed broadcast_3_piece0 on hadoop20.cusp.nyu.edu:55825 in memory (size: 35.0 KB, free: 366.3 MB)
2021-05-19 02:45:46 INFO  BlockManagerInfo:54 - Removed broadcast_3_piece0 on hadoop07.cusp.nyu.edu:57060 in memory (size: 35.0 KB, free: 366.3 MB)
2021-05-19 02:45:46 INFO  BlockManagerInfo:54 - Removed broadcast_3_piece0 on hadoop09.cusp.nyu.edu:44190 in memory (size: 35.0 KB, free: 366.3 MB)
2021-05-19 02:45:46 INFO  ContextCleaner:54 - Cleaned accumulator 41
2021-05-19 02:45:46 INFO  ContextCleaner:54 - Cleaned accumulator 46
2021-05-19 02:45:46 INFO  ContextCleaner:54 - Cleaned accumulator 59
2021-05-19 02:45:46 INFO  ContextCleaner:54 - Cleaned accumulator 58
2021-05-19 02:45:46 INFO  ContextCleaner:54 - Cleaned accumulator 49
2021-05-19 02:45:46 INFO  ContextCleaner:54 - Cleaned accumulator 75
2021-05-19 02:45:46 INFO  ContextCleaner:54 - Cleaned accumulator 45
2021-05-19 02:45:46 INFO  ContextCleaner:54 - Cleaned accumulator 63
2021-05-19 02:45:46 INFO  ContextCleaner:54 - Cleaned accumulator 84
2021-05-19 02:45:46 INFO  ContextCleaner:54 - Cleaned accumulator 67
2021-05-19 02:45:46 INFO  ContextCleaner:54 - Cleaned accumulator 38
2021-05-19 02:45:46 INFO  ContextCleaner:54 - Cleaned accumulator 70
2021-05-19 02:45:46 INFO  ContextCleaner:54 - Cleaned accumulator 48
2021-05-19 02:45:46 INFO  ContextCleaner:54 - Cleaned accumulator 62
2021-05-19 02:45:46 INFO  ContextCleaner:54 - Cleaned accumulator 55
2021-05-19 02:45:46 INFO  ContextCleaner:54 - Cleaned accumulator 64
2021-05-19 02:45:46 INFO  ContextCleaner:54 - Cleaned accumulator 74
2021-05-19 02:45:46 INFO  ContextCleaner:54 - Cleaned accumulator 76
2021-05-19 02:45:46 INFO  ContextCleaner:54 - Cleaned accumulator 40
2021-05-19 02:45:46 INFO  ContextCleaner:54 - Cleaned accumulator 57
2021-05-19 02:45:46 INFO  ContextCleaner:54 - Cleaned accumulator 71
2021-05-19 02:45:46 INFO  ContextCleaner:54 - Cleaned accumulator 53
2021-05-19 02:45:46 INFO  ContextCleaner:54 - Cleaned accumulator 54
2021-05-19 02:45:46 INFO  ContextCleaner:54 - Cleaned accumulator 77
2021-05-19 02:45:46 INFO  ContextCleaner:54 - Cleaned accumulator 81
2021-05-19 02:45:46 INFO  ContextCleaner:54 - Cleaned accumulator 69
2021-05-19 02:45:46 INFO  ContextCleaner:54 - Cleaned accumulator 80
2021-05-19 02:45:46 INFO  ContextCleaner:54 - Cleaned accumulator 61
2021-05-19 02:45:46 INFO  BlockManagerInfo:54 - Removed broadcast_4_piece0 on hadoop05.cusp.nyu.edu:36982 in memory (size: 35.0 KB, free: 366.3 MB)
2021-05-19 02:45:46 INFO  BlockManagerInfo:54 - Removed broadcast_4_piece0 on hadoop08.cusp.nyu.edu:54817 in memory (size: 35.0 KB, free: 366.3 MB)
2021-05-19 02:45:46 INFO  BlockManagerInfo:54 - Removed broadcast_4_piece0 on hadoop10.cusp.nyu.edu:51710 in memory (size: 35.0 KB, free: 366.3 MB)
2021-05-19 02:45:46 INFO  BlockManagerInfo:54 - Removed broadcast_4_piece0 on hadoop07.cusp.nyu.edu:57060 in memory (size: 35.0 KB, free: 366.3 MB)
2021-05-19 02:45:46 INFO  BlockManagerInfo:54 - Removed broadcast_4_piece0 on hadoop09.cusp.nyu.edu:44190 in memory (size: 35.0 KB, free: 366.3 MB)
2021-05-19 02:45:46 INFO  BlockManagerInfo:54 - Removed broadcast_4_piece0 on hadoop20.cusp.nyu.edu:55825 in memory (size: 35.0 KB, free: 366.3 MB)
2021-05-19 02:45:46 INFO  ContextCleaner:54 - Cleaned accumulator 66
2021-05-19 02:45:46 INFO  ContextCleaner:54 - Cleaned accumulator 68
2021-05-19 02:45:46 INFO  ContextCleaner:54 - Cleaned accumulator 50
2021-05-19 02:45:46 INFO  ContextCleaner:54 - Cleaned accumulator 42
2021-05-19 02:45:46 INFO  ContextCleaner:54 - Cleaned accumulator 78
2021-05-19 02:45:46 INFO  ContextCleaner:54 - Cleaned accumulator 82
2021-05-19 02:45:46 INFO  ContextCleaner:54 - Cleaned accumulator 79
2021-05-19 02:45:46 INFO  ContextCleaner:54 - Cleaned accumulator 72
2021-05-19 02:45:46 INFO  ContextCleaner:54 - Cleaned accumulator 73
2021-05-19 02:45:46 INFO  ContextCleaner:54 - Cleaned accumulator 51
2021-05-19 02:45:46 INFO  ContextCleaner:54 - Cleaned accumulator 52
2021-05-19 02:45:46 INFO  ContextCleaner:54 - Cleaned accumulator 85
2021-05-19 02:45:46 INFO  ContextCleaner:54 - Cleaned accumulator 39
2021-05-19 02:45:46 INFO  ContextCleaner:54 - Cleaned accumulator 83
2021-05-19 02:45:46 INFO  ContextCleaner:54 - Cleaned accumulator 56
2021-05-19 02:45:46 INFO  ContextCleaner:54 - Cleaned accumulator 60
2021-05-19 02:45:46 INFO  FileSourceStrategy:54 - Pruning directories with: 
2021-05-19 02:45:46 INFO  FileSourceStrategy:54 - Post-Scan Filters: (length(trim(value#58, None)) > 0)
2021-05-19 02:45:46 INFO  FileSourceStrategy:54 - Output Data Schema: struct<value: string>
2021-05-19 02:45:46 INFO  FileSourceScanExec:54 - Pushed Filters: 
2021-05-19 02:45:46 INFO  MemoryStore:54 - Block broadcast_5 stored as values in memory (estimated size 332.8 KB, free 366.0 MB)
2021-05-19 02:45:46 INFO  MemoryStore:54 - Block broadcast_5_piece0 stored as bytes in memory (estimated size 33.4 KB, free 365.9 MB)
2021-05-19 02:45:46 INFO  BlockManagerInfo:54 - Added broadcast_5_piece0 in memory on hadoop05.cusp.nyu.edu:36982 (size: 33.4 KB, free: 366.3 MB)
2021-05-19 02:45:46 INFO  SparkContext:54 - Created broadcast 5 from csv at NativeMethodAccessorImpl.java:0
2021-05-19 02:45:46 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 134217728 bytes, open cost is considered as scanning 4194304 bytes.
2021-05-19 02:45:46 INFO  SparkContext:54 - Starting job: csv at NativeMethodAccessorImpl.java:0
2021-05-19 02:45:46 INFO  DAGScheduler:54 - Got job 3 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
2021-05-19 02:45:46 INFO  DAGScheduler:54 - Final stage: ResultStage 3 (csv at NativeMethodAccessorImpl.java:0)
2021-05-19 02:45:46 INFO  DAGScheduler:54 - Parents of final stage: List()
2021-05-19 02:45:46 INFO  DAGScheduler:54 - Missing parents: List()
2021-05-19 02:45:46 INFO  DAGScheduler:54 - Submitting ResultStage 3 (MapPartitionsRDD[18] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
2021-05-19 02:45:46 INFO  MemoryStore:54 - Block broadcast_6 stored as values in memory (estimated size 8.8 KB, free 365.9 MB)
2021-05-19 02:45:46 INFO  MemoryStore:54 - Block broadcast_6_piece0 stored as bytes in memory (estimated size 4.5 KB, free 365.9 MB)
2021-05-19 02:45:46 INFO  BlockManagerInfo:54 - Added broadcast_6_piece0 in memory on hadoop05.cusp.nyu.edu:36982 (size: 4.5 KB, free: 366.3 MB)
2021-05-19 02:45:46 INFO  SparkContext:54 - Created broadcast 6 from broadcast at DAGScheduler.scala:1161
2021-05-19 02:45:46 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[18] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
2021-05-19 02:45:46 INFO  YarnClusterScheduler:54 - Adding task set 3.0 with 1 tasks
2021-05-19 02:45:46 INFO  TaskSetManager:54 - Starting task 0.0 in stage 3.0 (TID 100, hadoop07.cusp.nyu.edu, executor 3, partition 0, NODE_LOCAL, 8342 bytes)
2021-05-19 02:45:46 INFO  BlockManagerInfo:54 - Added broadcast_6_piece0 in memory on hadoop07.cusp.nyu.edu:57060 (size: 4.5 KB, free: 366.3 MB)
2021-05-19 02:45:47 INFO  BlockManagerInfo:54 - Added broadcast_5_piece0 in memory on hadoop07.cusp.nyu.edu:57060 (size: 33.4 KB, free: 366.3 MB)
2021-05-19 02:45:47 INFO  TaskSetManager:54 - Finished task 0.0 in stage 3.0 (TID 100) in 1045 ms on hadoop07.cusp.nyu.edu (executor 3) (1/1)
2021-05-19 02:45:47 INFO  YarnClusterScheduler:54 - Removed TaskSet 3.0, whose tasks have all completed, from pool 
2021-05-19 02:45:47 INFO  DAGScheduler:54 - ResultStage 3 (csv at NativeMethodAccessorImpl.java:0) finished in 1.130 s
2021-05-19 02:45:47 INFO  DAGScheduler:54 - Job 3 finished: csv at NativeMethodAccessorImpl.java:0, took 1.139967 s
2021-05-19 02:45:47 INFO  FileSourceStrategy:54 - Pruning directories with: 
2021-05-19 02:45:47 INFO  FileSourceStrategy:54 - Post-Scan Filters: 
2021-05-19 02:45:47 INFO  FileSourceStrategy:54 - Output Data Schema: struct<value: string>
2021-05-19 02:45:47 INFO  FileSourceScanExec:54 - Pushed Filters: 
2021-05-19 02:45:47 INFO  MemoryStore:54 - Block broadcast_7 stored as values in memory (estimated size 332.8 KB, free 365.6 MB)
2021-05-19 02:45:47 INFO  MemoryStore:54 - Block broadcast_7_piece0 stored as bytes in memory (estimated size 33.4 KB, free 365.6 MB)
2021-05-19 02:45:47 INFO  BlockManagerInfo:54 - Added broadcast_7_piece0 in memory on hadoop05.cusp.nyu.edu:36982 (size: 33.4 KB, free: 366.2 MB)
2021-05-19 02:45:47 INFO  SparkContext:54 - Created broadcast 7 from csv at NativeMethodAccessorImpl.java:0
2021-05-19 02:45:47 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 134217728 bytes, open cost is considered as scanning 4194304 bytes.
2021-05-19 02:45:47 INFO  FileSourceStrategy:54 - Pruning directories with: 
2021-05-19 02:45:47 INFO  FileSourceStrategy:54 - Post-Scan Filters: naics_code#19 INSET (445110,452210,445291,445292,445299,722410,445210,446110,445230,722513,311811,446191,722511,722515,452311,445220,445120)
2021-05-19 02:45:47 INFO  FileSourceStrategy:54 - Output Data Schema: struct<placekey: string, naics_code: string>
2021-05-19 02:45:47 INFO  FileSourceScanExec:54 - Pushed Filters: In(naics_code, [445110,452210,445291,445292,445299,722410,445210,446110,445230,722513,311811,446191,722511,722515,452311,445220,445120])
2021-05-19 02:45:48 INFO  ContextCleaner:54 - Cleaned accumulator 98
2021-05-19 02:45:48 INFO  BlockManagerInfo:54 - Removed broadcast_7_piece0 on hadoop05.cusp.nyu.edu:36982 in memory (size: 33.4 KB, free: 366.3 MB)
2021-05-19 02:45:48 INFO  ContextCleaner:54 - Cleaned accumulator 111
2021-05-19 02:45:48 INFO  ContextCleaner:54 - Cleaned accumulator 92
2021-05-19 02:45:48 INFO  ContextCleaner:54 - Cleaned accumulator 94
2021-05-19 02:45:48 INFO  ContextCleaner:54 - Cleaned accumulator 121
2021-05-19 02:45:48 INFO  BlockManagerInfo:54 - Removed broadcast_5_piece0 on hadoop05.cusp.nyu.edu:36982 in memory (size: 33.4 KB, free: 366.3 MB)
2021-05-19 02:45:48 INFO  BlockManagerInfo:54 - Removed broadcast_5_piece0 on hadoop07.cusp.nyu.edu:57060 in memory (size: 33.4 KB, free: 366.3 MB)
2021-05-19 02:45:48 INFO  ContextCleaner:54 - Cleaned accumulator 117
2021-05-19 02:45:48 INFO  ContextCleaner:54 - Cleaned accumulator 91
2021-05-19 02:45:48 INFO  ContextCleaner:54 - Cleaned accumulator 105
2021-05-19 02:45:48 INFO  ContextCleaner:54 - Cleaned accumulator 110
2021-05-19 02:45:48 INFO  ContextCleaner:54 - Cleaned accumulator 116
2021-05-19 02:45:48 INFO  ContextCleaner:54 - Cleaned accumulator 104
2021-05-19 02:45:48 INFO  ContextCleaner:54 - Cleaned accumulator 108
2021-05-19 02:45:48 INFO  ContextCleaner:54 - Cleaned accumulator 96
2021-05-19 02:45:48 INFO  ContextCleaner:54 - Cleaned accumulator 114
2021-05-19 02:45:48 INFO  ContextCleaner:54 - Cleaned accumulator 107
2021-05-19 02:45:48 INFO  ContextCleaner:54 - Cleaned accumulator 97
2021-05-19 02:45:48 INFO  ContextCleaner:54 - Cleaned accumulator 102
2021-05-19 02:45:48 INFO  ContextCleaner:54 - Cleaned accumulator 120
2021-05-19 02:45:48 INFO  ContextCleaner:54 - Cleaned accumulator 122
2021-05-19 02:45:48 INFO  ContextCleaner:54 - Cleaned accumulator 89
2021-05-19 02:45:48 INFO  ContextCleaner:54 - Cleaned accumulator 112
2021-05-19 02:45:48 INFO  ContextCleaner:54 - Cleaned accumulator 95
2021-05-19 02:45:48 INFO  BlockManagerInfo:54 - Removed broadcast_6_piece0 on hadoop05.cusp.nyu.edu:36982 in memory (size: 4.5 KB, free: 366.3 MB)
2021-05-19 02:45:48 INFO  BlockManagerInfo:54 - Removed broadcast_6_piece0 on hadoop07.cusp.nyu.edu:57060 in memory (size: 4.5 KB, free: 366.3 MB)
2021-05-19 02:45:48 INFO  ContextCleaner:54 - Cleaned accumulator 99
2021-05-19 02:45:48 INFO  ContextCleaner:54 - Cleaned accumulator 93
2021-05-19 02:45:48 INFO  ContextCleaner:54 - Cleaned accumulator 90
2021-05-19 02:45:48 INFO  ContextCleaner:54 - Cleaned accumulator 88
2021-05-19 02:45:48 INFO  ContextCleaner:54 - Cleaned accumulator 119
2021-05-19 02:45:48 INFO  ContextCleaner:54 - Cleaned accumulator 101
2021-05-19 02:45:48 INFO  ContextCleaner:54 - Cleaned accumulator 118
2021-05-19 02:45:48 INFO  ContextCleaner:54 - Cleaned accumulator 106
2021-05-19 02:45:48 INFO  ContextCleaner:54 - Cleaned accumulator 113
2021-05-19 02:45:48 INFO  ContextCleaner:54 - Cleaned accumulator 100
2021-05-19 02:45:48 INFO  ContextCleaner:54 - Cleaned accumulator 109
2021-05-19 02:45:48 INFO  ContextCleaner:54 - Cleaned accumulator 87
2021-05-19 02:45:48 INFO  ContextCleaner:54 - Cleaned accumulator 103
2021-05-19 02:45:48 INFO  ContextCleaner:54 - Cleaned accumulator 115
2021-05-19 02:45:48 INFO  CodeGenerator:54 - Code generated in 71.724867 ms
2021-05-19 02:45:48 INFO  CodeGenerator:54 - Code generated in 78.648144 ms
2021-05-19 02:45:48 INFO  CodeGenerator:54 - Code generated in 13.247971 ms
2021-05-19 02:45:48 INFO  CodeGenerator:54 - Code generated in 27.658592 ms
2021-05-19 02:45:48 INFO  MemoryStore:54 - Block broadcast_8 stored as values in memory (estimated size 332.8 KB, free 366.0 MB)
2021-05-19 02:45:48 INFO  MemoryStore:54 - Block broadcast_8_piece0 stored as bytes in memory (estimated size 33.4 KB, free 365.9 MB)
2021-05-19 02:45:48 INFO  BlockManagerInfo:54 - Added broadcast_8_piece0 in memory on hadoop05.cusp.nyu.edu:36982 (size: 33.4 KB, free: 366.3 MB)
2021-05-19 02:45:48 INFO  SparkContext:54 - Created broadcast 8 from collect at BDM_HW4.py:27
2021-05-19 02:45:48 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2021-05-19 02:45:48 INFO  SparkContext:54 - Starting job: collect at BDM_HW4.py:27
2021-05-19 02:45:48 INFO  DAGScheduler:54 - Registering RDD 34 (collect at BDM_HW4.py:27)
2021-05-19 02:45:48 INFO  DAGScheduler:54 - Got job 4 (collect at BDM_HW4.py:27) with 200 output partitions
2021-05-19 02:45:48 INFO  DAGScheduler:54 - Final stage: ResultStage 5 (collect at BDM_HW4.py:27)
2021-05-19 02:45:48 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 4)
2021-05-19 02:45:48 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 4)
2021-05-19 02:45:48 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 4 (MapPartitionsRDD[34] at collect at BDM_HW4.py:27), which has no missing parents
2021-05-19 02:45:48 INFO  MemoryStore:54 - Block broadcast_9 stored as values in memory (estimated size 42.3 KB, free 365.9 MB)
2021-05-19 02:45:48 INFO  MemoryStore:54 - Block broadcast_9_piece0 stored as bytes in memory (estimated size 20.3 KB, free 365.9 MB)
2021-05-19 02:45:48 INFO  BlockManagerInfo:54 - Added broadcast_9_piece0 in memory on hadoop05.cusp.nyu.edu:36982 (size: 20.3 KB, free: 366.2 MB)
2021-05-19 02:45:48 INFO  SparkContext:54 - Created broadcast 9 from broadcast at DAGScheduler.scala:1161
2021-05-19 02:45:48 INFO  DAGScheduler:54 - Submitting 8 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[34] at collect at BDM_HW4.py:27) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
2021-05-19 02:45:48 INFO  YarnClusterScheduler:54 - Adding task set 4.0 with 8 tasks
2021-05-19 02:45:48 INFO  TaskSetManager:54 - Starting task 0.0 in stage 4.0 (TID 101, hadoop08.cusp.nyu.edu, executor 5, partition 0, NODE_LOCAL, 8310 bytes)
2021-05-19 02:45:48 INFO  TaskSetManager:54 - Starting task 1.0 in stage 4.0 (TID 102, hadoop08.cusp.nyu.edu, executor 5, partition 1, NODE_LOCAL, 8310 bytes)
2021-05-19 02:45:48 INFO  TaskSetManager:54 - Starting task 2.0 in stage 4.0 (TID 103, hadoop08.cusp.nyu.edu, executor 5, partition 2, NODE_LOCAL, 8310 bytes)
2021-05-19 02:45:48 INFO  TaskSetManager:54 - Starting task 3.0 in stage 4.0 (TID 104, hadoop08.cusp.nyu.edu, executor 5, partition 3, NODE_LOCAL, 8310 bytes)
2021-05-19 02:45:48 INFO  TaskSetManager:54 - Starting task 4.0 in stage 4.0 (TID 105, hadoop08.cusp.nyu.edu, executor 5, partition 4, NODE_LOCAL, 8310 bytes)
2021-05-19 02:45:48 INFO  TaskSetManager:54 - Starting task 5.0 in stage 4.0 (TID 106, hadoop08.cusp.nyu.edu, executor 5, partition 5, NODE_LOCAL, 8310 bytes)
2021-05-19 02:45:48 INFO  TaskSetManager:54 - Starting task 6.0 in stage 4.0 (TID 107, hadoop08.cusp.nyu.edu, executor 5, partition 6, NODE_LOCAL, 8310 bytes)
2021-05-19 02:45:48 INFO  TaskSetManager:54 - Starting task 7.0 in stage 4.0 (TID 108, hadoop08.cusp.nyu.edu, executor 5, partition 7, NODE_LOCAL, 8310 bytes)
2021-05-19 02:45:48 INFO  BlockManagerInfo:54 - Added broadcast_9_piece0 in memory on hadoop08.cusp.nyu.edu:54817 (size: 20.3 KB, free: 366.3 MB)
2021-05-19 02:45:50 INFO  BlockManagerInfo:54 - Added broadcast_8_piece0 in memory on hadoop08.cusp.nyu.edu:54817 (size: 33.4 KB, free: 366.2 MB)
2021-05-19 02:45:51 INFO  BlockManagerInfo:54 - Added rdd_29_7 in memory on hadoop08.cusp.nyu.edu:54817 (size: 47.3 KB, free: 366.2 MB)
2021-05-19 02:45:51 INFO  BlockManagerInfo:54 - Added rdd_29_2 in memory on hadoop08.cusp.nyu.edu:54817 (size: 91.5 KB, free: 366.1 MB)
2021-05-19 02:45:51 INFO  BlockManagerInfo:54 - Added rdd_29_0 in memory on hadoop08.cusp.nyu.edu:54817 (size: 90.4 KB, free: 366.0 MB)
2021-05-19 02:45:51 INFO  BlockManagerInfo:54 - Added rdd_29_4 in memory on hadoop08.cusp.nyu.edu:54817 (size: 88.8 KB, free: 365.9 MB)
2021-05-19 02:45:51 INFO  BlockManagerInfo:54 - Added rdd_29_3 in memory on hadoop08.cusp.nyu.edu:54817 (size: 89.5 KB, free: 365.8 MB)
2021-05-19 02:45:51 INFO  BlockManagerInfo:54 - Added rdd_29_5 in memory on hadoop08.cusp.nyu.edu:54817 (size: 91.5 KB, free: 365.8 MB)
2021-05-19 02:45:51 INFO  BlockManagerInfo:54 - Added rdd_29_6 in memory on hadoop08.cusp.nyu.edu:54817 (size: 90.2 KB, free: 365.7 MB)
2021-05-19 02:45:51 INFO  BlockManagerInfo:54 - Added rdd_29_1 in memory on hadoop08.cusp.nyu.edu:54817 (size: 90.8 KB, free: 365.6 MB)
2021-05-19 02:45:51 INFO  TaskSetManager:54 - Finished task 5.0 in stage 4.0 (TID 106) in 2875 ms on hadoop08.cusp.nyu.edu (executor 5) (1/8)
2021-05-19 02:45:51 INFO  TaskSetManager:54 - Finished task 4.0 in stage 4.0 (TID 105) in 2875 ms on hadoop08.cusp.nyu.edu (executor 5) (2/8)
2021-05-19 02:45:51 INFO  PythonAccumulatorV2:54 - Connected to AccumulatorServer at host: 127.0.0.1 port: 60836
2021-05-19 02:45:51 INFO  TaskSetManager:54 - Finished task 0.0 in stage 4.0 (TID 101) in 2898 ms on hadoop08.cusp.nyu.edu (executor 5) (3/8)
2021-05-19 02:45:51 INFO  TaskSetManager:54 - Finished task 1.0 in stage 4.0 (TID 102) in 2897 ms on hadoop08.cusp.nyu.edu (executor 5) (4/8)
2021-05-19 02:45:51 INFO  TaskSetManager:54 - Finished task 3.0 in stage 4.0 (TID 104) in 2902 ms on hadoop08.cusp.nyu.edu (executor 5) (5/8)
2021-05-19 02:45:51 INFO  TaskSetManager:54 - Finished task 7.0 in stage 4.0 (TID 108) in 2900 ms on hadoop08.cusp.nyu.edu (executor 5) (6/8)
2021-05-19 02:45:51 INFO  TaskSetManager:54 - Finished task 2.0 in stage 4.0 (TID 103) in 2903 ms on hadoop08.cusp.nyu.edu (executor 5) (7/8)
2021-05-19 02:45:51 INFO  TaskSetManager:54 - Finished task 6.0 in stage 4.0 (TID 107) in 2902 ms on hadoop08.cusp.nyu.edu (executor 5) (8/8)
2021-05-19 02:45:51 INFO  YarnClusterScheduler:54 - Removed TaskSet 4.0, whose tasks have all completed, from pool 
2021-05-19 02:45:51 INFO  DAGScheduler:54 - ShuffleMapStage 4 (collect at BDM_HW4.py:27) finished in 2.936 s
2021-05-19 02:45:51 INFO  DAGScheduler:54 - looking for newly runnable stages
2021-05-19 02:45:51 INFO  DAGScheduler:54 - running: Set()
2021-05-19 02:45:51 INFO  DAGScheduler:54 - waiting: Set(ResultStage 5)
2021-05-19 02:45:51 INFO  DAGScheduler:54 - failed: Set()
2021-05-19 02:45:51 INFO  DAGScheduler:54 - Submitting ResultStage 5 (MapPartitionsRDD[37] at collect at BDM_HW4.py:27), which has no missing parents
2021-05-19 02:45:51 INFO  MemoryStore:54 - Block broadcast_10 stored as values in memory (estimated size 40.9 KB, free 365.8 MB)
2021-05-19 02:45:51 INFO  MemoryStore:54 - Block broadcast_10_piece0 stored as bytes in memory (estimated size 20.4 KB, free 365.8 MB)
2021-05-19 02:45:51 INFO  BlockManagerInfo:54 - Added broadcast_10_piece0 in memory on hadoop05.cusp.nyu.edu:36982 (size: 20.4 KB, free: 366.2 MB)
2021-05-19 02:45:51 INFO  SparkContext:54 - Created broadcast 10 from broadcast at DAGScheduler.scala:1161
2021-05-19 02:45:51 INFO  DAGScheduler:54 - Submitting 200 missing tasks from ResultStage 5 (MapPartitionsRDD[37] at collect at BDM_HW4.py:27) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
2021-05-19 02:45:51 INFO  YarnClusterScheduler:54 - Adding task set 5.0 with 200 tasks
2021-05-19 02:45:51 INFO  TaskSetManager:54 - Starting task 3.0 in stage 5.0 (TID 109, hadoop08.cusp.nyu.edu, executor 5, partition 3, NODE_LOCAL, 7756 bytes)
2021-05-19 02:45:51 INFO  TaskSetManager:54 - Starting task 18.0 in stage 5.0 (TID 110, hadoop08.cusp.nyu.edu, executor 5, partition 18, NODE_LOCAL, 7756 bytes)
2021-05-19 02:45:51 INFO  TaskSetManager:54 - Starting task 26.0 in stage 5.0 (TID 111, hadoop08.cusp.nyu.edu, executor 5, partition 26, NODE_LOCAL, 7756 bytes)
2021-05-19 02:45:51 INFO  TaskSetManager:54 - Starting task 35.0 in stage 5.0 (TID 112, hadoop08.cusp.nyu.edu, executor 5, partition 35, NODE_LOCAL, 7756 bytes)
2021-05-19 02:45:51 INFO  TaskSetManager:54 - Starting task 49.0 in stage 5.0 (TID 113, hadoop08.cusp.nyu.edu, executor 5, partition 49, NODE_LOCAL, 7756 bytes)
2021-05-19 02:45:51 INFO  TaskSetManager:54 - Starting task 75.0 in stage 5.0 (TID 114, hadoop08.cusp.nyu.edu, executor 5, partition 75, NODE_LOCAL, 7756 bytes)
2021-05-19 02:45:51 INFO  TaskSetManager:54 - Starting task 144.0 in stage 5.0 (TID 115, hadoop08.cusp.nyu.edu, executor 5, partition 144, NODE_LOCAL, 7756 bytes)
2021-05-19 02:45:51 INFO  TaskSetManager:54 - Starting task 166.0 in stage 5.0 (TID 116, hadoop08.cusp.nyu.edu, executor 5, partition 166, NODE_LOCAL, 7756 bytes)
2021-05-19 02:45:51 INFO  TaskSetManager:54 - Starting task 189.0 in stage 5.0 (TID 117, hadoop08.cusp.nyu.edu, executor 5, partition 189, NODE_LOCAL, 7756 bytes)
2021-05-19 02:45:51 INFO  TaskSetManager:54 - Starting task 0.0 in stage 5.0 (TID 118, hadoop07.cusp.nyu.edu, executor 3, partition 0, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:45:51 INFO  TaskSetManager:54 - Starting task 1.0 in stage 5.0 (TID 119, hadoop20.cusp.nyu.edu, executor 4, partition 1, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:45:51 INFO  TaskSetManager:54 - Starting task 2.0 in stage 5.0 (TID 120, hadoop10.cusp.nyu.edu, executor 2, partition 2, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:45:51 INFO  TaskSetManager:54 - Starting task 4.0 in stage 5.0 (TID 121, hadoop09.cusp.nyu.edu, executor 1, partition 4, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:45:51 INFO  TaskSetManager:54 - Starting task 5.0 in stage 5.0 (TID 122, hadoop08.cusp.nyu.edu, executor 5, partition 5, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:45:51 INFO  TaskSetManager:54 - Starting task 6.0 in stage 5.0 (TID 123, hadoop07.cusp.nyu.edu, executor 3, partition 6, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:45:51 INFO  TaskSetManager:54 - Starting task 7.0 in stage 5.0 (TID 124, hadoop20.cusp.nyu.edu, executor 4, partition 7, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:45:51 INFO  TaskSetManager:54 - Starting task 8.0 in stage 5.0 (TID 125, hadoop10.cusp.nyu.edu, executor 2, partition 8, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:45:51 INFO  TaskSetManager:54 - Starting task 9.0 in stage 5.0 (TID 126, hadoop09.cusp.nyu.edu, executor 1, partition 9, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:45:51 INFO  TaskSetManager:54 - Starting task 10.0 in stage 5.0 (TID 127, hadoop07.cusp.nyu.edu, executor 3, partition 10, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:45:51 INFO  TaskSetManager:54 - Starting task 11.0 in stage 5.0 (TID 128, hadoop20.cusp.nyu.edu, executor 4, partition 11, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:45:51 INFO  TaskSetManager:54 - Starting task 12.0 in stage 5.0 (TID 129, hadoop10.cusp.nyu.edu, executor 2, partition 12, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:45:51 INFO  TaskSetManager:54 - Starting task 13.0 in stage 5.0 (TID 130, hadoop09.cusp.nyu.edu, executor 1, partition 13, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:45:51 INFO  TaskSetManager:54 - Starting task 14.0 in stage 5.0 (TID 131, hadoop07.cusp.nyu.edu, executor 3, partition 14, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:45:51 INFO  TaskSetManager:54 - Starting task 15.0 in stage 5.0 (TID 132, hadoop20.cusp.nyu.edu, executor 4, partition 15, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:45:51 INFO  TaskSetManager:54 - Starting task 16.0 in stage 5.0 (TID 133, hadoop10.cusp.nyu.edu, executor 2, partition 16, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:45:51 INFO  TaskSetManager:54 - Starting task 17.0 in stage 5.0 (TID 134, hadoop09.cusp.nyu.edu, executor 1, partition 17, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:45:51 INFO  TaskSetManager:54 - Starting task 19.0 in stage 5.0 (TID 135, hadoop07.cusp.nyu.edu, executor 3, partition 19, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:45:51 INFO  TaskSetManager:54 - Starting task 20.0 in stage 5.0 (TID 136, hadoop20.cusp.nyu.edu, executor 4, partition 20, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:45:51 INFO  TaskSetManager:54 - Starting task 21.0 in stage 5.0 (TID 137, hadoop10.cusp.nyu.edu, executor 2, partition 21, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:45:51 INFO  TaskSetManager:54 - Starting task 22.0 in stage 5.0 (TID 138, hadoop09.cusp.nyu.edu, executor 1, partition 22, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:45:51 INFO  TaskSetManager:54 - Starting task 23.0 in stage 5.0 (TID 139, hadoop07.cusp.nyu.edu, executor 3, partition 23, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:45:51 INFO  TaskSetManager:54 - Starting task 24.0 in stage 5.0 (TID 140, hadoop20.cusp.nyu.edu, executor 4, partition 24, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:45:51 INFO  TaskSetManager:54 - Starting task 25.0 in stage 5.0 (TID 141, hadoop10.cusp.nyu.edu, executor 2, partition 25, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:45:51 INFO  TaskSetManager:54 - Starting task 27.0 in stage 5.0 (TID 142, hadoop09.cusp.nyu.edu, executor 1, partition 27, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:45:51 INFO  TaskSetManager:54 - Starting task 28.0 in stage 5.0 (TID 143, hadoop07.cusp.nyu.edu, executor 3, partition 28, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:45:51 INFO  TaskSetManager:54 - Starting task 29.0 in stage 5.0 (TID 144, hadoop20.cusp.nyu.edu, executor 4, partition 29, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:45:51 INFO  TaskSetManager:54 - Starting task 30.0 in stage 5.0 (TID 145, hadoop10.cusp.nyu.edu, executor 2, partition 30, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:45:51 INFO  TaskSetManager:54 - Starting task 31.0 in stage 5.0 (TID 146, hadoop09.cusp.nyu.edu, executor 1, partition 31, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:45:51 INFO  TaskSetManager:54 - Starting task 32.0 in stage 5.0 (TID 147, hadoop07.cusp.nyu.edu, executor 3, partition 32, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:45:51 INFO  TaskSetManager:54 - Starting task 33.0 in stage 5.0 (TID 148, hadoop20.cusp.nyu.edu, executor 4, partition 33, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:45:51 INFO  TaskSetManager:54 - Starting task 34.0 in stage 5.0 (TID 149, hadoop10.cusp.nyu.edu, executor 2, partition 34, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:45:51 INFO  TaskSetManager:54 - Starting task 36.0 in stage 5.0 (TID 150, hadoop09.cusp.nyu.edu, executor 1, partition 36, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:45:51 INFO  TaskSetManager:54 - Starting task 37.0 in stage 5.0 (TID 151, hadoop07.cusp.nyu.edu, executor 3, partition 37, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:45:51 INFO  TaskSetManager:54 - Starting task 38.0 in stage 5.0 (TID 152, hadoop20.cusp.nyu.edu, executor 4, partition 38, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:45:51 INFO  TaskSetManager:54 - Starting task 39.0 in stage 5.0 (TID 153, hadoop10.cusp.nyu.edu, executor 2, partition 39, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:45:51 INFO  TaskSetManager:54 - Starting task 40.0 in stage 5.0 (TID 154, hadoop09.cusp.nyu.edu, executor 1, partition 40, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:45:51 INFO  TaskSetManager:54 - Starting task 41.0 in stage 5.0 (TID 155, hadoop07.cusp.nyu.edu, executor 3, partition 41, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:45:51 INFO  TaskSetManager:54 - Starting task 42.0 in stage 5.0 (TID 156, hadoop20.cusp.nyu.edu, executor 4, partition 42, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:45:51 INFO  TaskSetManager:54 - Starting task 43.0 in stage 5.0 (TID 157, hadoop10.cusp.nyu.edu, executor 2, partition 43, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:45:51 INFO  TaskSetManager:54 - Starting task 44.0 in stage 5.0 (TID 158, hadoop09.cusp.nyu.edu, executor 1, partition 44, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:45:51 INFO  BlockManagerInfo:54 - Added broadcast_10_piece0 in memory on hadoop07.cusp.nyu.edu:57060 (size: 20.4 KB, free: 366.3 MB)
2021-05-19 02:45:51 INFO  BlockManagerInfo:54 - Added broadcast_10_piece0 in memory on hadoop10.cusp.nyu.edu:51710 (size: 20.4 KB, free: 366.3 MB)
2021-05-19 02:45:51 INFO  BlockManagerInfo:54 - Added broadcast_10_piece0 in memory on hadoop20.cusp.nyu.edu:55825 (size: 20.4 KB, free: 366.3 MB)
2021-05-19 02:45:51 INFO  BlockManagerInfo:54 - Added broadcast_10_piece0 in memory on hadoop09.cusp.nyu.edu:44190 (size: 20.4 KB, free: 366.3 MB)
2021-05-19 02:45:51 INFO  BlockManagerInfo:54 - Added broadcast_10_piece0 in memory on hadoop08.cusp.nyu.edu:54817 (size: 20.4 KB, free: 365.6 MB)
2021-05-19 02:45:51 INFO  MapOutputTrackerMasterEndpoint:54 - Asked to send map output locations for shuffle 0 to 192.168.72.178:41880
2021-05-19 02:45:52 INFO  BlockManagerInfo:54 - Removed broadcast_9_piece0 on hadoop05.cusp.nyu.edu:36982 in memory (size: 20.3 KB, free: 366.2 MB)
2021-05-19 02:45:52 INFO  BlockManagerInfo:54 - Removed broadcast_9_piece0 on hadoop08.cusp.nyu.edu:54817 in memory (size: 20.3 KB, free: 365.6 MB)
2021-05-19 02:45:52 INFO  ContextCleaner:54 - Cleaned accumulator 124
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Starting task 45.0 in stage 5.0 (TID 159, hadoop08.cusp.nyu.edu, executor 5, partition 45, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Finished task 5.0 in stage 5.0 (TID 122) in 317 ms on hadoop08.cusp.nyu.edu (executor 5) (1/200)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Starting task 46.0 in stage 5.0 (TID 160, hadoop08.cusp.nyu.edu, executor 5, partition 46, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Finished task 26.0 in stage 5.0 (TID 111) in 352 ms on hadoop08.cusp.nyu.edu (executor 5) (2/200)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Starting task 47.0 in stage 5.0 (TID 161, hadoop08.cusp.nyu.edu, executor 5, partition 47, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Finished task 3.0 in stage 5.0 (TID 109) in 357 ms on hadoop08.cusp.nyu.edu (executor 5) (3/200)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Starting task 48.0 in stage 5.0 (TID 162, hadoop08.cusp.nyu.edu, executor 5, partition 48, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Finished task 144.0 in stage 5.0 (TID 115) in 356 ms on hadoop08.cusp.nyu.edu (executor 5) (4/200)
2021-05-19 02:45:52 INFO  MapOutputTrackerMasterEndpoint:54 - Asked to send map output locations for shuffle 0 to 192.168.72.177:37542
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Starting task 50.0 in stage 5.0 (TID 163, hadoop08.cusp.nyu.edu, executor 5, partition 50, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Finished task 166.0 in stage 5.0 (TID 116) in 358 ms on hadoop08.cusp.nyu.edu (executor 5) (5/200)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Starting task 51.0 in stage 5.0 (TID 164, hadoop08.cusp.nyu.edu, executor 5, partition 51, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Finished task 49.0 in stage 5.0 (TID 113) in 364 ms on hadoop08.cusp.nyu.edu (executor 5) (6/200)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Starting task 52.0 in stage 5.0 (TID 165, hadoop08.cusp.nyu.edu, executor 5, partition 52, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Finished task 35.0 in stage 5.0 (TID 112) in 366 ms on hadoop08.cusp.nyu.edu (executor 5) (7/200)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Starting task 53.0 in stage 5.0 (TID 166, hadoop08.cusp.nyu.edu, executor 5, partition 53, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Starting task 54.0 in stage 5.0 (TID 167, hadoop08.cusp.nyu.edu, executor 5, partition 54, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Finished task 18.0 in stage 5.0 (TID 110) in 373 ms on hadoop08.cusp.nyu.edu (executor 5) (8/200)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Starting task 55.0 in stage 5.0 (TID 168, hadoop08.cusp.nyu.edu, executor 5, partition 55, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Finished task 75.0 in stage 5.0 (TID 114) in 372 ms on hadoop08.cusp.nyu.edu (executor 5) (9/200)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Finished task 189.0 in stage 5.0 (TID 117) in 371 ms on hadoop08.cusp.nyu.edu (executor 5) (10/200)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Starting task 56.0 in stage 5.0 (TID 169, hadoop08.cusp.nyu.edu, executor 5, partition 56, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Finished task 45.0 in stage 5.0 (TID 159) in 68 ms on hadoop08.cusp.nyu.edu (executor 5) (11/200)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Starting task 57.0 in stage 5.0 (TID 170, hadoop08.cusp.nyu.edu, executor 5, partition 57, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Finished task 46.0 in stage 5.0 (TID 160) in 58 ms on hadoop08.cusp.nyu.edu (executor 5) (12/200)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Starting task 58.0 in stage 5.0 (TID 171, hadoop08.cusp.nyu.edu, executor 5, partition 58, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Finished task 47.0 in stage 5.0 (TID 161) in 67 ms on hadoop08.cusp.nyu.edu (executor 5) (13/200)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Starting task 59.0 in stage 5.0 (TID 172, hadoop08.cusp.nyu.edu, executor 5, partition 59, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Finished task 51.0 in stage 5.0 (TID 164) in 65 ms on hadoop08.cusp.nyu.edu (executor 5) (14/200)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Starting task 60.0 in stage 5.0 (TID 173, hadoop08.cusp.nyu.edu, executor 5, partition 60, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Finished task 53.0 in stage 5.0 (TID 166) in 59 ms on hadoop08.cusp.nyu.edu (executor 5) (15/200)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Starting task 61.0 in stage 5.0 (TID 174, hadoop08.cusp.nyu.edu, executor 5, partition 61, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Finished task 54.0 in stage 5.0 (TID 167) in 68 ms on hadoop08.cusp.nyu.edu (executor 5) (16/200)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Starting task 62.0 in stage 5.0 (TID 175, hadoop08.cusp.nyu.edu, executor 5, partition 62, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Finished task 48.0 in stage 5.0 (TID 162) in 84 ms on hadoop08.cusp.nyu.edu (executor 5) (17/200)
2021-05-19 02:45:52 INFO  MapOutputTrackerMasterEndpoint:54 - Asked to send map output locations for shuffle 0 to 192.168.72.180:39670
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Starting task 63.0 in stage 5.0 (TID 176, hadoop08.cusp.nyu.edu, executor 5, partition 63, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Starting task 64.0 in stage 5.0 (TID 177, hadoop08.cusp.nyu.edu, executor 5, partition 64, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Finished task 50.0 in stage 5.0 (TID 163) in 97 ms on hadoop08.cusp.nyu.edu (executor 5) (18/200)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Finished task 55.0 in stage 5.0 (TID 168) in 85 ms on hadoop08.cusp.nyu.edu (executor 5) (19/200)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Starting task 65.0 in stage 5.0 (TID 178, hadoop08.cusp.nyu.edu, executor 5, partition 65, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Finished task 52.0 in stage 5.0 (TID 165) in 102 ms on hadoop08.cusp.nyu.edu (executor 5) (20/200)
2021-05-19 02:45:52 INFO  MapOutputTrackerMasterEndpoint:54 - Asked to send map output locations for shuffle 0 to 192.168.72.190:45953
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Starting task 66.0 in stage 5.0 (TID 179, hadoop08.cusp.nyu.edu, executor 5, partition 66, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Finished task 56.0 in stage 5.0 (TID 169) in 79 ms on hadoop08.cusp.nyu.edu (executor 5) (21/200)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Starting task 67.0 in stage 5.0 (TID 180, hadoop08.cusp.nyu.edu, executor 5, partition 67, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Finished task 57.0 in stage 5.0 (TID 170) in 65 ms on hadoop08.cusp.nyu.edu (executor 5) (22/200)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Starting task 68.0 in stage 5.0 (TID 181, hadoop08.cusp.nyu.edu, executor 5, partition 68, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Finished task 58.0 in stage 5.0 (TID 171) in 54 ms on hadoop08.cusp.nyu.edu (executor 5) (23/200)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Starting task 69.0 in stage 5.0 (TID 182, hadoop08.cusp.nyu.edu, executor 5, partition 69, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Finished task 59.0 in stage 5.0 (TID 172) in 48 ms on hadoop08.cusp.nyu.edu (executor 5) (24/200)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Starting task 70.0 in stage 5.0 (TID 183, hadoop08.cusp.nyu.edu, executor 5, partition 70, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Finished task 60.0 in stage 5.0 (TID 173) in 49 ms on hadoop08.cusp.nyu.edu (executor 5) (25/200)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Starting task 71.0 in stage 5.0 (TID 184, hadoop08.cusp.nyu.edu, executor 5, partition 71, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Finished task 61.0 in stage 5.0 (TID 174) in 42 ms on hadoop08.cusp.nyu.edu (executor 5) (26/200)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Starting task 72.0 in stage 5.0 (TID 185, hadoop08.cusp.nyu.edu, executor 5, partition 72, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Finished task 62.0 in stage 5.0 (TID 175) in 41 ms on hadoop08.cusp.nyu.edu (executor 5) (27/200)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Starting task 73.0 in stage 5.0 (TID 186, hadoop08.cusp.nyu.edu, executor 5, partition 73, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Finished task 64.0 in stage 5.0 (TID 177) in 27 ms on hadoop08.cusp.nyu.edu (executor 5) (28/200)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Starting task 74.0 in stage 5.0 (TID 187, hadoop08.cusp.nyu.edu, executor 5, partition 74, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Finished task 63.0 in stage 5.0 (TID 176) in 34 ms on hadoop08.cusp.nyu.edu (executor 5) (29/200)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Starting task 76.0 in stage 5.0 (TID 188, hadoop08.cusp.nyu.edu, executor 5, partition 76, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Finished task 65.0 in stage 5.0 (TID 178) in 31 ms on hadoop08.cusp.nyu.edu (executor 5) (30/200)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Starting task 77.0 in stage 5.0 (TID 189, hadoop08.cusp.nyu.edu, executor 5, partition 77, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Finished task 66.0 in stage 5.0 (TID 179) in 24 ms on hadoop08.cusp.nyu.edu (executor 5) (31/200)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Starting task 78.0 in stage 5.0 (TID 190, hadoop08.cusp.nyu.edu, executor 5, partition 78, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Finished task 67.0 in stage 5.0 (TID 180) in 24 ms on hadoop08.cusp.nyu.edu (executor 5) (32/200)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Starting task 79.0 in stage 5.0 (TID 191, hadoop08.cusp.nyu.edu, executor 5, partition 79, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Finished task 68.0 in stage 5.0 (TID 181) in 25 ms on hadoop08.cusp.nyu.edu (executor 5) (33/200)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Starting task 80.0 in stage 5.0 (TID 192, hadoop08.cusp.nyu.edu, executor 5, partition 80, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:45:52 INFO  MapOutputTrackerMasterEndpoint:54 - Asked to send map output locations for shuffle 0 to 192.168.72.179:34802
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Finished task 69.0 in stage 5.0 (TID 182) in 24 ms on hadoop08.cusp.nyu.edu (executor 5) (34/200)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Starting task 81.0 in stage 5.0 (TID 193, hadoop08.cusp.nyu.edu, executor 5, partition 81, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Finished task 70.0 in stage 5.0 (TID 183) in 23 ms on hadoop08.cusp.nyu.edu (executor 5) (35/200)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Starting task 82.0 in stage 5.0 (TID 194, hadoop08.cusp.nyu.edu, executor 5, partition 82, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Finished task 71.0 in stage 5.0 (TID 184) in 24 ms on hadoop08.cusp.nyu.edu (executor 5) (36/200)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Starting task 83.0 in stage 5.0 (TID 195, hadoop08.cusp.nyu.edu, executor 5, partition 83, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Finished task 72.0 in stage 5.0 (TID 185) in 25 ms on hadoop08.cusp.nyu.edu (executor 5) (37/200)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Starting task 84.0 in stage 5.0 (TID 196, hadoop08.cusp.nyu.edu, executor 5, partition 84, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Finished task 73.0 in stage 5.0 (TID 186) in 24 ms on hadoop08.cusp.nyu.edu (executor 5) (38/200)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Starting task 85.0 in stage 5.0 (TID 197, hadoop08.cusp.nyu.edu, executor 5, partition 85, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Finished task 74.0 in stage 5.0 (TID 187) in 24 ms on hadoop08.cusp.nyu.edu (executor 5) (39/200)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Starting task 86.0 in stage 5.0 (TID 198, hadoop08.cusp.nyu.edu, executor 5, partition 86, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Finished task 77.0 in stage 5.0 (TID 189) in 21 ms on hadoop08.cusp.nyu.edu (executor 5) (40/200)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Starting task 87.0 in stage 5.0 (TID 199, hadoop08.cusp.nyu.edu, executor 5, partition 87, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Finished task 76.0 in stage 5.0 (TID 188) in 24 ms on hadoop08.cusp.nyu.edu (executor 5) (41/200)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Starting task 88.0 in stage 5.0 (TID 200, hadoop08.cusp.nyu.edu, executor 5, partition 88, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Finished task 78.0 in stage 5.0 (TID 190) in 23 ms on hadoop08.cusp.nyu.edu (executor 5) (42/200)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Starting task 89.0 in stage 5.0 (TID 201, hadoop08.cusp.nyu.edu, executor 5, partition 89, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Finished task 79.0 in stage 5.0 (TID 191) in 28 ms on hadoop08.cusp.nyu.edu (executor 5) (43/200)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Starting task 90.0 in stage 5.0 (TID 202, hadoop08.cusp.nyu.edu, executor 5, partition 90, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Starting task 91.0 in stage 5.0 (TID 203, hadoop08.cusp.nyu.edu, executor 5, partition 91, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Finished task 81.0 in stage 5.0 (TID 193) in 30 ms on hadoop08.cusp.nyu.edu (executor 5) (44/200)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Finished task 80.0 in stage 5.0 (TID 192) in 32 ms on hadoop08.cusp.nyu.edu (executor 5) (45/200)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Starting task 92.0 in stage 5.0 (TID 204, hadoop08.cusp.nyu.edu, executor 5, partition 92, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Finished task 82.0 in stage 5.0 (TID 194) in 28 ms on hadoop08.cusp.nyu.edu (executor 5) (46/200)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Starting task 93.0 in stage 5.0 (TID 205, hadoop08.cusp.nyu.edu, executor 5, partition 93, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Finished task 84.0 in stage 5.0 (TID 196) in 28 ms on hadoop08.cusp.nyu.edu (executor 5) (47/200)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Starting task 94.0 in stage 5.0 (TID 206, hadoop08.cusp.nyu.edu, executor 5, partition 94, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Finished task 83.0 in stage 5.0 (TID 195) in 30 ms on hadoop08.cusp.nyu.edu (executor 5) (48/200)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Starting task 95.0 in stage 5.0 (TID 207, hadoop08.cusp.nyu.edu, executor 5, partition 95, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Finished task 85.0 in stage 5.0 (TID 197) in 29 ms on hadoop08.cusp.nyu.edu (executor 5) (49/200)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Starting task 96.0 in stage 5.0 (TID 208, hadoop08.cusp.nyu.edu, executor 5, partition 96, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Finished task 86.0 in stage 5.0 (TID 198) in 27 ms on hadoop08.cusp.nyu.edu (executor 5) (50/200)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Starting task 97.0 in stage 5.0 (TID 209, hadoop08.cusp.nyu.edu, executor 5, partition 97, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Finished task 87.0 in stage 5.0 (TID 199) in 26 ms on hadoop08.cusp.nyu.edu (executor 5) (51/200)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Starting task 98.0 in stage 5.0 (TID 210, hadoop08.cusp.nyu.edu, executor 5, partition 98, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Finished task 88.0 in stage 5.0 (TID 200) in 26 ms on hadoop08.cusp.nyu.edu (executor 5) (52/200)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Starting task 99.0 in stage 5.0 (TID 211, hadoop08.cusp.nyu.edu, executor 5, partition 99, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Finished task 89.0 in stage 5.0 (TID 201) in 22 ms on hadoop08.cusp.nyu.edu (executor 5) (53/200)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Starting task 100.0 in stage 5.0 (TID 212, hadoop08.cusp.nyu.edu, executor 5, partition 100, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Finished task 90.0 in stage 5.0 (TID 202) in 23 ms on hadoop08.cusp.nyu.edu (executor 5) (54/200)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Starting task 101.0 in stage 5.0 (TID 213, hadoop08.cusp.nyu.edu, executor 5, partition 101, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Finished task 91.0 in stage 5.0 (TID 203) in 25 ms on hadoop08.cusp.nyu.edu (executor 5) (55/200)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Starting task 102.0 in stage 5.0 (TID 214, hadoop08.cusp.nyu.edu, executor 5, partition 102, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Finished task 92.0 in stage 5.0 (TID 204) in 24 ms on hadoop08.cusp.nyu.edu (executor 5) (56/200)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Starting task 103.0 in stage 5.0 (TID 215, hadoop08.cusp.nyu.edu, executor 5, partition 103, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Finished task 93.0 in stage 5.0 (TID 205) in 24 ms on hadoop08.cusp.nyu.edu (executor 5) (57/200)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Starting task 104.0 in stage 5.0 (TID 216, hadoop08.cusp.nyu.edu, executor 5, partition 104, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Finished task 94.0 in stage 5.0 (TID 206) in 24 ms on hadoop08.cusp.nyu.edu (executor 5) (58/200)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Starting task 105.0 in stage 5.0 (TID 217, hadoop08.cusp.nyu.edu, executor 5, partition 105, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Starting task 106.0 in stage 5.0 (TID 218, hadoop08.cusp.nyu.edu, executor 5, partition 106, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Finished task 95.0 in stage 5.0 (TID 207) in 25 ms on hadoop08.cusp.nyu.edu (executor 5) (59/200)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Starting task 107.0 in stage 5.0 (TID 219, hadoop08.cusp.nyu.edu, executor 5, partition 107, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Finished task 97.0 in stage 5.0 (TID 209) in 24 ms on hadoop08.cusp.nyu.edu (executor 5) (60/200)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Finished task 96.0 in stage 5.0 (TID 208) in 27 ms on hadoop08.cusp.nyu.edu (executor 5) (61/200)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Starting task 108.0 in stage 5.0 (TID 220, hadoop08.cusp.nyu.edu, executor 5, partition 108, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Finished task 98.0 in stage 5.0 (TID 210) in 25 ms on hadoop08.cusp.nyu.edu (executor 5) (62/200)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Starting task 109.0 in stage 5.0 (TID 221, hadoop08.cusp.nyu.edu, executor 5, partition 109, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Finished task 99.0 in stage 5.0 (TID 211) in 24 ms on hadoop08.cusp.nyu.edu (executor 5) (63/200)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Starting task 110.0 in stage 5.0 (TID 222, hadoop08.cusp.nyu.edu, executor 5, partition 110, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Finished task 100.0 in stage 5.0 (TID 212) in 22 ms on hadoop08.cusp.nyu.edu (executor 5) (64/200)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Starting task 111.0 in stage 5.0 (TID 223, hadoop08.cusp.nyu.edu, executor 5, partition 111, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Finished task 101.0 in stage 5.0 (TID 213) in 23 ms on hadoop08.cusp.nyu.edu (executor 5) (65/200)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Starting task 112.0 in stage 5.0 (TID 224, hadoop08.cusp.nyu.edu, executor 5, partition 112, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Finished task 102.0 in stage 5.0 (TID 214) in 24 ms on hadoop08.cusp.nyu.edu (executor 5) (66/200)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Starting task 113.0 in stage 5.0 (TID 225, hadoop08.cusp.nyu.edu, executor 5, partition 113, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Finished task 104.0 in stage 5.0 (TID 216) in 21 ms on hadoop08.cusp.nyu.edu (executor 5) (67/200)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Starting task 114.0 in stage 5.0 (TID 226, hadoop08.cusp.nyu.edu, executor 5, partition 114, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Finished task 105.0 in stage 5.0 (TID 217) in 20 ms on hadoop08.cusp.nyu.edu (executor 5) (68/200)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Starting task 115.0 in stage 5.0 (TID 227, hadoop08.cusp.nyu.edu, executor 5, partition 115, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Finished task 103.0 in stage 5.0 (TID 215) in 34 ms on hadoop08.cusp.nyu.edu (executor 5) (69/200)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Starting task 116.0 in stage 5.0 (TID 228, hadoop08.cusp.nyu.edu, executor 5, partition 116, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Finished task 106.0 in stage 5.0 (TID 218) in 31 ms on hadoop08.cusp.nyu.edu (executor 5) (70/200)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Starting task 117.0 in stage 5.0 (TID 229, hadoop08.cusp.nyu.edu, executor 5, partition 117, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Finished task 107.0 in stage 5.0 (TID 219) in 30 ms on hadoop08.cusp.nyu.edu (executor 5) (71/200)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Starting task 118.0 in stage 5.0 (TID 230, hadoop08.cusp.nyu.edu, executor 5, partition 118, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Finished task 110.0 in stage 5.0 (TID 222) in 24 ms on hadoop08.cusp.nyu.edu (executor 5) (72/200)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Starting task 119.0 in stage 5.0 (TID 231, hadoop08.cusp.nyu.edu, executor 5, partition 119, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Finished task 108.0 in stage 5.0 (TID 220) in 65 ms on hadoop08.cusp.nyu.edu (executor 5) (73/200)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Starting task 120.0 in stage 5.0 (TID 232, hadoop08.cusp.nyu.edu, executor 5, partition 120, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Finished task 109.0 in stage 5.0 (TID 221) in 65 ms on hadoop08.cusp.nyu.edu (executor 5) (74/200)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Starting task 121.0 in stage 5.0 (TID 233, hadoop08.cusp.nyu.edu, executor 5, partition 121, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Finished task 111.0 in stage 5.0 (TID 223) in 59 ms on hadoop08.cusp.nyu.edu (executor 5) (75/200)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Starting task 122.0 in stage 5.0 (TID 234, hadoop08.cusp.nyu.edu, executor 5, partition 122, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Finished task 112.0 in stage 5.0 (TID 224) in 58 ms on hadoop08.cusp.nyu.edu (executor 5) (76/200)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Starting task 123.0 in stage 5.0 (TID 235, hadoop08.cusp.nyu.edu, executor 5, partition 123, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Finished task 114.0 in stage 5.0 (TID 226) in 60 ms on hadoop08.cusp.nyu.edu (executor 5) (77/200)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Starting task 124.0 in stage 5.0 (TID 236, hadoop08.cusp.nyu.edu, executor 5, partition 124, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Finished task 113.0 in stage 5.0 (TID 225) in 64 ms on hadoop08.cusp.nyu.edu (executor 5) (78/200)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Starting task 125.0 in stage 5.0 (TID 237, hadoop08.cusp.nyu.edu, executor 5, partition 125, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Finished task 116.0 in stage 5.0 (TID 228) in 52 ms on hadoop08.cusp.nyu.edu (executor 5) (79/200)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Starting task 126.0 in stage 5.0 (TID 238, hadoop08.cusp.nyu.edu, executor 5, partition 126, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Finished task 117.0 in stage 5.0 (TID 229) in 53 ms on hadoop08.cusp.nyu.edu (executor 5) (80/200)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Starting task 127.0 in stage 5.0 (TID 239, hadoop08.cusp.nyu.edu, executor 5, partition 127, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Finished task 115.0 in stage 5.0 (TID 227) in 57 ms on hadoop08.cusp.nyu.edu (executor 5) (81/200)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Starting task 128.0 in stage 5.0 (TID 240, hadoop08.cusp.nyu.edu, executor 5, partition 128, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Finished task 118.0 in stage 5.0 (TID 230) in 53 ms on hadoop08.cusp.nyu.edu (executor 5) (82/200)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Starting task 129.0 in stage 5.0 (TID 241, hadoop08.cusp.nyu.edu, executor 5, partition 129, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Finished task 119.0 in stage 5.0 (TID 231) in 21 ms on hadoop08.cusp.nyu.edu (executor 5) (83/200)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Starting task 130.0 in stage 5.0 (TID 242, hadoop08.cusp.nyu.edu, executor 5, partition 130, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Finished task 120.0 in stage 5.0 (TID 232) in 21 ms on hadoop08.cusp.nyu.edu (executor 5) (84/200)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Starting task 131.0 in stage 5.0 (TID 243, hadoop08.cusp.nyu.edu, executor 5, partition 131, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Finished task 121.0 in stage 5.0 (TID 233) in 22 ms on hadoop08.cusp.nyu.edu (executor 5) (85/200)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Starting task 132.0 in stage 5.0 (TID 244, hadoop08.cusp.nyu.edu, executor 5, partition 132, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Finished task 122.0 in stage 5.0 (TID 234) in 22 ms on hadoop08.cusp.nyu.edu (executor 5) (86/200)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Starting task 133.0 in stage 5.0 (TID 245, hadoop08.cusp.nyu.edu, executor 5, partition 133, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Finished task 123.0 in stage 5.0 (TID 235) in 18 ms on hadoop08.cusp.nyu.edu (executor 5) (87/200)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Starting task 134.0 in stage 5.0 (TID 246, hadoop08.cusp.nyu.edu, executor 5, partition 134, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Finished task 125.0 in stage 5.0 (TID 237) in 18 ms on hadoop08.cusp.nyu.edu (executor 5) (88/200)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Starting task 135.0 in stage 5.0 (TID 247, hadoop08.cusp.nyu.edu, executor 5, partition 135, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Finished task 124.0 in stage 5.0 (TID 236) in 21 ms on hadoop08.cusp.nyu.edu (executor 5) (89/200)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Starting task 136.0 in stage 5.0 (TID 248, hadoop08.cusp.nyu.edu, executor 5, partition 136, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Finished task 128.0 in stage 5.0 (TID 240) in 18 ms on hadoop08.cusp.nyu.edu (executor 5) (90/200)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Starting task 137.0 in stage 5.0 (TID 249, hadoop08.cusp.nyu.edu, executor 5, partition 137, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Finished task 126.0 in stage 5.0 (TID 238) in 23 ms on hadoop08.cusp.nyu.edu (executor 5) (91/200)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Starting task 138.0 in stage 5.0 (TID 250, hadoop08.cusp.nyu.edu, executor 5, partition 138, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Finished task 127.0 in stage 5.0 (TID 239) in 23 ms on hadoop08.cusp.nyu.edu (executor 5) (92/200)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Starting task 139.0 in stage 5.0 (TID 251, hadoop08.cusp.nyu.edu, executor 5, partition 139, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Finished task 130.0 in stage 5.0 (TID 242) in 19 ms on hadoop08.cusp.nyu.edu (executor 5) (93/200)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Starting task 140.0 in stage 5.0 (TID 252, hadoop08.cusp.nyu.edu, executor 5, partition 140, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Finished task 129.0 in stage 5.0 (TID 241) in 24 ms on hadoop08.cusp.nyu.edu (executor 5) (94/200)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Starting task 141.0 in stage 5.0 (TID 253, hadoop08.cusp.nyu.edu, executor 5, partition 141, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Finished task 132.0 in stage 5.0 (TID 244) in 18 ms on hadoop08.cusp.nyu.edu (executor 5) (95/200)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Starting task 142.0 in stage 5.0 (TID 254, hadoop08.cusp.nyu.edu, executor 5, partition 142, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Finished task 131.0 in stage 5.0 (TID 243) in 21 ms on hadoop08.cusp.nyu.edu (executor 5) (96/200)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Starting task 143.0 in stage 5.0 (TID 255, hadoop07.cusp.nyu.edu, executor 3, partition 143, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Finished task 14.0 in stage 5.0 (TID 131) in 663 ms on hadoop07.cusp.nyu.edu (executor 3) (97/200)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Starting task 145.0 in stage 5.0 (TID 256, hadoop07.cusp.nyu.edu, executor 3, partition 145, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Finished task 10.0 in stage 5.0 (TID 127) in 666 ms on hadoop07.cusp.nyu.edu (executor 3) (98/200)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Starting task 146.0 in stage 5.0 (TID 257, hadoop07.cusp.nyu.edu, executor 3, partition 146, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Finished task 23.0 in stage 5.0 (TID 139) in 665 ms on hadoop07.cusp.nyu.edu (executor 3) (99/200)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Starting task 147.0 in stage 5.0 (TID 258, hadoop07.cusp.nyu.edu, executor 3, partition 147, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Finished task 32.0 in stage 5.0 (TID 147) in 664 ms on hadoop07.cusp.nyu.edu (executor 3) (100/200)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Starting task 148.0 in stage 5.0 (TID 259, hadoop08.cusp.nyu.edu, executor 5, partition 148, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Finished task 133.0 in stage 5.0 (TID 245) in 24 ms on hadoop08.cusp.nyu.edu (executor 5) (101/200)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Starting task 149.0 in stage 5.0 (TID 260, hadoop07.cusp.nyu.edu, executor 3, partition 149, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Starting task 150.0 in stage 5.0 (TID 261, hadoop07.cusp.nyu.edu, executor 3, partition 150, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Finished task 0.0 in stage 5.0 (TID 118) in 677 ms on hadoop07.cusp.nyu.edu (executor 3) (102/200)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Starting task 151.0 in stage 5.0 (TID 262, hadoop08.cusp.nyu.edu, executor 5, partition 151, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Finished task 37.0 in stage 5.0 (TID 151) in 667 ms on hadoop07.cusp.nyu.edu (executor 3) (103/200)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Finished task 134.0 in stage 5.0 (TID 246) in 27 ms on hadoop08.cusp.nyu.edu (executor 5) (104/200)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Starting task 152.0 in stage 5.0 (TID 263, hadoop07.cusp.nyu.edu, executor 3, partition 152, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Finished task 19.0 in stage 5.0 (TID 135) in 675 ms on hadoop07.cusp.nyu.edu (executor 3) (105/200)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Starting task 153.0 in stage 5.0 (TID 264, hadoop07.cusp.nyu.edu, executor 3, partition 153, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Finished task 6.0 in stage 5.0 (TID 123) in 680 ms on hadoop07.cusp.nyu.edu (executor 3) (106/200)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Starting task 154.0 in stage 5.0 (TID 265, hadoop08.cusp.nyu.edu, executor 5, partition 154, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Finished task 135.0 in stage 5.0 (TID 247) in 29 ms on hadoop08.cusp.nyu.edu (executor 5) (107/200)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Starting task 155.0 in stage 5.0 (TID 266, hadoop07.cusp.nyu.edu, executor 3, partition 155, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Finished task 28.0 in stage 5.0 (TID 143) in 676 ms on hadoop07.cusp.nyu.edu (executor 3) (108/200)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Starting task 156.0 in stage 5.0 (TID 267, hadoop07.cusp.nyu.edu, executor 3, partition 156, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Finished task 41.0 in stage 5.0 (TID 155) in 675 ms on hadoop07.cusp.nyu.edu (executor 3) (109/200)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Starting task 157.0 in stage 5.0 (TID 268, hadoop08.cusp.nyu.edu, executor 5, partition 157, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Finished task 136.0 in stage 5.0 (TID 248) in 29 ms on hadoop08.cusp.nyu.edu (executor 5) (110/200)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Starting task 158.0 in stage 5.0 (TID 269, hadoop08.cusp.nyu.edu, executor 5, partition 158, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Finished task 137.0 in stage 5.0 (TID 249) in 29 ms on hadoop08.cusp.nyu.edu (executor 5) (111/200)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Starting task 159.0 in stage 5.0 (TID 270, hadoop08.cusp.nyu.edu, executor 5, partition 159, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Finished task 138.0 in stage 5.0 (TID 250) in 29 ms on hadoop08.cusp.nyu.edu (executor 5) (112/200)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Starting task 160.0 in stage 5.0 (TID 271, hadoop08.cusp.nyu.edu, executor 5, partition 160, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Starting task 161.0 in stage 5.0 (TID 272, hadoop08.cusp.nyu.edu, executor 5, partition 161, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Finished task 139.0 in stage 5.0 (TID 251) in 30 ms on hadoop08.cusp.nyu.edu (executor 5) (113/200)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Finished task 141.0 in stage 5.0 (TID 253) in 27 ms on hadoop08.cusp.nyu.edu (executor 5) (114/200)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Starting task 162.0 in stage 5.0 (TID 273, hadoop08.cusp.nyu.edu, executor 5, partition 162, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Starting task 163.0 in stage 5.0 (TID 274, hadoop08.cusp.nyu.edu, executor 5, partition 163, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Finished task 142.0 in stage 5.0 (TID 254) in 27 ms on hadoop08.cusp.nyu.edu (executor 5) (115/200)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Starting task 164.0 in stage 5.0 (TID 275, hadoop08.cusp.nyu.edu, executor 5, partition 164, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Finished task 140.0 in stage 5.0 (TID 252) in 31 ms on hadoop08.cusp.nyu.edu (executor 5) (116/200)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Finished task 148.0 in stage 5.0 (TID 259) in 22 ms on hadoop08.cusp.nyu.edu (executor 5) (117/200)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Starting task 165.0 in stage 5.0 (TID 276, hadoop08.cusp.nyu.edu, executor 5, partition 165, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Finished task 151.0 in stage 5.0 (TID 262) in 24 ms on hadoop08.cusp.nyu.edu (executor 5) (118/200)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Starting task 167.0 in stage 5.0 (TID 277, hadoop08.cusp.nyu.edu, executor 5, partition 167, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Finished task 157.0 in stage 5.0 (TID 268) in 16 ms on hadoop08.cusp.nyu.edu (executor 5) (119/200)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Starting task 168.0 in stage 5.0 (TID 278, hadoop08.cusp.nyu.edu, executor 5, partition 168, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Finished task 154.0 in stage 5.0 (TID 265) in 21 ms on hadoop08.cusp.nyu.edu (executor 5) (120/200)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Starting task 169.0 in stage 5.0 (TID 279, hadoop08.cusp.nyu.edu, executor 5, partition 169, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Finished task 161.0 in stage 5.0 (TID 272) in 22 ms on hadoop08.cusp.nyu.edu (executor 5) (121/200)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Starting task 170.0 in stage 5.0 (TID 280, hadoop08.cusp.nyu.edu, executor 5, partition 170, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Finished task 162.0 in stage 5.0 (TID 273) in 21 ms on hadoop08.cusp.nyu.edu (executor 5) (122/200)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Starting task 171.0 in stage 5.0 (TID 281, hadoop08.cusp.nyu.edu, executor 5, partition 171, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Finished task 159.0 in stage 5.0 (TID 270) in 27 ms on hadoop08.cusp.nyu.edu (executor 5) (123/200)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Starting task 172.0 in stage 5.0 (TID 282, hadoop08.cusp.nyu.edu, executor 5, partition 172, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Finished task 160.0 in stage 5.0 (TID 271) in 27 ms on hadoop08.cusp.nyu.edu (executor 5) (124/200)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Starting task 173.0 in stage 5.0 (TID 283, hadoop08.cusp.nyu.edu, executor 5, partition 173, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Finished task 158.0 in stage 5.0 (TID 269) in 30 ms on hadoop08.cusp.nyu.edu (executor 5) (125/200)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Starting task 174.0 in stage 5.0 (TID 284, hadoop08.cusp.nyu.edu, executor 5, partition 174, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Finished task 164.0 in stage 5.0 (TID 275) in 25 ms on hadoop08.cusp.nyu.edu (executor 5) (126/200)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Starting task 175.0 in stage 5.0 (TID 285, hadoop08.cusp.nyu.edu, executor 5, partition 175, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Finished task 163.0 in stage 5.0 (TID 274) in 27 ms on hadoop08.cusp.nyu.edu (executor 5) (127/200)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Starting task 176.0 in stage 5.0 (TID 286, hadoop08.cusp.nyu.edu, executor 5, partition 176, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Finished task 167.0 in stage 5.0 (TID 277) in 21 ms on hadoop08.cusp.nyu.edu (executor 5) (128/200)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Starting task 177.0 in stage 5.0 (TID 287, hadoop08.cusp.nyu.edu, executor 5, partition 177, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Finished task 165.0 in stage 5.0 (TID 276) in 24 ms on hadoop08.cusp.nyu.edu (executor 5) (129/200)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Starting task 178.0 in stage 5.0 (TID 288, hadoop08.cusp.nyu.edu, executor 5, partition 178, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Finished task 168.0 in stage 5.0 (TID 278) in 23 ms on hadoop08.cusp.nyu.edu (executor 5) (130/200)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Starting task 179.0 in stage 5.0 (TID 289, hadoop08.cusp.nyu.edu, executor 5, partition 179, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Finished task 170.0 in stage 5.0 (TID 280) in 15 ms on hadoop08.cusp.nyu.edu (executor 5) (131/200)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Starting task 180.0 in stage 5.0 (TID 290, hadoop08.cusp.nyu.edu, executor 5, partition 180, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Finished task 169.0 in stage 5.0 (TID 279) in 18 ms on hadoop08.cusp.nyu.edu (executor 5) (132/200)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Starting task 181.0 in stage 5.0 (TID 291, hadoop07.cusp.nyu.edu, executor 3, partition 181, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Starting task 182.0 in stage 5.0 (TID 292, hadoop07.cusp.nyu.edu, executor 3, partition 182, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Finished task 145.0 in stage 5.0 (TID 256) in 62 ms on hadoop07.cusp.nyu.edu (executor 3) (133/200)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Finished task 146.0 in stage 5.0 (TID 257) in 61 ms on hadoop07.cusp.nyu.edu (executor 3) (134/200)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Starting task 183.0 in stage 5.0 (TID 293, hadoop08.cusp.nyu.edu, executor 5, partition 183, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Finished task 171.0 in stage 5.0 (TID 281) in 18 ms on hadoop08.cusp.nyu.edu (executor 5) (135/200)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Starting task 184.0 in stage 5.0 (TID 294, hadoop07.cusp.nyu.edu, executor 3, partition 184, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Finished task 143.0 in stage 5.0 (TID 255) in 68 ms on hadoop07.cusp.nyu.edu (executor 3) (136/200)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Starting task 185.0 in stage 5.0 (TID 295, hadoop08.cusp.nyu.edu, executor 5, partition 185, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Finished task 174.0 in stage 5.0 (TID 284) in 18 ms on hadoop08.cusp.nyu.edu (executor 5) (137/200)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Starting task 186.0 in stage 5.0 (TID 296, hadoop07.cusp.nyu.edu, executor 3, partition 186, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Finished task 149.0 in stage 5.0 (TID 260) in 64 ms on hadoop07.cusp.nyu.edu (executor 3) (138/200)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Starting task 187.0 in stage 5.0 (TID 297, hadoop07.cusp.nyu.edu, executor 3, partition 187, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Finished task 147.0 in stage 5.0 (TID 258) in 68 ms on hadoop07.cusp.nyu.edu (executor 3) (139/200)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Starting task 188.0 in stage 5.0 (TID 298, hadoop08.cusp.nyu.edu, executor 5, partition 188, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Finished task 176.0 in stage 5.0 (TID 286) in 19 ms on hadoop08.cusp.nyu.edu (executor 5) (140/200)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Starting task 190.0 in stage 5.0 (TID 299, hadoop07.cusp.nyu.edu, executor 3, partition 190, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Finished task 150.0 in stage 5.0 (TID 261) in 67 ms on hadoop07.cusp.nyu.edu (executor 3) (141/200)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Starting task 191.0 in stage 5.0 (TID 300, hadoop08.cusp.nyu.edu, executor 5, partition 191, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Finished task 172.0 in stage 5.0 (TID 282) in 28 ms on hadoop08.cusp.nyu.edu (executor 5) (142/200)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Starting task 192.0 in stage 5.0 (TID 301, hadoop07.cusp.nyu.edu, executor 3, partition 192, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Finished task 155.0 in stage 5.0 (TID 266) in 61 ms on hadoop07.cusp.nyu.edu (executor 3) (143/200)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Starting task 193.0 in stage 5.0 (TID 302, hadoop08.cusp.nyu.edu, executor 5, partition 193, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Finished task 173.0 in stage 5.0 (TID 283) in 29 ms on hadoop08.cusp.nyu.edu (executor 5) (144/200)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Starting task 194.0 in stage 5.0 (TID 303, hadoop07.cusp.nyu.edu, executor 3, partition 194, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Finished task 156.0 in stage 5.0 (TID 267) in 63 ms on hadoop07.cusp.nyu.edu (executor 3) (145/200)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Starting task 195.0 in stage 5.0 (TID 304, hadoop07.cusp.nyu.edu, executor 3, partition 195, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Starting task 196.0 in stage 5.0 (TID 305, hadoop08.cusp.nyu.edu, executor 5, partition 196, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Finished task 153.0 in stage 5.0 (TID 264) in 69 ms on hadoop07.cusp.nyu.edu (executor 3) (146/200)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Starting task 197.0 in stage 5.0 (TID 306, hadoop08.cusp.nyu.edu, executor 5, partition 197, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Finished task 178.0 in stage 5.0 (TID 288) in 27 ms on hadoop08.cusp.nyu.edu (executor 5) (147/200)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Finished task 177.0 in stage 5.0 (TID 287) in 29 ms on hadoop08.cusp.nyu.edu (executor 5) (148/200)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Starting task 198.0 in stage 5.0 (TID 307, hadoop08.cusp.nyu.edu, executor 5, partition 198, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Finished task 175.0 in stage 5.0 (TID 285) in 34 ms on hadoop08.cusp.nyu.edu (executor 5) (149/200)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Starting task 199.0 in stage 5.0 (TID 308, hadoop08.cusp.nyu.edu, executor 5, partition 199, PROCESS_LOCAL, 7756 bytes)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Finished task 179.0 in stage 5.0 (TID 289) in 27 ms on hadoop08.cusp.nyu.edu (executor 5) (150/200)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Finished task 152.0 in stage 5.0 (TID 263) in 77 ms on hadoop07.cusp.nyu.edu (executor 3) (151/200)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Finished task 183.0 in stage 5.0 (TID 293) in 25 ms on hadoop08.cusp.nyu.edu (executor 5) (152/200)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Finished task 180.0 in stage 5.0 (TID 290) in 28 ms on hadoop08.cusp.nyu.edu (executor 5) (153/200)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Finished task 185.0 in stage 5.0 (TID 295) in 23 ms on hadoop08.cusp.nyu.edu (executor 5) (154/200)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Finished task 188.0 in stage 5.0 (TID 298) in 20 ms on hadoop08.cusp.nyu.edu (executor 5) (155/200)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Finished task 191.0 in stage 5.0 (TID 300) in 18 ms on hadoop08.cusp.nyu.edu (executor 5) (156/200)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Finished task 193.0 in stage 5.0 (TID 302) in 20 ms on hadoop08.cusp.nyu.edu (executor 5) (157/200)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Finished task 196.0 in stage 5.0 (TID 305) in 18 ms on hadoop08.cusp.nyu.edu (executor 5) (158/200)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Finished task 198.0 in stage 5.0 (TID 307) in 16 ms on hadoop08.cusp.nyu.edu (executor 5) (159/200)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Finished task 197.0 in stage 5.0 (TID 306) in 20 ms on hadoop08.cusp.nyu.edu (executor 5) (160/200)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Finished task 199.0 in stage 5.0 (TID 308) in 16 ms on hadoop08.cusp.nyu.edu (executor 5) (161/200)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Finished task 181.0 in stage 5.0 (TID 291) in 58 ms on hadoop07.cusp.nyu.edu (executor 3) (162/200)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Finished task 182.0 in stage 5.0 (TID 292) in 58 ms on hadoop07.cusp.nyu.edu (executor 3) (163/200)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Finished task 184.0 in stage 5.0 (TID 294) in 61 ms on hadoop07.cusp.nyu.edu (executor 3) (164/200)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Finished task 195.0 in stage 5.0 (TID 304) in 52 ms on hadoop07.cusp.nyu.edu (executor 3) (165/200)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Finished task 186.0 in stage 5.0 (TID 296) in 65 ms on hadoop07.cusp.nyu.edu (executor 3) (166/200)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Finished task 187.0 in stage 5.0 (TID 297) in 65 ms on hadoop07.cusp.nyu.edu (executor 3) (167/200)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Finished task 192.0 in stage 5.0 (TID 301) in 63 ms on hadoop07.cusp.nyu.edu (executor 3) (168/200)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Finished task 190.0 in stage 5.0 (TID 299) in 65 ms on hadoop07.cusp.nyu.edu (executor 3) (169/200)
2021-05-19 02:45:52 INFO  TaskSetManager:54 - Finished task 194.0 in stage 5.0 (TID 303) in 60 ms on hadoop07.cusp.nyu.edu (executor 3) (170/200)
2021-05-19 02:45:53 INFO  TaskSetManager:54 - Finished task 38.0 in stage 5.0 (TID 152) in 1370 ms on hadoop20.cusp.nyu.edu (executor 4) (171/200)
2021-05-19 02:45:53 INFO  TaskSetManager:54 - Finished task 24.0 in stage 5.0 (TID 140) in 1373 ms on hadoop20.cusp.nyu.edu (executor 4) (172/200)
2021-05-19 02:45:53 INFO  TaskSetManager:54 - Finished task 11.0 in stage 5.0 (TID 128) in 1379 ms on hadoop20.cusp.nyu.edu (executor 4) (173/200)
2021-05-19 02:45:53 INFO  TaskSetManager:54 - Finished task 15.0 in stage 5.0 (TID 132) in 1378 ms on hadoop20.cusp.nyu.edu (executor 4) (174/200)
2021-05-19 02:45:53 INFO  TaskSetManager:54 - Finished task 29.0 in stage 5.0 (TID 144) in 1375 ms on hadoop20.cusp.nyu.edu (executor 4) (175/200)
2021-05-19 02:45:53 INFO  TaskSetManager:54 - Finished task 7.0 in stage 5.0 (TID 124) in 1383 ms on hadoop20.cusp.nyu.edu (executor 4) (176/200)
2021-05-19 02:45:53 INFO  TaskSetManager:54 - Finished task 20.0 in stage 5.0 (TID 136) in 1379 ms on hadoop20.cusp.nyu.edu (executor 4) (177/200)
2021-05-19 02:45:53 INFO  TaskSetManager:54 - Finished task 1.0 in stage 5.0 (TID 119) in 1386 ms on hadoop20.cusp.nyu.edu (executor 4) (178/200)
2021-05-19 02:45:53 INFO  TaskSetManager:54 - Finished task 33.0 in stage 5.0 (TID 148) in 1376 ms on hadoop20.cusp.nyu.edu (executor 4) (179/200)
2021-05-19 02:45:53 INFO  TaskSetManager:54 - Finished task 42.0 in stage 5.0 (TID 156) in 1376 ms on hadoop20.cusp.nyu.edu (executor 4) (180/200)
2021-05-19 02:45:53 INFO  TaskSetManager:54 - Finished task 39.0 in stage 5.0 (TID 153) in 1487 ms on hadoop10.cusp.nyu.edu (executor 2) (181/200)
2021-05-19 02:45:53 INFO  TaskSetManager:54 - Finished task 34.0 in stage 5.0 (TID 149) in 1492 ms on hadoop10.cusp.nyu.edu (executor 2) (182/200)
2021-05-19 02:45:53 INFO  TaskSetManager:54 - Finished task 8.0 in stage 5.0 (TID 125) in 1500 ms on hadoop10.cusp.nyu.edu (executor 2) (183/200)
2021-05-19 02:45:53 INFO  TaskSetManager:54 - Finished task 25.0 in stage 5.0 (TID 141) in 1498 ms on hadoop10.cusp.nyu.edu (executor 2) (184/200)
2021-05-19 02:45:53 INFO  TaskSetManager:54 - Finished task 21.0 in stage 5.0 (TID 137) in 1500 ms on hadoop10.cusp.nyu.edu (executor 2) (185/200)
2021-05-19 02:45:53 INFO  TaskSetManager:54 - Finished task 30.0 in stage 5.0 (TID 145) in 1498 ms on hadoop10.cusp.nyu.edu (executor 2) (186/200)
2021-05-19 02:45:53 INFO  TaskSetManager:54 - Finished task 2.0 in stage 5.0 (TID 120) in 1512 ms on hadoop10.cusp.nyu.edu (executor 2) (187/200)
2021-05-19 02:45:53 INFO  TaskSetManager:54 - Finished task 43.0 in stage 5.0 (TID 157) in 1502 ms on hadoop10.cusp.nyu.edu (executor 2) (188/200)
2021-05-19 02:45:53 INFO  TaskSetManager:54 - Finished task 16.0 in stage 5.0 (TID 133) in 1508 ms on hadoop10.cusp.nyu.edu (executor 2) (189/200)
2021-05-19 02:45:53 INFO  TaskSetManager:54 - Finished task 12.0 in stage 5.0 (TID 129) in 1510 ms on hadoop10.cusp.nyu.edu (executor 2) (190/200)
2021-05-19 02:45:53 INFO  TaskSetManager:54 - Finished task 44.0 in stage 5.0 (TID 158) in 1505 ms on hadoop09.cusp.nyu.edu (executor 1) (191/200)
2021-05-19 02:45:53 INFO  TaskSetManager:54 - Finished task 13.0 in stage 5.0 (TID 130) in 1513 ms on hadoop09.cusp.nyu.edu (executor 1) (192/200)
2021-05-19 02:45:53 INFO  TaskSetManager:54 - Finished task 31.0 in stage 5.0 (TID 146) in 1511 ms on hadoop09.cusp.nyu.edu (executor 1) (193/200)
2021-05-19 02:45:53 INFO  TaskSetManager:54 - Finished task 4.0 in stage 5.0 (TID 121) in 1525 ms on hadoop09.cusp.nyu.edu (executor 1) (194/200)
2021-05-19 02:45:53 INFO  TaskSetManager:54 - Finished task 17.0 in stage 5.0 (TID 134) in 1526 ms on hadoop09.cusp.nyu.edu (executor 1) (195/200)
2021-05-19 02:45:53 INFO  TaskSetManager:54 - Finished task 22.0 in stage 5.0 (TID 138) in 1528 ms on hadoop09.cusp.nyu.edu (executor 1) (196/200)
2021-05-19 02:45:53 INFO  TaskSetManager:54 - Finished task 40.0 in stage 5.0 (TID 154) in 1525 ms on hadoop09.cusp.nyu.edu (executor 1) (197/200)
2021-05-19 02:45:53 INFO  TaskSetManager:54 - Finished task 9.0 in stage 5.0 (TID 126) in 1533 ms on hadoop09.cusp.nyu.edu (executor 1) (198/200)
2021-05-19 02:45:53 INFO  TaskSetManager:54 - Finished task 27.0 in stage 5.0 (TID 142) in 1529 ms on hadoop09.cusp.nyu.edu (executor 1) (199/200)
2021-05-19 02:45:53 INFO  TaskSetManager:54 - Finished task 36.0 in stage 5.0 (TID 150) in 1528 ms on hadoop09.cusp.nyu.edu (executor 1) (200/200)
2021-05-19 02:45:53 INFO  YarnClusterScheduler:54 - Removed TaskSet 5.0, whose tasks have all completed, from pool 
2021-05-19 02:45:53 INFO  DAGScheduler:54 - ResultStage 5 (collect at BDM_HW4.py:27) finished in 1.586 s
2021-05-19 02:45:53 INFO  DAGScheduler:54 - Job 4 finished: collect at BDM_HW4.py:27, took 4.596642 s
2021-05-19 02:45:53 INFO  ContextCleaner:54 - Cleaned accumulator 160
2021-05-19 02:45:53 INFO  BlockManagerInfo:54 - Removed broadcast_10_piece0 on hadoop05.cusp.nyu.edu:36982 in memory (size: 20.4 KB, free: 366.3 MB)
2021-05-19 02:45:53 INFO  BlockManagerInfo:54 - Removed broadcast_10_piece0 on hadoop08.cusp.nyu.edu:54817 in memory (size: 20.4 KB, free: 365.6 MB)
2021-05-19 02:45:53 INFO  BlockManagerInfo:54 - Removed broadcast_10_piece0 on hadoop10.cusp.nyu.edu:51710 in memory (size: 20.4 KB, free: 366.3 MB)
2021-05-19 02:45:53 INFO  BlockManagerInfo:54 - Removed broadcast_10_piece0 on hadoop07.cusp.nyu.edu:57060 in memory (size: 20.4 KB, free: 366.3 MB)
2021-05-19 02:45:53 INFO  BlockManagerInfo:54 - Removed broadcast_10_piece0 on hadoop09.cusp.nyu.edu:44190 in memory (size: 20.4 KB, free: 366.3 MB)
2021-05-19 02:45:53 INFO  BlockManagerInfo:54 - Removed broadcast_10_piece0 on hadoop20.cusp.nyu.edu:55825 in memory (size: 20.4 KB, free: 366.3 MB)
2021-05-19 02:45:53 INFO  ContextCleaner:54 - Cleaned accumulator 149
2021-05-19 02:45:53 INFO  ContextCleaner:54 - Cleaned accumulator 191
2021-05-19 02:45:53 INFO  ContextCleaner:54 - Cleaned accumulator 155
2021-05-19 02:45:53 INFO  ContextCleaner:54 - Cleaned accumulator 163
2021-05-19 02:45:53 INFO  ContextCleaner:54 - Cleaned accumulator 188
2021-05-19 02:45:53 INFO  ContextCleaner:54 - Cleaned accumulator 175
2021-05-19 02:45:53 INFO  ContextCleaner:54 - Cleaned accumulator 190
2021-05-19 02:45:53 INFO  ContextCleaner:54 - Cleaned accumulator 193
2021-05-19 02:45:53 INFO  ContextCleaner:54 - Cleaned accumulator 183
2021-05-19 02:45:53 INFO  ContextCleaner:54 - Cleaned accumulator 195
2021-05-19 02:45:53 INFO  ContextCleaner:54 - Cleaned accumulator 148
2021-05-19 02:45:53 INFO  ContextCleaner:54 - Cleaned accumulator 167
2021-05-19 02:45:53 INFO  ContextCleaner:54 - Cleaned accumulator 182
2021-05-19 02:45:53 INFO  ContextCleaner:54 - Cleaned accumulator 189
2021-05-19 02:45:53 INFO  ContextCleaner:54 - Cleaned accumulator 196
2021-05-19 02:45:53 INFO  ContextCleaner:54 - Cleaned accumulator 166
2021-05-19 02:45:53 INFO  ContextCleaner:54 - Cleaned accumulator 194
2021-05-19 02:45:53 INFO  ContextCleaner:54 - Cleaned accumulator 161
2021-05-19 02:45:53 INFO  ContextCleaner:54 - Cleaned accumulator 158
2021-05-19 02:45:53 INFO  ContextCleaner:54 - Cleaned accumulator 186
2021-05-19 02:45:53 INFO  ContextCleaner:54 - Cleaned accumulator 185
2021-05-19 02:45:53 INFO  ContextCleaner:54 - Cleaned accumulator 156
2021-05-19 02:45:53 INFO  ContextCleaner:54 - Cleaned accumulator 169
2021-05-19 02:45:53 INFO  ContextCleaner:54 - Cleaned accumulator 180
2021-05-19 02:45:53 INFO  ContextCleaner:54 - Cleaned accumulator 164
2021-05-19 02:45:53 INFO  ContextCleaner:54 - Cleaned accumulator 192
2021-05-19 02:45:53 INFO  ContextCleaner:54 - Cleaned accumulator 179
2021-05-19 02:45:53 INFO  ContextCleaner:54 - Cleaned accumulator 178
2021-05-19 02:45:53 INFO  ContextCleaner:54 - Cleaned accumulator 168
2021-05-19 02:45:53 INFO  ContextCleaner:54 - Cleaned accumulator 171
2021-05-19 02:45:53 INFO  ContextCleaner:54 - Cleaned accumulator 187
2021-05-19 02:45:53 INFO  ContextCleaner:54 - Cleaned accumulator 181
2021-05-19 02:45:53 INFO  ContextCleaner:54 - Cleaned accumulator 150
2021-05-19 02:45:53 INFO  ContextCleaner:54 - Cleaned accumulator 184
2021-05-19 02:45:53 INFO  ContextCleaner:54 - Cleaned accumulator 172
2021-05-19 02:45:53 INFO  ContextCleaner:54 - Cleaned accumulator 165
2021-05-19 02:45:53 INFO  ContextCleaner:54 - Cleaned accumulator 151
2021-05-19 02:45:53 INFO  ContextCleaner:54 - Cleaned accumulator 154
2021-05-19 02:45:53 INFO  ContextCleaner:54 - Cleaned accumulator 157
2021-05-19 02:45:53 INFO  ContextCleaner:54 - Cleaned accumulator 170
2021-05-19 02:45:53 INFO  ContextCleaner:54 - Cleaned accumulator 176
2021-05-19 02:45:53 INFO  ContextCleaner:54 - Cleaned accumulator 177
2021-05-19 02:45:53 INFO  ContextCleaner:54 - Cleaned accumulator 147
2021-05-19 02:45:53 INFO  ContextCleaner:54 - Cleaned accumulator 153
2021-05-19 02:45:53 INFO  ContextCleaner:54 - Cleaned accumulator 162
2021-05-19 02:45:53 INFO  ContextCleaner:54 - Cleaned accumulator 174
2021-05-19 02:45:53 INFO  ContextCleaner:54 - Cleaned accumulator 159
2021-05-19 02:45:53 INFO  ContextCleaner:54 - Cleaned accumulator 152
2021-05-19 02:45:53 INFO  ContextCleaner:54 - Cleaned accumulator 173
2021-05-19 02:45:54 INFO  FileSourceStrategy:54 - Pruning directories with: 
2021-05-19 02:45:54 INFO  FileSourceStrategy:54 - Post-Scan Filters: isnotnull(placekey#68)
2021-05-19 02:45:54 INFO  FileSourceStrategy:54 - Output Data Schema: struct<placekey: string, date_range_start: string, visits_by_day: string ... 1 more fields>
2021-05-19 02:45:54 INFO  FileSourceScanExec:54 - Pushed Filters: IsNotNull(placekey)
2021-05-19 02:45:54 WARN  Utils:66 - Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.debug.maxToStringFields' in SparkEnv.conf.
2021-05-19 02:45:54 INFO  FileOutputCommitter:108 - File Output Committer Algorithm version is 1
2021-05-19 02:45:54 INFO  SQLHadoopMapReduceCommitProtocol:54 - Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
2021-05-19 02:45:54 INFO  CodeGenerator:54 - Code generated in 27.058332 ms
2021-05-19 02:45:54 INFO  ContextCleaner:54 - Cleaned accumulator 131
2021-05-19 02:45:54 INFO  ContextCleaner:54 - Cleaned accumulator 197
2021-05-19 02:45:54 INFO  ContextCleaner:54 - Cleaned accumulator 133
2021-05-19 02:45:54 INFO  ContextCleaner:54 - Cleaned accumulator 138
2021-05-19 02:45:54 INFO  ContextCleaner:54 - Cleaned accumulator 125
2021-05-19 02:45:54 INFO  ContextCleaner:54 - Cleaned accumulator 198
2021-05-19 02:45:54 INFO  ContextCleaner:54 - Cleaned accumulator 128
2021-05-19 02:45:54 INFO  CodeGenerator:54 - Code generated in 95.667636 ms
2021-05-19 02:45:54 INFO  ContextCleaner:54 - Cleaned accumulator 132
2021-05-19 02:45:54 INFO  ContextCleaner:54 - Cleaned accumulator 126
2021-05-19 02:45:54 INFO  ContextCleaner:54 - Cleaned accumulator 134
2021-05-19 02:45:54 INFO  ContextCleaner:54 - Cleaned accumulator 139
2021-05-19 02:45:54 INFO  ContextCleaner:54 - Cleaned accumulator 136
2021-05-19 02:45:54 INFO  CodeGenerator:54 - Code generated in 103.011015 ms
2021-05-19 02:45:54 INFO  ContextCleaner:54 - Cleaned shuffle 0
2021-05-19 02:45:54 INFO  ContextCleaner:54 - Cleaned accumulator 137
2021-05-19 02:45:54 INFO  ContextCleaner:54 - Cleaned accumulator 135
2021-05-19 02:45:54 INFO  ContextCleaner:54 - Cleaned accumulator 129
2021-05-19 02:45:54 INFO  ContextCleaner:54 - Cleaned accumulator 127
2021-05-19 02:45:54 INFO  ContextCleaner:54 - Cleaned accumulator 130
2021-05-19 02:45:54 INFO  SparkContext:54 - Starting job: run at ThreadPoolExecutor.java:1149
2021-05-19 02:45:54 INFO  DAGScheduler:54 - Got job 5 (run at ThreadPoolExecutor.java:1149) with 8 output partitions
2021-05-19 02:45:54 INFO  DAGScheduler:54 - Final stage: ResultStage 6 (run at ThreadPoolExecutor.java:1149)
2021-05-19 02:45:54 INFO  DAGScheduler:54 - Parents of final stage: List()
2021-05-19 02:45:54 INFO  DAGScheduler:54 - Missing parents: List()
2021-05-19 02:45:54 INFO  DAGScheduler:54 - Submitting ResultStage 6 (MapPartitionsRDD[42] at run at ThreadPoolExecutor.java:1149), which has no missing parents
2021-05-19 02:45:54 INFO  MemoryStore:54 - Block broadcast_11 stored as values in memory (estimated size 29.9 KB, free 365.9 MB)
2021-05-19 02:45:54 INFO  MemoryStore:54 - Block broadcast_11_piece0 stored as bytes in memory (estimated size 14.1 KB, free 365.9 MB)
2021-05-19 02:45:54 INFO  CodeGenerator:54 - Code generated in 22.236095 ms
2021-05-19 02:45:54 INFO  BlockManagerInfo:54 - Added broadcast_11_piece0 in memory on hadoop05.cusp.nyu.edu:36982 (size: 14.1 KB, free: 366.3 MB)
2021-05-19 02:45:54 INFO  SparkContext:54 - Created broadcast 11 from broadcast at DAGScheduler.scala:1161
2021-05-19 02:45:54 INFO  DAGScheduler:54 - Submitting 8 missing tasks from ResultStage 6 (MapPartitionsRDD[42] at run at ThreadPoolExecutor.java:1149) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
2021-05-19 02:45:54 INFO  YarnClusterScheduler:54 - Adding task set 6.0 with 8 tasks
2021-05-19 02:45:54 INFO  TaskSetManager:54 - Starting task 0.0 in stage 6.0 (TID 309, hadoop08.cusp.nyu.edu, executor 5, partition 0, PROCESS_LOCAL, 8321 bytes)
2021-05-19 02:45:54 INFO  TaskSetManager:54 - Starting task 1.0 in stage 6.0 (TID 310, hadoop08.cusp.nyu.edu, executor 5, partition 1, PROCESS_LOCAL, 8321 bytes)
2021-05-19 02:45:54 INFO  TaskSetManager:54 - Starting task 2.0 in stage 6.0 (TID 311, hadoop08.cusp.nyu.edu, executor 5, partition 2, PROCESS_LOCAL, 8321 bytes)
2021-05-19 02:45:54 INFO  TaskSetManager:54 - Starting task 3.0 in stage 6.0 (TID 312, hadoop08.cusp.nyu.edu, executor 5, partition 3, PROCESS_LOCAL, 8321 bytes)
2021-05-19 02:45:54 INFO  TaskSetManager:54 - Starting task 4.0 in stage 6.0 (TID 313, hadoop08.cusp.nyu.edu, executor 5, partition 4, PROCESS_LOCAL, 8321 bytes)
2021-05-19 02:45:54 INFO  TaskSetManager:54 - Starting task 5.0 in stage 6.0 (TID 314, hadoop08.cusp.nyu.edu, executor 5, partition 5, PROCESS_LOCAL, 8321 bytes)
2021-05-19 02:45:54 INFO  TaskSetManager:54 - Starting task 6.0 in stage 6.0 (TID 315, hadoop08.cusp.nyu.edu, executor 5, partition 6, PROCESS_LOCAL, 8321 bytes)
2021-05-19 02:45:54 INFO  TaskSetManager:54 - Starting task 7.0 in stage 6.0 (TID 316, hadoop08.cusp.nyu.edu, executor 5, partition 7, PROCESS_LOCAL, 8321 bytes)
2021-05-19 02:45:54 INFO  CodeGenerator:54 - Code generated in 21.637712 ms
2021-05-19 02:45:54 INFO  BlockManagerInfo:54 - Added broadcast_11_piece0 in memory on hadoop08.cusp.nyu.edu:54817 (size: 14.1 KB, free: 365.6 MB)
2021-05-19 02:45:55 INFO  TaskSetManager:54 - Finished task 7.0 in stage 6.0 (TID 316) in 494 ms on hadoop08.cusp.nyu.edu (executor 5) (1/8)
2021-05-19 02:45:55 INFO  TaskSetManager:54 - Finished task 2.0 in stage 6.0 (TID 311) in 515 ms on hadoop08.cusp.nyu.edu (executor 5) (2/8)
2021-05-19 02:45:55 INFO  TaskSetManager:54 - Finished task 4.0 in stage 6.0 (TID 313) in 515 ms on hadoop08.cusp.nyu.edu (executor 5) (3/8)
2021-05-19 02:45:55 INFO  TaskSetManager:54 - Finished task 6.0 in stage 6.0 (TID 315) in 516 ms on hadoop08.cusp.nyu.edu (executor 5) (4/8)
2021-05-19 02:45:55 INFO  TaskSetManager:54 - Finished task 1.0 in stage 6.0 (TID 310) in 518 ms on hadoop08.cusp.nyu.edu (executor 5) (5/8)
2021-05-19 02:45:55 INFO  TaskSetManager:54 - Finished task 3.0 in stage 6.0 (TID 312) in 518 ms on hadoop08.cusp.nyu.edu (executor 5) (6/8)
2021-05-19 02:45:55 INFO  TaskSetManager:54 - Finished task 0.0 in stage 6.0 (TID 309) in 521 ms on hadoop08.cusp.nyu.edu (executor 5) (7/8)
2021-05-19 02:45:55 INFO  TaskSetManager:54 - Finished task 5.0 in stage 6.0 (TID 314) in 519 ms on hadoop08.cusp.nyu.edu (executor 5) (8/8)
2021-05-19 02:45:55 INFO  YarnClusterScheduler:54 - Removed TaskSet 6.0, whose tasks have all completed, from pool 
2021-05-19 02:45:55 INFO  DAGScheduler:54 - ResultStage 6 (run at ThreadPoolExecutor.java:1149) finished in 0.543 s
2021-05-19 02:45:55 INFO  DAGScheduler:54 - Job 5 finished: run at ThreadPoolExecutor.java:1149, took 0.552071 s
2021-05-19 02:45:55 INFO  CodeGenerator:54 - Code generated in 14.407144 ms
2021-05-19 02:45:55 INFO  MemoryStore:54 - Block broadcast_12 stored as values in memory (estimated size 4.0 MB, free 361.9 MB)
2021-05-19 02:45:55 INFO  MemoryStore:54 - Block broadcast_12_piece0 stored as bytes in memory (estimated size 580.1 KB, free 361.3 MB)
2021-05-19 02:45:55 INFO  BlockManagerInfo:54 - Added broadcast_12_piece0 in memory on hadoop05.cusp.nyu.edu:36982 (size: 580.1 KB, free: 365.7 MB)
2021-05-19 02:45:55 INFO  SparkContext:54 - Created broadcast 12 from run at ThreadPoolExecutor.java:1149
2021-05-19 02:45:55 INFO  CodeGenerator:54 - Code generated in 32.803928 ms
2021-05-19 02:45:55 INFO  MemoryStore:54 - Block broadcast_13 stored as values in memory (estimated size 332.8 KB, free 361.0 MB)
2021-05-19 02:45:55 INFO  MemoryStore:54 - Block broadcast_13_piece0 stored as bytes in memory (estimated size 33.4 KB, free 361.0 MB)
2021-05-19 02:45:55 INFO  BlockManagerInfo:54 - Added broadcast_13_piece0 in memory on hadoop05.cusp.nyu.edu:36982 (size: 33.4 KB, free: 365.7 MB)
2021-05-19 02:45:55 INFO  SparkContext:54 - Created broadcast 13 from csv at NativeMethodAccessorImpl.java:0
2021-05-19 02:45:55 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 134217728 bytes, open cost is considered as scanning 4194304 bytes.
2021-05-19 02:45:55 INFO  CodeGenerator:54 - Code generated in 21.774795 ms
2021-05-19 02:45:55 INFO  SparkContext:54 - Starting job: csv at NativeMethodAccessorImpl.java:0
2021-05-19 02:45:55 INFO  DAGScheduler:54 - Registering RDD 50 (csv at NativeMethodAccessorImpl.java:0)
2021-05-19 02:45:55 INFO  DAGScheduler:54 - Got job 6 (csv at NativeMethodAccessorImpl.java:0) with 200 output partitions
2021-05-19 02:45:55 INFO  DAGScheduler:54 - Final stage: ResultStage 8 (csv at NativeMethodAccessorImpl.java:0)
2021-05-19 02:45:55 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 7)
2021-05-19 02:45:55 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 7)
2021-05-19 02:45:55 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 7 (MapPartitionsRDD[50] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
2021-05-19 02:45:55 INFO  MemoryStore:54 - Block broadcast_14 stored as values in memory (estimated size 51.5 KB, free 360.9 MB)
2021-05-19 02:45:55 INFO  MemoryStore:54 - Block broadcast_14_piece0 stored as bytes in memory (estimated size 22.9 KB, free 360.9 MB)
2021-05-19 02:45:55 INFO  BlockManagerInfo:54 - Added broadcast_14_piece0 in memory on hadoop05.cusp.nyu.edu:36982 (size: 22.9 KB, free: 365.6 MB)
2021-05-19 02:45:55 INFO  SparkContext:54 - Created broadcast 14 from broadcast at DAGScheduler.scala:1161
2021-05-19 02:45:55 INFO  DAGScheduler:54 - Submitting 70 missing tasks from ShuffleMapStage 7 (MapPartitionsRDD[50] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
2021-05-19 02:45:55 INFO  YarnClusterScheduler:54 - Adding task set 7.0 with 70 tasks
2021-05-19 02:45:56 INFO  TaskSetManager:54 - Starting task 10.0 in stage 7.0 (TID 317, hadoop20.cusp.nyu.edu, executor 4, partition 10, NODE_LOCAL, 8331 bytes)
2021-05-19 02:45:56 INFO  TaskSetManager:54 - Starting task 19.0 in stage 7.0 (TID 318, hadoop09.cusp.nyu.edu, executor 1, partition 19, NODE_LOCAL, 8331 bytes)
2021-05-19 02:45:56 INFO  TaskSetManager:54 - Starting task 7.0 in stage 7.0 (TID 319, hadoop08.cusp.nyu.edu, executor 5, partition 7, NODE_LOCAL, 8331 bytes)
2021-05-19 02:45:56 INFO  TaskSetManager:54 - Starting task 0.0 in stage 7.0 (TID 320, hadoop07.cusp.nyu.edu, executor 3, partition 0, NODE_LOCAL, 8331 bytes)
2021-05-19 02:45:56 INFO  TaskSetManager:54 - Starting task 1.0 in stage 7.0 (TID 321, hadoop10.cusp.nyu.edu, executor 2, partition 1, NODE_LOCAL, 8331 bytes)
2021-05-19 02:45:56 INFO  TaskSetManager:54 - Starting task 18.0 in stage 7.0 (TID 322, hadoop20.cusp.nyu.edu, executor 4, partition 18, NODE_LOCAL, 8331 bytes)
2021-05-19 02:45:56 INFO  TaskSetManager:54 - Starting task 21.0 in stage 7.0 (TID 323, hadoop09.cusp.nyu.edu, executor 1, partition 21, NODE_LOCAL, 8331 bytes)
2021-05-19 02:45:56 INFO  TaskSetManager:54 - Starting task 12.0 in stage 7.0 (TID 324, hadoop08.cusp.nyu.edu, executor 5, partition 12, NODE_LOCAL, 8331 bytes)
2021-05-19 02:45:56 INFO  TaskSetManager:54 - Starting task 5.0 in stage 7.0 (TID 325, hadoop07.cusp.nyu.edu, executor 3, partition 5, NODE_LOCAL, 8331 bytes)
2021-05-19 02:45:56 INFO  TaskSetManager:54 - Starting task 3.0 in stage 7.0 (TID 326, hadoop10.cusp.nyu.edu, executor 2, partition 3, NODE_LOCAL, 8331 bytes)
2021-05-19 02:45:56 INFO  TaskSetManager:54 - Starting task 31.0 in stage 7.0 (TID 327, hadoop20.cusp.nyu.edu, executor 4, partition 31, NODE_LOCAL, 8331 bytes)
2021-05-19 02:45:56 INFO  TaskSetManager:54 - Starting task 27.0 in stage 7.0 (TID 328, hadoop09.cusp.nyu.edu, executor 1, partition 27, NODE_LOCAL, 8331 bytes)
2021-05-19 02:45:56 INFO  TaskSetManager:54 - Starting task 25.0 in stage 7.0 (TID 329, hadoop08.cusp.nyu.edu, executor 5, partition 25, NODE_LOCAL, 8331 bytes)
2021-05-19 02:45:56 INFO  TaskSetManager:54 - Starting task 22.0 in stage 7.0 (TID 330, hadoop07.cusp.nyu.edu, executor 3, partition 22, NODE_LOCAL, 8331 bytes)
2021-05-19 02:45:56 INFO  TaskSetManager:54 - Starting task 4.0 in stage 7.0 (TID 331, hadoop10.cusp.nyu.edu, executor 2, partition 4, NODE_LOCAL, 8331 bytes)
2021-05-19 02:45:56 INFO  TaskSetManager:54 - Starting task 45.0 in stage 7.0 (TID 332, hadoop20.cusp.nyu.edu, executor 4, partition 45, NODE_LOCAL, 8331 bytes)
2021-05-19 02:45:56 INFO  TaskSetManager:54 - Starting task 28.0 in stage 7.0 (TID 333, hadoop09.cusp.nyu.edu, executor 1, partition 28, NODE_LOCAL, 8331 bytes)
2021-05-19 02:45:56 INFO  TaskSetManager:54 - Starting task 36.0 in stage 7.0 (TID 334, hadoop08.cusp.nyu.edu, executor 5, partition 36, NODE_LOCAL, 8331 bytes)
2021-05-19 02:45:56 INFO  TaskSetManager:54 - Starting task 23.0 in stage 7.0 (TID 335, hadoop07.cusp.nyu.edu, executor 3, partition 23, NODE_LOCAL, 8331 bytes)
2021-05-19 02:45:56 INFO  TaskSetManager:54 - Starting task 9.0 in stage 7.0 (TID 336, hadoop10.cusp.nyu.edu, executor 2, partition 9, NODE_LOCAL, 8331 bytes)
2021-05-19 02:45:56 INFO  TaskSetManager:54 - Starting task 46.0 in stage 7.0 (TID 337, hadoop20.cusp.nyu.edu, executor 4, partition 46, NODE_LOCAL, 8331 bytes)
2021-05-19 02:45:56 INFO  TaskSetManager:54 - Starting task 30.0 in stage 7.0 (TID 338, hadoop09.cusp.nyu.edu, executor 1, partition 30, NODE_LOCAL, 8331 bytes)
2021-05-19 02:45:56 INFO  TaskSetManager:54 - Starting task 39.0 in stage 7.0 (TID 339, hadoop08.cusp.nyu.edu, executor 5, partition 39, NODE_LOCAL, 8331 bytes)
2021-05-19 02:45:56 INFO  TaskSetManager:54 - Starting task 24.0 in stage 7.0 (TID 340, hadoop07.cusp.nyu.edu, executor 3, partition 24, NODE_LOCAL, 8331 bytes)
2021-05-19 02:45:56 INFO  TaskSetManager:54 - Starting task 14.0 in stage 7.0 (TID 341, hadoop10.cusp.nyu.edu, executor 2, partition 14, NODE_LOCAL, 8331 bytes)
2021-05-19 02:45:56 INFO  TaskSetManager:54 - Starting task 50.0 in stage 7.0 (TID 342, hadoop20.cusp.nyu.edu, executor 4, partition 50, NODE_LOCAL, 8436 bytes)
2021-05-19 02:45:56 INFO  TaskSetManager:54 - Starting task 44.0 in stage 7.0 (TID 343, hadoop09.cusp.nyu.edu, executor 1, partition 44, NODE_LOCAL, 8331 bytes)
2021-05-19 02:45:56 INFO  TaskSetManager:54 - Starting task 43.0 in stage 7.0 (TID 344, hadoop08.cusp.nyu.edu, executor 5, partition 43, NODE_LOCAL, 8331 bytes)
2021-05-19 02:45:56 INFO  TaskSetManager:54 - Starting task 34.0 in stage 7.0 (TID 345, hadoop07.cusp.nyu.edu, executor 3, partition 34, NODE_LOCAL, 8331 bytes)
2021-05-19 02:45:56 INFO  TaskSetManager:54 - Starting task 20.0 in stage 7.0 (TID 346, hadoop10.cusp.nyu.edu, executor 2, partition 20, NODE_LOCAL, 8331 bytes)
2021-05-19 02:45:56 INFO  TaskSetManager:54 - Starting task 53.0 in stage 7.0 (TID 347, hadoop20.cusp.nyu.edu, executor 4, partition 53, NODE_LOCAL, 8436 bytes)
2021-05-19 02:45:56 INFO  TaskSetManager:54 - Starting task 57.0 in stage 7.0 (TID 348, hadoop09.cusp.nyu.edu, executor 1, partition 57, NODE_LOCAL, 8436 bytes)
2021-05-19 02:45:56 INFO  TaskSetManager:54 - Starting task 51.0 in stage 7.0 (TID 349, hadoop08.cusp.nyu.edu, executor 5, partition 51, NODE_LOCAL, 8436 bytes)
2021-05-19 02:45:56 INFO  TaskSetManager:54 - Starting task 37.0 in stage 7.0 (TID 350, hadoop07.cusp.nyu.edu, executor 3, partition 37, NODE_LOCAL, 8331 bytes)
2021-05-19 02:45:56 INFO  TaskSetManager:54 - Starting task 29.0 in stage 7.0 (TID 351, hadoop10.cusp.nyu.edu, executor 2, partition 29, NODE_LOCAL, 8331 bytes)
2021-05-19 02:45:56 INFO  TaskSetManager:54 - Starting task 60.0 in stage 7.0 (TID 352, hadoop20.cusp.nyu.edu, executor 4, partition 60, NODE_LOCAL, 8436 bytes)
2021-05-19 02:45:56 INFO  TaskSetManager:54 - Starting task 59.0 in stage 7.0 (TID 353, hadoop09.cusp.nyu.edu, executor 1, partition 59, NODE_LOCAL, 8436 bytes)
2021-05-19 02:45:56 INFO  TaskSetManager:54 - Starting task 56.0 in stage 7.0 (TID 354, hadoop08.cusp.nyu.edu, executor 5, partition 56, NODE_LOCAL, 8436 bytes)
2021-05-19 02:45:56 INFO  TaskSetManager:54 - Starting task 38.0 in stage 7.0 (TID 355, hadoop07.cusp.nyu.edu, executor 3, partition 38, NODE_LOCAL, 8331 bytes)
2021-05-19 02:45:56 INFO  TaskSetManager:54 - Starting task 40.0 in stage 7.0 (TID 356, hadoop10.cusp.nyu.edu, executor 2, partition 40, NODE_LOCAL, 8331 bytes)
2021-05-19 02:45:56 INFO  TaskSetManager:54 - Starting task 65.0 in stage 7.0 (TID 357, hadoop20.cusp.nyu.edu, executor 4, partition 65, NODE_LOCAL, 8541 bytes)
2021-05-19 02:45:56 INFO  TaskSetManager:54 - Starting task 62.0 in stage 7.0 (TID 358, hadoop09.cusp.nyu.edu, executor 1, partition 62, NODE_LOCAL, 8436 bytes)
2021-05-19 02:45:56 INFO  TaskSetManager:54 - Starting task 58.0 in stage 7.0 (TID 359, hadoop08.cusp.nyu.edu, executor 5, partition 58, NODE_LOCAL, 8436 bytes)
2021-05-19 02:45:56 INFO  TaskSetManager:54 - Starting task 41.0 in stage 7.0 (TID 360, hadoop07.cusp.nyu.edu, executor 3, partition 41, NODE_LOCAL, 8331 bytes)
2021-05-19 02:45:56 INFO  TaskSetManager:54 - Starting task 54.0 in stage 7.0 (TID 361, hadoop10.cusp.nyu.edu, executor 2, partition 54, NODE_LOCAL, 8436 bytes)
2021-05-19 02:45:56 INFO  TaskSetManager:54 - Starting task 66.0 in stage 7.0 (TID 362, hadoop09.cusp.nyu.edu, executor 1, partition 66, NODE_LOCAL, 8541 bytes)
2021-05-19 02:45:56 INFO  TaskSetManager:54 - Starting task 69.0 in stage 7.0 (TID 363, hadoop08.cusp.nyu.edu, executor 5, partition 69, NODE_LOCAL, 8541 bytes)
2021-05-19 02:45:56 INFO  TaskSetManager:54 - Starting task 42.0 in stage 7.0 (TID 364, hadoop07.cusp.nyu.edu, executor 3, partition 42, NODE_LOCAL, 8331 bytes)
2021-05-19 02:45:56 INFO  TaskSetManager:54 - Starting task 55.0 in stage 7.0 (TID 365, hadoop10.cusp.nyu.edu, executor 2, partition 55, NODE_LOCAL, 8436 bytes)
2021-05-19 02:45:56 INFO  BlockManagerInfo:54 - Added broadcast_14_piece0 in memory on hadoop08.cusp.nyu.edu:54817 (size: 22.9 KB, free: 365.6 MB)
2021-05-19 02:45:56 INFO  BlockManagerInfo:54 - Added broadcast_14_piece0 in memory on hadoop07.cusp.nyu.edu:57060 (size: 22.9 KB, free: 366.3 MB)
2021-05-19 02:45:56 INFO  BlockManagerInfo:54 - Added broadcast_14_piece0 in memory on hadoop20.cusp.nyu.edu:55825 (size: 22.9 KB, free: 366.3 MB)
2021-05-19 02:45:56 INFO  BlockManagerInfo:54 - Added broadcast_14_piece0 in memory on hadoop10.cusp.nyu.edu:51710 (size: 22.9 KB, free: 366.3 MB)
2021-05-19 02:45:56 INFO  BlockManagerInfo:54 - Added broadcast_14_piece0 in memory on hadoop09.cusp.nyu.edu:44190 (size: 22.9 KB, free: 366.3 MB)
2021-05-19 02:45:56 INFO  BlockManagerInfo:54 - Added broadcast_12_piece0 in memory on hadoop08.cusp.nyu.edu:54817 (size: 580.1 KB, free: 365.0 MB)
2021-05-19 02:45:56 INFO  BlockManagerInfo:54 - Added broadcast_12_piece0 in memory on hadoop07.cusp.nyu.edu:57060 (size: 580.1 KB, free: 365.7 MB)
2021-05-19 02:45:56 INFO  BlockManagerInfo:54 - Added broadcast_12_piece0 in memory on hadoop20.cusp.nyu.edu:55825 (size: 580.1 KB, free: 365.7 MB)
2021-05-19 02:45:56 INFO  BlockManagerInfo:54 - Added broadcast_12_piece0 in memory on hadoop10.cusp.nyu.edu:51710 (size: 580.1 KB, free: 365.7 MB)
2021-05-19 02:45:56 INFO  BlockManagerInfo:54 - Added broadcast_12_piece0 in memory on hadoop09.cusp.nyu.edu:44190 (size: 580.1 KB, free: 365.7 MB)
2021-05-19 02:45:56 INFO  BlockManagerInfo:54 - Added broadcast_13_piece0 in memory on hadoop08.cusp.nyu.edu:54817 (size: 33.4 KB, free: 365.0 MB)
2021-05-19 02:45:57 INFO  BlockManagerInfo:54 - Added broadcast_13_piece0 in memory on hadoop07.cusp.nyu.edu:57060 (size: 33.4 KB, free: 365.7 MB)
2021-05-19 02:45:57 INFO  BlockManagerInfo:54 - Added broadcast_13_piece0 in memory on hadoop10.cusp.nyu.edu:51710 (size: 33.4 KB, free: 365.7 MB)
2021-05-19 02:45:57 INFO  BlockManagerInfo:54 - Added broadcast_13_piece0 in memory on hadoop20.cusp.nyu.edu:55825 (size: 33.4 KB, free: 365.7 MB)
2021-05-19 02:45:57 INFO  BlockManagerInfo:54 - Added broadcast_13_piece0 in memory on hadoop09.cusp.nyu.edu:44190 (size: 33.4 KB, free: 365.7 MB)
2021-05-19 02:45:59 INFO  TaskSetManager:54 - Starting task 2.0 in stage 7.0 (TID 366, hadoop20.cusp.nyu.edu, executor 4, partition 2, RACK_LOCAL, 8331 bytes)
2021-05-19 02:46:05 INFO  ContextCleaner:54 - Cleaned accumulator 222
2021-05-19 02:46:05 INFO  ContextCleaner:54 - Cleaned accumulator 231
2021-05-19 02:46:05 INFO  ContextCleaner:54 - Cleaned accumulator 232
2021-05-19 02:46:05 INFO  ContextCleaner:54 - Cleaned accumulator 241
2021-05-19 02:46:05 INFO  ContextCleaner:54 - Cleaned accumulator 224
2021-05-19 02:46:05 INFO  ContextCleaner:54 - Cleaned accumulator 220
2021-05-19 02:46:05 INFO  ContextCleaner:54 - Cleaned accumulator 233
2021-05-19 02:46:05 INFO  ContextCleaner:54 - Cleaned accumulator 238
2021-05-19 02:46:05 INFO  ContextCleaner:54 - Cleaned accumulator 229
2021-05-19 02:46:05 INFO  ContextCleaner:54 - Cleaned accumulator 219
2021-05-19 02:46:05 INFO  ContextCleaner:54 - Cleaned accumulator 235
2021-05-19 02:46:05 INFO  ContextCleaner:54 - Cleaned accumulator 234
2021-05-19 02:46:05 INFO  ContextCleaner:54 - Cleaned accumulator 223
2021-05-19 02:46:05 INFO  ContextCleaner:54 - Cleaned accumulator 236
2021-05-19 02:46:05 INFO  ContextCleaner:54 - Cleaned accumulator 218
2021-05-19 02:46:05 INFO  ContextCleaner:54 - Cleaned accumulator 221
2021-05-19 02:46:05 INFO  BlockManagerInfo:54 - Removed broadcast_11_piece0 on hadoop05.cusp.nyu.edu:36982 in memory (size: 14.1 KB, free: 365.6 MB)
2021-05-19 02:46:05 INFO  BlockManagerInfo:54 - Removed broadcast_11_piece0 on hadoop08.cusp.nyu.edu:54817 in memory (size: 14.1 KB, free: 365.0 MB)
2021-05-19 02:46:05 INFO  ContextCleaner:54 - Cleaned accumulator 227
2021-05-19 02:46:05 INFO  ContextCleaner:54 - Cleaned accumulator 240
2021-05-19 02:46:05 INFO  ContextCleaner:54 - Cleaned accumulator 242
2021-05-19 02:46:05 INFO  ContextCleaner:54 - Cleaned accumulator 239
2021-05-19 02:46:05 INFO  ContextCleaner:54 - Cleaned accumulator 228
2021-05-19 02:46:05 INFO  ContextCleaner:54 - Cleaned accumulator 237
2021-05-19 02:46:05 INFO  ContextCleaner:54 - Cleaned accumulator 226
2021-05-19 02:46:05 INFO  ContextCleaner:54 - Cleaned accumulator 230
2021-05-19 02:46:05 INFO  ContextCleaner:54 - Cleaned accumulator 225
2021-05-19 02:46:07 INFO  TaskSetManager:54 - Starting task 6.0 in stage 7.0 (TID 367, hadoop08.cusp.nyu.edu, executor 5, partition 6, RACK_LOCAL, 8331 bytes)
2021-05-19 02:46:07 INFO  TaskSetManager:54 - Finished task 58.0 in stage 7.0 (TID 359) in 10990 ms on hadoop08.cusp.nyu.edu (executor 5) (1/70)
2021-05-19 02:46:07 INFO  TaskSetManager:54 - Starting task 8.0 in stage 7.0 (TID 368, hadoop08.cusp.nyu.edu, executor 5, partition 8, RACK_LOCAL, 8331 bytes)
2021-05-19 02:46:07 INFO  TaskSetManager:54 - Finished task 51.0 in stage 7.0 (TID 349) in 10996 ms on hadoop08.cusp.nyu.edu (executor 5) (2/70)
2021-05-19 02:46:07 INFO  TaskSetManager:54 - Starting task 11.0 in stage 7.0 (TID 369, hadoop08.cusp.nyu.edu, executor 5, partition 11, RACK_LOCAL, 8331 bytes)
2021-05-19 02:46:07 INFO  TaskSetManager:54 - Finished task 56.0 in stage 7.0 (TID 354) in 10998 ms on hadoop08.cusp.nyu.edu (executor 5) (3/70)
2021-05-19 02:46:07 INFO  TaskSetManager:54 - Starting task 13.0 in stage 7.0 (TID 370, hadoop09.cusp.nyu.edu, executor 1, partition 13, RACK_LOCAL, 8331 bytes)
2021-05-19 02:46:07 INFO  TaskSetManager:54 - Finished task 62.0 in stage 7.0 (TID 358) in 11382 ms on hadoop09.cusp.nyu.edu (executor 1) (4/70)
2021-05-19 02:46:07 INFO  YarnAllocator:54 - Completed container container_e10_1609183734776_5900_01_000005 on host: hadoop20.cusp.nyu.edu (state: COMPLETE, exit status: -104)
2021-05-19 02:46:07 WARN  YarnAllocator:66 - Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:46:07 WARN  YarnSchedulerBackend$YarnSchedulerEndpoint:66 - Requesting driver to remove executor 4 for reason Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:46:07 ERROR YarnClusterScheduler:70 - Lost executor 4 on hadoop20.cusp.nyu.edu: Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:46:07 WARN  TaskSetManager:66 - Lost task 18.0 in stage 7.0 (TID 322, hadoop20.cusp.nyu.edu, executor 4): ExecutorLostFailure (executor 4 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:46:07 WARN  TaskSetManager:66 - Lost task 60.0 in stage 7.0 (TID 352, hadoop20.cusp.nyu.edu, executor 4): ExecutorLostFailure (executor 4 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:46:07 WARN  TaskSetManager:66 - Lost task 46.0 in stage 7.0 (TID 337, hadoop20.cusp.nyu.edu, executor 4): ExecutorLostFailure (executor 4 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:46:07 WARN  TaskSetManager:66 - Lost task 31.0 in stage 7.0 (TID 327, hadoop20.cusp.nyu.edu, executor 4): ExecutorLostFailure (executor 4 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:46:07 WARN  TaskSetManager:66 - Lost task 65.0 in stage 7.0 (TID 357, hadoop20.cusp.nyu.edu, executor 4): ExecutorLostFailure (executor 4 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:46:07 WARN  TaskSetManager:66 - Lost task 2.0 in stage 7.0 (TID 366, hadoop20.cusp.nyu.edu, executor 4): ExecutorLostFailure (executor 4 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:46:07 WARN  TaskSetManager:66 - Lost task 50.0 in stage 7.0 (TID 342, hadoop20.cusp.nyu.edu, executor 4): ExecutorLostFailure (executor 4 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:46:07 WARN  TaskSetManager:66 - Lost task 45.0 in stage 7.0 (TID 332, hadoop20.cusp.nyu.edu, executor 4): ExecutorLostFailure (executor 4 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:46:07 WARN  TaskSetManager:66 - Lost task 10.0 in stage 7.0 (TID 317, hadoop20.cusp.nyu.edu, executor 4): ExecutorLostFailure (executor 4 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:46:07 WARN  TaskSetManager:66 - Lost task 53.0 in stage 7.0 (TID 347, hadoop20.cusp.nyu.edu, executor 4): ExecutorLostFailure (executor 4 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:46:07 INFO  DAGScheduler:54 - Executor lost: 4 (epoch 1)
2021-05-19 02:46:07 INFO  BlockManagerMasterEndpoint:54 - Trying to remove executor 4 from BlockManagerMaster.
2021-05-19 02:46:07 INFO  BlockManagerMasterEndpoint:54 - Removing block manager BlockManagerId(4, hadoop20.cusp.nyu.edu, 55825, None)
2021-05-19 02:46:07 INFO  BlockManagerMaster:54 - Removed 4 successfully in removeExecutor
2021-05-19 02:46:07 INFO  TaskSetManager:54 - Starting task 46.1 in stage 7.0 (TID 371, hadoop10.cusp.nyu.edu, executor 2, partition 46, NODE_LOCAL, 8331 bytes)
2021-05-19 02:46:07 INFO  TaskSetManager:54 - Finished task 54.0 in stage 7.0 (TID 361) in 11819 ms on hadoop10.cusp.nyu.edu (executor 2) (5/70)
2021-05-19 02:46:08 INFO  TaskSetManager:54 - Starting task 53.1 in stage 7.0 (TID 372, hadoop08.cusp.nyu.edu, executor 5, partition 53, NODE_LOCAL, 8436 bytes)
2021-05-19 02:46:08 INFO  TaskSetManager:54 - Finished task 7.0 in stage 7.0 (TID 319) in 12091 ms on hadoop08.cusp.nyu.edu (executor 5) (6/70)
2021-05-19 02:46:08 INFO  TaskSetManager:54 - Starting task 64.0 in stage 7.0 (TID 373, hadoop10.cusp.nyu.edu, executor 2, partition 64, NODE_LOCAL, 8541 bytes)
2021-05-19 02:46:08 INFO  TaskSetManager:54 - Finished task 55.0 in stage 7.0 (TID 365) in 12190 ms on hadoop10.cusp.nyu.edu (executor 2) (7/70)
2021-05-19 02:46:08 INFO  TaskSetManager:54 - Starting task 10.1 in stage 7.0 (TID 374, hadoop09.cusp.nyu.edu, executor 1, partition 10, NODE_LOCAL, 8331 bytes)
2021-05-19 02:46:08 INFO  TaskSetManager:54 - Finished task 59.0 in stage 7.0 (TID 353) in 12204 ms on hadoop09.cusp.nyu.edu (executor 1) (8/70)
2021-05-19 02:46:08 INFO  TaskSetManager:54 - Starting task 50.1 in stage 7.0 (TID 375, hadoop09.cusp.nyu.edu, executor 1, partition 50, NODE_LOCAL, 8436 bytes)
2021-05-19 02:46:08 INFO  TaskSetManager:54 - Finished task 57.0 in stage 7.0 (TID 348) in 12215 ms on hadoop09.cusp.nyu.edu (executor 1) (9/70)
2021-05-19 02:46:08 INFO  TaskSetManager:54 - Finished task 25.0 in stage 7.0 (TID 329) in 12237 ms on hadoop08.cusp.nyu.edu (executor 5) (10/70)
2021-05-19 02:46:09 INFO  YarnSchedulerBackend$YarnDriverEndpoint:54 - Disabling executor 5.
2021-05-19 02:46:09 INFO  DAGScheduler:54 - Executor lost: 5 (epoch 1)
2021-05-19 02:46:09 INFO  BlockManagerMasterEndpoint:54 - Trying to remove executor 5 from BlockManagerMaster.
2021-05-19 02:46:09 WARN  BlockManagerMasterEndpoint:66 - No more replicas available for rdd_29_2 !
2021-05-19 02:46:09 WARN  BlockManagerMasterEndpoint:66 - No more replicas available for rdd_29_4 !
2021-05-19 02:46:09 WARN  BlockManagerMasterEndpoint:66 - No more replicas available for rdd_29_1 !
2021-05-19 02:46:09 WARN  BlockManagerMasterEndpoint:66 - No more replicas available for rdd_29_0 !
2021-05-19 02:46:09 WARN  BlockManagerMasterEndpoint:66 - No more replicas available for rdd_29_3 !
2021-05-19 02:46:09 WARN  BlockManagerMasterEndpoint:66 - No more replicas available for rdd_29_5 !
2021-05-19 02:46:09 WARN  BlockManagerMasterEndpoint:66 - No more replicas available for rdd_29_6 !
2021-05-19 02:46:09 WARN  BlockManagerMasterEndpoint:66 - No more replicas available for rdd_29_7 !
2021-05-19 02:46:09 INFO  BlockManagerMasterEndpoint:54 - Removing block manager BlockManagerId(5, hadoop08.cusp.nyu.edu, 54817, None)
2021-05-19 02:46:09 INFO  BlockManagerMaster:54 - Removed 5 successfully in removeExecutor
2021-05-19 02:46:09 INFO  YarnAllocator:54 - Will request 1 executor container(s), each with 10 core(s) and 1408 MB memory (including 384 MB of overhead)
2021-05-19 02:46:09 INFO  YarnAllocator:54 - Submitted 1 unlocalized container requests.
2021-05-19 02:46:09 INFO  YarnAllocator:54 - Completed container container_e10_1609183734776_5900_01_000006 on host: hadoop08.cusp.nyu.edu (state: COMPLETE, exit status: -104)
2021-05-19 02:46:09 WARN  YarnAllocator:66 - Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:46:09 WARN  YarnSchedulerBackend$YarnSchedulerEndpoint:66 - Requesting driver to remove executor 5 for reason Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:46:09 ERROR YarnClusterScheduler:70 - Lost executor 5 on hadoop08.cusp.nyu.edu: Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:46:09 WARN  TaskSetManager:66 - Lost task 6.0 in stage 7.0 (TID 367, hadoop08.cusp.nyu.edu, executor 5): ExecutorLostFailure (executor 5 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:46:09 WARN  TaskSetManager:66 - Lost task 36.0 in stage 7.0 (TID 334, hadoop08.cusp.nyu.edu, executor 5): ExecutorLostFailure (executor 5 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:46:09 WARN  TaskSetManager:66 - Lost task 11.0 in stage 7.0 (TID 369, hadoop08.cusp.nyu.edu, executor 5): ExecutorLostFailure (executor 5 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:46:09 WARN  TaskSetManager:66 - Lost task 53.1 in stage 7.0 (TID 372, hadoop08.cusp.nyu.edu, executor 5): ExecutorLostFailure (executor 5 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:46:09 WARN  TaskSetManager:66 - Lost task 69.0 in stage 7.0 (TID 363, hadoop08.cusp.nyu.edu, executor 5): ExecutorLostFailure (executor 5 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:46:09 WARN  TaskSetManager:66 - Lost task 39.0 in stage 7.0 (TID 339, hadoop08.cusp.nyu.edu, executor 5): ExecutorLostFailure (executor 5 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:46:09 WARN  TaskSetManager:66 - Lost task 12.0 in stage 7.0 (TID 324, hadoop08.cusp.nyu.edu, executor 5): ExecutorLostFailure (executor 5 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:46:09 WARN  TaskSetManager:66 - Lost task 8.0 in stage 7.0 (TID 368, hadoop08.cusp.nyu.edu, executor 5): ExecutorLostFailure (executor 5 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:46:09 WARN  TaskSetManager:66 - Lost task 43.0 in stage 7.0 (TID 344, hadoop08.cusp.nyu.edu, executor 5): ExecutorLostFailure (executor 5 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:46:09 INFO  BlockManagerMasterEndpoint:54 - Trying to remove executor 5 from BlockManagerMaster.
2021-05-19 02:46:09 INFO  BlockManagerMaster:54 - Removal of executor 5 requested
2021-05-19 02:46:09 INFO  YarnSchedulerBackend$YarnDriverEndpoint:54 - Asked to remove non-existent executor 5
2021-05-19 02:46:09 INFO  YarnAllocator:54 - Will request 1 executor container(s), each with 10 core(s) and 1408 MB memory (including 384 MB of overhead)
2021-05-19 02:46:09 INFO  YarnAllocator:54 - Submitted 1 unlocalized container requests.
2021-05-19 02:46:09 INFO  AMRMClientImpl:360 - Received new token for : hadoop02.cusp.nyu.edu:8041
2021-05-19 02:46:09 INFO  YarnAllocator:54 - Launching container container_e10_1609183734776_5900_01_000007 on host hadoop02.cusp.nyu.edu for executor with ID 6
2021-05-19 02:46:09 INFO  YarnAllocator:54 - Received 1 containers from YARN, launching executors on 1 of them.
2021-05-19 02:46:09 INFO  YarnAllocator:54 - Completed container container_e10_1609183734776_5900_01_000003 on host: hadoop10.cusp.nyu.edu (state: COMPLETE, exit status: -104)
2021-05-19 02:46:09 WARN  YarnAllocator:66 - Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:46:09 WARN  YarnSchedulerBackend$YarnSchedulerEndpoint:66 - Requesting driver to remove executor 2 for reason Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:46:09 INFO  ContainerManagementProtocolProxy:81 - yarn.client.max-cached-nodemanagers-proxies : 0
2021-05-19 02:46:09 ERROR YarnClusterScheduler:70 - Lost executor 2 on hadoop10.cusp.nyu.edu: Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:46:09 WARN  TaskSetManager:66 - Lost task 64.0 in stage 7.0 (TID 373, hadoop10.cusp.nyu.edu, executor 2): ExecutorLostFailure (executor 2 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:46:09 WARN  TaskSetManager:66 - Lost task 20.0 in stage 7.0 (TID 346, hadoop10.cusp.nyu.edu, executor 2): ExecutorLostFailure (executor 2 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:46:09 WARN  TaskSetManager:66 - Lost task 4.0 in stage 7.0 (TID 331, hadoop10.cusp.nyu.edu, executor 2): ExecutorLostFailure (executor 2 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:46:09 WARN  TaskSetManager:66 - Lost task 9.0 in stage 7.0 (TID 336, hadoop10.cusp.nyu.edu, executor 2): ExecutorLostFailure (executor 2 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:46:09 WARN  TaskSetManager:66 - Lost task 1.0 in stage 7.0 (TID 321, hadoop10.cusp.nyu.edu, executor 2): ExecutorLostFailure (executor 2 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:46:09 WARN  TaskSetManager:66 - Lost task 29.0 in stage 7.0 (TID 351, hadoop10.cusp.nyu.edu, executor 2): ExecutorLostFailure (executor 2 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:46:09 INFO  ContainerManagementProtocolProxy:260 - Opening proxy : hadoop02.cusp.nyu.edu:8041
2021-05-19 02:46:09 WARN  TaskSetManager:66 - Lost task 14.0 in stage 7.0 (TID 341, hadoop10.cusp.nyu.edu, executor 2): ExecutorLostFailure (executor 2 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:46:09 WARN  TaskSetManager:66 - Lost task 3.0 in stage 7.0 (TID 326, hadoop10.cusp.nyu.edu, executor 2): ExecutorLostFailure (executor 2 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:46:09 WARN  TaskSetManager:66 - Lost task 46.1 in stage 7.0 (TID 371, hadoop10.cusp.nyu.edu, executor 2): ExecutorLostFailure (executor 2 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:46:09 WARN  TaskSetManager:66 - Lost task 40.0 in stage 7.0 (TID 356, hadoop10.cusp.nyu.edu, executor 2): ExecutorLostFailure (executor 2 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:46:09 INFO  DAGScheduler:54 - Executor lost: 2 (epoch 1)
2021-05-19 02:46:09 INFO  BlockManagerMasterEndpoint:54 - Trying to remove executor 2 from BlockManagerMaster.
2021-05-19 02:46:09 INFO  BlockManagerMasterEndpoint:54 - Removing block manager BlockManagerId(2, hadoop10.cusp.nyu.edu, 51710, None)
2021-05-19 02:46:09 INFO  BlockManagerMaster:54 - Removed 2 successfully in removeExecutor
2021-05-19 02:46:09 WARN  TransportChannelHandler:78 - Exception in connection from /192.168.72.180:39670
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileDispatcherImpl.read0(Native Method)
	at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)
	at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:223)
	at sun.nio.ch.IOUtil.read(IOUtil.java:192)
	at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:380)
	at io.netty.buffer.PooledUnsafeDirectByteBuf.setBytes(PooledUnsafeDirectByteBuf.java:288)
	at io.netty.buffer.AbstractByteBuf.writeBytes(AbstractByteBuf.java:1106)
	at io.netty.channel.socket.nio.NioSocketChannel.doReadBytes(NioSocketChannel.java:343)
	at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:123)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:645)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:580)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:497)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:459)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
2021-05-19 02:46:09 INFO  TaskSetManager:54 - Starting task 60.1 in stage 7.0 (TID 376, hadoop09.cusp.nyu.edu, executor 1, partition 60, NODE_LOCAL, 8436 bytes)
2021-05-19 02:46:09 INFO  TaskSetManager:54 - Finished task 30.0 in stage 7.0 (TID 338) in 13474 ms on hadoop09.cusp.nyu.edu (executor 1) (11/70)
2021-05-19 02:46:09 INFO  YarnAllocator:54 - Will request 1 executor container(s), each with 10 core(s) and 1408 MB memory (including 384 MB of overhead)
2021-05-19 02:46:09 INFO  YarnAllocator:54 - Submitted 1 unlocalized container requests.
2021-05-19 02:46:09 INFO  YarnAllocator:54 - Launching container container_e10_1609183734776_5900_01_000008 on host hadoop07.cusp.nyu.edu for executor with ID 7
2021-05-19 02:46:09 INFO  YarnAllocator:54 - Received 1 containers from YARN, launching executors on 1 of them.
2021-05-19 02:46:09 INFO  YarnAllocator:54 - Completed container container_e10_1609183734776_5900_01_000004 on host: hadoop07.cusp.nyu.edu (state: COMPLETE, exit status: -104)
2021-05-19 02:46:09 WARN  YarnAllocator:66 - Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:46:09 WARN  YarnSchedulerBackend$YarnSchedulerEndpoint:66 - Requesting driver to remove executor 3 for reason Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:46:09 INFO  ContainerManagementProtocolProxy:81 - yarn.client.max-cached-nodemanagers-proxies : 0
2021-05-19 02:46:09 ERROR YarnClusterScheduler:70 - Lost executor 3 on hadoop07.cusp.nyu.edu: Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:46:09 WARN  TaskSetManager:66 - Lost task 42.0 in stage 7.0 (TID 364, hadoop07.cusp.nyu.edu, executor 3): ExecutorLostFailure (executor 3 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:46:09 WARN  TaskSetManager:66 - Lost task 38.0 in stage 7.0 (TID 355, hadoop07.cusp.nyu.edu, executor 3): ExecutorLostFailure (executor 3 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:46:09 WARN  TaskSetManager:66 - Lost task 24.0 in stage 7.0 (TID 340, hadoop07.cusp.nyu.edu, executor 3): ExecutorLostFailure (executor 3 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:46:09 WARN  TaskSetManager:66 - Lost task 5.0 in stage 7.0 (TID 325, hadoop07.cusp.nyu.edu, executor 3): ExecutorLostFailure (executor 3 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:46:09 WARN  TaskSetManager:66 - Lost task 41.0 in stage 7.0 (TID 360, hadoop07.cusp.nyu.edu, executor 3): ExecutorLostFailure (executor 3 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:46:09 WARN  TaskSetManager:66 - Lost task 34.0 in stage 7.0 (TID 345, hadoop07.cusp.nyu.edu, executor 3): ExecutorLostFailure (executor 3 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:46:09 WARN  TaskSetManager:66 - Lost task 22.0 in stage 7.0 (TID 330, hadoop07.cusp.nyu.edu, executor 3): ExecutorLostFailure (executor 3 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:46:09 INFO  ContainerManagementProtocolProxy:260 - Opening proxy : hadoop07.cusp.nyu.edu:8041
2021-05-19 02:46:09 WARN  TaskSetManager:66 - Lost task 37.0 in stage 7.0 (TID 350, hadoop07.cusp.nyu.edu, executor 3): ExecutorLostFailure (executor 3 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:46:09 WARN  TaskSetManager:66 - Lost task 23.0 in stage 7.0 (TID 335, hadoop07.cusp.nyu.edu, executor 3): ExecutorLostFailure (executor 3 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:46:09 WARN  TaskSetManager:66 - Lost task 0.0 in stage 7.0 (TID 320, hadoop07.cusp.nyu.edu, executor 3): ExecutorLostFailure (executor 3 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:46:09 INFO  DAGScheduler:54 - Executor lost: 3 (epoch 1)
2021-05-19 02:46:09 INFO  BlockManagerMasterEndpoint:54 - Trying to remove executor 3 from BlockManagerMaster.
2021-05-19 02:46:09 INFO  BlockManagerMasterEndpoint:54 - Removing block manager BlockManagerId(3, hadoop07.cusp.nyu.edu, 57060, None)
2021-05-19 02:46:09 INFO  BlockManagerMaster:54 - Removed 3 successfully in removeExecutor
2021-05-19 02:46:09 WARN  TransportChannelHandler:78 - Exception in connection from /192.168.72.177:37542
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileDispatcherImpl.read0(Native Method)
	at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)
	at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:223)
	at sun.nio.ch.IOUtil.read(IOUtil.java:192)
	at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:380)
	at io.netty.buffer.PooledUnsafeDirectByteBuf.setBytes(PooledUnsafeDirectByteBuf.java:288)
	at io.netty.buffer.AbstractByteBuf.writeBytes(AbstractByteBuf.java:1106)
	at io.netty.channel.socket.nio.NioSocketChannel.doReadBytes(NioSocketChannel.java:343)
	at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:123)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:645)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:580)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:497)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:459)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
2021-05-19 02:46:09 INFO  TaskSetManager:54 - Finished task 27.0 in stage 7.0 (TID 328) in 13652 ms on hadoop09.cusp.nyu.edu (executor 1) (12/70)
2021-05-19 02:46:10 INFO  YarnSchedulerBackend$YarnDriverEndpoint:54 - Disabling executor 1.
2021-05-19 02:46:10 INFO  DAGScheduler:54 - Executor lost: 1 (epoch 1)
2021-05-19 02:46:10 INFO  YarnAllocator:54 - Will request 1 executor container(s), each with 10 core(s) and 1408 MB memory (including 384 MB of overhead)
2021-05-19 02:46:10 INFO  BlockManagerMasterEndpoint:54 - Trying to remove executor 1 from BlockManagerMaster.
2021-05-19 02:46:10 INFO  BlockManagerMasterEndpoint:54 - Removing block manager BlockManagerId(1, hadoop09.cusp.nyu.edu, 44190, None)
2021-05-19 02:46:10 INFO  YarnAllocator:54 - Submitted 1 unlocalized container requests.
2021-05-19 02:46:10 INFO  BlockManagerMaster:54 - Removed 1 successfully in removeExecutor
2021-05-19 02:46:10 INFO  AMRMClientImpl:360 - Received new token for : hadoop18.cusp.nyu.edu:8041
2021-05-19 02:46:10 INFO  AMRMClientImpl:360 - Received new token for : hadoop13.cusp.nyu.edu:8041
2021-05-19 02:46:10 INFO  YarnAllocator:54 - Launching container container_e10_1609183734776_5900_01_000009 on host hadoop13.cusp.nyu.edu for executor with ID 8
2021-05-19 02:46:10 INFO  YarnAllocator:54 - Launching container container_e10_1609183734776_5900_01_000010 on host hadoop18.cusp.nyu.edu for executor with ID 9
2021-05-19 02:46:10 INFO  YarnAllocator:54 - Received 2 containers from YARN, launching executors on 2 of them.
2021-05-19 02:46:10 INFO  YarnAllocator:54 - Completed container container_e10_1609183734776_5900_01_000002 on host: hadoop09.cusp.nyu.edu (state: COMPLETE, exit status: -104)
2021-05-19 02:46:10 WARN  YarnAllocator:66 - Container killed by YARN for exceeding memory limits.  1.7 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:46:10 INFO  ContainerManagementProtocolProxy:81 - yarn.client.max-cached-nodemanagers-proxies : 0
2021-05-19 02:46:10 WARN  YarnSchedulerBackend$YarnSchedulerEndpoint:66 - Requesting driver to remove executor 1 for reason Container killed by YARN for exceeding memory limits.  1.7 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:46:10 ERROR YarnClusterScheduler:70 - Lost executor 1 on hadoop09.cusp.nyu.edu: Container killed by YARN for exceeding memory limits.  1.7 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:46:10 INFO  ContainerManagementProtocolProxy:81 - yarn.client.max-cached-nodemanagers-proxies : 0
2021-05-19 02:46:10 WARN  TaskSetManager:66 - Lost task 60.1 in stage 7.0 (TID 376, hadoop09.cusp.nyu.edu, executor 1): ExecutorLostFailure (executor 1 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  1.7 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:46:10 WARN  TaskSetManager:66 - Lost task 13.0 in stage 7.0 (TID 370, hadoop09.cusp.nyu.edu, executor 1): ExecutorLostFailure (executor 1 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  1.7 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:46:10 WARN  TaskSetManager:66 - Lost task 44.0 in stage 7.0 (TID 343, hadoop09.cusp.nyu.edu, executor 1): ExecutorLostFailure (executor 1 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  1.7 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:46:10 INFO  ContainerManagementProtocolProxy:260 - Opening proxy : hadoop13.cusp.nyu.edu:8041
2021-05-19 02:46:10 WARN  TaskSetManager:66 - Lost task 19.0 in stage 7.0 (TID 318, hadoop09.cusp.nyu.edu, executor 1): ExecutorLostFailure (executor 1 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  1.7 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:46:10 WARN  TaskSetManager:66 - Lost task 50.1 in stage 7.0 (TID 375, hadoop09.cusp.nyu.edu, executor 1): ExecutorLostFailure (executor 1 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  1.7 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:46:10 WARN  TaskSetManager:66 - Lost task 28.0 in stage 7.0 (TID 333, hadoop09.cusp.nyu.edu, executor 1): ExecutorLostFailure (executor 1 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  1.7 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:46:10 WARN  TaskSetManager:66 - Lost task 21.0 in stage 7.0 (TID 323, hadoop09.cusp.nyu.edu, executor 1): ExecutorLostFailure (executor 1 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  1.7 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:46:10 WARN  TaskSetManager:66 - Lost task 66.0 in stage 7.0 (TID 362, hadoop09.cusp.nyu.edu, executor 1): ExecutorLostFailure (executor 1 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  1.7 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:46:10 INFO  ContainerManagementProtocolProxy:260 - Opening proxy : hadoop18.cusp.nyu.edu:8041
2021-05-19 02:46:10 WARN  TaskSetManager:66 - Lost task 10.1 in stage 7.0 (TID 374, hadoop09.cusp.nyu.edu, executor 1): ExecutorLostFailure (executor 1 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  1.7 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:46:10 INFO  BlockManagerMaster:54 - Removal of executor 1 requested
2021-05-19 02:46:10 INFO  BlockManagerMasterEndpoint:54 - Trying to remove executor 1 from BlockManagerMaster.
2021-05-19 02:46:10 INFO  YarnSchedulerBackend$YarnDriverEndpoint:54 - Asked to remove non-existent executor 1
2021-05-19 02:46:13 INFO  YarnAllocator:54 - Will request 1 executor container(s), each with 10 core(s) and 1408 MB memory (including 384 MB of overhead)
2021-05-19 02:46:13 INFO  YarnAllocator:54 - Submitted 1 unlocalized container requests.
2021-05-19 02:46:13 INFO  AMRMClientImpl:360 - Received new token for : hadoop04.cusp.nyu.edu:8041
2021-05-19 02:46:13 INFO  YarnSchedulerBackend$YarnDriverEndpoint:54 - Registered executor NettyRpcEndpointRef(spark-client://Executor) (192.168.72.177:37617) with ID 7
2021-05-19 02:46:13 INFO  TaskSetManager:54 - Starting task 28.1 in stage 7.0 (TID 377, hadoop07.cusp.nyu.edu, executor 7, partition 28, NODE_LOCAL, 8331 bytes)
2021-05-19 02:46:13 INFO  TaskSetManager:54 - Starting task 0.1 in stage 7.0 (TID 378, hadoop07.cusp.nyu.edu, executor 7, partition 0, NODE_LOCAL, 8331 bytes)
2021-05-19 02:46:13 INFO  TaskSetManager:54 - Starting task 23.1 in stage 7.0 (TID 379, hadoop07.cusp.nyu.edu, executor 7, partition 23, NODE_LOCAL, 8331 bytes)
2021-05-19 02:46:13 INFO  TaskSetManager:54 - Starting task 37.1 in stage 7.0 (TID 380, hadoop07.cusp.nyu.edu, executor 7, partition 37, NODE_LOCAL, 8331 bytes)
2021-05-19 02:46:13 INFO  TaskSetManager:54 - Starting task 22.1 in stage 7.0 (TID 381, hadoop07.cusp.nyu.edu, executor 7, partition 22, NODE_LOCAL, 8331 bytes)
2021-05-19 02:46:13 INFO  TaskSetManager:54 - Starting task 34.1 in stage 7.0 (TID 382, hadoop07.cusp.nyu.edu, executor 7, partition 34, NODE_LOCAL, 8331 bytes)
2021-05-19 02:46:13 INFO  TaskSetManager:54 - Starting task 41.1 in stage 7.0 (TID 383, hadoop07.cusp.nyu.edu, executor 7, partition 41, NODE_LOCAL, 8331 bytes)
2021-05-19 02:46:13 INFO  TaskSetManager:54 - Starting task 5.1 in stage 7.0 (TID 384, hadoop07.cusp.nyu.edu, executor 7, partition 5, NODE_LOCAL, 8331 bytes)
2021-05-19 02:46:13 INFO  TaskSetManager:54 - Starting task 24.1 in stage 7.0 (TID 385, hadoop07.cusp.nyu.edu, executor 7, partition 24, NODE_LOCAL, 8331 bytes)
2021-05-19 02:46:13 INFO  TaskSetManager:54 - Starting task 38.1 in stage 7.0 (TID 386, hadoop07.cusp.nyu.edu, executor 7, partition 38, NODE_LOCAL, 8331 bytes)
2021-05-19 02:46:13 INFO  YarnAllocator:54 - Launching container container_e10_1609183734776_5900_01_000011 on host hadoop18.cusp.nyu.edu for executor with ID 10
2021-05-19 02:46:13 INFO  YarnAllocator:54 - Received 2 containers from YARN, launching executors on 1 of them.
2021-05-19 02:46:13 INFO  ContainerManagementProtocolProxy:81 - yarn.client.max-cached-nodemanagers-proxies : 0
2021-05-19 02:46:13 INFO  ContainerManagementProtocolProxy:260 - Opening proxy : hadoop18.cusp.nyu.edu:8041
2021-05-19 02:46:13 INFO  BlockManagerMasterEndpoint:54 - Registering block manager hadoop07.cusp.nyu.edu:35847 with 366.3 MB RAM, BlockManagerId(7, hadoop07.cusp.nyu.edu, 35847, None)
2021-05-19 02:46:13 INFO  BlockManagerInfo:54 - Added broadcast_14_piece0 in memory on hadoop07.cusp.nyu.edu:35847 (size: 22.9 KB, free: 366.3 MB)
2021-05-19 02:46:15 INFO  BlockManagerInfo:54 - Added broadcast_12_piece0 in memory on hadoop07.cusp.nyu.edu:35847 (size: 580.1 KB, free: 365.7 MB)
2021-05-19 02:46:15 INFO  YarnSchedulerBackend$YarnDriverEndpoint:54 - Registered executor NettyRpcEndpointRef(spark-client://Executor) (192.168.72.172:57850) with ID 6
2021-05-19 02:46:15 INFO  TaskSetManager:54 - Starting task 14.1 in stage 7.0 (TID 387, hadoop02.cusp.nyu.edu, executor 6, partition 14, NODE_LOCAL, 8331 bytes)
2021-05-19 02:46:15 INFO  TaskSetManager:54 - Starting task 8.1 in stage 7.0 (TID 388, hadoop02.cusp.nyu.edu, executor 6, partition 8, NODE_LOCAL, 8331 bytes)
2021-05-19 02:46:15 INFO  TaskSetManager:54 - Starting task 11.1 in stage 7.0 (TID 389, hadoop02.cusp.nyu.edu, executor 6, partition 11, NODE_LOCAL, 8331 bytes)
2021-05-19 02:46:15 INFO  TaskSetManager:54 - Starting task 6.1 in stage 7.0 (TID 390, hadoop02.cusp.nyu.edu, executor 6, partition 6, NODE_LOCAL, 8331 bytes)
2021-05-19 02:46:15 INFO  TaskSetManager:54 - Starting task 45.1 in stage 7.0 (TID 391, hadoop02.cusp.nyu.edu, executor 6, partition 45, NODE_LOCAL, 8331 bytes)
2021-05-19 02:46:15 INFO  TaskSetManager:54 - Starting task 2.1 in stage 7.0 (TID 392, hadoop02.cusp.nyu.edu, executor 6, partition 2, NODE_LOCAL, 8331 bytes)
2021-05-19 02:46:15 INFO  TaskSetManager:54 - Starting task 17.0 in stage 7.0 (TID 393, hadoop02.cusp.nyu.edu, executor 6, partition 17, NODE_LOCAL, 8331 bytes)
2021-05-19 02:46:15 INFO  TaskSetManager:54 - Starting task 26.0 in stage 7.0 (TID 394, hadoop02.cusp.nyu.edu, executor 6, partition 26, NODE_LOCAL, 8331 bytes)
2021-05-19 02:46:15 INFO  TaskSetManager:54 - Starting task 47.0 in stage 7.0 (TID 395, hadoop02.cusp.nyu.edu, executor 6, partition 47, NODE_LOCAL, 8331 bytes)
2021-05-19 02:46:15 INFO  TaskSetManager:54 - Starting task 49.0 in stage 7.0 (TID 396, hadoop02.cusp.nyu.edu, executor 6, partition 49, NODE_LOCAL, 8436 bytes)
2021-05-19 02:46:15 INFO  BlockManagerMasterEndpoint:54 - Registering block manager hadoop02.cusp.nyu.edu:45477 with 366.3 MB RAM, BlockManagerId(6, hadoop02.cusp.nyu.edu, 45477, None)
2021-05-19 02:46:16 INFO  BlockManagerInfo:54 - Added broadcast_14_piece0 in memory on hadoop02.cusp.nyu.edu:45477 (size: 22.9 KB, free: 366.3 MB)
2021-05-19 02:46:16 INFO  AMRMClientImpl:360 - Received new token for : hadoop06.cusp.nyu.edu:8041
2021-05-19 02:46:16 INFO  YarnAllocator:54 - Received 1 containers from YARN, launching executors on 0 of them.
2021-05-19 02:46:16 INFO  YarnSchedulerBackend$YarnDriverEndpoint:54 - Registered executor NettyRpcEndpointRef(spark-client://Executor) (192.168.72.183:41650) with ID 8
2021-05-19 02:46:16 INFO  TaskSetManager:54 - Starting task 9.1 in stage 7.0 (TID 397, hadoop13.cusp.nyu.edu, executor 8, partition 9, NODE_LOCAL, 8331 bytes)
2021-05-19 02:46:16 INFO  TaskSetManager:54 - Starting task 4.1 in stage 7.0 (TID 398, hadoop13.cusp.nyu.edu, executor 8, partition 4, NODE_LOCAL, 8331 bytes)
2021-05-19 02:46:16 INFO  TaskSetManager:54 - Starting task 20.1 in stage 7.0 (TID 399, hadoop13.cusp.nyu.edu, executor 8, partition 20, NODE_LOCAL, 8331 bytes)
2021-05-19 02:46:16 INFO  TaskSetManager:54 - Starting task 43.1 in stage 7.0 (TID 400, hadoop13.cusp.nyu.edu, executor 8, partition 43, NODE_LOCAL, 8331 bytes)
2021-05-19 02:46:16 INFO  TaskSetManager:54 - Starting task 52.0 in stage 7.0 (TID 401, hadoop13.cusp.nyu.edu, executor 8, partition 52, NODE_LOCAL, 8436 bytes)
2021-05-19 02:46:16 INFO  YarnSchedulerBackend$YarnDriverEndpoint:54 - Registered executor NettyRpcEndpointRef(spark-client://Executor) (192.168.72.188:33348) with ID 9
2021-05-19 02:46:16 INFO  TaskSetManager:54 - Starting task 13.1 in stage 7.0 (TID 402, hadoop18.cusp.nyu.edu, executor 9, partition 13, NODE_LOCAL, 8331 bytes)
2021-05-19 02:46:16 INFO  TaskSetManager:54 - Starting task 60.2 in stage 7.0 (TID 403, hadoop18.cusp.nyu.edu, executor 9, partition 60, NODE_LOCAL, 8436 bytes)
2021-05-19 02:46:16 INFO  TaskSetManager:54 - Starting task 53.2 in stage 7.0 (TID 404, hadoop18.cusp.nyu.edu, executor 9, partition 53, NODE_LOCAL, 8436 bytes)
2021-05-19 02:46:16 INFO  TaskSetManager:54 - Starting task 31.1 in stage 7.0 (TID 405, hadoop18.cusp.nyu.edu, executor 9, partition 31, NODE_LOCAL, 8331 bytes)
2021-05-19 02:46:16 INFO  TaskSetManager:54 - Starting task 15.0 in stage 7.0 (TID 406, hadoop18.cusp.nyu.edu, executor 9, partition 15, NODE_LOCAL, 8331 bytes)
2021-05-19 02:46:16 INFO  TaskSetManager:54 - Starting task 16.0 in stage 7.0 (TID 407, hadoop18.cusp.nyu.edu, executor 9, partition 16, NODE_LOCAL, 8331 bytes)
2021-05-19 02:46:16 INFO  TaskSetManager:54 - Starting task 32.0 in stage 7.0 (TID 408, hadoop18.cusp.nyu.edu, executor 9, partition 32, NODE_LOCAL, 8331 bytes)
2021-05-19 02:46:16 INFO  TaskSetManager:54 - Starting task 35.0 in stage 7.0 (TID 409, hadoop18.cusp.nyu.edu, executor 9, partition 35, NODE_LOCAL, 8331 bytes)
2021-05-19 02:46:16 INFO  TaskSetManager:54 - Starting task 63.0 in stage 7.0 (TID 410, hadoop18.cusp.nyu.edu, executor 9, partition 63, NODE_LOCAL, 8541 bytes)
2021-05-19 02:46:16 INFO  BlockManagerMasterEndpoint:54 - Registering block manager hadoop13.cusp.nyu.edu:38130 with 366.3 MB RAM, BlockManagerId(8, hadoop13.cusp.nyu.edu, 38130, None)
2021-05-19 02:46:16 INFO  BlockManagerInfo:54 - Added broadcast_13_piece0 in memory on hadoop07.cusp.nyu.edu:35847 (size: 33.4 KB, free: 365.7 MB)
2021-05-19 02:46:16 INFO  BlockManagerMasterEndpoint:54 - Registering block manager hadoop18.cusp.nyu.edu:58292 with 366.3 MB RAM, BlockManagerId(9, hadoop18.cusp.nyu.edu, 58292, None)
2021-05-19 02:46:16 INFO  YarnSchedulerBackend$YarnDriverEndpoint:54 - Registered executor NettyRpcEndpointRef(spark-client://Executor) (192.168.72.188:33349) with ID 10
2021-05-19 02:46:16 INFO  BlockManagerInfo:54 - Added broadcast_14_piece0 in memory on hadoop13.cusp.nyu.edu:38130 (size: 22.9 KB, free: 366.3 MB)
2021-05-19 02:46:17 INFO  BlockManagerMasterEndpoint:54 - Registering block manager hadoop18.cusp.nyu.edu:48269 with 366.3 MB RAM, BlockManagerId(10, hadoop18.cusp.nyu.edu, 48269, None)
2021-05-19 02:46:17 INFO  BlockManagerInfo:54 - Added broadcast_14_piece0 in memory on hadoop18.cusp.nyu.edu:58292 (size: 22.9 KB, free: 366.3 MB)
2021-05-19 02:46:17 INFO  BlockManagerInfo:54 - Added broadcast_12_piece0 in memory on hadoop02.cusp.nyu.edu:45477 (size: 580.1 KB, free: 365.7 MB)
2021-05-19 02:46:18 INFO  BlockManagerInfo:54 - Added broadcast_12_piece0 in memory on hadoop13.cusp.nyu.edu:38130 (size: 580.1 KB, free: 365.7 MB)
2021-05-19 02:46:18 INFO  BlockManagerInfo:54 - Added broadcast_12_piece0 in memory on hadoop18.cusp.nyu.edu:58292 (size: 580.1 KB, free: 365.7 MB)
2021-05-19 02:46:19 INFO  BlockManagerInfo:54 - Added broadcast_13_piece0 in memory on hadoop02.cusp.nyu.edu:45477 (size: 33.4 KB, free: 365.7 MB)
2021-05-19 02:46:19 INFO  BlockManagerInfo:54 - Added broadcast_13_piece0 in memory on hadoop13.cusp.nyu.edu:38130 (size: 33.4 KB, free: 365.7 MB)
2021-05-19 02:46:19 INFO  TaskSetManager:54 - Starting task 10.2 in stage 7.0 (TID 411, hadoop13.cusp.nyu.edu, executor 8, partition 10, RACK_LOCAL, 8331 bytes)
2021-05-19 02:46:19 INFO  TaskSetManager:54 - Starting task 66.1 in stage 7.0 (TID 412, hadoop18.cusp.nyu.edu, executor 9, partition 66, RACK_LOCAL, 8541 bytes)
2021-05-19 02:46:19 INFO  TaskSetManager:54 - Starting task 21.1 in stage 7.0 (TID 413, hadoop18.cusp.nyu.edu, executor 10, partition 21, RACK_LOCAL, 8331 bytes)
2021-05-19 02:46:19 INFO  TaskSetManager:54 - Starting task 50.2 in stage 7.0 (TID 414, hadoop13.cusp.nyu.edu, executor 8, partition 50, RACK_LOCAL, 8436 bytes)
2021-05-19 02:46:19 INFO  TaskSetManager:54 - Starting task 19.1 in stage 7.0 (TID 415, hadoop18.cusp.nyu.edu, executor 10, partition 19, RACK_LOCAL, 8331 bytes)
2021-05-19 02:46:19 INFO  TaskSetManager:54 - Starting task 44.1 in stage 7.0 (TID 416, hadoop13.cusp.nyu.edu, executor 8, partition 44, RACK_LOCAL, 8331 bytes)
2021-05-19 02:46:19 INFO  TaskSetManager:54 - Starting task 42.1 in stage 7.0 (TID 417, hadoop18.cusp.nyu.edu, executor 10, partition 42, RACK_LOCAL, 8331 bytes)
2021-05-19 02:46:19 INFO  TaskSetManager:54 - Starting task 40.1 in stage 7.0 (TID 418, hadoop13.cusp.nyu.edu, executor 8, partition 40, RACK_LOCAL, 8331 bytes)
2021-05-19 02:46:19 INFO  TaskSetManager:54 - Starting task 46.2 in stage 7.0 (TID 419, hadoop18.cusp.nyu.edu, executor 10, partition 46, RACK_LOCAL, 8331 bytes)
2021-05-19 02:46:19 INFO  TaskSetManager:54 - Starting task 3.1 in stage 7.0 (TID 420, hadoop13.cusp.nyu.edu, executor 8, partition 3, RACK_LOCAL, 8331 bytes)
2021-05-19 02:46:19 INFO  TaskSetManager:54 - Starting task 29.1 in stage 7.0 (TID 421, hadoop18.cusp.nyu.edu, executor 10, partition 29, RACK_LOCAL, 8331 bytes)
2021-05-19 02:46:19 INFO  TaskSetManager:54 - Starting task 1.1 in stage 7.0 (TID 422, hadoop18.cusp.nyu.edu, executor 10, partition 1, RACK_LOCAL, 8331 bytes)
2021-05-19 02:46:19 INFO  TaskSetManager:54 - Starting task 64.1 in stage 7.0 (TID 423, hadoop18.cusp.nyu.edu, executor 10, partition 64, RACK_LOCAL, 8541 bytes)
2021-05-19 02:46:19 INFO  TaskSetManager:54 - Starting task 12.1 in stage 7.0 (TID 424, hadoop18.cusp.nyu.edu, executor 10, partition 12, RACK_LOCAL, 8331 bytes)
2021-05-19 02:46:19 INFO  TaskSetManager:54 - Starting task 39.1 in stage 7.0 (TID 425, hadoop18.cusp.nyu.edu, executor 10, partition 39, RACK_LOCAL, 8331 bytes)
2021-05-19 02:46:19 INFO  TaskSetManager:54 - Starting task 69.1 in stage 7.0 (TID 426, hadoop18.cusp.nyu.edu, executor 10, partition 69, RACK_LOCAL, 8541 bytes)
2021-05-19 02:46:20 INFO  BlockManagerInfo:54 - Added broadcast_13_piece0 in memory on hadoop18.cusp.nyu.edu:58292 (size: 33.4 KB, free: 365.7 MB)
2021-05-19 02:46:20 INFO  BlockManagerInfo:54 - Added broadcast_14_piece0 in memory on hadoop18.cusp.nyu.edu:48269 (size: 22.9 KB, free: 366.3 MB)
2021-05-19 02:46:22 INFO  BlockManagerInfo:54 - Added broadcast_12_piece0 in memory on hadoop18.cusp.nyu.edu:48269 (size: 580.1 KB, free: 365.7 MB)
2021-05-19 02:46:23 INFO  BlockManagerInfo:54 - Added broadcast_13_piece0 in memory on hadoop18.cusp.nyu.edu:48269 (size: 33.4 KB, free: 365.7 MB)
2021-05-19 02:46:28 INFO  YarnSchedulerBackend$YarnDriverEndpoint:54 - Disabling executor 7.
2021-05-19 02:46:28 INFO  DAGScheduler:54 - Executor lost: 7 (epoch 1)
2021-05-19 02:46:28 INFO  BlockManagerMasterEndpoint:54 - Trying to remove executor 7 from BlockManagerMaster.
2021-05-19 02:46:28 INFO  BlockManagerMasterEndpoint:54 - Removing block manager BlockManagerId(7, hadoop07.cusp.nyu.edu, 35847, None)
2021-05-19 02:46:28 INFO  BlockManagerMaster:54 - Removed 7 successfully in removeExecutor
2021-05-19 02:46:28 INFO  YarnAllocator:54 - Completed container container_e10_1609183734776_5900_01_000008 on host: hadoop07.cusp.nyu.edu (state: COMPLETE, exit status: -104)
2021-05-19 02:46:28 WARN  YarnAllocator:66 - Container killed by YARN for exceeding memory limits.  1.5 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:46:28 WARN  YarnSchedulerBackend$YarnSchedulerEndpoint:66 - Requesting driver to remove executor 7 for reason Container killed by YARN for exceeding memory limits.  1.5 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:46:28 ERROR YarnClusterScheduler:70 - Lost executor 7 on hadoop07.cusp.nyu.edu: Container killed by YARN for exceeding memory limits.  1.5 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:46:28 WARN  TaskSetManager:66 - Lost task 34.1 in stage 7.0 (TID 382, hadoop07.cusp.nyu.edu, executor 7): ExecutorLostFailure (executor 7 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  1.5 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:46:28 WARN  TaskSetManager:66 - Lost task 24.1 in stage 7.0 (TID 385, hadoop07.cusp.nyu.edu, executor 7): ExecutorLostFailure (executor 7 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  1.5 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:46:28 WARN  TaskSetManager:66 - Lost task 23.1 in stage 7.0 (TID 379, hadoop07.cusp.nyu.edu, executor 7): ExecutorLostFailure (executor 7 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  1.5 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:46:28 WARN  TaskSetManager:66 - Lost task 0.1 in stage 7.0 (TID 378, hadoop07.cusp.nyu.edu, executor 7): ExecutorLostFailure (executor 7 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  1.5 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:46:28 WARN  TaskSetManager:66 - Lost task 22.1 in stage 7.0 (TID 381, hadoop07.cusp.nyu.edu, executor 7): ExecutorLostFailure (executor 7 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  1.5 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:46:28 WARN  TaskSetManager:66 - Lost task 5.1 in stage 7.0 (TID 384, hadoop07.cusp.nyu.edu, executor 7): ExecutorLostFailure (executor 7 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  1.5 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:46:28 WARN  TaskSetManager:66 - Lost task 41.1 in stage 7.0 (TID 383, hadoop07.cusp.nyu.edu, executor 7): ExecutorLostFailure (executor 7 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  1.5 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:46:28 WARN  TaskSetManager:66 - Lost task 38.1 in stage 7.0 (TID 386, hadoop07.cusp.nyu.edu, executor 7): ExecutorLostFailure (executor 7 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  1.5 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:46:28 WARN  TaskSetManager:66 - Lost task 28.1 in stage 7.0 (TID 377, hadoop07.cusp.nyu.edu, executor 7): ExecutorLostFailure (executor 7 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  1.5 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:46:28 WARN  TaskSetManager:66 - Lost task 37.1 in stage 7.0 (TID 380, hadoop07.cusp.nyu.edu, executor 7): ExecutorLostFailure (executor 7 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  1.5 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:46:28 INFO  BlockManagerMasterEndpoint:54 - Trying to remove executor 7 from BlockManagerMaster.
2021-05-19 02:46:28 INFO  BlockManagerMaster:54 - Removal of executor 7 requested
2021-05-19 02:46:28 INFO  YarnSchedulerBackend$YarnDriverEndpoint:54 - Asked to remove non-existent executor 7
2021-05-19 02:46:31 INFO  YarnAllocator:54 - Will request 1 executor container(s), each with 10 core(s) and 1408 MB memory (including 384 MB of overhead)
2021-05-19 02:46:31 INFO  YarnAllocator:54 - Submitted 1 unlocalized container requests.
2021-05-19 02:46:32 INFO  YarnAllocator:54 - Launching container container_e10_1609183734776_5900_01_000014 on host hadoop04.cusp.nyu.edu for executor with ID 11
2021-05-19 02:46:32 INFO  YarnAllocator:54 - Received 1 containers from YARN, launching executors on 1 of them.
2021-05-19 02:46:32 INFO  ContainerManagementProtocolProxy:81 - yarn.client.max-cached-nodemanagers-proxies : 0
2021-05-19 02:46:32 INFO  ContainerManagementProtocolProxy:260 - Opening proxy : hadoop04.cusp.nyu.edu:8041
2021-05-19 02:46:32 INFO  TaskSetManager:54 - Starting task 37.2 in stage 7.0 (TID 427, hadoop02.cusp.nyu.edu, executor 6, partition 37, NODE_LOCAL, 8331 bytes)
2021-05-19 02:46:32 INFO  TaskSetManager:54 - Finished task 49.0 in stage 7.0 (TID 396) in 16878 ms on hadoop02.cusp.nyu.edu (executor 6) (13/70)
2021-05-19 02:46:32 INFO  TaskSetManager:54 - Starting task 41.2 in stage 7.0 (TID 428, hadoop13.cusp.nyu.edu, executor 8, partition 41, NODE_LOCAL, 8331 bytes)
2021-05-19 02:46:32 INFO  TaskSetManager:54 - Finished task 50.2 in stage 7.0 (TID 414) in 12856 ms on hadoop13.cusp.nyu.edu (executor 8) (14/70)
2021-05-19 02:46:32 INFO  TaskSetManager:54 - Starting task 5.2 in stage 7.0 (TID 429, hadoop13.cusp.nyu.edu, executor 8, partition 5, NODE_LOCAL, 8331 bytes)
2021-05-19 02:46:32 INFO  TaskSetManager:54 - Finished task 52.0 in stage 7.0 (TID 401) in 16364 ms on hadoop13.cusp.nyu.edu (executor 8) (15/70)
2021-05-19 02:46:33 INFO  TaskSetManager:54 - Starting task 38.2 in stage 7.0 (TID 430, hadoop18.cusp.nyu.edu, executor 9, partition 38, NODE_LOCAL, 8331 bytes)
2021-05-19 02:46:33 INFO  TaskSetManager:54 - Finished task 60.2 in stage 7.0 (TID 403) in 16512 ms on hadoop18.cusp.nyu.edu (executor 9) (16/70)
2021-05-19 02:46:33 INFO  YarnSchedulerBackend$YarnDriverEndpoint:54 - Disabling executor 6.
2021-05-19 02:46:33 INFO  DAGScheduler:54 - Executor lost: 6 (epoch 1)
2021-05-19 02:46:33 INFO  BlockManagerMasterEndpoint:54 - Trying to remove executor 6 from BlockManagerMaster.
2021-05-19 02:46:33 INFO  BlockManagerMasterEndpoint:54 - Removing block manager BlockManagerId(6, hadoop02.cusp.nyu.edu, 45477, None)
2021-05-19 02:46:33 INFO  BlockManagerMaster:54 - Removed 6 successfully in removeExecutor
2021-05-19 02:46:33 INFO  YarnAllocator:54 - Completed container container_e10_1609183734776_5900_01_000007 on host: hadoop02.cusp.nyu.edu (state: COMPLETE, exit status: -104)
2021-05-19 02:46:33 WARN  YarnAllocator:66 - Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:46:33 WARN  YarnSchedulerBackend$YarnSchedulerEndpoint:66 - Requesting driver to remove executor 6 for reason Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:46:33 ERROR YarnClusterScheduler:70 - Lost executor 6 on hadoop02.cusp.nyu.edu: Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:46:33 WARN  TaskSetManager:66 - Lost task 45.1 in stage 7.0 (TID 391, hadoop02.cusp.nyu.edu, executor 6): ExecutorLostFailure (executor 6 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:46:33 WARN  TaskSetManager:66 - Lost task 37.2 in stage 7.0 (TID 427, hadoop02.cusp.nyu.edu, executor 6): ExecutorLostFailure (executor 6 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:46:33 WARN  TaskSetManager:66 - Lost task 26.0 in stage 7.0 (TID 394, hadoop02.cusp.nyu.edu, executor 6): ExecutorLostFailure (executor 6 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:46:33 WARN  TaskSetManager:66 - Lost task 8.1 in stage 7.0 (TID 388, hadoop02.cusp.nyu.edu, executor 6): ExecutorLostFailure (executor 6 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:46:33 WARN  TaskSetManager:66 - Lost task 14.1 in stage 7.0 (TID 387, hadoop02.cusp.nyu.edu, executor 6): ExecutorLostFailure (executor 6 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:46:33 WARN  TaskSetManager:66 - Lost task 6.1 in stage 7.0 (TID 390, hadoop02.cusp.nyu.edu, executor 6): ExecutorLostFailure (executor 6 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:46:33 WARN  TaskSetManager:66 - Lost task 17.0 in stage 7.0 (TID 393, hadoop02.cusp.nyu.edu, executor 6): ExecutorLostFailure (executor 6 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:46:33 WARN  TaskSetManager:66 - Lost task 2.1 in stage 7.0 (TID 392, hadoop02.cusp.nyu.edu, executor 6): ExecutorLostFailure (executor 6 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:46:33 WARN  TaskSetManager:66 - Lost task 47.0 in stage 7.0 (TID 395, hadoop02.cusp.nyu.edu, executor 6): ExecutorLostFailure (executor 6 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:46:33 WARN  TaskSetManager:66 - Lost task 11.1 in stage 7.0 (TID 389, hadoop02.cusp.nyu.edu, executor 6): ExecutorLostFailure (executor 6 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:46:33 INFO  BlockManagerMaster:54 - Removal of executor 6 requested
2021-05-19 02:46:33 INFO  BlockManagerMasterEndpoint:54 - Trying to remove executor 6 from BlockManagerMaster.
2021-05-19 02:46:33 INFO  YarnSchedulerBackend$YarnDriverEndpoint:54 - Asked to remove non-existent executor 6
2021-05-19 02:46:33 INFO  TaskSetManager:54 - Starting task 14.2 in stage 7.0 (TID 431, hadoop13.cusp.nyu.edu, executor 8, partition 14, NODE_LOCAL, 8331 bytes)
2021-05-19 02:46:33 INFO  TaskSetManager:54 - Finished task 10.2 in stage 7.0 (TID 411) in 13517 ms on hadoop13.cusp.nyu.edu (executor 8) (17/70)
2021-05-19 02:46:33 INFO  YarnSchedulerBackend$YarnDriverEndpoint:54 - Disabling executor 9.
2021-05-19 02:46:33 INFO  DAGScheduler:54 - Executor lost: 9 (epoch 1)
2021-05-19 02:46:33 INFO  YarnAllocator:54 - Will request 1 executor container(s), each with 10 core(s) and 1408 MB memory (including 384 MB of overhead)
2021-05-19 02:46:33 INFO  BlockManagerMasterEndpoint:54 - Trying to remove executor 9 from BlockManagerMaster.
2021-05-19 02:46:33 INFO  YarnAllocator:54 - Submitted 1 unlocalized container requests.
2021-05-19 02:46:33 INFO  BlockManagerMasterEndpoint:54 - Removing block manager BlockManagerId(9, hadoop18.cusp.nyu.edu, 58292, None)
2021-05-19 02:46:33 INFO  BlockManagerMaster:54 - Removed 9 successfully in removeExecutor
2021-05-19 02:46:33 INFO  YarnAllocator:54 - Completed container container_e10_1609183734776_5900_01_000010 on host: hadoop18.cusp.nyu.edu (state: COMPLETE, exit status: -104)
2021-05-19 02:46:33 WARN  YarnAllocator:66 - Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:46:33 WARN  YarnSchedulerBackend$YarnSchedulerEndpoint:66 - Requesting driver to remove executor 9 for reason Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:46:33 ERROR YarnClusterScheduler:70 - Lost executor 9 on hadoop18.cusp.nyu.edu: Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:46:33 WARN  TaskSetManager:66 - Lost task 15.0 in stage 7.0 (TID 406, hadoop18.cusp.nyu.edu, executor 9): ExecutorLostFailure (executor 9 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:46:33 WARN  TaskSetManager:66 - Lost task 35.0 in stage 7.0 (TID 409, hadoop18.cusp.nyu.edu, executor 9): ExecutorLostFailure (executor 9 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:46:33 WARN  TaskSetManager:66 - Lost task 38.2 in stage 7.0 (TID 430, hadoop18.cusp.nyu.edu, executor 9): ExecutorLostFailure (executor 9 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:46:33 WARN  TaskSetManager:66 - Lost task 66.1 in stage 7.0 (TID 412, hadoop18.cusp.nyu.edu, executor 9): ExecutorLostFailure (executor 9 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:46:33 WARN  TaskSetManager:66 - Lost task 31.1 in stage 7.0 (TID 405, hadoop18.cusp.nyu.edu, executor 9): ExecutorLostFailure (executor 9 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:46:33 WARN  TaskSetManager:66 - Lost task 32.0 in stage 7.0 (TID 408, hadoop18.cusp.nyu.edu, executor 9): ExecutorLostFailure (executor 9 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:46:33 WARN  TaskSetManager:66 - Lost task 13.1 in stage 7.0 (TID 402, hadoop18.cusp.nyu.edu, executor 9): ExecutorLostFailure (executor 9 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:46:33 WARN  TaskSetManager:66 - Lost task 63.0 in stage 7.0 (TID 410, hadoop18.cusp.nyu.edu, executor 9): ExecutorLostFailure (executor 9 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:46:33 WARN  TaskSetManager:66 - Lost task 53.2 in stage 7.0 (TID 404, hadoop18.cusp.nyu.edu, executor 9): ExecutorLostFailure (executor 9 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:46:33 WARN  TaskSetManager:66 - Lost task 16.0 in stage 7.0 (TID 407, hadoop18.cusp.nyu.edu, executor 9): ExecutorLostFailure (executor 9 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:46:33 INFO  BlockManagerMaster:54 - Removal of executor 9 requested
2021-05-19 02:46:33 INFO  YarnSchedulerBackend$YarnDriverEndpoint:54 - Asked to remove non-existent executor 9
2021-05-19 02:46:33 INFO  BlockManagerMasterEndpoint:54 - Trying to remove executor 9 from BlockManagerMaster.
2021-05-19 02:46:33 INFO  YarnAllocator:54 - Will request 1 executor container(s), each with 10 core(s) and 1408 MB memory (including 384 MB of overhead)
2021-05-19 02:46:33 INFO  YarnAllocator:54 - Submitted 1 unlocalized container requests.
2021-05-19 02:46:33 INFO  YarnAllocator:54 - Launching container container_e10_1609183734776_5900_01_000015 on host hadoop02.cusp.nyu.edu for executor with ID 12
2021-05-19 02:46:33 INFO  YarnAllocator:54 - Received 1 containers from YARN, launching executors on 1 of them.
2021-05-19 02:46:33 INFO  ContainerManagementProtocolProxy:81 - yarn.client.max-cached-nodemanagers-proxies : 0
2021-05-19 02:46:33 INFO  ContainerManagementProtocolProxy:260 - Opening proxy : hadoop02.cusp.nyu.edu:8041
2021-05-19 02:46:33 INFO  TaskSetManager:54 - Starting task 26.1 in stage 7.0 (TID 432, hadoop13.cusp.nyu.edu, executor 8, partition 26, NODE_LOCAL, 8331 bytes)
2021-05-19 02:46:33 INFO  TaskSetManager:54 - Finished task 4.1 in stage 7.0 (TID 398) in 17524 ms on hadoop13.cusp.nyu.edu (executor 8) (18/70)
2021-05-19 02:46:34 INFO  TaskSetManager:54 - Starting task 23.2 in stage 7.0 (TID 433, hadoop13.cusp.nyu.edu, executor 8, partition 23, NODE_LOCAL, 8331 bytes)
2021-05-19 02:46:34 INFO  TaskSetManager:54 - Finished task 40.1 in stage 7.0 (TID 418) in 14087 ms on hadoop13.cusp.nyu.edu (executor 8) (19/70)
2021-05-19 02:46:34 INFO  TaskSetManager:54 - Starting task 34.2 in stage 7.0 (TID 434, hadoop13.cusp.nyu.edu, executor 8, partition 34, NODE_LOCAL, 8331 bytes)
2021-05-19 02:46:34 INFO  TaskSetManager:54 - Finished task 43.1 in stage 7.0 (TID 400) in 17636 ms on hadoop13.cusp.nyu.edu (executor 8) (20/70)
2021-05-19 02:46:34 INFO  TaskSetManager:54 - Finished task 20.1 in stage 7.0 (TID 399) in 17758 ms on hadoop13.cusp.nyu.edu (executor 8) (21/70)
2021-05-19 02:46:34 INFO  TaskSetManager:54 - Finished task 44.1 in stage 7.0 (TID 416) in 14552 ms on hadoop13.cusp.nyu.edu (executor 8) (22/70)
2021-05-19 02:46:34 INFO  TaskSetManager:54 - Finished task 9.1 in stage 7.0 (TID 397) in 18245 ms on hadoop13.cusp.nyu.edu (executor 8) (23/70)
2021-05-19 02:46:34 INFO  TaskSetManager:54 - Finished task 3.1 in stage 7.0 (TID 420) in 14980 ms on hadoop13.cusp.nyu.edu (executor 8) (24/70)
2021-05-19 02:46:35 INFO  YarnAllocator:54 - Launching container container_e10_1609183734776_5900_01_000016 on host hadoop06.cusp.nyu.edu for executor with ID 13
2021-05-19 02:46:35 INFO  YarnAllocator:54 - Received 1 containers from YARN, launching executors on 1 of them.
2021-05-19 02:46:35 INFO  ContainerManagementProtocolProxy:81 - yarn.client.max-cached-nodemanagers-proxies : 0
2021-05-19 02:46:35 INFO  ContainerManagementProtocolProxy:260 - Opening proxy : hadoop06.cusp.nyu.edu:8041
2021-05-19 02:46:35 INFO  YarnSchedulerBackend$YarnDriverEndpoint:54 - Disabling executor 8.
2021-05-19 02:46:35 INFO  DAGScheduler:54 - Executor lost: 8 (epoch 1)
2021-05-19 02:46:35 INFO  BlockManagerMasterEndpoint:54 - Trying to remove executor 8 from BlockManagerMaster.
2021-05-19 02:46:35 INFO  BlockManagerMasterEndpoint:54 - Removing block manager BlockManagerId(8, hadoop13.cusp.nyu.edu, 38130, None)
2021-05-19 02:46:35 INFO  BlockManagerMaster:54 - Removed 8 successfully in removeExecutor
2021-05-19 02:46:35 INFO  YarnAllocator:54 - Completed container container_e10_1609183734776_5900_01_000009 on host: hadoop13.cusp.nyu.edu (state: COMPLETE, exit status: -104)
2021-05-19 02:46:35 WARN  YarnAllocator:66 - Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:46:35 WARN  YarnSchedulerBackend$YarnSchedulerEndpoint:66 - Requesting driver to remove executor 8 for reason Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:46:35 ERROR YarnClusterScheduler:70 - Lost executor 8 on hadoop13.cusp.nyu.edu: Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:46:35 WARN  TaskSetManager:66 - Lost task 23.2 in stage 7.0 (TID 433, hadoop13.cusp.nyu.edu, executor 8): ExecutorLostFailure (executor 8 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:46:35 WARN  TaskSetManager:66 - Lost task 5.2 in stage 7.0 (TID 429, hadoop13.cusp.nyu.edu, executor 8): ExecutorLostFailure (executor 8 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:46:35 WARN  TaskSetManager:66 - Lost task 26.1 in stage 7.0 (TID 432, hadoop13.cusp.nyu.edu, executor 8): ExecutorLostFailure (executor 8 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:46:35 WARN  TaskSetManager:66 - Lost task 41.2 in stage 7.0 (TID 428, hadoop13.cusp.nyu.edu, executor 8): ExecutorLostFailure (executor 8 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:46:35 WARN  TaskSetManager:66 - Lost task 14.2 in stage 7.0 (TID 431, hadoop13.cusp.nyu.edu, executor 8): ExecutorLostFailure (executor 8 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:46:35 WARN  TaskSetManager:66 - Lost task 34.2 in stage 7.0 (TID 434, hadoop13.cusp.nyu.edu, executor 8): ExecutorLostFailure (executor 8 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:46:35 INFO  BlockManagerMaster:54 - Removal of executor 8 requested
2021-05-19 02:46:35 INFO  BlockManagerMasterEndpoint:54 - Trying to remove executor 8 from BlockManagerMaster.
2021-05-19 02:46:35 INFO  YarnSchedulerBackend$YarnDriverEndpoint:54 - Asked to remove non-existent executor 8
2021-05-19 02:46:37 INFO  YarnSchedulerBackend$YarnDriverEndpoint:54 - Registered executor NettyRpcEndpointRef(spark-client://Executor) (192.168.72.172:57911) with ID 12
2021-05-19 02:46:37 INFO  TaskSetManager:54 - Starting task 34.3 in stage 7.0 (TID 435, hadoop02.cusp.nyu.edu, executor 12, partition 34, NODE_LOCAL, 8331 bytes)
2021-05-19 02:46:37 INFO  TaskSetManager:54 - Starting task 14.3 in stage 7.0 (TID 436, hadoop02.cusp.nyu.edu, executor 12, partition 14, NODE_LOCAL, 8331 bytes)
2021-05-19 02:46:37 INFO  TaskSetManager:54 - Starting task 26.2 in stage 7.0 (TID 437, hadoop02.cusp.nyu.edu, executor 12, partition 26, NODE_LOCAL, 8331 bytes)
2021-05-19 02:46:37 INFO  TaskSetManager:54 - Starting task 11.2 in stage 7.0 (TID 438, hadoop02.cusp.nyu.edu, executor 12, partition 11, NODE_LOCAL, 8331 bytes)
2021-05-19 02:46:37 INFO  TaskSetManager:54 - Starting task 47.1 in stage 7.0 (TID 439, hadoop02.cusp.nyu.edu, executor 12, partition 47, NODE_LOCAL, 8331 bytes)
2021-05-19 02:46:37 INFO  TaskSetManager:54 - Starting task 2.2 in stage 7.0 (TID 440, hadoop02.cusp.nyu.edu, executor 12, partition 2, NODE_LOCAL, 8331 bytes)
2021-05-19 02:46:37 INFO  TaskSetManager:54 - Starting task 17.1 in stage 7.0 (TID 441, hadoop02.cusp.nyu.edu, executor 12, partition 17, NODE_LOCAL, 8331 bytes)
2021-05-19 02:46:37 INFO  TaskSetManager:54 - Starting task 6.2 in stage 7.0 (TID 442, hadoop02.cusp.nyu.edu, executor 12, partition 6, NODE_LOCAL, 8331 bytes)
2021-05-19 02:46:37 INFO  TaskSetManager:54 - Starting task 8.2 in stage 7.0 (TID 443, hadoop02.cusp.nyu.edu, executor 12, partition 8, NODE_LOCAL, 8331 bytes)
2021-05-19 02:46:37 INFO  TaskSetManager:54 - Starting task 37.3 in stage 7.0 (TID 444, hadoop02.cusp.nyu.edu, executor 12, partition 37, NODE_LOCAL, 8331 bytes)
2021-05-19 02:46:37 INFO  BlockManagerMasterEndpoint:54 - Registering block manager hadoop02.cusp.nyu.edu:43020 with 366.3 MB RAM, BlockManagerId(12, hadoop02.cusp.nyu.edu, 43020, None)
2021-05-19 02:46:37 INFO  BlockManagerInfo:54 - Added broadcast_14_piece0 in memory on hadoop02.cusp.nyu.edu:43020 (size: 22.9 KB, free: 366.3 MB)
2021-05-19 02:46:38 INFO  YarnSchedulerBackend$YarnDriverEndpoint:54 - Registered executor NettyRpcEndpointRef(spark-client://Executor) (192.168.72.174:59817) with ID 11
2021-05-19 02:46:38 INFO  TaskSetManager:54 - Starting task 23.3 in stage 7.0 (TID 445, hadoop18.cusp.nyu.edu, executor 10, partition 23, NODE_LOCAL, 8331 bytes)
2021-05-19 02:46:38 INFO  TaskSetManager:54 - Finished task 21.1 in stage 7.0 (TID 413) in 18624 ms on hadoop18.cusp.nyu.edu (executor 10) (25/70)
2021-05-19 02:46:38 INFO  TaskSetManager:54 - Starting task 16.1 in stage 7.0 (TID 446, hadoop18.cusp.nyu.edu, executor 10, partition 16, NODE_LOCAL, 8331 bytes)
2021-05-19 02:46:38 INFO  TaskSetManager:54 - Finished task 19.1 in stage 7.0 (TID 415) in 18682 ms on hadoop18.cusp.nyu.edu (executor 10) (26/70)
2021-05-19 02:46:38 INFO  YarnAllocator:54 - Will request 1 executor container(s), each with 10 core(s) and 1408 MB memory (including 384 MB of overhead)
2021-05-19 02:46:38 INFO  YarnAllocator:54 - Submitted 1 unlocalized container requests.
2021-05-19 02:46:38 INFO  BlockManagerMasterEndpoint:54 - Registering block manager hadoop04.cusp.nyu.edu:36965 with 366.3 MB RAM, BlockManagerId(11, hadoop04.cusp.nyu.edu, 36965, None)
2021-05-19 02:46:38 INFO  YarnAllocator:54 - Launching container container_e10_1609183734776_5900_01_000017 on host hadoop13.cusp.nyu.edu for executor with ID 14
2021-05-19 02:46:38 INFO  YarnAllocator:54 - Received 1 containers from YARN, launching executors on 1 of them.
2021-05-19 02:46:38 INFO  ContainerManagementProtocolProxy:81 - yarn.client.max-cached-nodemanagers-proxies : 0
2021-05-19 02:46:38 INFO  ContainerManagementProtocolProxy:260 - Opening proxy : hadoop13.cusp.nyu.edu:8041
2021-05-19 02:46:38 INFO  TaskSetManager:54 - Starting task 53.3 in stage 7.0 (TID 447, hadoop18.cusp.nyu.edu, executor 10, partition 53, NODE_LOCAL, 8436 bytes)
2021-05-19 02:46:38 INFO  TaskSetManager:54 - Finished task 39.1 in stage 7.0 (TID 425) in 18946 ms on hadoop18.cusp.nyu.edu (executor 10) (27/70)
2021-05-19 02:46:38 INFO  TaskSetManager:54 - Starting task 63.1 in stage 7.0 (TID 448, hadoop18.cusp.nyu.edu, executor 10, partition 63, NODE_LOCAL, 8541 bytes)
2021-05-19 02:46:38 INFO  TaskSetManager:54 - Finished task 12.1 in stage 7.0 (TID 424) in 18969 ms on hadoop18.cusp.nyu.edu (executor 10) (28/70)
2021-05-19 02:46:38 INFO  TaskSetManager:54 - Starting task 13.2 in stage 7.0 (TID 449, hadoop18.cusp.nyu.edu, executor 10, partition 13, NODE_LOCAL, 8331 bytes)
2021-05-19 02:46:38 INFO  TaskSetManager:54 - Finished task 29.1 in stage 7.0 (TID 421) in 19046 ms on hadoop18.cusp.nyu.edu (executor 10) (29/70)
2021-05-19 02:46:39 INFO  TaskSetManager:54 - Starting task 32.1 in stage 7.0 (TID 450, hadoop18.cusp.nyu.edu, executor 10, partition 32, NODE_LOCAL, 8331 bytes)
2021-05-19 02:46:39 INFO  TaskSetManager:54 - Finished task 42.1 in stage 7.0 (TID 417) in 19096 ms on hadoop18.cusp.nyu.edu (executor 10) (30/70)
2021-05-19 02:46:39 INFO  TaskSetManager:54 - Starting task 31.2 in stage 7.0 (TID 451, hadoop18.cusp.nyu.edu, executor 10, partition 31, NODE_LOCAL, 8331 bytes)
2021-05-19 02:46:39 INFO  TaskSetManager:54 - Finished task 46.2 in stage 7.0 (TID 419) in 19418 ms on hadoop18.cusp.nyu.edu (executor 10) (31/70)
2021-05-19 02:46:39 INFO  TaskSetManager:54 - Starting task 38.3 in stage 7.0 (TID 452, hadoop18.cusp.nyu.edu, executor 10, partition 38, NODE_LOCAL, 8331 bytes)
2021-05-19 02:46:39 INFO  TaskSetManager:54 - Finished task 1.1 in stage 7.0 (TID 422) in 19423 ms on hadoop18.cusp.nyu.edu (executor 10) (32/70)
2021-05-19 02:46:39 INFO  BlockManagerInfo:54 - Added broadcast_12_piece0 in memory on hadoop02.cusp.nyu.edu:43020 (size: 580.1 KB, free: 365.7 MB)
2021-05-19 02:46:39 INFO  YarnSchedulerBackend$YarnDriverEndpoint:54 - Disabling executor 10.
2021-05-19 02:46:39 INFO  DAGScheduler:54 - Executor lost: 10 (epoch 1)
2021-05-19 02:46:39 INFO  BlockManagerMasterEndpoint:54 - Trying to remove executor 10 from BlockManagerMaster.
2021-05-19 02:46:39 INFO  BlockManagerMasterEndpoint:54 - Removing block manager BlockManagerId(10, hadoop18.cusp.nyu.edu, 48269, None)
2021-05-19 02:46:39 INFO  BlockManagerMaster:54 - Removed 10 successfully in removeExecutor
2021-05-19 02:46:39 INFO  YarnAllocator:54 - Completed container container_e10_1609183734776_5900_01_000011 on host: hadoop18.cusp.nyu.edu (state: COMPLETE, exit status: -104)
2021-05-19 02:46:39 WARN  YarnAllocator:66 - Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:46:39 WARN  YarnSchedulerBackend$YarnSchedulerEndpoint:66 - Requesting driver to remove executor 10 for reason Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:46:39 ERROR YarnClusterScheduler:70 - Lost executor 10 on hadoop18.cusp.nyu.edu: Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:46:39 WARN  TaskSetManager:66 - Lost task 31.2 in stage 7.0 (TID 451, hadoop18.cusp.nyu.edu, executor 10): ExecutorLostFailure (executor 10 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:46:39 WARN  TaskSetManager:66 - Lost task 23.3 in stage 7.0 (TID 445, hadoop18.cusp.nyu.edu, executor 10): ExecutorLostFailure (executor 10 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:46:39 ERROR TaskSetManager:70 - Task 23 in stage 7.0 failed 4 times; aborting job
2021-05-19 02:46:39 WARN  TaskSetManager:66 - Lost task 63.1 in stage 7.0 (TID 448, hadoop18.cusp.nyu.edu, executor 10): ExecutorLostFailure (executor 10 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:46:39 WARN  TaskSetManager:66 - Lost task 53.3 in stage 7.0 (TID 447, hadoop18.cusp.nyu.edu, executor 10): ExecutorLostFailure (executor 10 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:46:39 WARN  TaskSetManager:66 - Lost task 32.1 in stage 7.0 (TID 450, hadoop18.cusp.nyu.edu, executor 10): ExecutorLostFailure (executor 10 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:46:39 WARN  TaskSetManager:66 - Lost task 64.1 in stage 7.0 (TID 423, hadoop18.cusp.nyu.edu, executor 10): ExecutorLostFailure (executor 10 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:46:39 WARN  TaskSetManager:66 - Lost task 69.1 in stage 7.0 (TID 426, hadoop18.cusp.nyu.edu, executor 10): ExecutorLostFailure (executor 10 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:46:39 WARN  TaskSetManager:66 - Lost task 38.3 in stage 7.0 (TID 452, hadoop18.cusp.nyu.edu, executor 10): ExecutorLostFailure (executor 10 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:46:39 WARN  TaskSetManager:66 - Lost task 16.1 in stage 7.0 (TID 446, hadoop18.cusp.nyu.edu, executor 10): ExecutorLostFailure (executor 10 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:46:39 WARN  TaskSetManager:66 - Lost task 13.2 in stage 7.0 (TID 449, hadoop18.cusp.nyu.edu, executor 10): ExecutorLostFailure (executor 10 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
2021-05-19 02:46:39 INFO  BlockManagerMasterEndpoint:54 - Trying to remove executor 10 from BlockManagerMaster.
2021-05-19 02:46:39 INFO  BlockManagerMaster:54 - Removal of executor 10 requested
2021-05-19 02:46:39 INFO  YarnSchedulerBackend$YarnDriverEndpoint:54 - Asked to remove non-existent executor 10
2021-05-19 02:46:39 INFO  YarnClusterScheduler:54 - Cancelling stage 7
2021-05-19 02:46:39 INFO  YarnClusterScheduler:54 - Killing all running tasks in stage 7: Stage cancelled
2021-05-19 02:46:39 INFO  YarnClusterScheduler:54 - Stage 7 was cancelled
2021-05-19 02:46:39 INFO  DAGScheduler:54 - ShuffleMapStage 7 (csv at NativeMethodAccessorImpl.java:0) failed in 44.036 s due to Job aborted due to stage failure: Task 23 in stage 7.0 failed 4 times, most recent failure: Lost task 23.3 in stage 7.0 (TID 445, hadoop18.cusp.nyu.edu, executor 10): ExecutorLostFailure (executor 10 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
Driver stacktrace:
2021-05-19 02:46:39 INFO  DAGScheduler:54 - Job 6 failed: csv at NativeMethodAccessorImpl.java:0, took 44.059446 s
2021-05-19 02:46:39 ERROR FileFormatWriter:91 - Aborting job 7dad10e4-b8a3-4390-bae1-f7dddab21b1e.
org.apache.spark.SparkException: Job aborted due to stage failure: Task 23 in stage 7.0 failed 4 times, most recent failure: Lost task 23.3 in stage 7.0 (TID 445, hadoop18.cusp.nyu.edu, executor 10): ExecutorLostFailure (executor 10 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1887)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1875)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1874)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1874)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:926)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2108)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2057)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2046)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:737)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2061)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2082)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2101)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2126)
	at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:945)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:363)
	at org.apache.spark.rdd.RDD.collect(RDD.scala:944)
	at org.apache.spark.RangePartitioner$.sketch(Partitioner.scala:309)
	at org.apache.spark.RangePartitioner.<init>(Partitioner.scala:171)
	at org.apache.spark.sql.execution.exchange.ShuffleExchangeExec$.prepareShuffleDependency(ShuffleExchangeExec.scala:224)
	at org.apache.spark.sql.execution.exchange.ShuffleExchangeExec.prepareShuffleDependency(ShuffleExchangeExec.scala:91)
	at org.apache.spark.sql.execution.exchange.ShuffleExchangeExec$$anonfun$doExecute$1.apply(ShuffleExchangeExec.scala:128)
	at org.apache.spark.sql.execution.exchange.ShuffleExchangeExec$$anonfun$doExecute$1.apply(ShuffleExchangeExec.scala:119)
	at org.apache.spark.sql.catalyst.errors.package$.attachTree(package.scala:52)
	at org.apache.spark.sql.execution.exchange.ShuffleExchangeExec.doExecute(ShuffleExchangeExec.scala:119)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)
	at org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)
	at org.apache.spark.sql.execution.InputAdapter.inputRDDs(WholeStageCodegenExec.scala:374)
	at org.apache.spark.sql.execution.SortExec.inputRDDs(SortExec.scala:121)
	at org.apache.spark.sql.execution.WholeStageCodegenExec.doExecute(WholeStageCodegenExec.scala:610)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)
	at org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)
	at org.apache.spark.sql.execution.columnar.CachedRDDBuilder.buildBuffers(InMemoryRelation.scala:89)
	at org.apache.spark.sql.execution.columnar.CachedRDDBuilder.cachedColumnBuffers(InMemoryRelation.scala:59)
	at org.apache.spark.sql.execution.columnar.InMemoryTableScanExec.filteredCachedBatches(InMemoryTableScanExec.scala:276)
	at org.apache.spark.sql.execution.columnar.InMemoryTableScanExec.inputRDD$lzycompute(InMemoryTableScanExec.scala:105)
	at org.apache.spark.sql.execution.columnar.InMemoryTableScanExec.inputRDD(InMemoryTableScanExec.scala:104)
	at org.apache.spark.sql.execution.columnar.InMemoryTableScanExec.doExecute(InMemoryTableScanExec.scala:310)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)
	at org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)
	at org.apache.spark.sql.execution.InputAdapter.inputRDDs(WholeStageCodegenExec.scala:374)
	at org.apache.spark.sql.execution.FilterExec.inputRDDs(basicPhysicalOperators.scala:121)
	at org.apache.spark.sql.execution.ProjectExec.inputRDDs(basicPhysicalOperators.scala:41)
	at org.apache.spark.sql.execution.WholeStageCodegenExec.doExecute(WholeStageCodegenExec.scala:610)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)
	at org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)
	at org.apache.spark.sql.execution.CoalesceExec.doExecute(basicPhysicalOperators.scala:597)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)
	at org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:143)
	at org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand.run(InsertIntoHadoopFsRelationCommand.scala:159)
	at org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult$lzycompute(commands.scala:104)
	at org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult(commands.scala:102)
	at org.apache.spark.sql.execution.command.DataWritingCommandExec.doExecute(commands.scala:122)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)
	at org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)
	at org.apache.spark.sql.execution.QueryExecution.toRdd$lzycompute(QueryExecution.scala:80)
	at org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:80)
	at org.apache.spark.sql.DataFrameWriter$$anonfun$runCommand$1.apply(DataFrameWriter.scala:668)
	at org.apache.spark.sql.DataFrameWriter$$anonfun$runCommand$1.apply(DataFrameWriter.scala:668)
	at org.apache.spark.sql.execution.SQLExecution$$anonfun$withNewExecutionId$1.apply(SQLExecution.scala:78)
	at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:125)
	at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:73)
	at org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:668)
	at org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:276)
	at org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:270)
	at org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:228)
	at org.apache.spark.sql.DataFrameWriter.csv(DataFrameWriter.scala:656)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:282)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.GatewayConnection.run(GatewayConnection.java:238)
	at java.lang.Thread.run(Thread.java:748)
Traceback (most recent call last):
  File "BDM_HW4.py", line 93, in <module>
    main(sc, spark)
  File "BDM_HW4.py", line 86, in main
    mode='overwrite', header=True)
  File "/localhome/cdp/yarn/nm/usercache/catherine.ng60/appcache/application_1609183734776_5900/container_e10_1609183734776_5900_01_000001/pyspark.zip/pyspark/sql/readwriter.py", line 929, in csv
  File "/localhome/cdp/yarn/nm/usercache/catherine.ng60/appcache/application_1609183734776_5900/container_e10_1609183734776_5900_01_000001/py4j-0.10.7-src.zip/py4j/java_gateway.py", line 1257, in __call__
  File "/localhome/cdp/yarn/nm/usercache/catherine.ng60/appcache/application_1609183734776_5900/container_e10_1609183734776_5900_01_000001/pyspark.zip/pyspark/sql/utils.py", line 63, in deco
  File "/localhome/cdp/yarn/nm/usercache/catherine.ng60/appcache/application_1609183734776_5900/container_e10_1609183734776_5900_01_000001/py4j-0.10.7-src.zip/py4j/protocol.py", line 328, in get_return_value
py4j.protocol.Py4JJavaError: An error occurred while calling o179.csv.
: org.apache.spark.SparkException: Job aborted.
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:196)
	at org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand.run(InsertIntoHadoopFsRelationCommand.scala:159)
	at org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult$lzycompute(commands.scala:104)
	at org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult(commands.scala:102)
	at org.apache.spark.sql.execution.command.DataWritingCommandExec.doExecute(commands.scala:122)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)
	at org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)
	at org.apache.spark.sql.execution.QueryExecution.toRdd$lzycompute(QueryExecution.scala:80)
	at org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:80)
	at org.apache.spark.sql.DataFrameWriter$$anonfun$runCommand$1.apply(DataFrameWriter.scala:668)
	at org.apache.spark.sql.DataFrameWriter$$anonfun$runCommand$1.apply(DataFrameWriter.scala:668)
	at org.apache.spark.sql.execution.SQLExecution$$anonfun$withNewExecutionId$1.apply(SQLExecution.scala:78)
	at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:125)
	at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:73)
	at org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:668)
	at org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:276)
	at org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:270)
	at org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:228)
	at org.apache.spark.sql.DataFrameWriter.csv(DataFrameWriter.scala:656)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:282)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.GatewayConnection.run(GatewayConnection.java:238)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.spark.SparkException: Job aborted due to stage failure: Task 23 in stage 7.0 failed 4 times, most recent failure: Lost task 23.3 in stage 7.0 (TID 445, hadoop18.cusp.nyu.edu, executor 10): ExecutorLostFailure (executor 10 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits.  1.6 GB of 1.5 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead or disabling yarn.nodemanager.vmem-check-enabled because of YARN-4714.
Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1887)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1875)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1874)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1874)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:926)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2108)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2057)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2046)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:737)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2061)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2082)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2101)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2126)
	at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:945)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:363)
	at org.apache.spark.rdd.RDD.collect(RDD.scala:944)
	at org.apache.spark.RangePartitioner$.sketch(Partitioner.scala:309)
	at org.apache.spark.RangePartitioner.<init>(Partitioner.scala:171)
	at org.apache.spark.sql.execution.exchange.ShuffleExchangeExec$.prepareShuffleDependency(ShuffleExchangeExec.scala:224)
	at org.apache.spark.sql.execution.exchange.ShuffleExchangeExec.prepareShuffleDependency(ShuffleExchangeExec.scala:91)
	at org.apache.spark.sql.execution.exchange.ShuffleExchangeExec$$anonfun$doExecute$1.apply(ShuffleExchangeExec.scala:128)
	at org.apache.spark.sql.execution.exchange.ShuffleExchangeExec$$anonfun$doExecute$1.apply(ShuffleExchangeExec.scala:119)
	at org.apache.spark.sql.catalyst.errors.package$.attachTree(package.scala:52)
	at org.apache.spark.sql.execution.exchange.ShuffleExchangeExec.doExecute(ShuffleExchangeExec.scala:119)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)
	at org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)
	at org.apache.spark.sql.execution.InputAdapter.inputRDDs(WholeStageCodegenExec.scala:374)
	at org.apache.spark.sql.execution.SortExec.inputRDDs(SortExec.scala:121)
	at org.apache.spark.sql.execution.WholeStageCodegenExec.doExecute(WholeStageCodegenExec.scala:610)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)
	at org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)
	at org.apache.spark.sql.execution.columnar.CachedRDDBuilder.buildBuffers(InMemoryRelation.scala:89)
	at org.apache.spark.sql.execution.columnar.CachedRDDBuilder.cachedColumnBuffers(InMemoryRelation.scala:59)
	at org.apache.spark.sql.execution.columnar.InMemoryTableScanExec.filteredCachedBatches(InMemoryTableScanExec.scala:276)
	at org.apache.spark.sql.execution.columnar.InMemoryTableScanExec.inputRDD$lzycompute(InMemoryTableScanExec.scala:105)
	at org.apache.spark.sql.execution.columnar.InMemoryTableScanExec.inputRDD(InMemoryTableScanExec.scala:104)
	at org.apache.spark.sql.execution.columnar.InMemoryTableScanExec.doExecute(InMemoryTableScanExec.scala:310)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)
	at org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)
	at org.apache.spark.sql.execution.InputAdapter.inputRDDs(WholeStageCodegenExec.scala:374)
	at org.apache.spark.sql.execution.FilterExec.inputRDDs(basicPhysicalOperators.scala:121)
	at org.apache.spark.sql.execution.ProjectExec.inputRDDs(basicPhysicalOperators.scala:41)
	at org.apache.spark.sql.execution.WholeStageCodegenExec.doExecute(WholeStageCodegenExec.scala:610)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)
	at org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)
	at org.apache.spark.sql.execution.CoalesceExec.doExecute(basicPhysicalOperators.scala:597)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)
	at org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)
	at org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)
	at org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:143)
	... 33 more

2021-05-19 02:46:40 ERROR ApplicationMaster:70 - User application exited with status 1
2021-05-19 02:46:40 INFO  ApplicationMaster:54 - Final app status: FAILED, exitCode: 1, (reason: User application exited with status 1)
2021-05-19 02:46:40 INFO  SparkContext:54 - Invoking stop() from shutdown hook
2021-05-19 02:46:40 INFO  AbstractConnector:318 - Stopped Spark@42198ffd{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2021-05-19 02:46:40 INFO  SparkUI:54 - Stopped Spark web UI at http://hadoop05.cusp.nyu.edu:59983
2021-05-19 02:46:40 INFO  YarnAllocator:54 - Driver requested a total number of 0 executor(s).
2021-05-19 02:46:40 INFO  YarnClusterSchedulerBackend:54 - Shutting down all executors
2021-05-19 02:46:40 INFO  YarnSchedulerBackend$YarnDriverEndpoint:54 - Asking each executor to shut down
2021-05-19 02:46:40 INFO  SchedulerExtensionServices:54 - Stopping SchedulerExtensionServices
(serviceOption=None,
 services=List(),
 started=false)
2021-05-19 02:46:40 INFO  MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!
2021-05-19 02:46:40 INFO  MemoryStore:54 - MemoryStore cleared
2021-05-19 02:46:40 INFO  BlockManager:54 - BlockManager stopped
2021-05-19 02:46:40 INFO  BlockManagerMaster:54 - BlockManagerMaster stopped
2021-05-19 02:46:40 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!
2021-05-19 02:46:40 INFO  SparkContext:54 - Successfully stopped SparkContext
2021-05-19 02:46:40 INFO  ShutdownHookManager:54 - Shutdown hook called
2021-05-19 02:46:40 INFO  ShutdownHookManager:54 - Deleting directory /localhome/cdp/yarn/nm/usercache/catherine.ng60/appcache/application_1609183734776_5900/spark-c89f5475-b76b-4517-8fbc-42cfd8bcfa2d
2021-05-19 02:46:40 INFO  ShutdownHookManager:54 - Deleting directory /localhome/cdp/yarn/nm/usercache/catherine.ng60/appcache/application_1609183734776_5900/spark-c89f5475-b76b-4517-8fbc-42cfd8bcfa2d/pyspark-0d897e59-53ce-41d9-a61a-abe7b8697be7

End of LogType:stdout
***********************************************************************

Container: container_e10_1609183734776_5900_01_000016 on hadoop06.cusp.nyu.edu_8041
LogAggregationType: AGGREGATED
===================================================================================
LogType:container-localizer-syslog
LogLastModifiedTime:Wed May 19 02:48:17 -0400 2021
LogLength:506
LogContents:
2021-05-19 02:46:36,346 INFO [main] org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ContainerLocalizer: Disk Validator: yarn.nodemanager.disk-validator is loaded.
2021-05-19 02:46:37,689 WARN [ContainerLocalizer Downloader] org.apache.hadoop.ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ipc.StandbyException): Operation category READ is not supported in state standby. Visit https://s.apache.org/sbnn-error

End of LogType:container-localizer-syslog
*******************************************************************************************


End of LogType:prelaunch.err
******************************************************************************

Container: container_e10_1609183734776_5900_01_000016 on hadoop06.cusp.nyu.edu_8041
LogAggregationType: AGGREGATED
===================================================================================
LogType:prelaunch.out
LogLastModifiedTime:Wed May 19 02:48:17 -0400 2021
LogLength:70
LogContents:
Setting up env variables
Setting up job resources
Launching container

End of LogType:prelaunch.out
******************************************************************************

Container: container_e10_1609183734776_5900_01_000016 on hadoop06.cusp.nyu.edu_8041
LogAggregationType: AGGREGATED
===================================================================================
LogType:stderr
LogLastModifiedTime:Wed May 19 02:48:17 -0400 2021
LogLength:3152
LogContents:
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/localhome/cdp/yarn/nm/filecache/31/spark-jars-2.4.0-hadoop2.7.jar/slf4j-log4j12-1.7.16.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-6.1.0-1.cdh6.1.0.p0.770702/jars/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Exception in thread "main" java.lang.reflect.UndeclaredThrowableException
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1713)
	at org.apache.spark.deploy.SparkHadoopUtil.runAsSparkUser(SparkHadoopUtil.scala:64)
	at org.apache.spark.executor.CoarseGrainedExecutorBackend$.run(CoarseGrainedExecutorBackend.scala:188)
	at org.apache.spark.executor.CoarseGrainedExecutorBackend$.main(CoarseGrainedExecutorBackend.scala:281)
	at org.apache.spark.executor.CoarseGrainedExecutorBackend.main(CoarseGrainedExecutorBackend.scala)
Caused by: org.apache.spark.SparkException: Exception thrown in awaitResult: 
	at org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:226)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:101)
	at org.apache.spark.executor.CoarseGrainedExecutorBackend$$anonfun$run$1.apply$mcV$sp(CoarseGrainedExecutorBackend.scala:201)
	at org.apache.spark.deploy.SparkHadoopUtil$$anon$2.run(SparkHadoopUtil.scala:65)
	at org.apache.spark.deploy.SparkHadoopUtil$$anon$2.run(SparkHadoopUtil.scala:64)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1698)
	... 4 more
Caused by: java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileDispatcherImpl.read0(Native Method)
	at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)
	at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:223)
	at sun.nio.ch.IOUtil.read(IOUtil.java:192)
	at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:380)
	at io.netty.buffer.PooledUnsafeDirectByteBuf.setBytes(PooledUnsafeDirectByteBuf.java:288)
	at io.netty.buffer.AbstractByteBuf.writeBytes(AbstractByteBuf.java:1106)
	at io.netty.channel.socket.nio.NioSocketChannel.doReadBytes(NioSocketChannel.java:343)
	at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:123)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:645)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:580)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:497)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:459)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)

End of LogType:stderr
***********************************************************************

Container: container_e10_1609183734776_5900_01_000016 on hadoop06.cusp.nyu.edu_8041
LogAggregationType: AGGREGATED
===================================================================================
LogType:stdout
LogLastModifiedTime:Wed May 19 02:48:17 -0400 2021
LogLength:2688
LogContents:
2021-05-19 02:46:39 INFO  CoarseGrainedExecutorBackend:2566 - Started daemon with process name: 5839@hadoop06.cusp.nyu.edu
2021-05-19 02:46:39 INFO  SignalUtils:54 - Registered signal handler for TERM
2021-05-19 02:46:39 INFO  SignalUtils:54 - Registered signal handler for HUP
2021-05-19 02:46:39 INFO  SignalUtils:54 - Registered signal handler for INT
2021-05-19 02:46:40 INFO  SecurityManager:54 - Changing view acls to: catherine.ng60
2021-05-19 02:46:40 INFO  SecurityManager:54 - Changing modify acls to: catherine.ng60
2021-05-19 02:46:40 INFO  SecurityManager:54 - Changing view acls groups to: 
2021-05-19 02:46:40 INFO  SecurityManager:54 - Changing modify acls groups to: 
2021-05-19 02:46:40 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(catherine.ng60); groups with view permissions: Set(); users  with modify permissions: Set(catherine.ng60); groups with modify permissions: Set()
2021-05-19 02:46:40 INFO  TransportClientFactory:267 - Successfully created connection to hadoop05.cusp.nyu.edu/192.168.72.175:47481 after 124 ms (0 ms spent in bootstraps)
2021-05-19 02:46:40 WARN  TransportChannelHandler:78 - Exception in connection from hadoop05.cusp.nyu.edu/192.168.72.175:47481
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileDispatcherImpl.read0(Native Method)
	at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)
	at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:223)
	at sun.nio.ch.IOUtil.read(IOUtil.java:192)
	at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:380)
	at io.netty.buffer.PooledUnsafeDirectByteBuf.setBytes(PooledUnsafeDirectByteBuf.java:288)
	at io.netty.buffer.AbstractByteBuf.writeBytes(AbstractByteBuf.java:1106)
	at io.netty.channel.socket.nio.NioSocketChannel.doReadBytes(NioSocketChannel.java:343)
	at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:123)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:645)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:580)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:497)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:459)
	at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138)
	at java.lang.Thread.run(Thread.java:748)
2021-05-19 02:46:40 ERROR TransportResponseHandler:154 - Still have 1 requests outstanding when connection from hadoop05.cusp.nyu.edu/192.168.72.175:47481 is closed

End of LogType:stdout
***********************************************************************


End of LogType:prelaunch.err
******************************************************************************

Container: container_e10_1609183734776_5900_02_000013 on hadoop06.cusp.nyu.edu_8041
LogAggregationType: AGGREGATED
===================================================================================
LogType:prelaunch.out
LogLastModifiedTime:Wed May 19 02:48:17 -0400 2021
LogLength:70
LogContents:
Setting up env variables
Setting up job resources
Launching container

End of LogType:prelaunch.out
******************************************************************************

Container: container_e10_1609183734776_5900_02_000013 on hadoop06.cusp.nyu.edu_8041
LogAggregationType: AGGREGATED
===================================================================================
LogType:stderr
LogLastModifiedTime:Wed May 19 02:48:17 -0400 2021
LogLength:529
LogContents:
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/localhome/cdp/yarn/nm/filecache/31/spark-jars-2.4.0-hadoop2.7.jar/slf4j-log4j12-1.7.16.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-6.1.0-1.cdh6.1.0.p0.770702/jars/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]

End of LogType:stderr
***********************************************************************

Container: container_e10_1609183734776_5900_02_000013 on hadoop06.cusp.nyu.edu_8041
LogAggregationType: AGGREGATED
===================================================================================
LogType:stdout
LogLastModifiedTime:Wed May 19 02:48:17 -0400 2021
LogLength:17330
LogContents:
2021-05-19 02:47:55 INFO  CoarseGrainedExecutorBackend:2566 - Started daemon with process name: 6842@hadoop06.cusp.nyu.edu
2021-05-19 02:47:55 INFO  SignalUtils:54 - Registered signal handler for TERM
2021-05-19 02:47:55 INFO  SignalUtils:54 - Registered signal handler for HUP
2021-05-19 02:47:55 INFO  SignalUtils:54 - Registered signal handler for INT
2021-05-19 02:47:56 INFO  SecurityManager:54 - Changing view acls to: catherine.ng60
2021-05-19 02:47:56 INFO  SecurityManager:54 - Changing modify acls to: catherine.ng60
2021-05-19 02:47:56 INFO  SecurityManager:54 - Changing view acls groups to: 
2021-05-19 02:47:56 INFO  SecurityManager:54 - Changing modify acls groups to: 
2021-05-19 02:47:56 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(catherine.ng60); groups with view permissions: Set(); users  with modify permissions: Set(catherine.ng60); groups with modify permissions: Set()
2021-05-19 02:47:57 INFO  TransportClientFactory:267 - Successfully created connection to hadoop02.cusp.nyu.edu/192.168.72.172:60108 after 120 ms (0 ms spent in bootstraps)
2021-05-19 02:47:57 INFO  SecurityManager:54 - Changing view acls to: catherine.ng60
2021-05-19 02:47:57 INFO  SecurityManager:54 - Changing modify acls to: catherine.ng60
2021-05-19 02:47:57 INFO  SecurityManager:54 - Changing view acls groups to: 
2021-05-19 02:47:57 INFO  SecurityManager:54 - Changing modify acls groups to: 
2021-05-19 02:47:57 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(catherine.ng60); groups with view permissions: Set(); users  with modify permissions: Set(catherine.ng60); groups with modify permissions: Set()
2021-05-19 02:47:57 INFO  TransportClientFactory:267 - Successfully created connection to hadoop02.cusp.nyu.edu/192.168.72.172:60108 after 4 ms (0 ms spent in bootstraps)
2021-05-19 02:47:57 INFO  DiskBlockManager:54 - Created local directory at /localhome/cdp/yarn/nm/usercache/catherine.ng60/appcache/application_1609183734776_5900/blockmgr-51171e5e-a5db-4812-b18a-e55ac687ef60
2021-05-19 02:47:57 INFO  MemoryStore:54 - MemoryStore started with capacity 366.3 MB
2021-05-19 02:47:57 INFO  CoarseGrainedExecutorBackend:54 - Connecting to driver: spark://CoarseGrainedScheduler@hadoop02.cusp.nyu.edu:60108
2021-05-19 02:47:57 INFO  CoarseGrainedExecutorBackend:54 - Successfully registered with driver
2021-05-19 02:47:57 INFO  Executor:54 - Starting executor ID 12 on host hadoop06.cusp.nyu.edu
2021-05-19 02:47:58 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 44467.
2021-05-19 02:47:58 INFO  NettyBlockTransferService:54 - Server created on hadoop06.cusp.nyu.edu:44467
2021-05-19 02:47:58 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2021-05-19 02:47:58 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(12, hadoop06.cusp.nyu.edu, 44467, None)
2021-05-19 02:47:58 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(12, hadoop06.cusp.nyu.edu, 44467, None)
2021-05-19 02:47:58 INFO  BlockManager:54 - external shuffle service port = 7337
2021-05-19 02:47:58 INFO  BlockManager:54 - Registering executor with local external shuffle service.
2021-05-19 02:47:58 INFO  TransportClientFactory:267 - Successfully created connection to hadoop06.cusp.nyu.edu/192.168.72.176:7337 after 3 ms (0 ms spent in bootstraps)
2021-05-19 02:47:58 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(12, hadoop06.cusp.nyu.edu, 44467, None)
2021-05-19 02:47:58 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 432
2021-05-19 02:47:58 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 433
2021-05-19 02:47:58 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 434
2021-05-19 02:47:58 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 435
2021-05-19 02:47:58 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 436
2021-05-19 02:47:58 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 437
2021-05-19 02:47:58 INFO  Executor:54 - Running task 47.3 in stage 7.0 (TID 432)
2021-05-19 02:47:58 INFO  Executor:54 - Running task 2.2 in stage 7.0 (TID 437)
2021-05-19 02:47:58 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 438
2021-05-19 02:47:58 INFO  Executor:54 - Running task 18.2 in stage 7.0 (TID 433)
2021-05-19 02:47:58 INFO  Executor:54 - Running task 39.2 in stage 7.0 (TID 435)
2021-05-19 02:47:58 INFO  Executor:54 - Running task 17.2 in stage 7.0 (TID 434)
2021-05-19 02:47:58 INFO  Executor:54 - Running task 25.2 in stage 7.0 (TID 436)
2021-05-19 02:47:58 INFO  Executor:54 - Running task 0.2 in stage 7.0 (TID 438)
2021-05-19 02:47:58 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 439
2021-05-19 02:47:58 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 440
2021-05-19 02:47:58 INFO  Executor:54 - Running task 7.2 in stage 7.0 (TID 439)
2021-05-19 02:47:58 INFO  Executor:54 - Running task 36.2 in stage 7.0 (TID 440)
2021-05-19 02:47:58 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 441
2021-05-19 02:47:58 INFO  Executor:54 - Running task 33.2 in stage 7.0 (TID 441)
2021-05-19 02:47:58 INFO  MapOutputTrackerWorker:54 - Updating epoch to 1 and clearing cache
2021-05-19 02:47:58 INFO  TorrentBroadcast:54 - Started reading broadcast variable 14
2021-05-19 02:47:58 INFO  TransportClientFactory:267 - Successfully created connection to hadoop02.cusp.nyu.edu/192.168.72.172:49352 after 3 ms (0 ms spent in bootstraps)
2021-05-19 02:47:58 INFO  MemoryStore:54 - Block broadcast_14_piece0 stored as bytes in memory (estimated size 22.9 KB, free 366.3 MB)
2021-05-19 02:47:58 INFO  TorrentBroadcast:54 - Reading broadcast variable 14 took 122 ms
2021-05-19 02:47:58 INFO  MemoryStore:54 - Block broadcast_14 stored as values in memory (estimated size 51.4 KB, free 366.2 MB)
2021-05-19 02:48:00 INFO  CodeGenerator:54 - Code generated in 375.541453 ms
2021-05-19 02:48:00 INFO  TorrentBroadcast:54 - Started reading broadcast variable 12
2021-05-19 02:48:00 INFO  MemoryStore:54 - Block broadcast_12_piece0 stored as bytes in memory (estimated size 580.1 KB, free 365.7 MB)
2021-05-19 02:48:00 INFO  TorrentBroadcast:54 - Reading broadcast variable 12 took 35 ms
2021-05-19 02:48:00 INFO  MemoryStore:54 - Block broadcast_12 stored as values in memory (estimated size 5.0 MB, free 360.7 MB)
2021-05-19 02:48:00 INFO  CodeGenerator:54 - Code generated in 45.396065 ms
2021-05-19 02:48:01 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00002, range: 0-134217728, partition values: [empty row]
2021-05-19 02:48:01 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00000, range: 0-134217728, partition values: [empty row]
2021-05-19 02:48:01 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00007, range: 0-134217728, partition values: [empty row]
2021-05-19 02:48:01 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00018, range: 0-134217728, partition values: [empty row]
2021-05-19 02:48:01 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00033, range: 0-134217728, partition values: [empty row]
2021-05-19 02:48:01 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00039, range: 0-134217728, partition values: [empty row]
2021-05-19 02:48:01 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00025, range: 0-134217728, partition values: [empty row]
2021-05-19 02:48:01 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00047, range: 0-134217728, partition values: [empty row]
2021-05-19 02:48:01 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00036, range: 0-134217728, partition values: [empty row]
2021-05-19 02:48:01 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00017, range: 0-134217728, partition values: [empty row]
2021-05-19 02:48:01 INFO  CodeGenerator:54 - Code generated in 72.162574 ms
2021-05-19 02:48:01 INFO  TorrentBroadcast:54 - Started reading broadcast variable 13
2021-05-19 02:48:01 INFO  MemoryStore:54 - Block broadcast_13_piece0 stored as bytes in memory (estimated size 33.4 KB, free 360.6 MB)
2021-05-19 02:48:01 INFO  TorrentBroadcast:54 - Reading broadcast variable 13 took 26 ms
2021-05-19 02:48:01 INFO  CodeGenerator:54 - Code generated in 91.564111 ms
2021-05-19 02:48:01 INFO  CodeGenerator:54 - Code generated in 37.879029 ms
2021-05-19 02:48:01 INFO  CodeGenerator:54 - Code generated in 49.904062 ms
2021-05-19 02:48:01 INFO  CodeGenerator:54 - Code generated in 35.631798 ms
2021-05-19 02:48:01 INFO  MemoryStore:54 - Block broadcast_13 stored as values in memory (estimated size 506.4 KB, free 360.1 MB)
2021-05-19 02:48:03 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: 22t-223@627-wc7-vcq, 2019-07-15T00:00:00-04:00, [6,4,9,8,6,5,7]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: 22t-223@627-wc7-vcq
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00033
2021-05-19 02:48:03 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: 222-222@627-sbc-pqf, 2018-12-31T00:00:00-05:00, [4,4,28,20,22,6,8]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: 222-222@627-sbc-pqf
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00007
2021-05-19 02:48:03 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: zzw-222@627-wc2-5fz, 2020-06-15T00:00:00-04:00, [0,2,1,1,1,2,0]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: zzw-222@627-wc2-5fz
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00025
2021-05-19 02:48:03 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: 22k-222@627-vsp-3wk, 2020-08-10T00:00:00-04:00, [0,1,1,0,0,2,0]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: 22k-222@627-vsp-3wk
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00018
2021-05-19 02:48:03 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: 22j-222@627-w9f-wff, 2020-07-27T00:00:00-04:00, [6,7,14,14,7,7,8]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: 22j-222@627-w9f-wff
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00036
2021-05-19 02:48:03 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: 227-224@627-s6m-yn5, 2020-06-15T00:00:00-04:00, [1,1,4,4,3,1,6]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: 227-224@627-s6m-yn5
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00017
2021-05-19 02:48:03 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: 222-222@627-vsg-8n5, 2020-05-04T00:00:00-04:00, [3,1,2,2,5,3,2]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: 222-222@627-vsg-8n5
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00047
2021-05-19 02:48:03 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: 226-223@627-wgt-z2k, 2018-12-31T00:00:00-05:00, [0,0,0,0,2,0,0]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: 226-223@627-wgt-z2k
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00002
2021-05-19 02:48:03 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: 22x-222@627-wgt-snq, 2020-07-13T00:00:00-04:00, [1,1,1,4,2,1,6]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: 22x-222@627-wgt-snq
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00039
2021-05-19 02:48:03 INFO  CodeGenerator:54 - Code generated in 46.414995 ms
2021-05-19 02:48:03 INFO  CodeGenerator:54 - Code generated in 25.891437 ms
2021-05-19 02:48:03 INFO  CodeGenerator:54 - Code generated in 29.380031 ms
2021-05-19 02:48:04 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:48:04 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:48:04 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:48:04 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:48:04 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:48:04 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:48:04 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:48:04 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:48:04 INFO  CodeGenerator:54 - Code generated in 55.053081 ms
2021-05-19 02:48:04 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:48:04 INFO  CodeGenerator:54 - Code generated in 27.212388 ms
2021-05-19 02:48:04 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:48:04 INFO  CodeGenerator:54 - Code generated in 22.124691 ms
2021-05-19 02:48:04 INFO  CodeGenerator:54 - Code generated in 23.661441 ms
2021-05-19 02:48:14 INFO  PythonUDFRunner:54 - Times: total = 13623, boot = 692, init = 2324, finish = 10607
2021-05-19 02:48:14 INFO  PythonUDFRunner:54 - Times: total = 13698, boot = 742, init = 2278, finish = 10678
2021-05-19 02:48:14 INFO  PythonUDFRunner:54 - Times: total = 14033, boot = 723, init = 2288, finish = 11022
2021-05-19 02:48:14 INFO  CodeGenerator:54 - Code generated in 28.75881 ms
2021-05-19 02:48:14 INFO  PythonUDFRunner:54 - Times: total = 14226, boot = 751, init = 2265, finish = 11210
2021-05-19 02:48:14 INFO  PythonUDFRunner:54 - Times: total = 14326, boot = 770, init = 2245, finish = 11311
2021-05-19 02:48:14 INFO  PythonUDFRunner:54 - Times: total = 14439, boot = 781, init = 2240, finish = 11418
2021-05-19 02:48:15 INFO  PythonUDFRunner:54 - Times: total = 14476, boot = 761, init = 2259, finish = 11456
2021-05-19 02:48:15 INFO  PythonUDFRunner:54 - Times: total = 14644, boot = 703, init = 2314, finish = 11627
2021-05-19 02:48:15 INFO  PythonUDFRunner:54 - Times: total = 14668, boot = 733, init = 2282, finish = 11653
2021-05-19 02:48:15 INFO  PythonUDFRunner:54 - Times: total = 14740, boot = 713, init = 2314, finish = 11713
2021-05-19 02:48:15 ERROR CoarseGrainedExecutorBackend:43 - RECEIVED SIGNAL TERM
2021-05-19 02:48:15 INFO  DiskBlockManager:54 - Shutdown hook called
2021-05-19 02:48:15 INFO  ShutdownHookManager:54 - Shutdown hook called
2021-05-19 02:48:15 INFO  ShutdownHookManager:54 - Deleting directory /localhome/cdp/yarn/nm/usercache/catherine.ng60/appcache/application_1609183734776_5900/spark-965ffa17-ea4c-415f-900d-410c10a1fa0e

End of LogType:stdout
***********************************************************************


End of LogType:prelaunch.err
******************************************************************************

Container: container_e10_1609183734776_5900_02_000005 on hadoop06.cusp.nyu.edu_8041
LogAggregationType: AGGREGATED
===================================================================================
LogType:prelaunch.out
LogLastModifiedTime:Wed May 19 02:48:17 -0400 2021
LogLength:70
LogContents:
Setting up env variables
Setting up job resources
Launching container

End of LogType:prelaunch.out
******************************************************************************

Container: container_e10_1609183734776_5900_02_000005 on hadoop06.cusp.nyu.edu_8041
LogAggregationType: AGGREGATED
===================================================================================
LogType:stderr
LogLastModifiedTime:Wed May 19 02:48:17 -0400 2021
LogLength:529
LogContents:
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/localhome/cdp/yarn/nm/filecache/31/spark-jars-2.4.0-hadoop2.7.jar/slf4j-log4j12-1.7.16.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-6.1.0-1.cdh6.1.0.p0.770702/jars/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]

End of LogType:stderr
***********************************************************************

Container: container_e10_1609183734776_5900_02_000005 on hadoop06.cusp.nyu.edu_8041
LogAggregationType: AGGREGATED
===================================================================================
LogType:stdout
LogLastModifiedTime:Wed May 19 02:48:17 -0400 2021
LogLength:47136
LogContents:
2021-05-19 02:46:52 INFO  CoarseGrainedExecutorBackend:2566 - Started daemon with process name: 5997@hadoop06.cusp.nyu.edu
2021-05-19 02:46:52 INFO  SignalUtils:54 - Registered signal handler for TERM
2021-05-19 02:46:52 INFO  SignalUtils:54 - Registered signal handler for HUP
2021-05-19 02:46:52 INFO  SignalUtils:54 - Registered signal handler for INT
2021-05-19 02:46:53 INFO  SecurityManager:54 - Changing view acls to: catherine.ng60
2021-05-19 02:46:53 INFO  SecurityManager:54 - Changing modify acls to: catherine.ng60
2021-05-19 02:46:53 INFO  SecurityManager:54 - Changing view acls groups to: 
2021-05-19 02:46:53 INFO  SecurityManager:54 - Changing modify acls groups to: 
2021-05-19 02:46:53 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(catherine.ng60); groups with view permissions: Set(); users  with modify permissions: Set(catherine.ng60); groups with modify permissions: Set()
2021-05-19 02:46:54 INFO  TransportClientFactory:267 - Successfully created connection to hadoop02.cusp.nyu.edu/192.168.72.172:60108 after 126 ms (0 ms spent in bootstraps)
2021-05-19 02:46:54 INFO  SecurityManager:54 - Changing view acls to: catherine.ng60
2021-05-19 02:46:54 INFO  SecurityManager:54 - Changing modify acls to: catherine.ng60
2021-05-19 02:46:54 INFO  SecurityManager:54 - Changing view acls groups to: 
2021-05-19 02:46:54 INFO  SecurityManager:54 - Changing modify acls groups to: 
2021-05-19 02:46:54 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(catherine.ng60); groups with view permissions: Set(); users  with modify permissions: Set(catherine.ng60); groups with modify permissions: Set()
2021-05-19 02:46:54 INFO  TransportClientFactory:267 - Successfully created connection to hadoop02.cusp.nyu.edu/192.168.72.172:60108 after 3 ms (0 ms spent in bootstraps)
2021-05-19 02:46:55 INFO  DiskBlockManager:54 - Created local directory at /localhome/cdp/yarn/nm/usercache/catherine.ng60/appcache/application_1609183734776_5900/blockmgr-312a13f3-e4d4-4475-8bae-ecc91f22225e
2021-05-19 02:46:55 INFO  MemoryStore:54 - MemoryStore started with capacity 366.3 MB
2021-05-19 02:46:55 INFO  CoarseGrainedExecutorBackend:54 - Connecting to driver: spark://CoarseGrainedScheduler@hadoop02.cusp.nyu.edu:60108
2021-05-19 02:46:55 INFO  CoarseGrainedExecutorBackend:54 - Successfully registered with driver
2021-05-19 02:46:55 INFO  Executor:54 - Starting executor ID 4 on host hadoop06.cusp.nyu.edu
2021-05-19 02:46:55 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 53410.
2021-05-19 02:46:55 INFO  NettyBlockTransferService:54 - Server created on hadoop06.cusp.nyu.edu:53410
2021-05-19 02:46:55 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2021-05-19 02:46:55 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(4, hadoop06.cusp.nyu.edu, 53410, None)
2021-05-19 02:46:55 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(4, hadoop06.cusp.nyu.edu, 53410, None)
2021-05-19 02:46:55 INFO  BlockManager:54 - external shuffle service port = 7337
2021-05-19 02:46:55 INFO  BlockManager:54 - Registering executor with local external shuffle service.
2021-05-19 02:46:55 INFO  TransportClientFactory:267 - Successfully created connection to hadoop06.cusp.nyu.edu/192.168.72.176:7337 after 2 ms (0 ms spent in bootstraps)
2021-05-19 02:46:55 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(4, hadoop06.cusp.nyu.edu, 53410, None)
2021-05-19 02:47:04 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 1
2021-05-19 02:47:04 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 6
2021-05-19 02:47:04 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 11
2021-05-19 02:47:04 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 16
2021-05-19 02:47:04 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 21
2021-05-19 02:47:04 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 26
2021-05-19 02:47:04 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 31
2021-05-19 02:47:04 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 36
2021-05-19 02:47:04 INFO  Executor:54 - Running task 5.0 in stage 1.0 (TID 6)
2021-05-19 02:47:04 INFO  Executor:54 - Running task 25.0 in stage 1.0 (TID 26)
2021-05-19 02:47:04 INFO  Executor:54 - Running task 15.0 in stage 1.0 (TID 16)
2021-05-19 02:47:04 INFO  Executor:54 - Running task 35.0 in stage 1.0 (TID 36)
2021-05-19 02:47:04 INFO  Executor:54 - Running task 10.0 in stage 1.0 (TID 11)
2021-05-19 02:47:04 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 41
2021-05-19 02:47:04 INFO  Executor:54 - Running task 0.0 in stage 1.0 (TID 1)
2021-05-19 02:47:04 INFO  Executor:54 - Running task 20.0 in stage 1.0 (TID 21)
2021-05-19 02:47:04 INFO  Executor:54 - Running task 30.0 in stage 1.0 (TID 31)
2021-05-19 02:47:04 INFO  Executor:54 - Running task 40.0 in stage 1.0 (TID 41)
2021-05-19 02:47:04 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 46
2021-05-19 02:47:04 INFO  Executor:54 - Running task 45.0 in stage 1.0 (TID 46)
2021-05-19 02:47:05 INFO  TorrentBroadcast:54 - Started reading broadcast variable 3
2021-05-19 02:47:05 INFO  TransportClientFactory:267 - Successfully created connection to hadoop17.cusp.nyu.edu/192.168.72.187:39842 after 5 ms (0 ms spent in bootstraps)
2021-05-19 02:47:05 INFO  MemoryStore:54 - Block broadcast_3_piece0 stored as bytes in memory (estimated size 35.0 KB, free 366.3 MB)
2021-05-19 02:47:05 INFO  TorrentBroadcast:54 - Reading broadcast variable 3 took 202 ms
2021-05-19 02:47:05 INFO  MemoryStore:54 - Block broadcast_3 stored as values in memory (estimated size 129.0 KB, free 366.1 MB)
2021-05-19 02:47:07 INFO  Executor:54 - Finished task 0.0 in stage 1.0 (TID 1). 837 bytes result sent to driver
2021-05-19 02:47:07 INFO  Executor:54 - Finished task 35.0 in stage 1.0 (TID 36). 1492 bytes result sent to driver
2021-05-19 02:47:07 INFO  Executor:54 - Finished task 5.0 in stage 1.0 (TID 6). 1492 bytes result sent to driver
2021-05-19 02:47:07 INFO  Executor:54 - Finished task 25.0 in stage 1.0 (TID 26). 1492 bytes result sent to driver
2021-05-19 02:47:07 INFO  Executor:54 - Finished task 20.0 in stage 1.0 (TID 21). 1492 bytes result sent to driver
2021-05-19 02:47:07 INFO  Executor:54 - Finished task 30.0 in stage 1.0 (TID 31). 1492 bytes result sent to driver
2021-05-19 02:47:07 INFO  Executor:54 - Finished task 15.0 in stage 1.0 (TID 16). 1492 bytes result sent to driver
2021-05-19 02:47:07 INFO  Executor:54 - Finished task 45.0 in stage 1.0 (TID 46). 1492 bytes result sent to driver
2021-05-19 02:47:07 INFO  Executor:54 - Finished task 40.0 in stage 1.0 (TID 41). 1492 bytes result sent to driver
2021-05-19 02:47:07 INFO  Executor:54 - Finished task 10.0 in stage 1.0 (TID 11). 1492 bytes result sent to driver
2021-05-19 02:47:08 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 51
2021-05-19 02:47:08 INFO  Executor:54 - Running task 0.0 in stage 2.0 (TID 51)
2021-05-19 02:47:08 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 56
2021-05-19 02:47:08 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 61
2021-05-19 02:47:08 INFO  Executor:54 - Running task 5.0 in stage 2.0 (TID 56)
2021-05-19 02:47:08 INFO  Executor:54 - Running task 10.0 in stage 2.0 (TID 61)
2021-05-19 02:47:08 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 66
2021-05-19 02:47:08 INFO  Executor:54 - Running task 15.0 in stage 2.0 (TID 66)
2021-05-19 02:47:08 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 71
2021-05-19 02:47:08 INFO  Executor:54 - Running task 20.0 in stage 2.0 (TID 71)
2021-05-19 02:47:08 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 76
2021-05-19 02:47:08 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 81
2021-05-19 02:47:08 INFO  Executor:54 - Running task 25.0 in stage 2.0 (TID 76)
2021-05-19 02:47:08 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 86
2021-05-19 02:47:08 INFO  Executor:54 - Running task 30.0 in stage 2.0 (TID 81)
2021-05-19 02:47:08 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 91
2021-05-19 02:47:08 INFO  Executor:54 - Running task 35.0 in stage 2.0 (TID 86)
2021-05-19 02:47:08 INFO  Executor:54 - Running task 40.0 in stage 2.0 (TID 91)
2021-05-19 02:47:08 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 96
2021-05-19 02:47:08 INFO  Executor:54 - Running task 45.0 in stage 2.0 (TID 96)
2021-05-19 02:47:08 INFO  TorrentBroadcast:54 - Started reading broadcast variable 4
2021-05-19 02:47:08 INFO  TransportClientFactory:267 - Successfully created connection to hadoop02.cusp.nyu.edu/192.168.72.172:49352 after 4 ms (0 ms spent in bootstraps)
2021-05-19 02:47:08 INFO  MemoryStore:54 - Block broadcast_4_piece0 stored as bytes in memory (estimated size 35.0 KB, free 366.1 MB)
2021-05-19 02:47:08 INFO  TorrentBroadcast:54 - Reading broadcast variable 4 took 50 ms
2021-05-19 02:47:08 INFO  MemoryStore:54 - Block broadcast_4 stored as values in memory (estimated size 129.0 KB, free 366.0 MB)
2021-05-19 02:47:08 INFO  Executor:54 - Finished task 5.0 in stage 2.0 (TID 56). 1449 bytes result sent to driver
2021-05-19 02:47:08 INFO  Executor:54 - Finished task 30.0 in stage 2.0 (TID 81). 1449 bytes result sent to driver
2021-05-19 02:47:08 INFO  Executor:54 - Finished task 0.0 in stage 2.0 (TID 51). 1449 bytes result sent to driver
2021-05-19 02:47:08 INFO  Executor:54 - Finished task 35.0 in stage 2.0 (TID 86). 1449 bytes result sent to driver
2021-05-19 02:47:08 INFO  Executor:54 - Finished task 40.0 in stage 2.0 (TID 91). 1449 bytes result sent to driver
2021-05-19 02:47:08 INFO  Executor:54 - Finished task 25.0 in stage 2.0 (TID 76). 1449 bytes result sent to driver
2021-05-19 02:47:08 INFO  Executor:54 - Finished task 45.0 in stage 2.0 (TID 96). 1449 bytes result sent to driver
2021-05-19 02:47:08 INFO  Executor:54 - Finished task 20.0 in stage 2.0 (TID 71). 1449 bytes result sent to driver
2021-05-19 02:47:08 INFO  Executor:54 - Finished task 10.0 in stage 2.0 (TID 61). 1449 bytes result sent to driver
2021-05-19 02:47:08 INFO  Executor:54 - Finished task 15.0 in stage 2.0 (TID 66). 1406 bytes result sent to driver
2021-05-19 02:47:09 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 100
2021-05-19 02:47:09 INFO  Executor:54 - Running task 0.0 in stage 3.0 (TID 100)
2021-05-19 02:47:09 INFO  TorrentBroadcast:54 - Started reading broadcast variable 6
2021-05-19 02:47:09 INFO  MemoryStore:54 - Block broadcast_6_piece0 stored as bytes in memory (estimated size 4.5 KB, free 366.1 MB)
2021-05-19 02:47:09 INFO  TorrentBroadcast:54 - Reading broadcast variable 6 took 22 ms
2021-05-19 02:47:09 INFO  MemoryStore:54 - Block broadcast_6 stored as values in memory (estimated size 8.8 KB, free 366.1 MB)
2021-05-19 02:47:09 INFO  CodeGenerator:54 - Code generated in 277.587909 ms
2021-05-19 02:47:09 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00000, range: 0-134217728, partition values: [empty row]
2021-05-19 02:47:09 INFO  CodeGenerator:54 - Code generated in 25.890649 ms
2021-05-19 02:47:09 INFO  TorrentBroadcast:54 - Started reading broadcast variable 5
2021-05-19 02:47:09 INFO  MemoryStore:54 - Block broadcast_5_piece0 stored as bytes in memory (estimated size 33.4 KB, free 366.1 MB)
2021-05-19 02:47:09 INFO  TorrentBroadcast:54 - Reading broadcast variable 5 took 20 ms
2021-05-19 02:47:09 INFO  MemoryStore:54 - Block broadcast_5 stored as values in memory (estimated size 506.4 KB, free 365.6 MB)
2021-05-19 02:47:09 INFO  Executor:54 - Finished task 0.0 in stage 3.0 (TID 100). 1646 bytes result sent to driver
2021-05-19 02:47:14 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 119
2021-05-19 02:47:14 INFO  Executor:54 - Running task 1.0 in stage 5.0 (TID 119)
2021-05-19 02:47:14 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 124
2021-05-19 02:47:14 INFO  Executor:54 - Running task 7.0 in stage 5.0 (TID 124)
2021-05-19 02:47:14 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 128
2021-05-19 02:47:14 INFO  Executor:54 - Running task 11.0 in stage 5.0 (TID 128)
2021-05-19 02:47:14 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 132
2021-05-19 02:47:14 INFO  Executor:54 - Running task 15.0 in stage 5.0 (TID 132)
2021-05-19 02:47:14 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 136
2021-05-19 02:47:14 INFO  Executor:54 - Running task 20.0 in stage 5.0 (TID 136)
2021-05-19 02:47:14 INFO  MapOutputTrackerWorker:54 - Updating epoch to 1 and clearing cache
2021-05-19 02:47:14 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 140
2021-05-19 02:47:14 INFO  Executor:54 - Running task 24.0 in stage 5.0 (TID 140)
2021-05-19 02:47:14 INFO  TorrentBroadcast:54 - Started reading broadcast variable 10
2021-05-19 02:47:14 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 144
2021-05-19 02:47:14 INFO  Executor:54 - Running task 29.0 in stage 5.0 (TID 144)
2021-05-19 02:47:14 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 148
2021-05-19 02:47:14 INFO  Executor:54 - Running task 33.0 in stage 5.0 (TID 148)
2021-05-19 02:47:14 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 152
2021-05-19 02:47:14 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 156
2021-05-19 02:47:14 INFO  Executor:54 - Running task 38.0 in stage 5.0 (TID 152)
2021-05-19 02:47:14 INFO  Executor:54 - Running task 42.0 in stage 5.0 (TID 156)
2021-05-19 02:47:14 INFO  MemoryStore:54 - Block broadcast_10_piece0 stored as bytes in memory (estimated size 20.4 KB, free 366.3 MB)
2021-05-19 02:47:14 INFO  TorrentBroadcast:54 - Reading broadcast variable 10 took 28 ms
2021-05-19 02:47:14 INFO  MemoryStore:54 - Block broadcast_10 stored as values in memory (estimated size 40.9 KB, free 366.2 MB)
2021-05-19 02:47:14 INFO  MapOutputTrackerWorker:54 - Don't have map outputs for shuffle 0, fetching them
2021-05-19 02:47:14 INFO  MapOutputTrackerWorker:54 - Don't have map outputs for shuffle 0, fetching them
2021-05-19 02:47:14 INFO  MapOutputTrackerWorker:54 - Don't have map outputs for shuffle 0, fetching them
2021-05-19 02:47:14 INFO  MapOutputTrackerWorker:54 - Don't have map outputs for shuffle 0, fetching them
2021-05-19 02:47:14 INFO  MapOutputTrackerWorker:54 - Don't have map outputs for shuffle 0, fetching them
2021-05-19 02:47:14 INFO  MapOutputTrackerWorker:54 - Don't have map outputs for shuffle 0, fetching them
2021-05-19 02:47:14 INFO  MapOutputTrackerWorker:54 - Don't have map outputs for shuffle 0, fetching them
2021-05-19 02:47:14 INFO  MapOutputTrackerWorker:54 - Don't have map outputs for shuffle 0, fetching them
2021-05-19 02:47:14 INFO  MapOutputTrackerWorker:54 - Don't have map outputs for shuffle 0, fetching them
2021-05-19 02:47:14 INFO  MapOutputTrackerWorker:54 - Doing the fetch; tracker endpoint = NettyRpcEndpointRef(spark://MapOutputTracker@hadoop02.cusp.nyu.edu:60108)
2021-05-19 02:47:14 INFO  MapOutputTrackerWorker:54 - Don't have map outputs for shuffle 0, fetching them
2021-05-19 02:47:14 INFO  MapOutputTrackerWorker:54 - Got the output locations
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 9 ms
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 10 ms
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 10 ms
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 10 ms
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 7 ms
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 9 ms
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 15 ms
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 15 ms
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 12 ms
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 11 ms
2021-05-19 02:47:14 INFO  CodeGenerator:54 - Code generated in 78.836188 ms
2021-05-19 02:47:14 INFO  CodeGenerator:54 - Code generated in 30.945191 ms
2021-05-19 02:47:14 INFO  CodeGenerator:54 - Code generated in 15.126258 ms
2021-05-19 02:47:15 INFO  Executor:54 - Finished task 42.0 in stage 5.0 (TID 156). 3733 bytes result sent to driver
2021-05-19 02:47:15 INFO  Executor:54 - Finished task 15.0 in stage 5.0 (TID 132). 3733 bytes result sent to driver
2021-05-19 02:47:15 INFO  Executor:54 - Finished task 20.0 in stage 5.0 (TID 136). 3776 bytes result sent to driver
2021-05-19 02:47:15 INFO  Executor:54 - Finished task 33.0 in stage 5.0 (TID 148). 3733 bytes result sent to driver
2021-05-19 02:47:15 INFO  Executor:54 - Finished task 1.0 in stage 5.0 (TID 119). 3733 bytes result sent to driver
2021-05-19 02:47:15 INFO  Executor:54 - Finished task 11.0 in stage 5.0 (TID 128). 3733 bytes result sent to driver
2021-05-19 02:47:15 INFO  Executor:54 - Finished task 38.0 in stage 5.0 (TID 152). 3733 bytes result sent to driver
2021-05-19 02:47:15 INFO  Executor:54 - Finished task 29.0 in stage 5.0 (TID 144). 3733 bytes result sent to driver
2021-05-19 02:47:15 INFO  Executor:54 - Finished task 7.0 in stage 5.0 (TID 124). 3733 bytes result sent to driver
2021-05-19 02:47:15 INFO  Executor:54 - Finished task 24.0 in stage 5.0 (TID 140). 3733 bytes result sent to driver
2021-05-19 02:47:15 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 236
2021-05-19 02:47:15 INFO  Executor:54 - Running task 124.0 in stage 5.0 (TID 236)
2021-05-19 02:47:15 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 237
2021-05-19 02:47:15 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 238
2021-05-19 02:47:15 INFO  Executor:54 - Running task 125.0 in stage 5.0 (TID 237)
2021-05-19 02:47:15 INFO  Executor:54 - Running task 126.0 in stage 5.0 (TID 238)
2021-05-19 02:47:15 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 240
2021-05-19 02:47:15 INFO  Executor:54 - Running task 128.0 in stage 5.0 (TID 240)
2021-05-19 02:47:15 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 242
2021-05-19 02:47:15 INFO  Executor:54 - Running task 130.0 in stage 5.0 (TID 242)
2021-05-19 02:47:15 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 245
2021-05-19 02:47:15 INFO  Executor:54 - Running task 133.0 in stage 5.0 (TID 245)
2021-05-19 02:47:15 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 247
2021-05-19 02:47:15 INFO  Executor:54 - Running task 135.0 in stage 5.0 (TID 247)
2021-05-19 02:47:15 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 248
2021-05-19 02:47:15 INFO  Executor:54 - Running task 136.0 in stage 5.0 (TID 248)
2021-05-19 02:47:15 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 249
2021-05-19 02:47:15 INFO  Executor:54 - Running task 137.0 in stage 5.0 (TID 249)
2021-05-19 02:47:15 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 250
2021-05-19 02:47:15 INFO  Executor:54 - Running task 138.0 in stage 5.0 (TID 250)
2021-05-19 02:47:15 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:47:15 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2021-05-19 02:47:15 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:47:15 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2021-05-19 02:47:15 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:47:15 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:47:15 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2021-05-19 02:47:15 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2021-05-19 02:47:15 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:47:15 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2021-05-19 02:47:15 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:47:15 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2021-05-19 02:47:15 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:47:15 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:47:15 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2021-05-19 02:47:15 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:47:15 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:47:15 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2021-05-19 02:47:15 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2021-05-19 02:47:15 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 2 ms
2021-05-19 02:47:15 INFO  Executor:54 - Finished task 124.0 in stage 5.0 (TID 236). 3733 bytes result sent to driver
2021-05-19 02:47:15 INFO  Executor:54 - Finished task 133.0 in stage 5.0 (TID 245). 3733 bytes result sent to driver
2021-05-19 02:47:15 INFO  Executor:54 - Finished task 128.0 in stage 5.0 (TID 240). 3733 bytes result sent to driver
2021-05-19 02:47:15 INFO  Executor:54 - Finished task 125.0 in stage 5.0 (TID 237). 3733 bytes result sent to driver
2021-05-19 02:47:15 INFO  Executor:54 - Finished task 126.0 in stage 5.0 (TID 238). 3733 bytes result sent to driver
2021-05-19 02:47:15 INFO  Executor:54 - Finished task 130.0 in stage 5.0 (TID 242). 3733 bytes result sent to driver
2021-05-19 02:47:15 INFO  Executor:54 - Finished task 138.0 in stage 5.0 (TID 250). 3733 bytes result sent to driver
2021-05-19 02:47:15 INFO  Executor:54 - Finished task 137.0 in stage 5.0 (TID 249). 3776 bytes result sent to driver
2021-05-19 02:47:15 INFO  Executor:54 - Finished task 135.0 in stage 5.0 (TID 247). 3733 bytes result sent to driver
2021-05-19 02:47:15 INFO  Executor:54 - Finished task 136.0 in stage 5.0 (TID 248). 3733 bytes result sent to driver
2021-05-19 02:47:15 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 261
2021-05-19 02:47:15 INFO  Executor:54 - Running task 150.0 in stage 5.0 (TID 261)
2021-05-19 02:47:15 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 262
2021-05-19 02:47:15 INFO  Executor:54 - Running task 151.0 in stage 5.0 (TID 262)
2021-05-19 02:47:15 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 263
2021-05-19 02:47:15 INFO  Executor:54 - Running task 152.0 in stage 5.0 (TID 263)
2021-05-19 02:47:15 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 265
2021-05-19 02:47:15 INFO  Executor:54 - Running task 154.0 in stage 5.0 (TID 265)
2021-05-19 02:47:15 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 267
2021-05-19 02:47:15 INFO  Executor:54 - Running task 156.0 in stage 5.0 (TID 267)
2021-05-19 02:47:15 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:47:15 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2021-05-19 02:47:15 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 270
2021-05-19 02:47:15 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:47:15 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 271
2021-05-19 02:47:15 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 2 ms
2021-05-19 02:47:15 INFO  Executor:54 - Running task 159.0 in stage 5.0 (TID 270)
2021-05-19 02:47:15 INFO  Executor:54 - Running task 160.0 in stage 5.0 (TID 271)
2021-05-19 02:47:15 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:47:15 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 273
2021-05-19 02:47:15 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2021-05-19 02:47:15 INFO  Executor:54 - Running task 162.0 in stage 5.0 (TID 273)
2021-05-19 02:47:15 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:47:15 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:47:15 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2021-05-19 02:47:15 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2021-05-19 02:47:15 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 275
2021-05-19 02:47:15 INFO  Executor:54 - Running task 164.0 in stage 5.0 (TID 275)
2021-05-19 02:47:15 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 276
2021-05-19 02:47:15 INFO  Executor:54 - Running task 165.0 in stage 5.0 (TID 276)
2021-05-19 02:47:15 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:47:15 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:47:15 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2021-05-19 02:47:15 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2021-05-19 02:47:15 INFO  Executor:54 - Finished task 151.0 in stage 5.0 (TID 262). 3733 bytes result sent to driver
2021-05-19 02:47:15 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:47:15 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2021-05-19 02:47:15 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:47:15 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2021-05-19 02:47:15 INFO  Executor:54 - Finished task 156.0 in stage 5.0 (TID 267). 3733 bytes result sent to driver
2021-05-19 02:47:15 INFO  Executor:54 - Finished task 154.0 in stage 5.0 (TID 265). 3733 bytes result sent to driver
2021-05-19 02:47:15 INFO  Executor:54 - Finished task 150.0 in stage 5.0 (TID 261). 3733 bytes result sent to driver
2021-05-19 02:47:15 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 286
2021-05-19 02:47:15 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:47:15 INFO  Executor:54 - Running task 176.0 in stage 5.0 (TID 286)
2021-05-19 02:47:15 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2021-05-19 02:47:15 INFO  Executor:54 - Finished task 152.0 in stage 5.0 (TID 263). 3776 bytes result sent to driver
2021-05-19 02:47:15 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 292
2021-05-19 02:47:15 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 293
2021-05-19 02:47:15 INFO  Executor:54 - Running task 182.0 in stage 5.0 (TID 292)
2021-05-19 02:47:15 INFO  Executor:54 - Running task 183.0 in stage 5.0 (TID 293)
2021-05-19 02:47:15 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 294
2021-05-19 02:47:15 INFO  Executor:54 - Running task 184.0 in stage 5.0 (TID 294)
2021-05-19 02:47:15 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 295
2021-05-19 02:47:15 INFO  Executor:54 - Running task 185.0 in stage 5.0 (TID 295)
2021-05-19 02:47:15 INFO  Executor:54 - Finished task 165.0 in stage 5.0 (TID 276). 3733 bytes result sent to driver
2021-05-19 02:47:15 INFO  Executor:54 - Finished task 162.0 in stage 5.0 (TID 273). 3733 bytes result sent to driver
2021-05-19 02:47:15 INFO  Executor:54 - Finished task 159.0 in stage 5.0 (TID 270). 3776 bytes result sent to driver
2021-05-19 02:47:15 INFO  Executor:54 - Finished task 160.0 in stage 5.0 (TID 271). 3733 bytes result sent to driver
2021-05-19 02:47:15 INFO  Executor:54 - Finished task 164.0 in stage 5.0 (TID 275). 3733 bytes result sent to driver
2021-05-19 02:47:15 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:47:15 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2021-05-19 02:47:15 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 296
2021-05-19 02:47:15 INFO  Executor:54 - Running task 186.0 in stage 5.0 (TID 296)
2021-05-19 02:47:15 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 297
2021-05-19 02:47:15 INFO  Executor:54 - Running task 187.0 in stage 5.0 (TID 297)
2021-05-19 02:47:15 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 298
2021-05-19 02:47:15 INFO  Executor:54 - Running task 188.0 in stage 5.0 (TID 298)
2021-05-19 02:47:15 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:47:15 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2021-05-19 02:47:15 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 299
2021-05-19 02:47:15 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 300
2021-05-19 02:47:15 INFO  Executor:54 - Running task 190.0 in stage 5.0 (TID 299)
2021-05-19 02:47:15 INFO  Executor:54 - Running task 191.0 in stage 5.0 (TID 300)
2021-05-19 02:47:15 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:47:15 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2021-05-19 02:47:15 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:47:15 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:47:15 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2021-05-19 02:47:15 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2021-05-19 02:47:15 INFO  Executor:54 - Finished task 176.0 in stage 5.0 (TID 286). 3776 bytes result sent to driver
2021-05-19 02:47:15 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:47:15 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2021-05-19 02:47:15 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 305
2021-05-19 02:47:15 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:47:15 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:47:15 INFO  Executor:54 - Running task 196.0 in stage 5.0 (TID 305)
2021-05-19 02:47:15 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:47:15 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2021-05-19 02:47:15 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 4 ms
2021-05-19 02:47:15 INFO  Executor:54 - Finished task 183.0 in stage 5.0 (TID 293). 3733 bytes result sent to driver
2021-05-19 02:47:15 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 6 ms
2021-05-19 02:47:15 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:47:15 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 5 ms
2021-05-19 02:47:15 INFO  Executor:54 - Finished task 184.0 in stage 5.0 (TID 294). 3733 bytes result sent to driver
2021-05-19 02:47:15 INFO  Executor:54 - Finished task 185.0 in stage 5.0 (TID 295). 3733 bytes result sent to driver
2021-05-19 02:47:15 INFO  Executor:54 - Finished task 182.0 in stage 5.0 (TID 292). 3733 bytes result sent to driver
2021-05-19 02:47:15 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:47:15 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2021-05-19 02:47:15 INFO  Executor:54 - Finished task 187.0 in stage 5.0 (TID 297). 3776 bytes result sent to driver
2021-05-19 02:47:15 INFO  Executor:54 - Finished task 190.0 in stage 5.0 (TID 299). 3733 bytes result sent to driver
2021-05-19 02:47:15 INFO  Executor:54 - Finished task 191.0 in stage 5.0 (TID 300). 3733 bytes result sent to driver
2021-05-19 02:47:15 INFO  Executor:54 - Finished task 188.0 in stage 5.0 (TID 298). 3733 bytes result sent to driver
2021-05-19 02:47:15 INFO  Executor:54 - Finished task 186.0 in stage 5.0 (TID 296). 3733 bytes result sent to driver
2021-05-19 02:47:15 INFO  Executor:54 - Finished task 196.0 in stage 5.0 (TID 305). 3733 bytes result sent to driver
2021-05-19 02:47:18 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 317
2021-05-19 02:47:18 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 321
2021-05-19 02:47:18 INFO  Executor:54 - Running task 0.0 in stage 7.0 (TID 317)
2021-05-19 02:47:18 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 325
2021-05-19 02:47:18 INFO  Executor:54 - Running task 2.0 in stage 7.0 (TID 321)
2021-05-19 02:47:18 INFO  Executor:54 - Running task 7.0 in stage 7.0 (TID 325)
2021-05-19 02:47:18 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 329
2021-05-19 02:47:18 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 333
2021-05-19 02:47:18 INFO  Executor:54 - Running task 17.0 in stage 7.0 (TID 329)
2021-05-19 02:47:18 INFO  Executor:54 - Running task 18.0 in stage 7.0 (TID 333)
2021-05-19 02:47:18 INFO  TorrentBroadcast:54 - Started reading broadcast variable 14
2021-05-19 02:47:18 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 337
2021-05-19 02:47:18 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 341
2021-05-19 02:47:18 INFO  Executor:54 - Running task 25.0 in stage 7.0 (TID 337)
2021-05-19 02:47:18 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 345
2021-05-19 02:47:18 INFO  Executor:54 - Running task 33.0 in stage 7.0 (TID 341)
2021-05-19 02:47:18 INFO  Executor:54 - Running task 36.0 in stage 7.0 (TID 345)
2021-05-19 02:47:19 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 349
2021-05-19 02:47:19 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 352
2021-05-19 02:47:19 INFO  Executor:54 - Running task 39.0 in stage 7.0 (TID 349)
2021-05-19 02:47:19 INFO  Executor:54 - Running task 47.0 in stage 7.0 (TID 352)
2021-05-19 02:47:19 INFO  MemoryStore:54 - Block broadcast_14_piece0 stored as bytes in memory (estimated size 22.9 KB, free 366.3 MB)
2021-05-19 02:47:19 INFO  TorrentBroadcast:54 - Reading broadcast variable 14 took 27 ms
2021-05-19 02:47:19 INFO  MemoryStore:54 - Block broadcast_14 stored as values in memory (estimated size 51.4 KB, free 366.2 MB)
2021-05-19 02:47:19 INFO  CodeGenerator:54 - Code generated in 62.196514 ms
2021-05-19 02:47:19 INFO  TorrentBroadcast:54 - Started reading broadcast variable 12
2021-05-19 02:47:19 INFO  MemoryStore:54 - Block broadcast_12_piece0 stored as bytes in memory (estimated size 580.1 KB, free 365.7 MB)
2021-05-19 02:47:19 INFO  TorrentBroadcast:54 - Reading broadcast variable 12 took 22 ms
2021-05-19 02:47:19 INFO  MemoryStore:54 - Block broadcast_12 stored as values in memory (estimated size 5.0 MB, free 360.7 MB)
2021-05-19 02:47:19 INFO  CodeGenerator:54 - Code generated in 19.007049 ms
2021-05-19 02:47:20 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00007, range: 0-134217728, partition values: [empty row]
2021-05-19 02:47:20 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00033, range: 0-134217728, partition values: [empty row]
2021-05-19 02:47:20 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00017, range: 0-134217728, partition values: [empty row]
2021-05-19 02:47:20 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00002, range: 0-134217728, partition values: [empty row]
2021-05-19 02:47:20 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00000, range: 0-134217728, partition values: [empty row]
2021-05-19 02:47:20 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00036, range: 0-134217728, partition values: [empty row]
2021-05-19 02:47:20 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00018, range: 0-134217728, partition values: [empty row]
2021-05-19 02:47:20 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00025, range: 0-134217728, partition values: [empty row]
2021-05-19 02:47:20 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00047, range: 0-134217728, partition values: [empty row]
2021-05-19 02:47:20 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00039, range: 0-134217728, partition values: [empty row]
2021-05-19 02:47:20 INFO  CodeGenerator:54 - Code generated in 56.557735 ms
2021-05-19 02:47:20 INFO  TorrentBroadcast:54 - Started reading broadcast variable 13
2021-05-19 02:47:20 INFO  MemoryStore:54 - Block broadcast_13_piece0 stored as bytes in memory (estimated size 33.4 KB, free 360.6 MB)
2021-05-19 02:47:20 INFO  TorrentBroadcast:54 - Reading broadcast variable 13 took 23 ms
2021-05-19 02:47:20 INFO  CodeGenerator:54 - Code generated in 84.720117 ms
2021-05-19 02:47:20 INFO  MemoryStore:54 - Block broadcast_13 stored as values in memory (estimated size 506.4 KB, free 360.1 MB)
2021-05-19 02:47:20 INFO  CodeGenerator:54 - Code generated in 34.111002 ms
2021-05-19 02:47:20 INFO  CodeGenerator:54 - Code generated in 84.118614 ms
2021-05-19 02:47:20 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: 22x-222@627-wgt-snq, 2020-07-13T00:00:00-04:00, [1,1,1,4,2,1,6]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: 22x-222@627-wgt-snq
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00039
2021-05-19 02:47:20 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: 226-223@627-wgt-z2k, 2018-12-31T00:00:00-05:00, [0,0,0,0,2,0,0]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: 226-223@627-wgt-z2k
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00002
2021-05-19 02:47:20 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: 22k-222@627-vsp-3wk, 2020-08-10T00:00:00-04:00, [0,1,1,0,0,2,0]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: 22k-222@627-vsp-3wk
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00018
2021-05-19 02:47:20 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: 222-222@627-vsg-8n5, 2020-05-04T00:00:00-04:00, [3,1,2,2,5,3,2]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: 222-222@627-vsg-8n5
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00047
2021-05-19 02:47:20 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: 22t-223@627-wc7-vcq, 2019-07-15T00:00:00-04:00, [6,4,9,8,6,5,7]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: 22t-223@627-wc7-vcq
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00033
2021-05-19 02:47:20 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: 22j-222@627-w9f-wff, 2020-07-27T00:00:00-04:00, [6,7,14,14,7,7,8]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: 22j-222@627-w9f-wff
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00036
2021-05-19 02:47:20 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: 227-224@627-s6m-yn5, 2020-06-15T00:00:00-04:00, [1,1,4,4,3,1,6]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: 227-224@627-s6m-yn5
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00017
2021-05-19 02:47:20 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: zzw-222@627-wc2-5fz, 2020-06-15T00:00:00-04:00, [0,2,1,1,1,2,0]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: zzw-222@627-wc2-5fz
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00025
2021-05-19 02:47:20 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: 222-222@627-sbc-pqf, 2018-12-31T00:00:00-05:00, [4,4,28,20,22,6,8]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: 222-222@627-sbc-pqf
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00007
2021-05-19 02:47:20 INFO  CodeGenerator:54 - Code generated in 42.853586 ms
2021-05-19 02:47:21 INFO  CodeGenerator:54 - Code generated in 17.564677 ms
2021-05-19 02:47:21 INFO  CodeGenerator:54 - Code generated in 22.531374 ms
2021-05-19 02:47:21 INFO  CodeGenerator:54 - Code generated in 19.258208 ms
2021-05-19 02:47:21 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:47:21 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:47:21 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:47:21 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:47:21 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:47:21 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:47:21 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:47:21 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:47:21 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:47:21 INFO  CodeGenerator:54 - Code generated in 33.83303 ms
2021-05-19 02:47:22 INFO  CodeGenerator:54 - Code generated in 30.869886 ms
2021-05-19 02:47:22 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:47:22 INFO  CodeGenerator:54 - Code generated in 18.068705 ms
2021-05-19 02:47:22 INFO  CodeGenerator:54 - Code generated in 48.944056 ms
2021-05-19 02:47:31 INFO  PythonUDFRunner:54 - Times: total = 12325, boot = 687, init = 962, finish = 10676
2021-05-19 02:47:31 INFO  PythonUDFRunner:54 - Times: total = 12350, boot = 783, init = 871, finish = 10696
2021-05-19 02:47:32 INFO  PythonUDFRunner:54 - Times: total = 12642, boot = 758, init = 880, finish = 11004
2021-05-19 02:47:32 ERROR CoarseGrainedExecutorBackend:43 - RECEIVED SIGNAL TERM
2021-05-19 02:47:32 INFO  DiskBlockManager:54 - Shutdown hook called
2021-05-19 02:47:32 INFO  ShutdownHookManager:54 - Shutdown hook called
2021-05-19 02:47:32 INFO  ShutdownHookManager:54 - Deleting directory /localhome/cdp/yarn/nm/usercache/catherine.ng60/appcache/application_1609183734776_5900/spark-1a33b11a-aed4-4bf0-89dd-cd9a4a874cf1

End of LogType:stdout
***********************************************************************


End of LogType:prelaunch.err
******************************************************************************

Container: container_e10_1609183734776_5900_02_000007 on hadoop06.cusp.nyu.edu_8041
LogAggregationType: AGGREGATED
===================================================================================
LogType:prelaunch.out
LogLastModifiedTime:Wed May 19 02:48:17 -0400 2021
LogLength:70
LogContents:
Setting up env variables
Setting up job resources
Launching container

End of LogType:prelaunch.out
******************************************************************************

Container: container_e10_1609183734776_5900_02_000007 on hadoop06.cusp.nyu.edu_8041
LogAggregationType: AGGREGATED
===================================================================================
LogType:stderr
LogLastModifiedTime:Wed May 19 02:48:17 -0400 2021
LogLength:529
LogContents:
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/localhome/cdp/yarn/nm/filecache/31/spark-jars-2.4.0-hadoop2.7.jar/slf4j-log4j12-1.7.16.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-6.1.0-1.cdh6.1.0.p0.770702/jars/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]

End of LogType:stderr
***********************************************************************

Container: container_e10_1609183734776_5900_02_000007 on hadoop06.cusp.nyu.edu_8041
LogAggregationType: AGGREGATED
===================================================================================
LogType:stdout
LogLastModifiedTime:Wed May 19 02:48:17 -0400 2021
LogLength:16160
LogContents:
2021-05-19 02:47:33 INFO  CoarseGrainedExecutorBackend:2566 - Started daemon with process name: 6434@hadoop06.cusp.nyu.edu
2021-05-19 02:47:33 INFO  SignalUtils:54 - Registered signal handler for TERM
2021-05-19 02:47:33 INFO  SignalUtils:54 - Registered signal handler for HUP
2021-05-19 02:47:33 INFO  SignalUtils:54 - Registered signal handler for INT
2021-05-19 02:47:34 INFO  SecurityManager:54 - Changing view acls to: catherine.ng60
2021-05-19 02:47:34 INFO  SecurityManager:54 - Changing modify acls to: catherine.ng60
2021-05-19 02:47:34 INFO  SecurityManager:54 - Changing view acls groups to: 
2021-05-19 02:47:34 INFO  SecurityManager:54 - Changing modify acls groups to: 
2021-05-19 02:47:34 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(catherine.ng60); groups with view permissions: Set(); users  with modify permissions: Set(catherine.ng60); groups with modify permissions: Set()
2021-05-19 02:47:34 INFO  TransportClientFactory:267 - Successfully created connection to hadoop02.cusp.nyu.edu/192.168.72.172:60108 after 117 ms (0 ms spent in bootstraps)
2021-05-19 02:47:34 INFO  SecurityManager:54 - Changing view acls to: catherine.ng60
2021-05-19 02:47:34 INFO  SecurityManager:54 - Changing modify acls to: catherine.ng60
2021-05-19 02:47:34 INFO  SecurityManager:54 - Changing view acls groups to: 
2021-05-19 02:47:34 INFO  SecurityManager:54 - Changing modify acls groups to: 
2021-05-19 02:47:34 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(catherine.ng60); groups with view permissions: Set(); users  with modify permissions: Set(catherine.ng60); groups with modify permissions: Set()
2021-05-19 02:47:35 INFO  TransportClientFactory:267 - Successfully created connection to hadoop02.cusp.nyu.edu/192.168.72.172:60108 after 4 ms (0 ms spent in bootstraps)
2021-05-19 02:47:35 INFO  DiskBlockManager:54 - Created local directory at /localhome/cdp/yarn/nm/usercache/catherine.ng60/appcache/application_1609183734776_5900/blockmgr-4e053310-37c8-4ca9-89ed-4349d0bc9cf0
2021-05-19 02:47:35 INFO  MemoryStore:54 - MemoryStore started with capacity 366.3 MB
2021-05-19 02:47:35 INFO  CoarseGrainedExecutorBackend:54 - Connecting to driver: spark://CoarseGrainedScheduler@hadoop02.cusp.nyu.edu:60108
2021-05-19 02:47:35 INFO  CoarseGrainedExecutorBackend:54 - Successfully registered with driver
2021-05-19 02:47:35 INFO  Executor:54 - Starting executor ID 6 on host hadoop06.cusp.nyu.edu
2021-05-19 02:47:35 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 34178.
2021-05-19 02:47:35 INFO  NettyBlockTransferService:54 - Server created on hadoop06.cusp.nyu.edu:34178
2021-05-19 02:47:35 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2021-05-19 02:47:35 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(6, hadoop06.cusp.nyu.edu, 34178, None)
2021-05-19 02:47:35 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(6, hadoop06.cusp.nyu.edu, 34178, None)
2021-05-19 02:47:35 INFO  BlockManager:54 - external shuffle service port = 7337
2021-05-19 02:47:35 INFO  BlockManager:54 - Registering executor with local external shuffle service.
2021-05-19 02:47:35 INFO  TransportClientFactory:267 - Successfully created connection to hadoop06.cusp.nyu.edu/192.168.72.176:7337 after 3 ms (0 ms spent in bootstraps)
2021-05-19 02:47:35 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(6, hadoop06.cusp.nyu.edu, 34178, None)
2021-05-19 02:47:35 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 371
2021-05-19 02:47:35 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 372
2021-05-19 02:47:35 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 373
2021-05-19 02:47:35 INFO  Executor:54 - Running task 17.1 in stage 7.0 (TID 371)
2021-05-19 02:47:35 INFO  Executor:54 - Running task 0.1 in stage 7.0 (TID 372)
2021-05-19 02:47:35 INFO  Executor:54 - Running task 33.1 in stage 7.0 (TID 373)
2021-05-19 02:47:35 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 374
2021-05-19 02:47:35 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 375
2021-05-19 02:47:35 INFO  Executor:54 - Running task 18.1 in stage 7.0 (TID 374)
2021-05-19 02:47:35 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 376
2021-05-19 02:47:35 INFO  Executor:54 - Running task 2.1 in stage 7.0 (TID 375)
2021-05-19 02:47:35 INFO  Executor:54 - Running task 36.1 in stage 7.0 (TID 376)
2021-05-19 02:47:35 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 377
2021-05-19 02:47:35 INFO  Executor:54 - Running task 25.1 in stage 7.0 (TID 377)
2021-05-19 02:47:35 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 378
2021-05-19 02:47:35 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 379
2021-05-19 02:47:35 INFO  Executor:54 - Running task 7.1 in stage 7.0 (TID 378)
2021-05-19 02:47:35 INFO  Executor:54 - Running task 47.1 in stage 7.0 (TID 379)
2021-05-19 02:47:35 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 380
2021-05-19 02:47:35 INFO  Executor:54 - Running task 39.1 in stage 7.0 (TID 380)
2021-05-19 02:47:35 INFO  MapOutputTrackerWorker:54 - Updating epoch to 1 and clearing cache
2021-05-19 02:47:35 INFO  TorrentBroadcast:54 - Started reading broadcast variable 14
2021-05-19 02:47:36 INFO  TransportClientFactory:267 - Successfully created connection to hadoop02.cusp.nyu.edu/192.168.72.172:49352 after 3 ms (0 ms spent in bootstraps)
2021-05-19 02:47:36 INFO  MemoryStore:54 - Block broadcast_14_piece0 stored as bytes in memory (estimated size 22.9 KB, free 366.3 MB)
2021-05-19 02:47:36 INFO  TorrentBroadcast:54 - Reading broadcast variable 14 took 132 ms
2021-05-19 02:47:36 INFO  MemoryStore:54 - Block broadcast_14 stored as values in memory (estimated size 51.4 KB, free 366.2 MB)
2021-05-19 02:47:37 INFO  CodeGenerator:54 - Code generated in 369.331441 ms
2021-05-19 02:47:37 INFO  TorrentBroadcast:54 - Started reading broadcast variable 12
2021-05-19 02:47:37 INFO  MemoryStore:54 - Block broadcast_12_piece0 stored as bytes in memory (estimated size 580.1 KB, free 365.7 MB)
2021-05-19 02:47:37 INFO  TorrentBroadcast:54 - Reading broadcast variable 12 took 33 ms
2021-05-19 02:47:37 INFO  MemoryStore:54 - Block broadcast_12 stored as values in memory (estimated size 5.0 MB, free 360.7 MB)
2021-05-19 02:47:38 INFO  CodeGenerator:54 - Code generated in 53.27056 ms
2021-05-19 02:47:38 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00007, range: 0-134217728, partition values: [empty row]
2021-05-19 02:47:38 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00025, range: 0-134217728, partition values: [empty row]
2021-05-19 02:47:38 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00039, range: 0-134217728, partition values: [empty row]
2021-05-19 02:47:38 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00036, range: 0-134217728, partition values: [empty row]
2021-05-19 02:47:38 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00000, range: 0-134217728, partition values: [empty row]
2021-05-19 02:47:38 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00033, range: 0-134217728, partition values: [empty row]
2021-05-19 02:47:38 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00018, range: 0-134217728, partition values: [empty row]
2021-05-19 02:47:38 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00002, range: 0-134217728, partition values: [empty row]
2021-05-19 02:47:39 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00047, range: 0-134217728, partition values: [empty row]
2021-05-19 02:47:39 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00017, range: 0-134217728, partition values: [empty row]
2021-05-19 02:47:39 INFO  CodeGenerator:54 - Code generated in 70.877885 ms
2021-05-19 02:47:39 INFO  TorrentBroadcast:54 - Started reading broadcast variable 13
2021-05-19 02:47:39 INFO  MemoryStore:54 - Block broadcast_13_piece0 stored as bytes in memory (estimated size 33.4 KB, free 360.6 MB)
2021-05-19 02:47:39 INFO  TorrentBroadcast:54 - Reading broadcast variable 13 took 23 ms
2021-05-19 02:47:39 INFO  CodeGenerator:54 - Code generated in 84.658437 ms
2021-05-19 02:47:39 INFO  CodeGenerator:54 - Code generated in 43.327775 ms
2021-05-19 02:47:39 INFO  MemoryStore:54 - Block broadcast_13 stored as values in memory (estimated size 506.4 KB, free 360.1 MB)
2021-05-19 02:47:39 INFO  CodeGenerator:54 - Code generated in 60.486866 ms
2021-05-19 02:47:39 INFO  CodeGenerator:54 - Code generated in 29.109784 ms
2021-05-19 02:47:40 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: 22x-222@627-wgt-snq, 2020-07-13T00:00:00-04:00, [1,1,1,4,2,1,6]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: 22x-222@627-wgt-snq
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00039
2021-05-19 02:47:40 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: 226-223@627-wgt-z2k, 2018-12-31T00:00:00-05:00, [0,0,0,0,2,0,0]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: 226-223@627-wgt-z2k
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00002
2021-05-19 02:47:40 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: 22t-223@627-wc7-vcq, 2019-07-15T00:00:00-04:00, [6,4,9,8,6,5,7]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: 22t-223@627-wc7-vcq
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00033
2021-05-19 02:47:40 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: 227-224@627-s6m-yn5, 2020-06-15T00:00:00-04:00, [1,1,4,4,3,1,6]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: 227-224@627-s6m-yn5
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00017
2021-05-19 02:47:40 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: 22j-222@627-w9f-wff, 2020-07-27T00:00:00-04:00, [6,7,14,14,7,7,8]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: 22j-222@627-w9f-wff
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00036
2021-05-19 02:47:40 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: 222-222@627-vsg-8n5, 2020-05-04T00:00:00-04:00, [3,1,2,2,5,3,2]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: 222-222@627-vsg-8n5
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00047
2021-05-19 02:47:40 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: 22k-222@627-vsp-3wk, 2020-08-10T00:00:00-04:00, [0,1,1,0,0,2,0]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: 22k-222@627-vsp-3wk
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00018
2021-05-19 02:47:40 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: 222-222@627-sbc-pqf, 2018-12-31T00:00:00-05:00, [4,4,28,20,22,6,8]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: 222-222@627-sbc-pqf
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00007
2021-05-19 02:47:40 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: zzw-222@627-wc2-5fz, 2020-06-15T00:00:00-04:00, [0,2,1,1,1,2,0]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: zzw-222@627-wc2-5fz
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00025
2021-05-19 02:47:41 INFO  CodeGenerator:54 - Code generated in 20.483767 ms
2021-05-19 02:47:41 INFO  CodeGenerator:54 - Code generated in 50.887623 ms
2021-05-19 02:47:41 INFO  CodeGenerator:54 - Code generated in 27.256188 ms
2021-05-19 02:47:42 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:47:42 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:47:42 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:47:42 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:47:42 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:47:42 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:47:42 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:47:42 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:47:42 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:47:42 INFO  CodeGenerator:54 - Code generated in 38.650555 ms
2021-05-19 02:47:42 INFO  CodeGenerator:54 - Code generated in 28.609905 ms
2021-05-19 02:47:42 INFO  CodeGenerator:54 - Code generated in 19.732138 ms
2021-05-19 02:47:42 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:47:42 INFO  CodeGenerator:54 - Code generated in 25.411223 ms
2021-05-19 02:47:50 ERROR CoarseGrainedExecutorBackend:43 - RECEIVED SIGNAL TERM
2021-05-19 02:47:50 INFO  DiskBlockManager:54 - Shutdown hook called
2021-05-19 02:47:50 INFO  ShutdownHookManager:54 - Shutdown hook called
2021-05-19 02:47:50 INFO  ShutdownHookManager:54 - Deleting directory /localhome/cdp/yarn/nm/usercache/catherine.ng60/appcache/application_1609183734776_5900/spark-4eb32da9-ee2f-44ea-abe9-2e1d6140814e

End of LogType:stdout
***********************************************************************


End of LogType:prelaunch.err
******************************************************************************

Container: container_e10_1609183734776_5900_01_000008 on hadoop07.cusp.nyu.edu_8041
LogAggregationType: AGGREGATED
===================================================================================
LogType:prelaunch.out
LogLastModifiedTime:Wed May 19 02:48:18 -0400 2021
LogLength:70
LogContents:
Setting up env variables
Setting up job resources
Launching container

End of LogType:prelaunch.out
******************************************************************************

Container: container_e10_1609183734776_5900_01_000008 on hadoop07.cusp.nyu.edu_8041
LogAggregationType: AGGREGATED
===================================================================================
LogType:stderr
LogLastModifiedTime:Wed May 19 02:48:18 -0400 2021
LogLength:529
LogContents:
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/localhome/cdp/yarn/nm/filecache/25/spark-jars-2.4.0-hadoop2.7.jar/slf4j-log4j12-1.7.16.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-6.1.0-1.cdh6.1.0.p0.770702/jars/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]

End of LogType:stderr
***********************************************************************

Container: container_e10_1609183734776_5900_01_000008 on hadoop07.cusp.nyu.edu_8041
LogAggregationType: AGGREGATED
===================================================================================
LogType:stdout
LogLastModifiedTime:Wed May 19 02:48:18 -0400 2021
LogLength:16180
LogContents:
2021-05-19 02:46:10 INFO  CoarseGrainedExecutorBackend:2566 - Started daemon with process name: 36729@hadoop07.cusp.nyu.edu
2021-05-19 02:46:10 INFO  SignalUtils:54 - Registered signal handler for TERM
2021-05-19 02:46:10 INFO  SignalUtils:54 - Registered signal handler for HUP
2021-05-19 02:46:10 INFO  SignalUtils:54 - Registered signal handler for INT
2021-05-19 02:46:11 INFO  SecurityManager:54 - Changing view acls to: catherine.ng60
2021-05-19 02:46:11 INFO  SecurityManager:54 - Changing modify acls to: catherine.ng60
2021-05-19 02:46:11 INFO  SecurityManager:54 - Changing view acls groups to: 
2021-05-19 02:46:11 INFO  SecurityManager:54 - Changing modify acls groups to: 
2021-05-19 02:46:11 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(catherine.ng60); groups with view permissions: Set(); users  with modify permissions: Set(catherine.ng60); groups with modify permissions: Set()
2021-05-19 02:46:12 INFO  TransportClientFactory:267 - Successfully created connection to hadoop05.cusp.nyu.edu/192.168.72.175:47481 after 108 ms (0 ms spent in bootstraps)
2021-05-19 02:46:12 INFO  SecurityManager:54 - Changing view acls to: catherine.ng60
2021-05-19 02:46:12 INFO  SecurityManager:54 - Changing modify acls to: catherine.ng60
2021-05-19 02:46:12 INFO  SecurityManager:54 - Changing view acls groups to: 
2021-05-19 02:46:12 INFO  SecurityManager:54 - Changing modify acls groups to: 
2021-05-19 02:46:12 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(catherine.ng60); groups with view permissions: Set(); users  with modify permissions: Set(catherine.ng60); groups with modify permissions: Set()
2021-05-19 02:46:12 INFO  TransportClientFactory:267 - Successfully created connection to hadoop05.cusp.nyu.edu/192.168.72.175:47481 after 4 ms (0 ms spent in bootstraps)
2021-05-19 02:46:12 INFO  DiskBlockManager:54 - Created local directory at /localhome/cdp/yarn/nm/usercache/catherine.ng60/appcache/application_1609183734776_5900/blockmgr-2e4538ce-99b6-4470-970a-b0dbd6865d42
2021-05-19 02:46:12 INFO  MemoryStore:54 - MemoryStore started with capacity 366.3 MB
2021-05-19 02:46:13 INFO  CoarseGrainedExecutorBackend:54 - Connecting to driver: spark://CoarseGrainedScheduler@hadoop05.cusp.nyu.edu:47481
2021-05-19 02:46:13 INFO  CoarseGrainedExecutorBackend:54 - Successfully registered with driver
2021-05-19 02:46:13 INFO  Executor:54 - Starting executor ID 7 on host hadoop07.cusp.nyu.edu
2021-05-19 02:46:13 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 35847.
2021-05-19 02:46:13 INFO  NettyBlockTransferService:54 - Server created on hadoop07.cusp.nyu.edu:35847
2021-05-19 02:46:13 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2021-05-19 02:46:13 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(7, hadoop07.cusp.nyu.edu, 35847, None)
2021-05-19 02:46:13 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(7, hadoop07.cusp.nyu.edu, 35847, None)
2021-05-19 02:46:13 INFO  BlockManager:54 - external shuffle service port = 7337
2021-05-19 02:46:13 INFO  BlockManager:54 - Registering executor with local external shuffle service.
2021-05-19 02:46:13 INFO  TransportClientFactory:267 - Successfully created connection to hadoop07.cusp.nyu.edu/192.168.72.177:7337 after 3 ms (0 ms spent in bootstraps)
2021-05-19 02:46:13 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(7, hadoop07.cusp.nyu.edu, 35847, None)
2021-05-19 02:46:13 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 377
2021-05-19 02:46:13 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 378
2021-05-19 02:46:13 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 379
2021-05-19 02:46:13 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 380
2021-05-19 02:46:13 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 381
2021-05-19 02:46:13 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 382
2021-05-19 02:46:13 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 383
2021-05-19 02:46:13 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 384
2021-05-19 02:46:13 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 385
2021-05-19 02:46:13 INFO  Executor:54 - Running task 0.1 in stage 7.0 (TID 378)
2021-05-19 02:46:13 INFO  Executor:54 - Running task 24.1 in stage 7.0 (TID 385)
2021-05-19 02:46:13 INFO  Executor:54 - Running task 22.1 in stage 7.0 (TID 381)
2021-05-19 02:46:13 INFO  Executor:54 - Running task 37.1 in stage 7.0 (TID 380)
2021-05-19 02:46:13 INFO  Executor:54 - Running task 28.1 in stage 7.0 (TID 377)
2021-05-19 02:46:13 INFO  Executor:54 - Running task 23.1 in stage 7.0 (TID 379)
2021-05-19 02:46:13 INFO  Executor:54 - Running task 41.1 in stage 7.0 (TID 383)
2021-05-19 02:46:13 INFO  Executor:54 - Running task 5.1 in stage 7.0 (TID 384)
2021-05-19 02:46:13 INFO  Executor:54 - Running task 34.1 in stage 7.0 (TID 382)
2021-05-19 02:46:13 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 386
2021-05-19 02:46:13 INFO  Executor:54 - Running task 38.1 in stage 7.0 (TID 386)
2021-05-19 02:46:13 INFO  MapOutputTrackerWorker:54 - Updating epoch to 1 and clearing cache
2021-05-19 02:46:13 INFO  TorrentBroadcast:54 - Started reading broadcast variable 14
2021-05-19 02:46:13 INFO  TransportClientFactory:267 - Successfully created connection to hadoop05.cusp.nyu.edu/192.168.72.175:36982 after 3 ms (0 ms spent in bootstraps)
2021-05-19 02:46:13 INFO  MemoryStore:54 - Block broadcast_14_piece0 stored as bytes in memory (estimated size 22.9 KB, free 366.3 MB)
2021-05-19 02:46:13 INFO  TorrentBroadcast:54 - Reading broadcast variable 14 took 131 ms
2021-05-19 02:46:14 INFO  MemoryStore:54 - Block broadcast_14 stored as values in memory (estimated size 51.5 KB, free 366.2 MB)
2021-05-19 02:46:15 INFO  CodeGenerator:54 - Code generated in 366.687104 ms
2021-05-19 02:46:15 INFO  TorrentBroadcast:54 - Started reading broadcast variable 12
2021-05-19 02:46:15 INFO  MemoryStore:54 - Block broadcast_12_piece0 stored as bytes in memory (estimated size 580.1 KB, free 365.7 MB)
2021-05-19 02:46:15 INFO  TorrentBroadcast:54 - Reading broadcast variable 12 took 36 ms
2021-05-19 02:46:15 INFO  MemoryStore:54 - Block broadcast_12 stored as values in memory (estimated size 5.0 MB, free 360.7 MB)
2021-05-19 02:46:15 INFO  CodeGenerator:54 - Code generated in 24.124395 ms
2021-05-19 02:46:16 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00034, range: 0-134217728, partition values: [empty row]
2021-05-19 02:46:16 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00005, range: 0-134217728, partition values: [empty row]
2021-05-19 02:46:16 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00022, range: 0-134217728, partition values: [empty row]
2021-05-19 02:46:16 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00038, range: 0-134217728, partition values: [empty row]
2021-05-19 02:46:16 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00024, range: 0-134217728, partition values: [empty row]
2021-05-19 02:46:16 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00023, range: 0-134217728, partition values: [empty row]
2021-05-19 02:46:16 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00041, range: 0-134217728, partition values: [empty row]
2021-05-19 02:46:16 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00037, range: 0-134217728, partition values: [empty row]
2021-05-19 02:46:16 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00028, range: 0-134217728, partition values: [empty row]
2021-05-19 02:46:16 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00000, range: 0-134217728, partition values: [empty row]
2021-05-19 02:46:16 INFO  CodeGenerator:54 - Code generated in 38.199704 ms
2021-05-19 02:46:16 INFO  TorrentBroadcast:54 - Started reading broadcast variable 13
2021-05-19 02:46:16 INFO  MemoryStore:54 - Block broadcast_13_piece0 stored as bytes in memory (estimated size 33.4 KB, free 360.6 MB)
2021-05-19 02:46:16 INFO  TorrentBroadcast:54 - Reading broadcast variable 13 took 22 ms
2021-05-19 02:46:16 INFO  CodeGenerator:54 - Code generated in 55.349707 ms
2021-05-19 02:46:16 INFO  CodeGenerator:54 - Code generated in 58.420404 ms
2021-05-19 02:46:16 INFO  MemoryStore:54 - Block broadcast_13 stored as values in memory (estimated size 506.4 KB, free 360.1 MB)
2021-05-19 02:46:16 INFO  CodeGenerator:54 - Code generated in 54.645539 ms
2021-05-19 02:46:16 INFO  CodeGenerator:54 - Code generated in 30.250474 ms
2021-05-19 02:46:18 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: 224-222@627-s8r-975, 2019-12-02T00:00:00-05:00, [15,24,17,27,24,13,21]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: 224-222@627-s8r-975
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00024
2021-05-19 02:46:18 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: 22f-222@627-wdh-sdv, 2019-06-10T00:00:00-04:00, [4,2,3,3,3,1,0]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: 22f-222@627-wdh-sdv
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00038
2021-05-19 02:46:18 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: 22j-222@627-wc7-8jv, 2019-05-13T00:00:00-04:00, [1,1,0,2,2,4,1]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: 22j-222@627-wc7-8jv
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00028
2021-05-19 02:46:18 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: 22b-222@627-s4r-s3q, 2019-11-04T00:00:00-05:00, [20,15,14,25,21,16,15]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: 22b-222@627-s4r-s3q
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00023
2021-05-19 02:46:18 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: zzw-222@627-s6d-wx5, 2019-12-02T00:00:00-05:00, [1,1,0,0,0,4,5]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: zzw-222@627-s6d-wx5
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00034
2021-05-19 02:46:18 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: zzw-226@627-wc7-49z, 2019-02-11T00:00:00-05:00, [26,15,15,20,33,6,11]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: zzw-226@627-wc7-49z
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00022
2021-05-19 02:46:18 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: zzw-222@627-s65-bx5, 2020-09-28T00:00:00-04:00, [0,1,0,2,0,0,0]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: zzw-222@627-s65-bx5
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00041
2021-05-19 02:46:18 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: zzy-222@627-wf8-59f, 2019-07-08T00:00:00-04:00, [0,5,1,0,6,2,4]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: zzy-222@627-wf8-59f
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00037
2021-05-19 02:46:18 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: 222-222@627-s95-rc5, 2018-12-31T00:00:00-05:00, [5,6,50,52,24,0,0]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: 222-222@627-s95-rc5
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00005
2021-05-19 02:46:19 INFO  CodeGenerator:54 - Code generated in 24.873319 ms
2021-05-19 02:46:19 INFO  CodeGenerator:54 - Code generated in 55.905712 ms
2021-05-19 02:46:19 INFO  CodeGenerator:54 - Code generated in 32.018752 ms
2021-05-19 02:46:19 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:46:19 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:46:19 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:46:19 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:46:19 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:46:19 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:46:19 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:46:19 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:46:19 INFO  CodeGenerator:54 - Code generated in 37.93821 ms
2021-05-19 02:46:19 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:46:20 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:46:20 INFO  CodeGenerator:54 - Code generated in 53.712498 ms
2021-05-19 02:46:20 INFO  CodeGenerator:54 - Code generated in 19.163085 ms
2021-05-19 02:46:20 INFO  CodeGenerator:54 - Code generated in 18.753748 ms
2021-05-19 02:46:28 ERROR CoarseGrainedExecutorBackend:43 - RECEIVED SIGNAL TERM
2021-05-19 02:46:28 INFO  DiskBlockManager:54 - Shutdown hook called
2021-05-19 02:46:28 INFO  ShutdownHookManager:54 - Shutdown hook called
2021-05-19 02:46:28 INFO  ShutdownHookManager:54 - Deleting directory /localhome/cdp/yarn/nm/usercache/catherine.ng60/appcache/application_1609183734776_5900/spark-8b48e52b-f053-404c-8491-a0e9b5792dc5

End of LogType:stdout
***********************************************************************

Container: container_e10_1609183734776_5900_01_000004 on hadoop07.cusp.nyu.edu_8041
LogAggregationType: AGGREGATED
===================================================================================
LogType:container-localizer-syslog
LogLastModifiedTime:Wed May 19 02:48:18 -0400 2021
LogLength:506
LogContents:
2021-05-19 02:45:27,130 INFO [main] org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ContainerLocalizer: Disk Validator: yarn.nodemanager.disk-validator is loaded.
2021-05-19 02:45:28,447 WARN [ContainerLocalizer Downloader] org.apache.hadoop.ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ipc.StandbyException): Operation category READ is not supported in state standby. Visit https://s.apache.org/sbnn-error

End of LogType:container-localizer-syslog
*******************************************************************************************


End of LogType:prelaunch.err
******************************************************************************

Container: container_e10_1609183734776_5900_01_000004 on hadoop07.cusp.nyu.edu_8041
LogAggregationType: AGGREGATED
===================================================================================
LogType:prelaunch.out
LogLastModifiedTime:Wed May 19 02:48:18 -0400 2021
LogLength:70
LogContents:
Setting up env variables
Setting up job resources
Launching container

End of LogType:prelaunch.out
******************************************************************************

Container: container_e10_1609183734776_5900_01_000004 on hadoop07.cusp.nyu.edu_8041
LogAggregationType: AGGREGATED
===================================================================================
LogType:stderr
LogLastModifiedTime:Wed May 19 02:48:18 -0400 2021
LogLength:529
LogContents:
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/localhome/cdp/yarn/nm/filecache/25/spark-jars-2.4.0-hadoop2.7.jar/slf4j-log4j12-1.7.16.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-6.1.0-1.cdh6.1.0.p0.770702/jars/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]

End of LogType:stderr
***********************************************************************

Container: container_e10_1609183734776_5900_01_000004 on hadoop07.cusp.nyu.edu_8041
LogAggregationType: AGGREGATED
===================================================================================
LogType:stdout
LogLastModifiedTime:Wed May 19 02:48:18 -0400 2021
LogLength:41492
LogContents:
2021-05-19 02:45:30 INFO  CoarseGrainedExecutorBackend:2566 - Started daemon with process name: 36280@hadoop07.cusp.nyu.edu
2021-05-19 02:45:30 INFO  SignalUtils:54 - Registered signal handler for TERM
2021-05-19 02:45:30 INFO  SignalUtils:54 - Registered signal handler for HUP
2021-05-19 02:45:30 INFO  SignalUtils:54 - Registered signal handler for INT
2021-05-19 02:45:30 INFO  SecurityManager:54 - Changing view acls to: catherine.ng60
2021-05-19 02:45:30 INFO  SecurityManager:54 - Changing modify acls to: catherine.ng60
2021-05-19 02:45:30 INFO  SecurityManager:54 - Changing view acls groups to: 
2021-05-19 02:45:30 INFO  SecurityManager:54 - Changing modify acls groups to: 
2021-05-19 02:45:30 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(catherine.ng60); groups with view permissions: Set(); users  with modify permissions: Set(catherine.ng60); groups with modify permissions: Set()
2021-05-19 02:45:31 INFO  TransportClientFactory:267 - Successfully created connection to hadoop05.cusp.nyu.edu/192.168.72.175:47481 after 122 ms (0 ms spent in bootstraps)
2021-05-19 02:45:31 INFO  SecurityManager:54 - Changing view acls to: catherine.ng60
2021-05-19 02:45:31 INFO  SecurityManager:54 - Changing modify acls to: catherine.ng60
2021-05-19 02:45:31 INFO  SecurityManager:54 - Changing view acls groups to: 
2021-05-19 02:45:31 INFO  SecurityManager:54 - Changing modify acls groups to: 
2021-05-19 02:45:31 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(catherine.ng60); groups with view permissions: Set(); users  with modify permissions: Set(catherine.ng60); groups with modify permissions: Set()
2021-05-19 02:45:31 INFO  TransportClientFactory:267 - Successfully created connection to hadoop05.cusp.nyu.edu/192.168.72.175:47481 after 4 ms (0 ms spent in bootstraps)
2021-05-19 02:45:32 INFO  DiskBlockManager:54 - Created local directory at /localhome/cdp/yarn/nm/usercache/catherine.ng60/appcache/application_1609183734776_5900/blockmgr-e37379b2-1aca-437e-ab3d-56a189842808
2021-05-19 02:45:32 INFO  MemoryStore:54 - MemoryStore started with capacity 366.3 MB
2021-05-19 02:45:32 INFO  CoarseGrainedExecutorBackend:54 - Connecting to driver: spark://CoarseGrainedScheduler@hadoop05.cusp.nyu.edu:47481
2021-05-19 02:45:32 INFO  CoarseGrainedExecutorBackend:54 - Successfully registered with driver
2021-05-19 02:45:32 INFO  Executor:54 - Starting executor ID 3 on host hadoop07.cusp.nyu.edu
2021-05-19 02:45:32 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 57060.
2021-05-19 02:45:32 INFO  NettyBlockTransferService:54 - Server created on hadoop07.cusp.nyu.edu:57060
2021-05-19 02:45:32 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2021-05-19 02:45:32 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(3, hadoop07.cusp.nyu.edu, 57060, None)
2021-05-19 02:45:32 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(3, hadoop07.cusp.nyu.edu, 57060, None)
2021-05-19 02:45:32 INFO  BlockManager:54 - external shuffle service port = 7337
2021-05-19 02:45:32 INFO  BlockManager:54 - Registering executor with local external shuffle service.
2021-05-19 02:45:32 INFO  TransportClientFactory:267 - Successfully created connection to hadoop07.cusp.nyu.edu/192.168.72.177:7337 after 5 ms (0 ms spent in bootstraps)
2021-05-19 02:45:32 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(3, hadoop07.cusp.nyu.edu, 57060, None)
2021-05-19 02:45:42 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 2
2021-05-19 02:45:42 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 7
2021-05-19 02:45:42 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 12
2021-05-19 02:45:42 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 17
2021-05-19 02:45:42 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 22
2021-05-19 02:45:42 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 27
2021-05-19 02:45:42 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 32
2021-05-19 02:45:42 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 37
2021-05-19 02:45:42 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 42
2021-05-19 02:45:42 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 47
2021-05-19 02:45:42 INFO  Executor:54 - Running task 31.0 in stage 1.0 (TID 32)
2021-05-19 02:45:42 INFO  Executor:54 - Running task 26.0 in stage 1.0 (TID 27)
2021-05-19 02:45:42 INFO  Executor:54 - Running task 21.0 in stage 1.0 (TID 22)
2021-05-19 02:45:42 INFO  Executor:54 - Running task 41.0 in stage 1.0 (TID 42)
2021-05-19 02:45:42 INFO  Executor:54 - Running task 1.0 in stage 1.0 (TID 2)
2021-05-19 02:45:42 INFO  Executor:54 - Running task 6.0 in stage 1.0 (TID 7)
2021-05-19 02:45:42 INFO  Executor:54 - Running task 16.0 in stage 1.0 (TID 17)
2021-05-19 02:45:42 INFO  Executor:54 - Running task 36.0 in stage 1.0 (TID 37)
2021-05-19 02:45:42 INFO  Executor:54 - Running task 11.0 in stage 1.0 (TID 12)
2021-05-19 02:45:42 INFO  Executor:54 - Running task 46.0 in stage 1.0 (TID 47)
2021-05-19 02:45:43 INFO  TorrentBroadcast:54 - Started reading broadcast variable 3
2021-05-19 02:45:43 INFO  TransportClientFactory:267 - Successfully created connection to hadoop08.cusp.nyu.edu/192.168.72.178:54817 after 4 ms (0 ms spent in bootstraps)
2021-05-19 02:45:43 INFO  MemoryStore:54 - Block broadcast_3_piece0 stored as bytes in memory (estimated size 35.0 KB, free 366.3 MB)
2021-05-19 02:45:43 INFO  TorrentBroadcast:54 - Reading broadcast variable 3 took 178 ms
2021-05-19 02:45:43 INFO  MemoryStore:54 - Block broadcast_3 stored as values in memory (estimated size 129.0 KB, free 366.1 MB)
2021-05-19 02:45:45 INFO  Executor:54 - Finished task 1.0 in stage 1.0 (TID 2). 1492 bytes result sent to driver
2021-05-19 02:45:45 INFO  Executor:54 - Finished task 11.0 in stage 1.0 (TID 12). 1492 bytes result sent to driver
2021-05-19 02:45:45 INFO  Executor:54 - Finished task 41.0 in stage 1.0 (TID 42). 1492 bytes result sent to driver
2021-05-19 02:45:45 INFO  Executor:54 - Finished task 46.0 in stage 1.0 (TID 47). 1492 bytes result sent to driver
2021-05-19 02:45:45 INFO  Executor:54 - Finished task 21.0 in stage 1.0 (TID 22). 1492 bytes result sent to driver
2021-05-19 02:45:45 INFO  Executor:54 - Finished task 31.0 in stage 1.0 (TID 32). 1492 bytes result sent to driver
2021-05-19 02:45:45 INFO  Executor:54 - Finished task 6.0 in stage 1.0 (TID 7). 1492 bytes result sent to driver
2021-05-19 02:45:45 INFO  Executor:54 - Finished task 36.0 in stage 1.0 (TID 37). 1492 bytes result sent to driver
2021-05-19 02:45:45 INFO  Executor:54 - Finished task 16.0 in stage 1.0 (TID 17). 1492 bytes result sent to driver
2021-05-19 02:45:45 INFO  Executor:54 - Finished task 26.0 in stage 1.0 (TID 27). 1492 bytes result sent to driver
2021-05-19 02:45:45 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 55
2021-05-19 02:45:45 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 60
2021-05-19 02:45:45 INFO  Executor:54 - Running task 4.0 in stage 2.0 (TID 55)
2021-05-19 02:45:45 INFO  Executor:54 - Running task 9.0 in stage 2.0 (TID 60)
2021-05-19 02:45:45 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 65
2021-05-19 02:45:45 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 70
2021-05-19 02:45:45 INFO  Executor:54 - Running task 14.0 in stage 2.0 (TID 65)
2021-05-19 02:45:45 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 75
2021-05-19 02:45:45 INFO  Executor:54 - Running task 19.0 in stage 2.0 (TID 70)
2021-05-19 02:45:45 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 80
2021-05-19 02:45:45 INFO  Executor:54 - Running task 24.0 in stage 2.0 (TID 75)
2021-05-19 02:45:45 INFO  Executor:54 - Running task 29.0 in stage 2.0 (TID 80)
2021-05-19 02:45:45 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 85
2021-05-19 02:45:45 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 90
2021-05-19 02:45:45 INFO  Executor:54 - Running task 34.0 in stage 2.0 (TID 85)
2021-05-19 02:45:45 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 95
2021-05-19 02:45:45 INFO  Executor:54 - Running task 39.0 in stage 2.0 (TID 90)
2021-05-19 02:45:45 INFO  Executor:54 - Running task 44.0 in stage 2.0 (TID 95)
2021-05-19 02:45:45 INFO  TorrentBroadcast:54 - Started reading broadcast variable 4
2021-05-19 02:45:45 INFO  TransportClientFactory:267 - Successfully created connection to hadoop05.cusp.nyu.edu/192.168.72.175:36982 after 5 ms (0 ms spent in bootstraps)
2021-05-19 02:45:45 INFO  MemoryStore:54 - Block broadcast_4_piece0 stored as bytes in memory (estimated size 35.0 KB, free 366.1 MB)
2021-05-19 02:45:45 INFO  TorrentBroadcast:54 - Reading broadcast variable 4 took 62 ms
2021-05-19 02:45:45 INFO  MemoryStore:54 - Block broadcast_4 stored as values in memory (estimated size 129.0 KB, free 366.0 MB)
2021-05-19 02:45:45 INFO  Executor:54 - Finished task 24.0 in stage 2.0 (TID 75). 1449 bytes result sent to driver
2021-05-19 02:45:45 INFO  Executor:54 - Finished task 39.0 in stage 2.0 (TID 90). 1449 bytes result sent to driver
2021-05-19 02:45:45 INFO  Executor:54 - Finished task 29.0 in stage 2.0 (TID 80). 1449 bytes result sent to driver
2021-05-19 02:45:45 INFO  Executor:54 - Finished task 4.0 in stage 2.0 (TID 55). 1449 bytes result sent to driver
2021-05-19 02:45:45 INFO  Executor:54 - Finished task 34.0 in stage 2.0 (TID 85). 1449 bytes result sent to driver
2021-05-19 02:45:45 INFO  Executor:54 - Finished task 9.0 in stage 2.0 (TID 60). 1406 bytes result sent to driver
2021-05-19 02:45:45 INFO  Executor:54 - Finished task 44.0 in stage 2.0 (TID 95). 1406 bytes result sent to driver
2021-05-19 02:45:45 INFO  Executor:54 - Finished task 19.0 in stage 2.0 (TID 70). 1449 bytes result sent to driver
2021-05-19 02:45:45 INFO  Executor:54 - Finished task 14.0 in stage 2.0 (TID 65). 1449 bytes result sent to driver
2021-05-19 02:45:46 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 100
2021-05-19 02:45:46 INFO  Executor:54 - Running task 0.0 in stage 3.0 (TID 100)
2021-05-19 02:45:46 INFO  TorrentBroadcast:54 - Started reading broadcast variable 6
2021-05-19 02:45:46 INFO  MemoryStore:54 - Block broadcast_6_piece0 stored as bytes in memory (estimated size 4.5 KB, free 366.3 MB)
2021-05-19 02:45:46 INFO  TorrentBroadcast:54 - Reading broadcast variable 6 took 24 ms
2021-05-19 02:45:46 INFO  MemoryStore:54 - Block broadcast_6 stored as values in memory (estimated size 8.8 KB, free 366.3 MB)
2021-05-19 02:45:47 INFO  CodeGenerator:54 - Code generated in 384.069909 ms
2021-05-19 02:45:47 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00000, range: 0-134217728, partition values: [empty row]
2021-05-19 02:45:47 INFO  CodeGenerator:54 - Code generated in 30.518028 ms
2021-05-19 02:45:47 INFO  TorrentBroadcast:54 - Started reading broadcast variable 5
2021-05-19 02:45:47 INFO  MemoryStore:54 - Block broadcast_5_piece0 stored as bytes in memory (estimated size 33.4 KB, free 366.3 MB)
2021-05-19 02:45:47 INFO  TorrentBroadcast:54 - Reading broadcast variable 5 took 22 ms
2021-05-19 02:45:47 INFO  MemoryStore:54 - Block broadcast_5 stored as values in memory (estimated size 506.4 KB, free 365.8 MB)
2021-05-19 02:45:47 INFO  Executor:54 - Finished task 0.0 in stage 3.0 (TID 100). 1646 bytes result sent to driver
2021-05-19 02:45:51 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 118
2021-05-19 02:45:51 INFO  Executor:54 - Running task 0.0 in stage 5.0 (TID 118)
2021-05-19 02:45:51 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 123
2021-05-19 02:45:51 INFO  Executor:54 - Running task 6.0 in stage 5.0 (TID 123)
2021-05-19 02:45:51 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 127
2021-05-19 02:45:51 INFO  MapOutputTrackerWorker:54 - Updating epoch to 1 and clearing cache
2021-05-19 02:45:51 INFO  Executor:54 - Running task 10.0 in stage 5.0 (TID 127)
2021-05-19 02:45:51 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 131
2021-05-19 02:45:51 INFO  Executor:54 - Running task 14.0 in stage 5.0 (TID 131)
2021-05-19 02:45:51 INFO  TorrentBroadcast:54 - Started reading broadcast variable 10
2021-05-19 02:45:51 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 135
2021-05-19 02:45:51 INFO  Executor:54 - Running task 19.0 in stage 5.0 (TID 135)
2021-05-19 02:45:51 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 139
2021-05-19 02:45:51 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 143
2021-05-19 02:45:51 INFO  Executor:54 - Running task 23.0 in stage 5.0 (TID 139)
2021-05-19 02:45:51 INFO  Executor:54 - Running task 28.0 in stage 5.0 (TID 143)
2021-05-19 02:45:51 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 147
2021-05-19 02:45:51 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 151
2021-05-19 02:45:51 INFO  Executor:54 - Running task 32.0 in stage 5.0 (TID 147)
2021-05-19 02:45:51 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 155
2021-05-19 02:45:51 INFO  Executor:54 - Running task 37.0 in stage 5.0 (TID 151)
2021-05-19 02:45:51 INFO  Executor:54 - Running task 41.0 in stage 5.0 (TID 155)
2021-05-19 02:45:51 INFO  MemoryStore:54 - Block broadcast_10_piece0 stored as bytes in memory (estimated size 20.4 KB, free 366.3 MB)
2021-05-19 02:45:51 INFO  TorrentBroadcast:54 - Reading broadcast variable 10 took 36 ms
2021-05-19 02:45:51 INFO  MemoryStore:54 - Block broadcast_10 stored as values in memory (estimated size 40.9 KB, free 366.2 MB)
2021-05-19 02:45:52 INFO  MapOutputTrackerWorker:54 - Don't have map outputs for shuffle 0, fetching them
2021-05-19 02:45:52 INFO  MapOutputTrackerWorker:54 - Don't have map outputs for shuffle 0, fetching them
2021-05-19 02:45:52 INFO  MapOutputTrackerWorker:54 - Don't have map outputs for shuffle 0, fetching them
2021-05-19 02:45:52 INFO  MapOutputTrackerWorker:54 - Doing the fetch; tracker endpoint = NettyRpcEndpointRef(spark://MapOutputTracker@hadoop05.cusp.nyu.edu:47481)
2021-05-19 02:45:52 INFO  MapOutputTrackerWorker:54 - Don't have map outputs for shuffle 0, fetching them
2021-05-19 02:45:52 INFO  MapOutputTrackerWorker:54 - Don't have map outputs for shuffle 0, fetching them
2021-05-19 02:45:52 INFO  MapOutputTrackerWorker:54 - Don't have map outputs for shuffle 0, fetching them
2021-05-19 02:45:52 INFO  MapOutputTrackerWorker:54 - Don't have map outputs for shuffle 0, fetching them
2021-05-19 02:45:52 INFO  MapOutputTrackerWorker:54 - Don't have map outputs for shuffle 0, fetching them
2021-05-19 02:45:52 INFO  MapOutputTrackerWorker:54 - Don't have map outputs for shuffle 0, fetching them
2021-05-19 02:45:52 INFO  MapOutputTrackerWorker:54 - Don't have map outputs for shuffle 0, fetching them
2021-05-19 02:45:52 INFO  MapOutputTrackerWorker:54 - Got the output locations
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 14 ms
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 16 ms
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 18 ms
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 15 ms
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 16 ms
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 15 ms
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 14 ms
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 14 ms
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 14 ms
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 14 ms
2021-05-19 02:45:52 INFO  CodeGenerator:54 - Code generated in 93.347212 ms
2021-05-19 02:45:52 INFO  CodeGenerator:54 - Code generated in 21.224076 ms
2021-05-19 02:45:52 INFO  CodeGenerator:54 - Code generated in 31.680144 ms
2021-05-19 02:45:52 INFO  Executor:54 - Finished task 14.0 in stage 5.0 (TID 131). 3733 bytes result sent to driver
2021-05-19 02:45:52 INFO  Executor:54 - Finished task 10.0 in stage 5.0 (TID 127). 3733 bytes result sent to driver
2021-05-19 02:45:52 INFO  Executor:54 - Finished task 23.0 in stage 5.0 (TID 139). 3733 bytes result sent to driver
2021-05-19 02:45:52 INFO  Executor:54 - Finished task 32.0 in stage 5.0 (TID 147). 3733 bytes result sent to driver
2021-05-19 02:45:52 INFO  Executor:54 - Finished task 0.0 in stage 5.0 (TID 118). 3733 bytes result sent to driver
2021-05-19 02:45:52 INFO  Executor:54 - Finished task 37.0 in stage 5.0 (TID 151). 3733 bytes result sent to driver
2021-05-19 02:45:52 INFO  Executor:54 - Finished task 19.0 in stage 5.0 (TID 135). 3733 bytes result sent to driver
2021-05-19 02:45:52 INFO  Executor:54 - Finished task 6.0 in stage 5.0 (TID 123). 3733 bytes result sent to driver
2021-05-19 02:45:52 INFO  Executor:54 - Finished task 28.0 in stage 5.0 (TID 143). 3733 bytes result sent to driver
2021-05-19 02:45:52 INFO  Executor:54 - Finished task 41.0 in stage 5.0 (TID 155). 3733 bytes result sent to driver
2021-05-19 02:45:52 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 255
2021-05-19 02:45:52 INFO  Executor:54 - Running task 143.0 in stage 5.0 (TID 255)
2021-05-19 02:45:52 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 256
2021-05-19 02:45:52 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 257
2021-05-19 02:45:52 INFO  Executor:54 - Running task 145.0 in stage 5.0 (TID 256)
2021-05-19 02:45:52 INFO  Executor:54 - Running task 146.0 in stage 5.0 (TID 257)
2021-05-19 02:45:52 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 258
2021-05-19 02:45:52 INFO  Executor:54 - Running task 147.0 in stage 5.0 (TID 258)
2021-05-19 02:45:52 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 260
2021-05-19 02:45:52 INFO  Executor:54 - Running task 149.0 in stage 5.0 (TID 260)
2021-05-19 02:45:52 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 261
2021-05-19 02:45:52 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 263
2021-05-19 02:45:52 INFO  Executor:54 - Running task 150.0 in stage 5.0 (TID 261)
2021-05-19 02:45:52 INFO  Executor:54 - Running task 152.0 in stage 5.0 (TID 263)
2021-05-19 02:45:52 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 264
2021-05-19 02:45:52 INFO  Executor:54 - Running task 153.0 in stage 5.0 (TID 264)
2021-05-19 02:45:52 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 266
2021-05-19 02:45:52 INFO  Executor:54 - Running task 155.0 in stage 5.0 (TID 266)
2021-05-19 02:45:52 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 267
2021-05-19 02:45:52 INFO  Executor:54 - Running task 156.0 in stage 5.0 (TID 267)
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2021-05-19 02:45:52 INFO  Executor:54 - Finished task 145.0 in stage 5.0 (TID 256). 3733 bytes result sent to driver
2021-05-19 02:45:52 INFO  Executor:54 - Finished task 146.0 in stage 5.0 (TID 257). 3733 bytes result sent to driver
2021-05-19 02:45:52 INFO  Executor:54 - Finished task 143.0 in stage 5.0 (TID 255). 3733 bytes result sent to driver
2021-05-19 02:45:52 INFO  Executor:54 - Finished task 149.0 in stage 5.0 (TID 260). 3733 bytes result sent to driver
2021-05-19 02:45:52 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 291
2021-05-19 02:45:52 INFO  Executor:54 - Running task 181.0 in stage 5.0 (TID 291)
2021-05-19 02:45:52 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 292
2021-05-19 02:45:52 INFO  Executor:54 - Finished task 147.0 in stage 5.0 (TID 258). 3733 bytes result sent to driver
2021-05-19 02:45:52 INFO  Executor:54 - Running task 182.0 in stage 5.0 (TID 292)
2021-05-19 02:45:52 INFO  Executor:54 - Finished task 150.0 in stage 5.0 (TID 261). 3733 bytes result sent to driver
2021-05-19 02:45:52 INFO  Executor:54 - Finished task 155.0 in stage 5.0 (TID 266). 3733 bytes result sent to driver
2021-05-19 02:45:52 INFO  Executor:54 - Finished task 156.0 in stage 5.0 (TID 267). 3733 bytes result sent to driver
2021-05-19 02:45:52 INFO  Executor:54 - Finished task 153.0 in stage 5.0 (TID 264). 3733 bytes result sent to driver
2021-05-19 02:45:52 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 294
2021-05-19 02:45:52 INFO  Executor:54 - Finished task 152.0 in stage 5.0 (TID 263). 3733 bytes result sent to driver
2021-05-19 02:45:52 INFO  Executor:54 - Running task 184.0 in stage 5.0 (TID 294)
2021-05-19 02:45:52 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 296
2021-05-19 02:45:52 INFO  Executor:54 - Running task 186.0 in stage 5.0 (TID 296)
2021-05-19 02:45:52 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 297
2021-05-19 02:45:52 INFO  Executor:54 - Running task 187.0 in stage 5.0 (TID 297)
2021-05-19 02:45:52 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 299
2021-05-19 02:45:52 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 301
2021-05-19 02:45:52 INFO  Executor:54 - Running task 190.0 in stage 5.0 (TID 299)
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:45:52 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 303
2021-05-19 02:45:52 INFO  Executor:54 - Running task 192.0 in stage 5.0 (TID 301)
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:45:52 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 304
2021-05-19 02:45:52 INFO  Executor:54 - Running task 194.0 in stage 5.0 (TID 303)
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2021-05-19 02:45:52 INFO  Executor:54 - Running task 195.0 in stage 5.0 (TID 304)
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 3 ms
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 2 ms
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 2 ms
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:45:52 INFO  Executor:54 - Finished task 181.0 in stage 5.0 (TID 291). 3776 bytes result sent to driver
2021-05-19 02:45:52 INFO  Executor:54 - Finished task 182.0 in stage 5.0 (TID 292). 3733 bytes result sent to driver
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2021-05-19 02:45:52 INFO  Executor:54 - Finished task 184.0 in stage 5.0 (TID 294). 3733 bytes result sent to driver
2021-05-19 02:45:52 INFO  Executor:54 - Finished task 195.0 in stage 5.0 (TID 304). 3733 bytes result sent to driver
2021-05-19 02:45:52 INFO  Executor:54 - Finished task 186.0 in stage 5.0 (TID 296). 3776 bytes result sent to driver
2021-05-19 02:45:52 INFO  Executor:54 - Finished task 187.0 in stage 5.0 (TID 297). 3733 bytes result sent to driver
2021-05-19 02:45:52 INFO  Executor:54 - Finished task 190.0 in stage 5.0 (TID 299). 3776 bytes result sent to driver
2021-05-19 02:45:52 INFO  Executor:54 - Finished task 192.0 in stage 5.0 (TID 301). 3776 bytes result sent to driver
2021-05-19 02:45:52 INFO  Executor:54 - Finished task 194.0 in stage 5.0 (TID 303). 3733 bytes result sent to driver
2021-05-19 02:45:56 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 320
2021-05-19 02:45:56 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 325
2021-05-19 02:45:56 INFO  Executor:54 - Running task 0.0 in stage 7.0 (TID 320)
2021-05-19 02:45:56 INFO  Executor:54 - Running task 5.0 in stage 7.0 (TID 325)
2021-05-19 02:45:56 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 330
2021-05-19 02:45:56 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 335
2021-05-19 02:45:56 INFO  Executor:54 - Running task 22.0 in stage 7.0 (TID 330)
2021-05-19 02:45:56 INFO  Executor:54 - Running task 23.0 in stage 7.0 (TID 335)
2021-05-19 02:45:56 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 340
2021-05-19 02:45:56 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 345
2021-05-19 02:45:56 INFO  Executor:54 - Running task 24.0 in stage 7.0 (TID 340)
2021-05-19 02:45:56 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 350
2021-05-19 02:45:56 INFO  Executor:54 - Running task 34.0 in stage 7.0 (TID 345)
2021-05-19 02:45:56 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 355
2021-05-19 02:45:56 INFO  Executor:54 - Running task 37.0 in stage 7.0 (TID 350)
2021-05-19 02:45:56 INFO  TorrentBroadcast:54 - Started reading broadcast variable 14
2021-05-19 02:45:56 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 360
2021-05-19 02:45:56 INFO  Executor:54 - Running task 41.0 in stage 7.0 (TID 360)
2021-05-19 02:45:56 INFO  Executor:54 - Running task 38.0 in stage 7.0 (TID 355)
2021-05-19 02:45:56 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 364
2021-05-19 02:45:56 INFO  Executor:54 - Running task 42.0 in stage 7.0 (TID 364)
2021-05-19 02:45:56 INFO  MemoryStore:54 - Block broadcast_14_piece0 stored as bytes in memory (estimated size 22.9 KB, free 366.3 MB)
2021-05-19 02:45:56 INFO  TorrentBroadcast:54 - Reading broadcast variable 14 took 32 ms
2021-05-19 02:45:56 INFO  MemoryStore:54 - Block broadcast_14 stored as values in memory (estimated size 51.5 KB, free 366.2 MB)
2021-05-19 02:45:56 INFO  CodeGenerator:54 - Code generated in 51.249921 ms
2021-05-19 02:45:56 INFO  TorrentBroadcast:54 - Started reading broadcast variable 12
2021-05-19 02:45:56 INFO  MemoryStore:54 - Block broadcast_12_piece0 stored as bytes in memory (estimated size 580.1 KB, free 365.7 MB)
2021-05-19 02:45:56 INFO  TorrentBroadcast:54 - Reading broadcast variable 12 took 29 ms
2021-05-19 02:45:56 INFO  MemoryStore:54 - Block broadcast_12 stored as values in memory (estimated size 5.0 MB, free 360.7 MB)
2021-05-19 02:45:56 INFO  CodeGenerator:54 - Code generated in 25.24875 ms
2021-05-19 02:45:57 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00034, range: 0-134217728, partition values: [empty row]
2021-05-19 02:45:57 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00023, range: 0-134217728, partition values: [empty row]
2021-05-19 02:45:57 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00037, range: 0-134217728, partition values: [empty row]
2021-05-19 02:45:57 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00024, range: 0-134217728, partition values: [empty row]
2021-05-19 02:45:57 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00022, range: 0-134217728, partition values: [empty row]
2021-05-19 02:45:57 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00000, range: 0-134217728, partition values: [empty row]
2021-05-19 02:45:57 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00041, range: 0-134217728, partition values: [empty row]
2021-05-19 02:45:57 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00005, range: 0-134217728, partition values: [empty row]
2021-05-19 02:45:57 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00038, range: 0-134217728, partition values: [empty row]
2021-05-19 02:45:57 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00042, range: 0-134217728, partition values: [empty row]
2021-05-19 02:45:57 INFO  CodeGenerator:54 - Code generated in 57.062945 ms
2021-05-19 02:45:57 INFO  CodeGenerator:54 - Code generated in 83.212339 ms
2021-05-19 02:45:57 INFO  TorrentBroadcast:54 - Started reading broadcast variable 13
2021-05-19 02:45:57 INFO  MemoryStore:54 - Block broadcast_13_piece0 stored as bytes in memory (estimated size 33.4 KB, free 360.6 MB)
2021-05-19 02:45:57 INFO  TorrentBroadcast:54 - Reading broadcast variable 13 took 18 ms
2021-05-19 02:45:57 INFO  CodeGenerator:54 - Code generated in 35.484112 ms
2021-05-19 02:45:57 INFO  MemoryStore:54 - Block broadcast_13 stored as values in memory (estimated size 506.4 KB, free 360.1 MB)
2021-05-19 02:45:57 INFO  CodeGenerator:54 - Code generated in 31.256677 ms
2021-05-19 02:45:57 INFO  CodeGenerator:54 - Code generated in 36.250681 ms
2021-05-19 02:45:57 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: 224-222@627-s8r-975, 2019-12-02T00:00:00-05:00, [15,24,17,27,24,13,21]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: 224-222@627-s8r-975
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00024
2021-05-19 02:45:57 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: 222-222@627-s95-rc5, 2018-12-31T00:00:00-05:00, [5,6,50,52,24,0,0]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: 222-222@627-s95-rc5
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00005
2021-05-19 02:45:57 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: 22f-222@627-s8x-c5z, 2020-10-26T00:00:00-04:00, [1,0,0,0,0,0,0]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: 22f-222@627-s8x-c5z
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00042
2021-05-19 02:45:57 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: zzy-222@627-wf8-59f, 2019-07-08T00:00:00-04:00, [0,5,1,0,6,2,4]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: zzy-222@627-wf8-59f
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00037
2021-05-19 02:45:57 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: 22b-222@627-s4r-s3q, 2019-11-04T00:00:00-05:00, [20,15,14,25,21,16,15]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: 22b-222@627-s4r-s3q
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00023
2021-05-19 02:45:57 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: zzw-222@627-s6d-wx5, 2019-12-02T00:00:00-05:00, [1,1,0,0,0,4,5]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: zzw-222@627-s6d-wx5
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00034
2021-05-19 02:45:57 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: zzw-226@627-wc7-49z, 2019-02-11T00:00:00-05:00, [26,15,15,20,33,6,11]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: zzw-226@627-wc7-49z
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00022
2021-05-19 02:45:57 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: zzw-222@627-s65-bx5, 2020-09-28T00:00:00-04:00, [0,1,0,2,0,0,0]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: zzw-222@627-s65-bx5
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00041
2021-05-19 02:45:57 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: 22f-222@627-wdh-sdv, 2019-06-10T00:00:00-04:00, [4,2,3,3,3,1,0]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: 22f-222@627-wdh-sdv
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00038
2021-05-19 02:45:58 INFO  CodeGenerator:54 - Code generated in 16.12973 ms
2021-05-19 02:45:58 INFO  CodeGenerator:54 - Code generated in 52.799293 ms
2021-05-19 02:45:58 INFO  CodeGenerator:54 - Code generated in 25.74136 ms
2021-05-19 02:45:59 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:45:59 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:45:59 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:45:59 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:45:59 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:45:59 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:45:59 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:45:59 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:45:59 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:45:59 INFO  CodeGenerator:54 - Code generated in 53.469752 ms
2021-05-19 02:45:59 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:45:59 INFO  CodeGenerator:54 - Code generated in 61.152236 ms
2021-05-19 02:45:59 INFO  CodeGenerator:54 - Code generated in 19.16202 ms
2021-05-19 02:45:59 INFO  CodeGenerator:54 - Code generated in 19.020725 ms
2021-05-19 02:46:08 INFO  PythonUDFRunner:54 - Times: total = 12266, boot = 675, init = 949, finish = 10642
2021-05-19 02:46:08 INFO  PythonUDFRunner:54 - Times: total = 12285, boot = 749, init = 879, finish = 10657
2021-05-19 02:46:09 INFO  PythonUDFRunner:54 - Times: total = 12565, boot = 727, init = 891, finish = 10947
2021-05-19 02:46:09 INFO  PythonUDFRunner:54 - Times: total = 12572, boot = 771, init = 858, finish = 10943
2021-05-19 02:46:09 INFO  PythonUDFRunner:54 - Times: total = 12581, boot = 739, init = 883, finish = 10959
2021-05-19 02:46:09 INFO  PythonUDFRunner:54 - Times: total = 12642, boot = 707, init = 915, finish = 11020
2021-05-19 02:46:09 INFO  UnsafeExternalSorter:209 - Thread 122 spilling sort data of 34.0 MB to disk (0  time so far)
2021-05-19 02:46:09 INFO  PythonUDFRunner:54 - Times: total = 12743, boot = 717, init = 907, finish = 11119
2021-05-19 02:46:09 INFO  PythonUDFRunner:54 - Times: total = 12755, boot = 698, init = 930, finish = 11127
2021-05-19 02:46:09 ERROR CoarseGrainedExecutorBackend:43 - RECEIVED SIGNAL TERM
2021-05-19 02:46:09 INFO  DiskBlockManager:54 - Shutdown hook called
2021-05-19 02:46:09 INFO  ShutdownHookManager:54 - Shutdown hook called
2021-05-19 02:46:09 INFO  ShutdownHookManager:54 - Deleting directory /localhome/cdp/yarn/nm/usercache/catherine.ng60/appcache/application_1609183734776_5900/spark-b5fe8447-29c7-4c6e-a9ea-100bc4165841

End of LogType:stdout
***********************************************************************

Container: container_e10_1609183734776_5900_01_000006 on hadoop08.cusp.nyu.edu_8041
LogAggregationType: AGGREGATED
===================================================================================
LogType:container-localizer-syslog
LogLastModifiedTime:Wed May 19 02:48:18 -0400 2021
LogLength:506
LogContents:
2021-05-19 02:45:27,067 INFO [main] org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ContainerLocalizer: Disk Validator: yarn.nodemanager.disk-validator is loaded.
2021-05-19 02:45:28,330 WARN [ContainerLocalizer Downloader] org.apache.hadoop.ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ipc.StandbyException): Operation category READ is not supported in state standby. Visit https://s.apache.org/sbnn-error

End of LogType:container-localizer-syslog
*******************************************************************************************


End of LogType:prelaunch.err
******************************************************************************

Container: container_e10_1609183734776_5900_01_000006 on hadoop08.cusp.nyu.edu_8041
LogAggregationType: AGGREGATED
===================================================================================
LogType:prelaunch.out
LogLastModifiedTime:Wed May 19 02:48:18 -0400 2021
LogLength:70
LogContents:
Setting up env variables
Setting up job resources
Launching container

End of LogType:prelaunch.out
******************************************************************************

Container: container_e10_1609183734776_5900_01_000006 on hadoop08.cusp.nyu.edu_8041
LogAggregationType: AGGREGATED
===================================================================================
LogType:stderr
LogLastModifiedTime:Wed May 19 02:48:18 -0400 2021
LogLength:529
LogContents:
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/localhome/cdp/yarn/nm/filecache/35/spark-jars-2.4.0-hadoop2.7.jar/slf4j-log4j12-1.7.16.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-6.1.0-1.cdh6.1.0.p0.770702/jars/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]

End of LogType:stderr
***********************************************************************

Container: container_e10_1609183734776_5900_01_000006 on hadoop08.cusp.nyu.edu_8041
LogAggregationType: AGGREGATED
===================================================================================
LogType:stdout
LogLastModifiedTime:Wed May 19 02:48:18 -0400 2021
LogLength:131510
LogContents:
2021-05-19 02:45:29 INFO  CoarseGrainedExecutorBackend:2566 - Started daemon with process name: 49054@hadoop08.cusp.nyu.edu
2021-05-19 02:45:29 INFO  SignalUtils:54 - Registered signal handler for TERM
2021-05-19 02:45:29 INFO  SignalUtils:54 - Registered signal handler for HUP
2021-05-19 02:45:29 INFO  SignalUtils:54 - Registered signal handler for INT
2021-05-19 02:45:30 INFO  SecurityManager:54 - Changing view acls to: catherine.ng60
2021-05-19 02:45:30 INFO  SecurityManager:54 - Changing modify acls to: catherine.ng60
2021-05-19 02:45:30 INFO  SecurityManager:54 - Changing view acls groups to: 
2021-05-19 02:45:30 INFO  SecurityManager:54 - Changing modify acls groups to: 
2021-05-19 02:45:30 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(catherine.ng60); groups with view permissions: Set(); users  with modify permissions: Set(catherine.ng60); groups with modify permissions: Set()
2021-05-19 02:45:31 INFO  TransportClientFactory:267 - Successfully created connection to hadoop05.cusp.nyu.edu/192.168.72.175:47481 after 118 ms (0 ms spent in bootstraps)
2021-05-19 02:45:31 INFO  SecurityManager:54 - Changing view acls to: catherine.ng60
2021-05-19 02:45:31 INFO  SecurityManager:54 - Changing modify acls to: catherine.ng60
2021-05-19 02:45:31 INFO  SecurityManager:54 - Changing view acls groups to: 
2021-05-19 02:45:31 INFO  SecurityManager:54 - Changing modify acls groups to: 
2021-05-19 02:45:31 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(catherine.ng60); groups with view permissions: Set(); users  with modify permissions: Set(catherine.ng60); groups with modify permissions: Set()
2021-05-19 02:45:31 INFO  TransportClientFactory:267 - Successfully created connection to hadoop05.cusp.nyu.edu/192.168.72.175:47481 after 4 ms (0 ms spent in bootstraps)
2021-05-19 02:45:31 INFO  DiskBlockManager:54 - Created local directory at /localhome/cdp/yarn/nm/usercache/catherine.ng60/appcache/application_1609183734776_5900/blockmgr-78de6f60-96d0-4db1-953c-9de50022ec93
2021-05-19 02:45:32 INFO  MemoryStore:54 - MemoryStore started with capacity 366.3 MB
2021-05-19 02:45:32 INFO  CoarseGrainedExecutorBackend:54 - Connecting to driver: spark://CoarseGrainedScheduler@hadoop05.cusp.nyu.edu:47481
2021-05-19 02:45:32 INFO  CoarseGrainedExecutorBackend:54 - Successfully registered with driver
2021-05-19 02:45:32 INFO  Executor:54 - Starting executor ID 5 on host hadoop08.cusp.nyu.edu
2021-05-19 02:45:32 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 54817.
2021-05-19 02:45:32 INFO  NettyBlockTransferService:54 - Server created on hadoop08.cusp.nyu.edu:54817
2021-05-19 02:45:32 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2021-05-19 02:45:32 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(5, hadoop08.cusp.nyu.edu, 54817, None)
2021-05-19 02:45:32 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(5, hadoop08.cusp.nyu.edu, 54817, None)
2021-05-19 02:45:32 INFO  BlockManager:54 - external shuffle service port = 7337
2021-05-19 02:45:32 INFO  BlockManager:54 - Registering executor with local external shuffle service.
2021-05-19 02:45:32 INFO  TransportClientFactory:267 - Successfully created connection to hadoop08.cusp.nyu.edu/192.168.72.178:7337 after 3 ms (0 ms spent in bootstraps)
2021-05-19 02:45:32 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(5, hadoop08.cusp.nyu.edu, 54817, None)
2021-05-19 02:45:38 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 0
2021-05-19 02:45:38 INFO  Executor:54 - Running task 0.0 in stage 0.0 (TID 0)
2021-05-19 02:45:38 INFO  TorrentBroadcast:54 - Started reading broadcast variable 1
2021-05-19 02:45:38 INFO  TransportClientFactory:267 - Successfully created connection to hadoop05.cusp.nyu.edu/192.168.72.175:36982 after 5 ms (0 ms spent in bootstraps)
2021-05-19 02:45:38 INFO  MemoryStore:54 - Block broadcast_1_piece0 stored as bytes in memory (estimated size 4.5 KB, free 366.3 MB)
2021-05-19 02:45:38 INFO  TorrentBroadcast:54 - Reading broadcast variable 1 took 189 ms
2021-05-19 02:45:39 INFO  MemoryStore:54 - Block broadcast_1 stored as values in memory (estimated size 8.8 KB, free 366.3 MB)
2021-05-19 02:45:40 INFO  CodeGenerator:54 - Code generated in 467.006704 ms
2021-05-19 02:45:40 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/core-places-nyc.csv, range: 0-4194304, partition values: [empty row]
2021-05-19 02:45:40 INFO  CodeGenerator:54 - Code generated in 25.813205 ms
2021-05-19 02:45:40 INFO  TorrentBroadcast:54 - Started reading broadcast variable 0
2021-05-19 02:45:40 INFO  MemoryStore:54 - Block broadcast_0_piece0 stored as bytes in memory (estimated size 33.4 KB, free 366.3 MB)
2021-05-19 02:45:40 INFO  TorrentBroadcast:54 - Reading broadcast variable 0 took 36 ms
2021-05-19 02:45:40 INFO  MemoryStore:54 - Block broadcast_0 stored as values in memory (estimated size 506.4 KB, free 365.8 MB)
2021-05-19 02:45:41 INFO  Executor:54 - Finished task 0.0 in stage 0.0 (TID 0). 1594 bytes result sent to driver
2021-05-19 02:45:42 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 1
2021-05-19 02:45:42 INFO  Executor:54 - Running task 0.0 in stage 1.0 (TID 1)
2021-05-19 02:45:42 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 6
2021-05-19 02:45:42 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 11
2021-05-19 02:45:42 INFO  Executor:54 - Running task 5.0 in stage 1.0 (TID 6)
2021-05-19 02:45:42 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 16
2021-05-19 02:45:42 INFO  Executor:54 - Running task 10.0 in stage 1.0 (TID 11)
2021-05-19 02:45:42 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 21
2021-05-19 02:45:42 INFO  Executor:54 - Running task 15.0 in stage 1.0 (TID 16)
2021-05-19 02:45:42 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 26
2021-05-19 02:45:42 INFO  Executor:54 - Running task 20.0 in stage 1.0 (TID 21)
2021-05-19 02:45:42 INFO  Executor:54 - Running task 25.0 in stage 1.0 (TID 26)
2021-05-19 02:45:42 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 31
2021-05-19 02:45:42 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 36
2021-05-19 02:45:42 INFO  Executor:54 - Running task 30.0 in stage 1.0 (TID 31)
2021-05-19 02:45:42 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 41
2021-05-19 02:45:42 INFO  Executor:54 - Running task 35.0 in stage 1.0 (TID 36)
2021-05-19 02:45:42 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 46
2021-05-19 02:45:42 INFO  Executor:54 - Running task 40.0 in stage 1.0 (TID 41)
2021-05-19 02:45:42 INFO  Executor:54 - Running task 45.0 in stage 1.0 (TID 46)
2021-05-19 02:45:42 INFO  TorrentBroadcast:54 - Started reading broadcast variable 3
2021-05-19 02:45:42 INFO  MemoryStore:54 - Block broadcast_3_piece0 stored as bytes in memory (estimated size 35.0 KB, free 365.7 MB)
2021-05-19 02:45:42 INFO  TorrentBroadcast:54 - Reading broadcast variable 3 took 28 ms
2021-05-19 02:45:42 INFO  MemoryStore:54 - Block broadcast_3 stored as values in memory (estimated size 129.0 KB, free 365.6 MB)
2021-05-19 02:45:42 INFO  Executor:54 - Finished task 0.0 in stage 1.0 (TID 1). 837 bytes result sent to driver
2021-05-19 02:45:42 INFO  Executor:54 - Finished task 40.0 in stage 1.0 (TID 41). 1492 bytes result sent to driver
2021-05-19 02:45:42 INFO  Executor:54 - Finished task 25.0 in stage 1.0 (TID 26). 1492 bytes result sent to driver
2021-05-19 02:45:42 INFO  Executor:54 - Finished task 5.0 in stage 1.0 (TID 6). 1492 bytes result sent to driver
2021-05-19 02:45:42 INFO  Executor:54 - Finished task 45.0 in stage 1.0 (TID 46). 1492 bytes result sent to driver
2021-05-19 02:45:42 INFO  Executor:54 - Finished task 10.0 in stage 1.0 (TID 11). 1492 bytes result sent to driver
2021-05-19 02:45:42 INFO  Executor:54 - Finished task 35.0 in stage 1.0 (TID 36). 1492 bytes result sent to driver
2021-05-19 02:45:42 INFO  Executor:54 - Finished task 30.0 in stage 1.0 (TID 31). 1492 bytes result sent to driver
2021-05-19 02:45:42 INFO  Executor:54 - Finished task 20.0 in stage 1.0 (TID 21). 1492 bytes result sent to driver
2021-05-19 02:45:42 INFO  Executor:54 - Finished task 15.0 in stage 1.0 (TID 16). 1492 bytes result sent to driver
2021-05-19 02:45:45 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 54
2021-05-19 02:45:45 INFO  Executor:54 - Running task 3.0 in stage 2.0 (TID 54)
2021-05-19 02:45:45 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 59
2021-05-19 02:45:45 INFO  Executor:54 - Running task 8.0 in stage 2.0 (TID 59)
2021-05-19 02:45:45 INFO  TorrentBroadcast:54 - Started reading broadcast variable 4
2021-05-19 02:45:45 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 64
2021-05-19 02:45:45 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 69
2021-05-19 02:45:45 INFO  Executor:54 - Running task 18.0 in stage 2.0 (TID 69)
2021-05-19 02:45:45 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 74
2021-05-19 02:45:45 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 79
2021-05-19 02:45:45 INFO  Executor:54 - Running task 13.0 in stage 2.0 (TID 64)
2021-05-19 02:45:45 INFO  Executor:54 - Running task 23.0 in stage 2.0 (TID 74)
2021-05-19 02:45:45 INFO  Executor:54 - Running task 28.0 in stage 2.0 (TID 79)
2021-05-19 02:45:45 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 84
2021-05-19 02:45:45 INFO  Executor:54 - Running task 33.0 in stage 2.0 (TID 84)
2021-05-19 02:45:45 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 89
2021-05-19 02:45:45 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 94
2021-05-19 02:45:45 INFO  Executor:54 - Running task 38.0 in stage 2.0 (TID 89)
2021-05-19 02:45:45 INFO  Executor:54 - Running task 43.0 in stage 2.0 (TID 94)
2021-05-19 02:45:45 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 99
2021-05-19 02:45:45 INFO  Executor:54 - Running task 48.0 in stage 2.0 (TID 99)
2021-05-19 02:45:45 INFO  MemoryStore:54 - Block broadcast_4_piece0 stored as bytes in memory (estimated size 35.0 KB, free 366.1 MB)
2021-05-19 02:45:45 INFO  TorrentBroadcast:54 - Reading broadcast variable 4 took 40 ms
2021-05-19 02:45:45 INFO  MemoryStore:54 - Block broadcast_4 stored as values in memory (estimated size 129.0 KB, free 366.0 MB)
2021-05-19 02:45:45 INFO  Executor:54 - Finished task 3.0 in stage 2.0 (TID 54). 1406 bytes result sent to driver
2021-05-19 02:45:45 INFO  Executor:54 - Finished task 38.0 in stage 2.0 (TID 89). 1449 bytes result sent to driver
2021-05-19 02:45:45 INFO  Executor:54 - Finished task 13.0 in stage 2.0 (TID 64). 1449 bytes result sent to driver
2021-05-19 02:45:45 INFO  Executor:54 - Finished task 48.0 in stage 2.0 (TID 99). 1449 bytes result sent to driver
2021-05-19 02:45:45 INFO  Executor:54 - Finished task 43.0 in stage 2.0 (TID 94). 1449 bytes result sent to driver
2021-05-19 02:45:45 INFO  Executor:54 - Finished task 28.0 in stage 2.0 (TID 79). 1449 bytes result sent to driver
2021-05-19 02:45:45 INFO  Executor:54 - Finished task 33.0 in stage 2.0 (TID 84). 1449 bytes result sent to driver
2021-05-19 02:45:45 INFO  Executor:54 - Finished task 18.0 in stage 2.0 (TID 69). 1449 bytes result sent to driver
2021-05-19 02:45:45 INFO  Executor:54 - Finished task 23.0 in stage 2.0 (TID 74). 1449 bytes result sent to driver
2021-05-19 02:45:45 INFO  Executor:54 - Finished task 8.0 in stage 2.0 (TID 59). 1449 bytes result sent to driver
2021-05-19 02:45:48 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 101
2021-05-19 02:45:48 INFO  Executor:54 - Running task 0.0 in stage 4.0 (TID 101)
2021-05-19 02:45:48 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 102
2021-05-19 02:45:48 INFO  Executor:54 - Running task 1.0 in stage 4.0 (TID 102)
2021-05-19 02:45:48 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 103
2021-05-19 02:45:48 INFO  Executor:54 - Running task 2.0 in stage 4.0 (TID 103)
2021-05-19 02:45:48 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 104
2021-05-19 02:45:48 INFO  Executor:54 - Running task 3.0 in stage 4.0 (TID 104)
2021-05-19 02:45:48 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 105
2021-05-19 02:45:48 INFO  Executor:54 - Running task 4.0 in stage 4.0 (TID 105)
2021-05-19 02:45:48 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 106
2021-05-19 02:45:48 INFO  Executor:54 - Running task 5.0 in stage 4.0 (TID 106)
2021-05-19 02:45:48 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 107
2021-05-19 02:45:48 INFO  TorrentBroadcast:54 - Started reading broadcast variable 9
2021-05-19 02:45:48 INFO  Executor:54 - Running task 6.0 in stage 4.0 (TID 107)
2021-05-19 02:45:48 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 108
2021-05-19 02:45:48 INFO  Executor:54 - Running task 7.0 in stage 4.0 (TID 108)
2021-05-19 02:45:48 INFO  MemoryStore:54 - Block broadcast_9_piece0 stored as bytes in memory (estimated size 20.3 KB, free 366.3 MB)
2021-05-19 02:45:48 INFO  TorrentBroadcast:54 - Reading broadcast variable 9 took 33 ms
2021-05-19 02:45:48 INFO  MemoryStore:54 - Block broadcast_9 stored as values in memory (estimated size 42.3 KB, free 366.2 MB)
2021-05-19 02:45:49 INFO  CodeGenerator:54 - Code generated in 43.11241 ms
2021-05-19 02:45:49 INFO  CodeGenerator:54 - Code generated in 43.179259 ms
2021-05-19 02:45:50 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/core-places-nyc.csv, range: 4194304-8388608, partition values: [empty row]
2021-05-19 02:45:50 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/core-places-nyc.csv, range: 20971520-25165824, partition values: [empty row]
2021-05-19 02:45:50 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/core-places-nyc.csv, range: 0-4194304, partition values: [empty row]
2021-05-19 02:45:50 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/core-places-nyc.csv, range: 16777216-20971520, partition values: [empty row]
2021-05-19 02:45:50 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/core-places-nyc.csv, range: 12582912-16777216, partition values: [empty row]
2021-05-19 02:45:50 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/core-places-nyc.csv, range: 8388608-12582912, partition values: [empty row]
2021-05-19 02:45:50 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/core-places-nyc.csv, range: 25165824-29360128, partition values: [empty row]
2021-05-19 02:45:50 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/core-places-nyc.csv, range: 29360128-31553829, partition values: [empty row]
2021-05-19 02:45:50 INFO  CodeGenerator:54 - Code generated in 64.403424 ms
2021-05-19 02:45:50 INFO  CodeGenerator:54 - Code generated in 54.254732 ms
2021-05-19 02:45:50 INFO  TorrentBroadcast:54 - Started reading broadcast variable 8
2021-05-19 02:45:50 INFO  MemoryStore:54 - Block broadcast_8_piece0 stored as bytes in memory (estimated size 33.4 KB, free 366.2 MB)
2021-05-19 02:45:50 INFO  CodeGenerator:54 - Code generated in 35.149885 ms
2021-05-19 02:45:50 INFO  TorrentBroadcast:54 - Reading broadcast variable 8 took 25 ms
2021-05-19 02:45:50 INFO  MemoryStore:54 - Block broadcast_8 stored as values in memory (estimated size 506.4 KB, free 365.7 MB)
2021-05-19 02:45:51 INFO  PythonUDFRunner:54 - Times: total = 1457, boot = 764, init = 688, finish = 5
2021-05-19 02:45:51 INFO  MemoryStore:54 - Block rdd_29_7 stored as values in memory (estimated size 47.3 KB, free 349.7 MB)
2021-05-19 02:45:51 INFO  PythonUDFRunner:54 - Times: total = 1539, boot = 740, init = 786, finish = 13
2021-05-19 02:45:51 INFO  PythonUDFRunner:54 - Times: total = 1556, boot = 697, init = 842, finish = 17
2021-05-19 02:45:51 INFO  PythonUDFRunner:54 - Times: total = 1552, boot = 707, init = 829, finish = 16
2021-05-19 02:45:51 INFO  PythonUDFRunner:54 - Times: total = 1537, boot = 752, init = 774, finish = 11
2021-05-19 02:45:51 INFO  PythonUDFRunner:54 - Times: total = 1562, boot = 684, init = 861, finish = 17
2021-05-19 02:45:51 INFO  PythonUDFRunner:54 - Times: total = 1567, boot = 730, init = 825, finish = 12
2021-05-19 02:45:51 INFO  PythonUDFRunner:54 - Times: total = 1570, boot = 718, init = 834, finish = 18
2021-05-19 02:45:51 INFO  CodeGenerator:54 - Code generated in 20.008657 ms
2021-05-19 02:45:51 INFO  MemoryStore:54 - Block rdd_29_2 stored as values in memory (estimated size 91.5 KB, free 349.6 MB)
2021-05-19 02:45:51 INFO  MemoryStore:54 - Block rdd_29_0 stored as values in memory (estimated size 90.4 KB, free 349.4 MB)
2021-05-19 02:45:51 INFO  MemoryStore:54 - Block rdd_29_4 stored as values in memory (estimated size 88.8 KB, free 349.4 MB)
2021-05-19 02:45:51 INFO  MemoryStore:54 - Block rdd_29_3 stored as values in memory (estimated size 89.5 KB, free 349.0 MB)
2021-05-19 02:45:51 INFO  MemoryStore:54 - Block rdd_29_5 stored as values in memory (estimated size 91.5 KB, free 349.0 MB)
2021-05-19 02:45:51 INFO  MemoryStore:54 - Block rdd_29_6 stored as values in memory (estimated size 90.2 KB, free 349.0 MB)
2021-05-19 02:45:51 INFO  MemoryStore:54 - Block rdd_29_1 stored as values in memory (estimated size 90.8 KB, free 349.0 MB)
2021-05-19 02:45:51 INFO  CodeGenerator:54 - Code generated in 56.759733 ms
2021-05-19 02:45:51 INFO  CodeGenerator:54 - Code generated in 99.400262 ms
2021-05-19 02:45:51 INFO  CodeGenerator:54 - Code generated in 14.508074 ms
2021-05-19 02:45:51 INFO  CodeGenerator:54 - Code generated in 14.894132 ms
2021-05-19 02:45:51 INFO  CodeGenerator:54 - Code generated in 40.515295 ms
2021-05-19 02:45:51 INFO  Executor:54 - Finished task 5.0 in stage 4.0 (TID 106). 3433 bytes result sent to driver
2021-05-19 02:45:51 INFO  Executor:54 - Finished task 4.0 in stage 4.0 (TID 105). 3433 bytes result sent to driver
2021-05-19 02:45:51 INFO  Executor:54 - Finished task 0.0 in stage 4.0 (TID 101). 3433 bytes result sent to driver
2021-05-19 02:45:51 INFO  Executor:54 - Finished task 1.0 in stage 4.0 (TID 102). 3433 bytes result sent to driver
2021-05-19 02:45:51 INFO  Executor:54 - Finished task 3.0 in stage 4.0 (TID 104). 3433 bytes result sent to driver
2021-05-19 02:45:51 INFO  Executor:54 - Finished task 7.0 in stage 4.0 (TID 108). 3433 bytes result sent to driver
2021-05-19 02:45:51 INFO  Executor:54 - Finished task 2.0 in stage 4.0 (TID 103). 3476 bytes result sent to driver
2021-05-19 02:45:51 INFO  Executor:54 - Finished task 6.0 in stage 4.0 (TID 107). 3476 bytes result sent to driver
2021-05-19 02:45:51 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 109
2021-05-19 02:45:51 INFO  Executor:54 - Running task 3.0 in stage 5.0 (TID 109)
2021-05-19 02:45:51 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 110
2021-05-19 02:45:51 INFO  Executor:54 - Running task 18.0 in stage 5.0 (TID 110)
2021-05-19 02:45:51 INFO  MapOutputTrackerWorker:54 - Updating epoch to 1 and clearing cache
2021-05-19 02:45:51 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 111
2021-05-19 02:45:51 INFO  TorrentBroadcast:54 - Started reading broadcast variable 10
2021-05-19 02:45:51 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 112
2021-05-19 02:45:51 INFO  Executor:54 - Running task 26.0 in stage 5.0 (TID 111)
2021-05-19 02:45:51 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 113
2021-05-19 02:45:51 INFO  Executor:54 - Running task 35.0 in stage 5.0 (TID 112)
2021-05-19 02:45:51 INFO  Executor:54 - Running task 49.0 in stage 5.0 (TID 113)
2021-05-19 02:45:51 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 114
2021-05-19 02:45:51 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 115
2021-05-19 02:45:51 INFO  Executor:54 - Running task 75.0 in stage 5.0 (TID 114)
2021-05-19 02:45:51 INFO  Executor:54 - Running task 144.0 in stage 5.0 (TID 115)
2021-05-19 02:45:51 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 116
2021-05-19 02:45:51 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 117
2021-05-19 02:45:51 INFO  Executor:54 - Running task 166.0 in stage 5.0 (TID 116)
2021-05-19 02:45:51 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 122
2021-05-19 02:45:51 INFO  Executor:54 - Running task 189.0 in stage 5.0 (TID 117)
2021-05-19 02:45:51 INFO  Executor:54 - Running task 5.0 in stage 5.0 (TID 122)
2021-05-19 02:45:51 INFO  MemoryStore:54 - Block broadcast_10_piece0 stored as bytes in memory (estimated size 20.4 KB, free 365.0 MB)
2021-05-19 02:45:51 INFO  TorrentBroadcast:54 - Reading broadcast variable 10 took 38 ms
2021-05-19 02:45:51 INFO  MemoryStore:54 - Block broadcast_10 stored as values in memory (estimated size 40.9 KB, free 365.0 MB)
2021-05-19 02:45:51 INFO  MapOutputTrackerWorker:54 - Don't have map outputs for shuffle 0, fetching them
2021-05-19 02:45:51 INFO  MapOutputTrackerWorker:54 - Don't have map outputs for shuffle 0, fetching them
2021-05-19 02:45:51 INFO  MapOutputTrackerWorker:54 - Don't have map outputs for shuffle 0, fetching them
2021-05-19 02:45:51 INFO  MapOutputTrackerWorker:54 - Don't have map outputs for shuffle 0, fetching them
2021-05-19 02:45:51 INFO  MapOutputTrackerWorker:54 - Don't have map outputs for shuffle 0, fetching them
2021-05-19 02:45:51 INFO  MapOutputTrackerWorker:54 - Don't have map outputs for shuffle 0, fetching them
2021-05-19 02:45:51 INFO  MapOutputTrackerWorker:54 - Doing the fetch; tracker endpoint = NettyRpcEndpointRef(spark://MapOutputTracker@hadoop05.cusp.nyu.edu:47481)
2021-05-19 02:45:51 INFO  MapOutputTrackerWorker:54 - Don't have map outputs for shuffle 0, fetching them
2021-05-19 02:45:51 INFO  MapOutputTrackerWorker:54 - Don't have map outputs for shuffle 0, fetching them
2021-05-19 02:45:51 INFO  MapOutputTrackerWorker:54 - Don't have map outputs for shuffle 0, fetching them
2021-05-19 02:45:51 INFO  MapOutputTrackerWorker:54 - Don't have map outputs for shuffle 0, fetching them
2021-05-19 02:45:51 INFO  MapOutputTrackerWorker:54 - Got the output locations
2021-05-19 02:45:51 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:45:51 INFO  ShuffleBlockFetcherIterator:54 - Getting 8 non-empty blocks including 8 local blocks and 0 remote blocks
2021-05-19 02:45:51 INFO  ShuffleBlockFetcherIterator:54 - Getting 8 non-empty blocks including 8 local blocks and 0 remote blocks
2021-05-19 02:45:51 INFO  ShuffleBlockFetcherIterator:54 - Getting 8 non-empty blocks including 8 local blocks and 0 remote blocks
2021-05-19 02:45:51 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 20 ms
2021-05-19 02:45:51 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 19 ms
2021-05-19 02:45:51 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 18 ms
2021-05-19 02:45:51 INFO  ShuffleBlockFetcherIterator:54 - Getting 8 non-empty blocks including 8 local blocks and 0 remote blocks
2021-05-19 02:45:51 INFO  ShuffleBlockFetcherIterator:54 - Getting 8 non-empty blocks including 8 local blocks and 0 remote blocks
2021-05-19 02:45:51 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 19 ms
2021-05-19 02:45:51 INFO  ShuffleBlockFetcherIterator:54 - Getting 8 non-empty blocks including 8 local blocks and 0 remote blocks
2021-05-19 02:45:51 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 23 ms
2021-05-19 02:45:51 INFO  ShuffleBlockFetcherIterator:54 - Getting 8 non-empty blocks including 8 local blocks and 0 remote blocks
2021-05-19 02:45:51 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 20 ms
2021-05-19 02:45:51 INFO  ShuffleBlockFetcherIterator:54 - Getting 8 non-empty blocks including 8 local blocks and 0 remote blocks
2021-05-19 02:45:51 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 24 ms
2021-05-19 02:45:51 INFO  ShuffleBlockFetcherIterator:54 - Getting 8 non-empty blocks including 8 local blocks and 0 remote blocks
2021-05-19 02:45:51 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 25 ms
2021-05-19 02:45:51 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 21 ms
2021-05-19 02:45:51 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 20 ms
2021-05-19 02:45:52 INFO  CodeGenerator:54 - Code generated in 69.14437 ms
2021-05-19 02:45:52 INFO  Executor:54 - Finished task 5.0 in stage 5.0 (TID 122). 3776 bytes result sent to driver
2021-05-19 02:45:52 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 159
2021-05-19 02:45:52 INFO  Executor:54 - Running task 45.0 in stage 5.0 (TID 159)
2021-05-19 02:45:52 INFO  Executor:54 - Finished task 26.0 in stage 5.0 (TID 111). 3806 bytes result sent to driver
2021-05-19 02:45:52 INFO  Executor:54 - Finished task 3.0 in stage 5.0 (TID 109). 3763 bytes result sent to driver
2021-05-19 02:45:52 INFO  Executor:54 - Finished task 144.0 in stage 5.0 (TID 115). 3763 bytes result sent to driver
2021-05-19 02:45:52 INFO  Executor:54 - Finished task 166.0 in stage 5.0 (TID 116). 3763 bytes result sent to driver
2021-05-19 02:45:52 INFO  Executor:54 - Finished task 49.0 in stage 5.0 (TID 113). 3763 bytes result sent to driver
2021-05-19 02:45:52 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 160
2021-05-19 02:45:52 INFO  Executor:54 - Running task 46.0 in stage 5.0 (TID 160)
2021-05-19 02:45:52 INFO  Executor:54 - Finished task 35.0 in stage 5.0 (TID 112). 3762 bytes result sent to driver
2021-05-19 02:45:52 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 161
2021-05-19 02:45:52 INFO  Executor:54 - Finished task 18.0 in stage 5.0 (TID 110). 3806 bytes result sent to driver
2021-05-19 02:45:52 INFO  Executor:54 - Finished task 75.0 in stage 5.0 (TID 114). 3763 bytes result sent to driver
2021-05-19 02:45:52 INFO  Executor:54 - Running task 47.0 in stage 5.0 (TID 161)
2021-05-19 02:45:52 INFO  Executor:54 - Finished task 189.0 in stage 5.0 (TID 117). 3763 bytes result sent to driver
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2021-05-19 02:45:52 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 162
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2021-05-19 02:45:52 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 163
2021-05-19 02:45:52 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 164
2021-05-19 02:45:52 INFO  Executor:54 - Running task 50.0 in stage 5.0 (TID 163)
2021-05-19 02:45:52 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 165
2021-05-19 02:45:52 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 166
2021-05-19 02:45:52 INFO  Executor:54 - Running task 48.0 in stage 5.0 (TID 162)
2021-05-19 02:45:52 INFO  Executor:54 - Running task 53.0 in stage 5.0 (TID 166)
2021-05-19 02:45:52 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 167
2021-05-19 02:45:52 INFO  Executor:54 - Running task 52.0 in stage 5.0 (TID 165)
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 3 ms
2021-05-19 02:45:52 INFO  Executor:54 - Running task 51.0 in stage 5.0 (TID 164)
2021-05-19 02:45:52 INFO  Executor:54 - Finished task 45.0 in stage 5.0 (TID 159). 3733 bytes result sent to driver
2021-05-19 02:45:52 INFO  Executor:54 - Running task 54.0 in stage 5.0 (TID 167)
2021-05-19 02:45:52 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 168
2021-05-19 02:45:52 INFO  Executor:54 - Running task 55.0 in stage 5.0 (TID 168)
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2021-05-19 02:45:52 INFO  Executor:54 - Finished task 46.0 in stage 5.0 (TID 160). 3733 bytes result sent to driver
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 4 ms
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 2 ms
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 8 ms
2021-05-19 02:45:52 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 169
2021-05-19 02:45:52 INFO  Executor:54 - Finished task 47.0 in stage 5.0 (TID 161). 3733 bytes result sent to driver
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 2 ms
2021-05-19 02:45:52 INFO  Executor:54 - Running task 56.0 in stage 5.0 (TID 169)
2021-05-19 02:45:52 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 170
2021-05-19 02:45:52 INFO  Executor:54 - Running task 57.0 in stage 5.0 (TID 170)
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2021-05-19 02:45:52 INFO  Executor:54 - Finished task 51.0 in stage 5.0 (TID 164). 3733 bytes result sent to driver
2021-05-19 02:45:52 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 171
2021-05-19 02:45:52 INFO  Executor:54 - Running task 58.0 in stage 5.0 (TID 171)
2021-05-19 02:45:52 INFO  Executor:54 - Finished task 53.0 in stage 5.0 (TID 166). 3733 bytes result sent to driver
2021-05-19 02:45:52 INFO  Executor:54 - Finished task 54.0 in stage 5.0 (TID 167). 3733 bytes result sent to driver
2021-05-19 02:45:52 INFO  Executor:54 - Finished task 48.0 in stage 5.0 (TID 162). 3733 bytes result sent to driver
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:45:52 INFO  Executor:54 - Finished task 50.0 in stage 5.0 (TID 163). 3733 bytes result sent to driver
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2021-05-19 02:45:52 INFO  Executor:54 - Finished task 55.0 in stage 5.0 (TID 168). 3733 bytes result sent to driver
2021-05-19 02:45:52 INFO  Executor:54 - Finished task 52.0 in stage 5.0 (TID 165). 3733 bytes result sent to driver
2021-05-19 02:45:52 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 172
2021-05-19 02:45:52 INFO  Executor:54 - Running task 59.0 in stage 5.0 (TID 172)
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:45:52 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 173
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2021-05-19 02:45:52 INFO  Executor:54 - Running task 60.0 in stage 5.0 (TID 173)
2021-05-19 02:45:52 INFO  Executor:54 - Finished task 56.0 in stage 5.0 (TID 169). 3733 bytes result sent to driver
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2021-05-19 02:45:52 INFO  Executor:54 - Finished task 57.0 in stage 5.0 (TID 170). 3733 bytes result sent to driver
2021-05-19 02:45:52 INFO  Executor:54 - Finished task 58.0 in stage 5.0 (TID 171). 3733 bytes result sent to driver
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2021-05-19 02:45:52 INFO  Executor:54 - Finished task 59.0 in stage 5.0 (TID 172). 3733 bytes result sent to driver
2021-05-19 02:45:52 INFO  Executor:54 - Finished task 60.0 in stage 5.0 (TID 173). 3733 bytes result sent to driver
2021-05-19 02:45:52 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 174
2021-05-19 02:45:52 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 175
2021-05-19 02:45:52 INFO  Executor:54 - Running task 61.0 in stage 5.0 (TID 174)
2021-05-19 02:45:52 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 176
2021-05-19 02:45:52 INFO  Executor:54 - Running task 62.0 in stage 5.0 (TID 175)
2021-05-19 02:45:52 INFO  Executor:54 - Running task 63.0 in stage 5.0 (TID 176)
2021-05-19 02:45:52 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 177
2021-05-19 02:45:52 INFO  Executor:54 - Running task 64.0 in stage 5.0 (TID 177)
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2021-05-19 02:45:52 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 178
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:45:52 INFO  Executor:54 - Running task 65.0 in stage 5.0 (TID 178)
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2021-05-19 02:45:52 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 179
2021-05-19 02:45:52 INFO  Executor:54 - Running task 66.0 in stage 5.0 (TID 179)
2021-05-19 02:45:52 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 180
2021-05-19 02:45:52 INFO  Executor:54 - Running task 67.0 in stage 5.0 (TID 180)
2021-05-19 02:45:52 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 181
2021-05-19 02:45:52 INFO  Executor:54 - Running task 68.0 in stage 5.0 (TID 181)
2021-05-19 02:45:52 INFO  Executor:54 - Finished task 61.0 in stage 5.0 (TID 174). 3733 bytes result sent to driver
2021-05-19 02:45:52 INFO  Executor:54 - Finished task 62.0 in stage 5.0 (TID 175). 3733 bytes result sent to driver
2021-05-19 02:45:52 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 182
2021-05-19 02:45:52 INFO  Executor:54 - Running task 69.0 in stage 5.0 (TID 182)
2021-05-19 02:45:52 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 183
2021-05-19 02:45:52 INFO  Executor:54 - Running task 70.0 in stage 5.0 (TID 183)
2021-05-19 02:45:52 INFO  Executor:54 - Finished task 64.0 in stage 5.0 (TID 177). 3776 bytes result sent to driver
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:45:52 INFO  Executor:54 - Finished task 63.0 in stage 5.0 (TID 176). 3733 bytes result sent to driver
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2021-05-19 02:45:52 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 184
2021-05-19 02:45:52 INFO  Executor:54 - Running task 71.0 in stage 5.0 (TID 184)
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:45:52 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 185
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2021-05-19 02:45:52 INFO  Executor:54 - Running task 72.0 in stage 5.0 (TID 185)
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:45:52 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 186
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2021-05-19 02:45:52 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 187
2021-05-19 02:45:52 INFO  Executor:54 - Running task 73.0 in stage 5.0 (TID 186)
2021-05-19 02:45:52 INFO  Executor:54 - Running task 74.0 in stage 5.0 (TID 187)
2021-05-19 02:45:52 INFO  Executor:54 - Finished task 65.0 in stage 5.0 (TID 178). 3733 bytes result sent to driver
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:45:52 INFO  Executor:54 - Finished task 66.0 in stage 5.0 (TID 179). 3733 bytes result sent to driver
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2021-05-19 02:45:52 INFO  Executor:54 - Finished task 67.0 in stage 5.0 (TID 180). 3733 bytes result sent to driver
2021-05-19 02:45:52 INFO  Executor:54 - Finished task 68.0 in stage 5.0 (TID 181). 3733 bytes result sent to driver
2021-05-19 02:45:52 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 188
2021-05-19 02:45:52 INFO  Executor:54 - Finished task 69.0 in stage 5.0 (TID 182). 3733 bytes result sent to driver
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:45:52 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 189
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2021-05-19 02:45:52 INFO  Executor:54 - Finished task 70.0 in stage 5.0 (TID 183). 3776 bytes result sent to driver
2021-05-19 02:45:52 INFO  Executor:54 - Running task 76.0 in stage 5.0 (TID 188)
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:45:52 INFO  Executor:54 - Running task 77.0 in stage 5.0 (TID 189)
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2021-05-19 02:45:52 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 190
2021-05-19 02:45:52 INFO  Executor:54 - Running task 78.0 in stage 5.0 (TID 190)
2021-05-19 02:45:52 INFO  Executor:54 - Finished task 71.0 in stage 5.0 (TID 184). 3733 bytes result sent to driver
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:45:52 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 191
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2021-05-19 02:45:52 INFO  Executor:54 - Finished task 72.0 in stage 5.0 (TID 185). 3733 bytes result sent to driver
2021-05-19 02:45:52 INFO  Executor:54 - Running task 79.0 in stage 5.0 (TID 191)
2021-05-19 02:45:52 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 192
2021-05-19 02:45:52 INFO  Executor:54 - Finished task 73.0 in stage 5.0 (TID 186). 3733 bytes result sent to driver
2021-05-19 02:45:52 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 193
2021-05-19 02:45:52 INFO  Executor:54 - Running task 80.0 in stage 5.0 (TID 192)
2021-05-19 02:45:52 INFO  Executor:54 - Finished task 74.0 in stage 5.0 (TID 187). 3733 bytes result sent to driver
2021-05-19 02:45:52 INFO  Executor:54 - Running task 81.0 in stage 5.0 (TID 193)
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2021-05-19 02:45:52 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 194
2021-05-19 02:45:52 INFO  Executor:54 - Running task 82.0 in stage 5.0 (TID 194)
2021-05-19 02:45:52 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 195
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:45:52 INFO  Executor:54 - Finished task 77.0 in stage 5.0 (TID 189). 3733 bytes result sent to driver
2021-05-19 02:45:52 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 196
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2021-05-19 02:45:52 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 197
2021-05-19 02:45:52 INFO  Executor:54 - Running task 83.0 in stage 5.0 (TID 195)
2021-05-19 02:45:52 INFO  Executor:54 - Finished task 76.0 in stage 5.0 (TID 188). 3733 bytes result sent to driver
2021-05-19 02:45:52 INFO  Executor:54 - Running task 85.0 in stage 5.0 (TID 197)
2021-05-19 02:45:52 INFO  Executor:54 - Running task 84.0 in stage 5.0 (TID 196)
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 2 ms
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2021-05-19 02:45:52 INFO  Executor:54 - Finished task 78.0 in stage 5.0 (TID 190). 3776 bytes result sent to driver
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2021-05-19 02:45:52 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 198
2021-05-19 02:45:52 INFO  Executor:54 - Running task 86.0 in stage 5.0 (TID 198)
2021-05-19 02:45:52 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 199
2021-05-19 02:45:52 INFO  Executor:54 - Running task 87.0 in stage 5.0 (TID 199)
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2021-05-19 02:45:52 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 200
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:45:52 INFO  Executor:54 - Running task 88.0 in stage 5.0 (TID 200)
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:45:52 INFO  Executor:54 - Finished task 79.0 in stage 5.0 (TID 191). 3733 bytes result sent to driver
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2021-05-19 02:45:52 INFO  Executor:54 - Finished task 81.0 in stage 5.0 (TID 193). 3733 bytes result sent to driver
2021-05-19 02:45:52 INFO  Executor:54 - Finished task 80.0 in stage 5.0 (TID 192). 3733 bytes result sent to driver
2021-05-19 02:45:52 INFO  Executor:54 - Finished task 82.0 in stage 5.0 (TID 194). 3733 bytes result sent to driver
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2021-05-19 02:45:52 INFO  Executor:54 - Finished task 84.0 in stage 5.0 (TID 196). 3733 bytes result sent to driver
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2021-05-19 02:45:52 INFO  Executor:54 - Finished task 83.0 in stage 5.0 (TID 195). 3733 bytes result sent to driver
2021-05-19 02:45:52 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 201
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2021-05-19 02:45:52 INFO  Executor:54 - Running task 89.0 in stage 5.0 (TID 201)
2021-05-19 02:45:52 INFO  Executor:54 - Finished task 85.0 in stage 5.0 (TID 197). 3733 bytes result sent to driver
2021-05-19 02:45:52 INFO  Executor:54 - Finished task 86.0 in stage 5.0 (TID 198). 3733 bytes result sent to driver
2021-05-19 02:45:52 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 202
2021-05-19 02:45:52 INFO  Executor:54 - Running task 90.0 in stage 5.0 (TID 202)
2021-05-19 02:45:52 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 203
2021-05-19 02:45:52 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 204
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:45:52 INFO  Executor:54 - Running task 91.0 in stage 5.0 (TID 203)
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2021-05-19 02:45:52 INFO  Executor:54 - Running task 92.0 in stage 5.0 (TID 204)
2021-05-19 02:45:52 INFO  Executor:54 - Finished task 87.0 in stage 5.0 (TID 199). 3733 bytes result sent to driver
2021-05-19 02:45:52 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 205
2021-05-19 02:45:52 INFO  Executor:54 - Running task 93.0 in stage 5.0 (TID 205)
2021-05-19 02:45:52 INFO  Executor:54 - Finished task 88.0 in stage 5.0 (TID 200). 3733 bytes result sent to driver
2021-05-19 02:45:52 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 206
2021-05-19 02:45:52 INFO  Executor:54 - Running task 94.0 in stage 5.0 (TID 206)
2021-05-19 02:45:52 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 207
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2021-05-19 02:45:52 INFO  Executor:54 - Running task 95.0 in stage 5.0 (TID 207)
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2021-05-19 02:45:52 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 208
2021-05-19 02:45:52 INFO  Executor:54 - Running task 96.0 in stage 5.0 (TID 208)
2021-05-19 02:45:52 INFO  Executor:54 - Finished task 89.0 in stage 5.0 (TID 201). 3733 bytes result sent to driver
2021-05-19 02:45:52 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 209
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:45:52 INFO  Executor:54 - Running task 97.0 in stage 5.0 (TID 209)
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:45:52 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 210
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2021-05-19 02:45:52 INFO  Executor:54 - Running task 98.0 in stage 5.0 (TID 210)
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2021-05-19 02:45:52 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 211
2021-05-19 02:45:52 INFO  Executor:54 - Running task 99.0 in stage 5.0 (TID 211)
2021-05-19 02:45:52 INFO  Executor:54 - Finished task 90.0 in stage 5.0 (TID 202). 3733 bytes result sent to driver
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2021-05-19 02:45:52 INFO  Executor:54 - Finished task 91.0 in stage 5.0 (TID 203). 3733 bytes result sent to driver
2021-05-19 02:45:52 INFO  Executor:54 - Finished task 92.0 in stage 5.0 (TID 204). 3776 bytes result sent to driver
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2021-05-19 02:45:52 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 212
2021-05-19 02:45:52 INFO  Executor:54 - Running task 100.0 in stage 5.0 (TID 212)
2021-05-19 02:45:52 INFO  Executor:54 - Finished task 93.0 in stage 5.0 (TID 205). 3733 bytes result sent to driver
2021-05-19 02:45:52 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 213
2021-05-19 02:45:52 INFO  Executor:54 - Finished task 94.0 in stage 5.0 (TID 206). 3733 bytes result sent to driver
2021-05-19 02:45:52 INFO  Executor:54 - Running task 101.0 in stage 5.0 (TID 213)
2021-05-19 02:45:52 INFO  Executor:54 - Finished task 97.0 in stage 5.0 (TID 209). 3733 bytes result sent to driver
2021-05-19 02:45:52 INFO  Executor:54 - Finished task 95.0 in stage 5.0 (TID 207). 3733 bytes result sent to driver
2021-05-19 02:45:52 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 214
2021-05-19 02:45:52 INFO  Executor:54 - Finished task 96.0 in stage 5.0 (TID 208). 3733 bytes result sent to driver
2021-05-19 02:45:52 INFO  Executor:54 - Running task 102.0 in stage 5.0 (TID 214)
2021-05-19 02:45:52 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 215
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2021-05-19 02:45:52 INFO  Executor:54 - Running task 103.0 in stage 5.0 (TID 215)
2021-05-19 02:45:52 INFO  Executor:54 - Finished task 98.0 in stage 5.0 (TID 210). 3733 bytes result sent to driver
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:45:52 INFO  Executor:54 - Finished task 99.0 in stage 5.0 (TID 211). 3733 bytes result sent to driver
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2021-05-19 02:45:52 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 216
2021-05-19 02:45:52 INFO  Executor:54 - Running task 104.0 in stage 5.0 (TID 216)
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2021-05-19 02:45:52 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 217
2021-05-19 02:45:52 INFO  Executor:54 - Running task 105.0 in stage 5.0 (TID 217)
2021-05-19 02:45:52 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 218
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:45:52 INFO  Executor:54 - Running task 106.0 in stage 5.0 (TID 218)
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2021-05-19 02:45:52 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 219
2021-05-19 02:45:52 INFO  Executor:54 - Running task 107.0 in stage 5.0 (TID 219)
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2021-05-19 02:45:52 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 220
2021-05-19 02:45:52 INFO  Executor:54 - Finished task 100.0 in stage 5.0 (TID 212). 3733 bytes result sent to driver
2021-05-19 02:45:52 INFO  Executor:54 - Running task 108.0 in stage 5.0 (TID 220)
2021-05-19 02:45:52 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 221
2021-05-19 02:45:52 INFO  Executor:54 - Running task 109.0 in stage 5.0 (TID 221)
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:45:52 INFO  Executor:54 - Finished task 101.0 in stage 5.0 (TID 213). 3733 bytes result sent to driver
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2021-05-19 02:45:52 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 222
2021-05-19 02:45:52 INFO  Executor:54 - Running task 110.0 in stage 5.0 (TID 222)
2021-05-19 02:45:52 INFO  Executor:54 - Finished task 102.0 in stage 5.0 (TID 214). 3776 bytes result sent to driver
2021-05-19 02:45:52 INFO  Executor:54 - Finished task 104.0 in stage 5.0 (TID 216). 3733 bytes result sent to driver
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2021-05-19 02:45:52 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 223
2021-05-19 02:45:52 INFO  Executor:54 - Finished task 105.0 in stage 5.0 (TID 217). 3733 bytes result sent to driver
2021-05-19 02:45:52 INFO  Executor:54 - Running task 111.0 in stage 5.0 (TID 223)
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2021-05-19 02:45:52 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 224
2021-05-19 02:45:52 INFO  Executor:54 - Running task 112.0 in stage 5.0 (TID 224)
2021-05-19 02:45:52 INFO  Executor:54 - Finished task 103.0 in stage 5.0 (TID 215). 3733 bytes result sent to driver
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2021-05-19 02:45:52 INFO  Executor:54 - Finished task 106.0 in stage 5.0 (TID 218). 3733 bytes result sent to driver
2021-05-19 02:45:52 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 225
2021-05-19 02:45:52 INFO  Executor:54 - Running task 113.0 in stage 5.0 (TID 225)
2021-05-19 02:45:52 INFO  Executor:54 - Finished task 107.0 in stage 5.0 (TID 219). 3733 bytes result sent to driver
2021-05-19 02:45:52 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 226
2021-05-19 02:45:52 INFO  Executor:54 - Running task 114.0 in stage 5.0 (TID 226)
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2021-05-19 02:45:52 INFO  Executor:54 - Finished task 110.0 in stage 5.0 (TID 222). 3733 bytes result sent to driver
2021-05-19 02:45:52 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 227
2021-05-19 02:45:52 INFO  Executor:54 - Running task 115.0 in stage 5.0 (TID 227)
2021-05-19 02:45:52 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 228
2021-05-19 02:45:52 INFO  Executor:54 - Running task 116.0 in stage 5.0 (TID 228)
2021-05-19 02:45:52 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 229
2021-05-19 02:45:52 INFO  Executor:54 - Finished task 111.0 in stage 5.0 (TID 223). 3733 bytes result sent to driver
2021-05-19 02:45:52 INFO  Executor:54 - Running task 117.0 in stage 5.0 (TID 229)
2021-05-19 02:45:52 INFO  Executor:54 - Finished task 108.0 in stage 5.0 (TID 220). 3733 bytes result sent to driver
2021-05-19 02:45:52 INFO  Executor:54 - Finished task 109.0 in stage 5.0 (TID 221). 3733 bytes result sent to driver
2021-05-19 02:45:52 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 230
2021-05-19 02:45:52 INFO  Executor:54 - Running task 118.0 in stage 5.0 (TID 230)
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 30 ms
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2021-05-19 02:45:52 INFO  Executor:54 - Finished task 112.0 in stage 5.0 (TID 224). 3776 bytes result sent to driver
2021-05-19 02:45:52 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 231
2021-05-19 02:45:52 INFO  Executor:54 - Running task 119.0 in stage 5.0 (TID 231)
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2021-05-19 02:45:52 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 232
2021-05-19 02:45:52 INFO  Executor:54 - Running task 120.0 in stage 5.0 (TID 232)
2021-05-19 02:45:52 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 233
2021-05-19 02:45:52 INFO  Executor:54 - Finished task 114.0 in stage 5.0 (TID 226). 3776 bytes result sent to driver
2021-05-19 02:45:52 INFO  Executor:54 - Finished task 113.0 in stage 5.0 (TID 225). 3776 bytes result sent to driver
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:45:52 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 234
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2021-05-19 02:45:52 INFO  Executor:54 - Running task 121.0 in stage 5.0 (TID 233)
2021-05-19 02:45:52 INFO  Executor:54 - Running task 122.0 in stage 5.0 (TID 234)
2021-05-19 02:45:52 INFO  Executor:54 - Finished task 116.0 in stage 5.0 (TID 228). 3776 bytes result sent to driver
2021-05-19 02:45:52 INFO  Executor:54 - Finished task 117.0 in stage 5.0 (TID 229). 3776 bytes result sent to driver
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2021-05-19 02:45:52 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 235
2021-05-19 02:45:52 INFO  Executor:54 - Finished task 115.0 in stage 5.0 (TID 227). 3776 bytes result sent to driver
2021-05-19 02:45:52 INFO  Executor:54 - Finished task 118.0 in stage 5.0 (TID 230). 3733 bytes result sent to driver
2021-05-19 02:45:52 INFO  Executor:54 - Running task 123.0 in stage 5.0 (TID 235)
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:45:52 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 236
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2021-05-19 02:45:52 INFO  Executor:54 - Finished task 119.0 in stage 5.0 (TID 231). 3733 bytes result sent to driver
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2021-05-19 02:45:52 INFO  Executor:54 - Running task 124.0 in stage 5.0 (TID 236)
2021-05-19 02:45:52 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 237
2021-05-19 02:45:52 INFO  Executor:54 - Running task 125.0 in stage 5.0 (TID 237)
2021-05-19 02:45:52 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 238
2021-05-19 02:45:52 INFO  Executor:54 - Running task 126.0 in stage 5.0 (TID 238)
2021-05-19 02:45:52 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 239
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2021-05-19 02:45:52 INFO  Executor:54 - Running task 127.0 in stage 5.0 (TID 239)
2021-05-19 02:45:52 INFO  Executor:54 - Finished task 120.0 in stage 5.0 (TID 232). 3733 bytes result sent to driver
2021-05-19 02:45:52 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 240
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:45:52 INFO  Executor:54 - Running task 128.0 in stage 5.0 (TID 240)
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2021-05-19 02:45:52 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 241
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:45:52 INFO  Executor:54 - Running task 129.0 in stage 5.0 (TID 241)
2021-05-19 02:45:52 INFO  Executor:54 - Finished task 121.0 in stage 5.0 (TID 233). 3733 bytes result sent to driver
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2021-05-19 02:45:52 INFO  Executor:54 - Finished task 122.0 in stage 5.0 (TID 234). 3733 bytes result sent to driver
2021-05-19 02:45:52 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 242
2021-05-19 02:45:52 INFO  Executor:54 - Running task 130.0 in stage 5.0 (TID 242)
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2021-05-19 02:45:52 INFO  Executor:54 - Finished task 123.0 in stage 5.0 (TID 235). 3733 bytes result sent to driver
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:45:52 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 243
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2021-05-19 02:45:52 INFO  Executor:54 - Finished task 125.0 in stage 5.0 (TID 237). 3733 bytes result sent to driver
2021-05-19 02:45:52 INFO  Executor:54 - Running task 131.0 in stage 5.0 (TID 243)
2021-05-19 02:45:52 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 244
2021-05-19 02:45:52 INFO  Executor:54 - Running task 132.0 in stage 5.0 (TID 244)
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:45:52 INFO  Executor:54 - Finished task 124.0 in stage 5.0 (TID 236). 3733 bytes result sent to driver
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:45:52 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 245
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2021-05-19 02:45:52 INFO  Executor:54 - Running task 133.0 in stage 5.0 (TID 245)
2021-05-19 02:45:52 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 246
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:45:52 INFO  Executor:54 - Finished task 128.0 in stage 5.0 (TID 240). 3733 bytes result sent to driver
2021-05-19 02:45:52 INFO  Executor:54 - Running task 134.0 in stage 5.0 (TID 246)
2021-05-19 02:45:52 INFO  Executor:54 - Finished task 126.0 in stage 5.0 (TID 238). 3733 bytes result sent to driver
2021-05-19 02:45:52 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 247
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2021-05-19 02:45:52 INFO  Executor:54 - Running task 135.0 in stage 5.0 (TID 247)
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2021-05-19 02:45:52 INFO  Executor:54 - Finished task 127.0 in stage 5.0 (TID 239). 3733 bytes result sent to driver
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2021-05-19 02:45:52 INFO  Executor:54 - Finished task 130.0 in stage 5.0 (TID 242). 3733 bytes result sent to driver
2021-05-19 02:45:52 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 248
2021-05-19 02:45:52 INFO  Executor:54 - Running task 136.0 in stage 5.0 (TID 248)
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2021-05-19 02:45:52 INFO  Executor:54 - Finished task 129.0 in stage 5.0 (TID 241). 3733 bytes result sent to driver
2021-05-19 02:45:52 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 249
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2021-05-19 02:45:52 INFO  Executor:54 - Running task 137.0 in stage 5.0 (TID 249)
2021-05-19 02:45:52 INFO  Executor:54 - Finished task 132.0 in stage 5.0 (TID 244). 3733 bytes result sent to driver
2021-05-19 02:45:52 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 250
2021-05-19 02:45:52 INFO  Executor:54 - Running task 138.0 in stage 5.0 (TID 250)
2021-05-19 02:45:52 INFO  Executor:54 - Finished task 131.0 in stage 5.0 (TID 243). 3733 bytes result sent to driver
2021-05-19 02:45:52 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 251
2021-05-19 02:45:52 INFO  Executor:54 - Running task 139.0 in stage 5.0 (TID 251)
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2021-05-19 02:45:52 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 252
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:45:52 INFO  Executor:54 - Finished task 133.0 in stage 5.0 (TID 245). 3733 bytes result sent to driver
2021-05-19 02:45:52 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 253
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2021-05-19 02:45:52 INFO  Executor:54 - Running task 140.0 in stage 5.0 (TID 252)
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:45:52 INFO  Executor:54 - Finished task 134.0 in stage 5.0 (TID 246). 3733 bytes result sent to driver
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2021-05-19 02:45:52 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 254
2021-05-19 02:45:52 INFO  Executor:54 - Running task 141.0 in stage 5.0 (TID 253)
2021-05-19 02:45:52 INFO  Executor:54 - Running task 142.0 in stage 5.0 (TID 254)
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2021-05-19 02:45:52 INFO  Executor:54 - Finished task 135.0 in stage 5.0 (TID 247). 3733 bytes result sent to driver
2021-05-19 02:45:52 INFO  Executor:54 - Finished task 136.0 in stage 5.0 (TID 248). 3776 bytes result sent to driver
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:45:52 INFO  Executor:54 - Finished task 137.0 in stage 5.0 (TID 249). 3733 bytes result sent to driver
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2021-05-19 02:45:52 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 259
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2021-05-19 02:45:52 INFO  Executor:54 - Running task 148.0 in stage 5.0 (TID 259)
2021-05-19 02:45:52 INFO  Executor:54 - Finished task 138.0 in stage 5.0 (TID 250). 3733 bytes result sent to driver
2021-05-19 02:45:52 INFO  Executor:54 - Finished task 139.0 in stage 5.0 (TID 251). 3733 bytes result sent to driver
2021-05-19 02:45:52 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 262
2021-05-19 02:45:52 INFO  Executor:54 - Running task 151.0 in stage 5.0 (TID 262)
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2021-05-19 02:45:52 INFO  Executor:54 - Finished task 141.0 in stage 5.0 (TID 253). 3776 bytes result sent to driver
2021-05-19 02:45:52 INFO  Executor:54 - Finished task 142.0 in stage 5.0 (TID 254). 3733 bytes result sent to driver
2021-05-19 02:45:52 INFO  Executor:54 - Finished task 140.0 in stage 5.0 (TID 252). 3733 bytes result sent to driver
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2021-05-19 02:45:52 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 265
2021-05-19 02:45:52 INFO  Executor:54 - Running task 154.0 in stage 5.0 (TID 265)
2021-05-19 02:45:52 INFO  Executor:54 - Finished task 148.0 in stage 5.0 (TID 259). 3733 bytes result sent to driver
2021-05-19 02:45:52 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 268
2021-05-19 02:45:52 INFO  Executor:54 - Running task 157.0 in stage 5.0 (TID 268)
2021-05-19 02:45:52 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 269
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:45:52 INFO  Executor:54 - Running task 158.0 in stage 5.0 (TID 269)
2021-05-19 02:45:52 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 270
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2021-05-19 02:45:52 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 271
2021-05-19 02:45:52 INFO  Executor:54 - Running task 159.0 in stage 5.0 (TID 270)
2021-05-19 02:45:52 INFO  Executor:54 - Running task 160.0 in stage 5.0 (TID 271)
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2021-05-19 02:45:52 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 272
2021-05-19 02:45:52 INFO  Executor:54 - Running task 161.0 in stage 5.0 (TID 272)
2021-05-19 02:45:52 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 273
2021-05-19 02:45:52 INFO  Executor:54 - Running task 162.0 in stage 5.0 (TID 273)
2021-05-19 02:45:52 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 274
2021-05-19 02:45:52 INFO  Executor:54 - Running task 163.0 in stage 5.0 (TID 274)
2021-05-19 02:45:52 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 275
2021-05-19 02:45:52 INFO  Executor:54 - Running task 164.0 in stage 5.0 (TID 275)
2021-05-19 02:45:52 INFO  Executor:54 - Finished task 151.0 in stage 5.0 (TID 262). 3776 bytes result sent to driver
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:45:52 INFO  Executor:54 - Finished task 157.0 in stage 5.0 (TID 268). 3733 bytes result sent to driver
2021-05-19 02:45:52 INFO  Executor:54 - Finished task 154.0 in stage 5.0 (TID 265). 3733 bytes result sent to driver
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:45:52 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 276
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2021-05-19 02:45:52 INFO  Executor:54 - Running task 165.0 in stage 5.0 (TID 276)
2021-05-19 02:45:52 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 277
2021-05-19 02:45:52 INFO  Executor:54 - Running task 167.0 in stage 5.0 (TID 277)
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2021-05-19 02:45:52 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 278
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:45:52 INFO  Executor:54 - Running task 168.0 in stage 5.0 (TID 278)
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:45:52 INFO  Executor:54 - Finished task 161.0 in stage 5.0 (TID 272). 3733 bytes result sent to driver
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2021-05-19 02:45:52 INFO  Executor:54 - Finished task 162.0 in stage 5.0 (TID 273). 3733 bytes result sent to driver
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:45:52 INFO  Executor:54 - Finished task 159.0 in stage 5.0 (TID 270). 3733 bytes result sent to driver
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2021-05-19 02:45:52 INFO  Executor:54 - Finished task 160.0 in stage 5.0 (TID 271). 3733 bytes result sent to driver
2021-05-19 02:45:52 INFO  Executor:54 - Finished task 158.0 in stage 5.0 (TID 269). 3733 bytes result sent to driver
2021-05-19 02:45:52 INFO  Executor:54 - Finished task 164.0 in stage 5.0 (TID 275). 3733 bytes result sent to driver
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:45:52 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 279
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2021-05-19 02:45:52 INFO  Executor:54 - Running task 169.0 in stage 5.0 (TID 279)
2021-05-19 02:45:52 INFO  Executor:54 - Finished task 163.0 in stage 5.0 (TID 274). 3733 bytes result sent to driver
2021-05-19 02:45:52 INFO  Executor:54 - Finished task 167.0 in stage 5.0 (TID 277). 3733 bytes result sent to driver
2021-05-19 02:45:52 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 280
2021-05-19 02:45:52 INFO  Executor:54 - Running task 170.0 in stage 5.0 (TID 280)
2021-05-19 02:45:52 INFO  Executor:54 - Finished task 165.0 in stage 5.0 (TID 276). 3733 bytes result sent to driver
2021-05-19 02:45:52 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 281
2021-05-19 02:45:52 INFO  Executor:54 - Running task 171.0 in stage 5.0 (TID 281)
2021-05-19 02:45:52 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 282
2021-05-19 02:45:52 INFO  Executor:54 - Running task 172.0 in stage 5.0 (TID 282)
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2021-05-19 02:45:52 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 283
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:45:52 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 284
2021-05-19 02:45:52 INFO  Executor:54 - Running task 173.0 in stage 5.0 (TID 283)
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2021-05-19 02:45:52 INFO  Executor:54 - Running task 174.0 in stage 5.0 (TID 284)
2021-05-19 02:45:52 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 285
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:45:52 INFO  Executor:54 - Finished task 168.0 in stage 5.0 (TID 278). 3733 bytes result sent to driver
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2021-05-19 02:45:52 INFO  Executor:54 - Running task 175.0 in stage 5.0 (TID 285)
2021-05-19 02:45:52 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 286
2021-05-19 02:45:52 INFO  Executor:54 - Running task 176.0 in stage 5.0 (TID 286)
2021-05-19 02:45:52 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 287
2021-05-19 02:45:52 INFO  Executor:54 - Running task 177.0 in stage 5.0 (TID 287)
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2021-05-19 02:45:52 INFO  Executor:54 - Finished task 170.0 in stage 5.0 (TID 280). 3733 bytes result sent to driver
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2021-05-19 02:45:52 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 288
2021-05-19 02:45:52 INFO  Executor:54 - Finished task 169.0 in stage 5.0 (TID 279). 3733 bytes result sent to driver
2021-05-19 02:45:52 INFO  Executor:54 - Running task 178.0 in stage 5.0 (TID 288)
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2021-05-19 02:45:52 INFO  Executor:54 - Finished task 171.0 in stage 5.0 (TID 281). 3733 bytes result sent to driver
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2021-05-19 02:45:52 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 289
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:45:52 INFO  Executor:54 - Running task 179.0 in stage 5.0 (TID 289)
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2021-05-19 02:45:52 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 290
2021-05-19 02:45:52 INFO  Executor:54 - Running task 180.0 in stage 5.0 (TID 290)
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:45:52 INFO  Executor:54 - Finished task 174.0 in stage 5.0 (TID 284). 3733 bytes result sent to driver
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2021-05-19 02:45:52 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 293
2021-05-19 02:45:52 INFO  Executor:54 - Running task 183.0 in stage 5.0 (TID 293)
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:45:52 INFO  Executor:54 - Finished task 176.0 in stage 5.0 (TID 286). 3733 bytes result sent to driver
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2021-05-19 02:45:52 INFO  Executor:54 - Finished task 172.0 in stage 5.0 (TID 282). 3733 bytes result sent to driver
2021-05-19 02:45:52 INFO  Executor:54 - Finished task 173.0 in stage 5.0 (TID 283). 3733 bytes result sent to driver
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:45:52 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 295
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2021-05-19 02:45:52 INFO  Executor:54 - Running task 185.0 in stage 5.0 (TID 295)
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:45:52 INFO  Executor:54 - Finished task 178.0 in stage 5.0 (TID 288). 3733 bytes result sent to driver
2021-05-19 02:45:52 INFO  Executor:54 - Finished task 177.0 in stage 5.0 (TID 287). 3733 bytes result sent to driver
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2021-05-19 02:45:52 INFO  Executor:54 - Finished task 175.0 in stage 5.0 (TID 285). 3733 bytes result sent to driver
2021-05-19 02:45:52 INFO  Executor:54 - Finished task 179.0 in stage 5.0 (TID 289). 3733 bytes result sent to driver
2021-05-19 02:45:52 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 298
2021-05-19 02:45:52 INFO  Executor:54 - Running task 188.0 in stage 5.0 (TID 298)
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2021-05-19 02:45:52 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 300
2021-05-19 02:45:52 INFO  Executor:54 - Finished task 180.0 in stage 5.0 (TID 290). 3733 bytes result sent to driver
2021-05-19 02:45:52 INFO  Executor:54 - Finished task 183.0 in stage 5.0 (TID 293). 3733 bytes result sent to driver
2021-05-19 02:45:52 INFO  Executor:54 - Running task 191.0 in stage 5.0 (TID 300)
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2021-05-19 02:45:52 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 302
2021-05-19 02:45:52 INFO  Executor:54 - Running task 193.0 in stage 5.0 (TID 302)
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2021-05-19 02:45:52 INFO  Executor:54 - Finished task 185.0 in stage 5.0 (TID 295). 3733 bytes result sent to driver
2021-05-19 02:45:52 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 305
2021-05-19 02:45:52 INFO  Executor:54 - Running task 196.0 in stage 5.0 (TID 305)
2021-05-19 02:45:52 INFO  Executor:54 - Finished task 188.0 in stage 5.0 (TID 298). 3733 bytes result sent to driver
2021-05-19 02:45:52 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 306
2021-05-19 02:45:52 INFO  Executor:54 - Running task 197.0 in stage 5.0 (TID 306)
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:45:52 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 307
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2021-05-19 02:45:52 INFO  Executor:54 - Running task 198.0 in stage 5.0 (TID 307)
2021-05-19 02:45:52 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 308
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:45:52 INFO  Executor:54 - Running task 199.0 in stage 5.0 (TID 308)
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2021-05-19 02:45:52 INFO  Executor:54 - Finished task 191.0 in stage 5.0 (TID 300). 3776 bytes result sent to driver
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2021-05-19 02:45:52 INFO  Executor:54 - Finished task 193.0 in stage 5.0 (TID 302). 3733 bytes result sent to driver
2021-05-19 02:45:52 INFO  Executor:54 - Finished task 196.0 in stage 5.0 (TID 305). 3733 bytes result sent to driver
2021-05-19 02:45:52 INFO  Executor:54 - Finished task 197.0 in stage 5.0 (TID 306). 3733 bytes result sent to driver
2021-05-19 02:45:52 INFO  Executor:54 - Finished task 198.0 in stage 5.0 (TID 307). 3733 bytes result sent to driver
2021-05-19 02:45:52 INFO  Executor:54 - Finished task 199.0 in stage 5.0 (TID 308). 3733 bytes result sent to driver
2021-05-19 02:45:54 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 309
2021-05-19 02:45:54 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 310
2021-05-19 02:45:54 INFO  Executor:54 - Running task 0.0 in stage 6.0 (TID 309)
2021-05-19 02:45:54 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 311
2021-05-19 02:45:54 INFO  Executor:54 - Running task 1.0 in stage 6.0 (TID 310)
2021-05-19 02:45:54 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 312
2021-05-19 02:45:54 INFO  Executor:54 - Running task 2.0 in stage 6.0 (TID 311)
2021-05-19 02:45:54 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 313
2021-05-19 02:45:54 INFO  Executor:54 - Running task 3.0 in stage 6.0 (TID 312)
2021-05-19 02:45:54 INFO  Executor:54 - Running task 4.0 in stage 6.0 (TID 313)
2021-05-19 02:45:54 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 314
2021-05-19 02:45:54 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 315
2021-05-19 02:45:54 INFO  Executor:54 - Running task 5.0 in stage 6.0 (TID 314)
2021-05-19 02:45:54 INFO  TorrentBroadcast:54 - Started reading broadcast variable 11
2021-05-19 02:45:54 INFO  Executor:54 - Running task 6.0 in stage 6.0 (TID 315)
2021-05-19 02:45:54 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 316
2021-05-19 02:45:54 INFO  Executor:54 - Running task 7.0 in stage 6.0 (TID 316)
2021-05-19 02:45:54 INFO  MemoryStore:54 - Block broadcast_11_piece0 stored as bytes in memory (estimated size 14.1 KB, free 365.1 MB)
2021-05-19 02:45:54 INFO  TorrentBroadcast:54 - Reading broadcast variable 11 took 23 ms
2021-05-19 02:45:54 INFO  MemoryStore:54 - Block broadcast_11 stored as values in memory (estimated size 29.9 KB, free 365.1 MB)
2021-05-19 02:45:54 INFO  BlockManager:54 - Found block rdd_29_0 locally
2021-05-19 02:45:54 INFO  BlockManager:54 - Found block rdd_29_3 locally
2021-05-19 02:45:54 INFO  BlockManager:54 - Found block rdd_29_1 locally
2021-05-19 02:45:54 INFO  BlockManager:54 - Found block rdd_29_7 locally
2021-05-19 02:45:54 INFO  BlockManager:54 - Found block rdd_29_4 locally
2021-05-19 02:45:54 INFO  BlockManager:54 - Found block rdd_29_5 locally
2021-05-19 02:45:54 INFO  BlockManager:54 - Found block rdd_29_6 locally
2021-05-19 02:45:54 INFO  BlockManager:54 - Found block rdd_29_2 locally
2021-05-19 02:45:55 INFO  InMemoryTableScanExec:54 - Predicate isnotnull(placekey#10) generates partition filter: ((placekey.count#263 - placekey.nullCount#262) > 0)
2021-05-19 02:45:55 INFO  InMemoryTableScanExec:54 - Predicate isnotnull(placekey#10) generates partition filter: ((placekey.count#263 - placekey.nullCount#262) > 0)
2021-05-19 02:45:55 INFO  InMemoryTableScanExec:54 - Predicate isnotnull(placekey#10) generates partition filter: ((placekey.count#263 - placekey.nullCount#262) > 0)
2021-05-19 02:45:55 INFO  InMemoryTableScanExec:54 - Predicate isnotnull(placekey#10) generates partition filter: ((placekey.count#263 - placekey.nullCount#262) > 0)
2021-05-19 02:45:55 INFO  InMemoryTableScanExec:54 - Predicate isnotnull(placekey#10) generates partition filter: ((placekey.count#263 - placekey.nullCount#262) > 0)
2021-05-19 02:45:55 INFO  InMemoryTableScanExec:54 - Predicate isnotnull(placekey#10) generates partition filter: ((placekey.count#263 - placekey.nullCount#262) > 0)
2021-05-19 02:45:55 INFO  InMemoryTableScanExec:54 - Predicate isnotnull(placekey#10) generates partition filter: ((placekey.count#263 - placekey.nullCount#262) > 0)
2021-05-19 02:45:55 INFO  InMemoryTableScanExec:54 - Predicate isnotnull(placekey#10) generates partition filter: ((placekey.count#263 - placekey.nullCount#262) > 0)
2021-05-19 02:45:55 INFO  CodeGenerator:54 - Code generated in 13.900678 ms
2021-05-19 02:45:55 INFO  CodeGenerator:54 - Code generated in 22.064297 ms
2021-05-19 02:45:55 INFO  CodeGenerator:54 - Code generated in 14.921536 ms
2021-05-19 02:45:55 INFO  Executor:54 - Finished task 7.0 in stage 6.0 (TID 316). 30798 bytes result sent to driver
2021-05-19 02:45:55 INFO  Executor:54 - Finished task 2.0 in stage 6.0 (TID 311). 57630 bytes result sent to driver
2021-05-19 02:45:55 INFO  Executor:54 - Finished task 4.0 in stage 6.0 (TID 313). 55801 bytes result sent to driver
2021-05-19 02:45:55 INFO  Executor:54 - Finished task 6.0 in stage 6.0 (TID 315). 56873 bytes result sent to driver
2021-05-19 02:45:55 INFO  Executor:54 - Finished task 1.0 in stage 6.0 (TID 310). 56912 bytes result sent to driver
2021-05-19 02:45:55 INFO  Executor:54 - Finished task 3.0 in stage 6.0 (TID 312). 56165 bytes result sent to driver
2021-05-19 02:45:55 INFO  Executor:54 - Finished task 0.0 in stage 6.0 (TID 309). 56818 bytes result sent to driver
2021-05-19 02:45:55 INFO  Executor:54 - Finished task 5.0 in stage 6.0 (TID 314). 57359 bytes result sent to driver
2021-05-19 02:45:56 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 319
2021-05-19 02:45:56 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 324
2021-05-19 02:45:56 INFO  Executor:54 - Running task 7.0 in stage 7.0 (TID 319)
2021-05-19 02:45:56 INFO  Executor:54 - Running task 12.0 in stage 7.0 (TID 324)
2021-05-19 02:45:56 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 329
2021-05-19 02:45:56 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 334
2021-05-19 02:45:56 INFO  Executor:54 - Running task 25.0 in stage 7.0 (TID 329)
2021-05-19 02:45:56 INFO  Executor:54 - Running task 36.0 in stage 7.0 (TID 334)
2021-05-19 02:45:56 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 339
2021-05-19 02:45:56 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 344
2021-05-19 02:45:56 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 349
2021-05-19 02:45:56 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 354
2021-05-19 02:45:56 INFO  Executor:54 - Running task 39.0 in stage 7.0 (TID 339)
2021-05-19 02:45:56 INFO  Executor:54 - Running task 51.0 in stage 7.0 (TID 349)
2021-05-19 02:45:56 INFO  Executor:54 - Running task 56.0 in stage 7.0 (TID 354)
2021-05-19 02:45:56 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 359
2021-05-19 02:45:56 INFO  Executor:54 - Running task 43.0 in stage 7.0 (TID 344)
2021-05-19 02:45:56 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 363
2021-05-19 02:45:56 INFO  Executor:54 - Running task 58.0 in stage 7.0 (TID 359)
2021-05-19 02:45:56 INFO  TorrentBroadcast:54 - Started reading broadcast variable 14
2021-05-19 02:45:56 INFO  Executor:54 - Running task 69.0 in stage 7.0 (TID 363)
2021-05-19 02:45:56 INFO  MemoryStore:54 - Block broadcast_14_piece0 stored as bytes in memory (estimated size 22.9 KB, free 365.0 MB)
2021-05-19 02:45:56 INFO  TorrentBroadcast:54 - Reading broadcast variable 14 took 17 ms
2021-05-19 02:45:56 INFO  MemoryStore:54 - Block broadcast_14 stored as values in memory (estimated size 51.5 KB, free 365.0 MB)
2021-05-19 02:45:56 INFO  CodeGenerator:54 - Code generated in 49.538196 ms
2021-05-19 02:45:56 INFO  TorrentBroadcast:54 - Started reading broadcast variable 12
2021-05-19 02:45:56 INFO  MemoryStore:54 - Block broadcast_12_piece0 stored as bytes in memory (estimated size 580.1 KB, free 364.4 MB)
2021-05-19 02:45:56 INFO  TorrentBroadcast:54 - Reading broadcast variable 12 took 19 ms
2021-05-19 02:45:56 INFO  MemoryStore:54 - Block broadcast_12 stored as values in memory (estimated size 5.0 MB, free 359.4 MB)
2021-05-19 02:45:56 INFO  CodeGenerator:54 - Code generated in 20.802677 ms
2021-05-19 02:45:56 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00039, range: 0-134217728, partition values: [empty row]
2021-05-19 02:45:56 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00007, range: 0-134217728, partition values: [empty row]
2021-05-19 02:45:56 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00036, range: 0-134217728, partition values: [empty row]
2021-05-19 02:45:56 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00013, range: 134217728-177061523, partition values: [empty row]
2021-05-19 02:45:56 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00012, range: 0-134217728, partition values: [empty row]
2021-05-19 02:45:56 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00038, range: 134217728-172697253, partition values: [empty row]
2021-05-19 02:45:56 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00016, range: 134217728-178714481, partition values: [empty row]
2021-05-19 02:45:56 INFO  TorrentBroadcast:54 - Started reading broadcast variable 13
2021-05-19 02:45:56 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00022, range: 134217728-177544240, partition values: [empty row]
2021-05-19 02:45:56 INFO  MemoryStore:54 - Block broadcast_13_piece0 stored as bytes in memory (estimated size 33.4 KB, free 359.4 MB)
2021-05-19 02:45:56 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00025, range: 0-134217728, partition values: [empty row]
2021-05-19 02:45:56 INFO  TorrentBroadcast:54 - Reading broadcast variable 13 took 29 ms
2021-05-19 02:45:56 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00043, range: 0-134217728, partition values: [empty row]
2021-05-19 02:45:56 INFO  MemoryStore:54 - Block broadcast_13 stored as values in memory (estimated size 506.4 KB, free 358.9 MB)
2021-05-19 02:45:56 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: zzw-222@627-wc2-5fz, 2020-06-15T00:00:00-04:00, [0,2,1,1,1,2,0]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: zzw-222@627-wc2-5fz
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00025
2021-05-19 02:45:56 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: 25p-222@627-s8j-94v, 2020-06-08T00:00:00-04:00, [1,1,0,2,0,0,0]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: 25p-222@627-s8j-94v
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00043
2021-05-19 02:45:56 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: 22x-222@627-wgt-snq, 2020-07-13T00:00:00-04:00, [1,1,1,4,2,1,6]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: 22x-222@627-wgt-snq
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00039
2021-05-19 02:45:56 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: 22p-222@627-s5x-c3q, 2018-12-31T00:00:00-05:00, [3,2,4,4,4,6,0]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: 22p-222@627-s5x-c3q
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00012
2021-05-19 02:45:56 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: 222-222@627-sbc-pqf, 2018-12-31T00:00:00-05:00, [4,4,28,20,22,6,8]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: 222-222@627-sbc-pqf
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00007
2021-05-19 02:45:56 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: 22j-222@627-w9f-wff, 2020-07-27T00:00:00-04:00, [6,7,14,14,7,7,8]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: 22j-222@627-w9f-wff
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00036
2021-05-19 02:45:56 INFO  CodeGenerator:54 - Code generated in 54.306661 ms
2021-05-19 02:45:56 INFO  CodeGenerator:54 - Code generated in 30.529341 ms
2021-05-19 02:45:56 INFO  CodeGenerator:54 - Code generated in 23.148515 ms
2021-05-19 02:45:56 INFO  CodeGenerator:54 - Code generated in 15.067247 ms
2021-05-19 02:45:57 INFO  CodeGenerator:54 - Code generated in 14.480511 ms
2021-05-19 02:45:57 INFO  CodeGenerator:54 - Code generated in 14.544344 ms
2021-05-19 02:45:57 INFO  CodeGenerator:54 - Code generated in 16.503565 ms
2021-05-19 02:45:57 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:45:57 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:45:57 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:45:57 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:45:57 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:45:57 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:45:57 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:45:57 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:45:57 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:45:57 INFO  CodeGenerator:54 - Code generated in 35.070928 ms
2021-05-19 02:45:58 INFO  CodeGenerator:54 - Code generated in 22.942176 ms
2021-05-19 02:45:58 INFO  CodeGenerator:54 - Code generated in 26.168201 ms
2021-05-19 02:45:58 INFO  CodeGenerator:54 - Code generated in 11.437217 ms
2021-05-19 02:45:58 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:45:58 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00029, range: 134217728-172005177, partition values: [empty row]
2021-05-19 02:45:58 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00014, range: 134217728-177434121, partition values: [empty row]
2021-05-19 02:45:58 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00035, range: 134217728-177038143, partition values: [empty row]
2021-05-19 02:45:58 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00021, range: 134217728-178612317, partition values: [empty row]
2021-05-19 02:46:01 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00005, range: 134217728-171011271, partition values: [empty row]
2021-05-19 02:46:06 INFO  PythonUDFRunner:54 - Times: total = 9724, boot = -5523, init = 6224, finish = 9023
2021-05-19 02:46:06 INFO  PythonUDFRunner:54 - Times: total = 9826, boot = -5628, init = 6346, finish = 9108
2021-05-19 02:46:06 INFO  PythonUDFRunner:54 - Times: total = 9894, boot = -5526, init = 6232, finish = 9188
2021-05-19 02:46:06 INFO  CodeGenerator:54 - Code generated in 23.50249 ms
2021-05-19 02:46:07 INFO  Executor:54 - Finished task 58.0 in stage 7.0 (TID 359). 4270 bytes result sent to driver
2021-05-19 02:46:07 INFO  Executor:54 - Finished task 51.0 in stage 7.0 (TID 349). 4270 bytes result sent to driver
2021-05-19 02:46:07 INFO  Executor:54 - Finished task 56.0 in stage 7.0 (TID 354). 4270 bytes result sent to driver
2021-05-19 02:46:07 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 367
2021-05-19 02:46:07 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 368
2021-05-19 02:46:07 INFO  Executor:54 - Running task 6.0 in stage 7.0 (TID 367)
2021-05-19 02:46:07 INFO  Executor:54 - Running task 8.0 in stage 7.0 (TID 368)
2021-05-19 02:46:07 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 369
2021-05-19 02:46:07 INFO  Executor:54 - Running task 11.0 in stage 7.0 (TID 369)
2021-05-19 02:46:07 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00006, range: 0-134217728, partition values: [empty row]
2021-05-19 02:46:07 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00008, range: 0-134217728, partition values: [empty row]
2021-05-19 02:46:07 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00011, range: 0-134217728, partition values: [empty row]
2021-05-19 02:46:07 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: 237-224@627-rwx-wtv, 2018-12-31T00:00:00-05:00, [1,0,12,14,0,4,4]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: 237-224@627-rwx-wtv
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00006
2021-05-19 02:46:07 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: 22n-224@627-wc7-qfz, 2018-12-31T00:00:00-05:00, [4,2,14,28,22,22,26]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: 22n-224@627-wc7-qfz
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00008
2021-05-19 02:46:07 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: 238-222@627-s8g-tqf, 2018-12-31T00:00:00-05:00, [0,2,2,4,2,2,2]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: 238-222@627-s8g-tqf
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00011
2021-05-19 02:46:07 INFO  UnsafeExternalSorter:209 - Thread 132 spilling sort data of 32.0 MB to disk (0  time so far)
2021-05-19 02:46:07 INFO  UnsafeExternalSorter:209 - Thread 130 spilling sort data of 32.0 MB to disk (0  time so far)
2021-05-19 02:46:07 INFO  PythonUDFRunner:54 - Times: total = 11412, boot = -5550, init = 6260, finish = 10702
2021-05-19 02:46:08 INFO  PythonUDFRunner:54 - Times: total = 11639, boot = 40, init = 692, finish = 10907
2021-05-19 02:46:08 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:46:08 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:46:08 INFO  UnsafeExternalSorter:209 - Thread 129 spilling sort data of 32.0 MB to disk (0  time so far)
2021-05-19 02:46:08 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:46:08 INFO  Executor:54 - Finished task 7.0 in stage 7.0 (TID 319). 4270 bytes result sent to driver
2021-05-19 02:46:08 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 372
2021-05-19 02:46:08 INFO  Executor:54 - Running task 53.1 in stage 7.0 (TID 372)
2021-05-19 02:46:08 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00026, range: 134217728-178435909, partition values: [empty row]
2021-05-19 02:46:08 INFO  UnsafeExternalSorter:209 - Thread 134 spilling sort data of 32.0 MB to disk (0  time so far)
2021-05-19 02:46:08 INFO  Executor:54 - Finished task 25.0 in stage 7.0 (TID 329). 4270 bytes result sent to driver
2021-05-19 02:46:08 ERROR CoarseGrainedExecutorBackend:43 - RECEIVED SIGNAL TERM
2021-05-19 02:46:08 INFO  DiskBlockManager:54 - Shutdown hook called
2021-05-19 02:46:08 INFO  ShutdownHookManager:54 - Shutdown hook called
2021-05-19 02:46:08 INFO  ShutdownHookManager:54 - Deleting directory /localhome/cdp/yarn/nm/usercache/catherine.ng60/appcache/application_1609183734776_5900/spark-515ad8c2-32ba-4045-a078-eae9676e85b6
2021-05-19 02:46:08 ERROR TaskContextImpl:91 - Error in TaskCompletionListener
java.io.IOException: Filesystem closed
	at org.apache.hadoop.hdfs.DFSClient.checkOpen(DFSClient.java:808)
	at org.apache.hadoop.hdfs.DFSInputStream.close(DFSInputStream.java:710)
	at java.io.FilterInputStream.close(FilterInputStream.java:181)
	at org.apache.hadoop.util.LineReader.close(LineReader.java:150)
	at org.apache.hadoop.mapreduce.lib.input.LineRecordReader.close(LineRecordReader.java:231)
	at org.apache.spark.sql.execution.datasources.RecordReaderIterator.close(RecordReaderIterator.scala:62)
	at org.apache.spark.sql.execution.datasources.HadoopFileLinesReader.close(HadoopFileLinesReader.scala:73)
	at org.apache.spark.sql.execution.datasources.csv.TextInputCSVDataSource$$anonfun$4$$anonfun$apply$2.apply(CSVDataSource.scala:200)
	at org.apache.spark.sql.execution.datasources.csv.TextInputCSVDataSource$$anonfun$4$$anonfun$apply$2.apply(CSVDataSource.scala:200)
	at org.apache.spark.TaskContext$$anon$1.onTaskCompletion(TaskContext.scala:131)
	at org.apache.spark.TaskContextImpl$$anonfun$markTaskCompleted$1.apply(TaskContextImpl.scala:117)
	at org.apache.spark.TaskContextImpl$$anonfun$markTaskCompleted$1.apply(TaskContextImpl.scala:117)
	at org.apache.spark.TaskContextImpl$$anonfun$invokeListeners$1.apply(TaskContextImpl.scala:130)
	at org.apache.spark.TaskContextImpl$$anonfun$invokeListeners$1.apply(TaskContextImpl.scala:128)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.TaskContextImpl.invokeListeners(TaskContextImpl.scala:128)
	at org.apache.spark.TaskContextImpl.markTaskCompleted(TaskContextImpl.scala:116)
	at org.apache.spark.scheduler.Task.run(Task.scala:131)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:402)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:408)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2021-05-19 02:46:08 ERROR Executor:91 - Exception in task 53.1 in stage 7.0 (TID 372)
org.apache.spark.util.TaskCompletionListenerException: Filesystem closed

Previous exception in task: Filesystem closed
	org.apache.hadoop.hdfs.DFSClient.checkOpen(DFSClient.java:808)
	org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:868)
	org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:934)
	java.io.DataInputStream.read(DataInputStream.java:149)
	org.apache.hadoop.mapreduce.lib.input.UncompressedSplitLineReader.fillBuffer(UncompressedSplitLineReader.java:62)
	org.apache.hadoop.util.LineReader.readDefaultLine(LineReader.java:216)
	org.apache.hadoop.util.LineReader.readLine(LineReader.java:174)
	org.apache.hadoop.mapreduce.lib.input.UncompressedSplitLineReader.readLine(UncompressedSplitLineReader.java:94)
	org.apache.hadoop.mapreduce.lib.input.LineRecordReader.nextKeyValue(LineRecordReader.java:186)
	org.apache.spark.sql.execution.datasources.RecordReaderIterator.hasNext(RecordReaderIterator.scala:39)
	org.apache.spark.sql.execution.datasources.HadoopFileLinesReader.hasNext(HadoopFileLinesReader.scala:69)
	scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:462)
	scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:101)
	org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source)
	org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$11$$anon$1.hasNext(WholeStageCodegenExec.scala:619)
	scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	scala.collection.Iterator$GroupedIterator.takeDestructively(Iterator.scala:1073)
	scala.collection.Iterator$GroupedIterator.go(Iterator.scala:1089)
	scala.collection.Iterator$GroupedIterator.fill(Iterator.scala:1127)
	scala.collection.Iterator$GroupedIterator.hasNext(Iterator.scala:1130)
	scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	scala.collection.Iterator$class.foreach(Iterator.scala:891)
	scala.collection.AbstractIterator.foreach(Iterator.scala:1334)
	org.apache.spark.api.python.PythonRDD$.writeIteratorToStream(PythonRDD.scala:224)
	org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$2.writeIteratorToStream(PythonUDFRunner.scala:50)
	org.apache.spark.api.python.BasePythonRunner$WriterThread$$anonfun$run$1.apply(PythonRunner.scala:345)
	org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1945)
	org.apache.spark.api.python.BasePythonRunner$WriterThread.run(PythonRunner.scala:194)
	at org.apache.spark.TaskContextImpl.invokeListeners(TaskContextImpl.scala:138)
	at org.apache.spark.TaskContextImpl.markTaskCompleted(TaskContextImpl.scala:116)
	at org.apache.spark.scheduler.Task.run(Task.scala:131)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:402)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:408)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2021-05-19 02:46:08 INFO  Executor:54 - Not reporting error to driver during JVM shutdown.
2021-05-19 02:46:08 ERROR TaskContextImpl:91 - Error in TaskCompletionListener
java.io.IOException: Filesystem closed
	at org.apache.hadoop.hdfs.DFSClient.checkOpen(DFSClient.java:808)
	at org.apache.hadoop.hdfs.DFSInputStream.close(DFSInputStream.java:710)
	at java.io.FilterInputStream.close(FilterInputStream.java:181)
	at org.apache.hadoop.util.LineReader.close(LineReader.java:150)
	at org.apache.hadoop.mapreduce.lib.input.LineRecordReader.close(LineRecordReader.java:231)
	at org.apache.spark.sql.execution.datasources.RecordReaderIterator.close(RecordReaderIterator.scala:62)
	at org.apache.spark.sql.execution.datasources.HadoopFileLinesReader.close(HadoopFileLinesReader.scala:73)
	at org.apache.spark.sql.execution.datasources.csv.TextInputCSVDataSource$$anonfun$4$$anonfun$apply$2.apply(CSVDataSource.scala:200)
	at org.apache.spark.sql.execution.datasources.csv.TextInputCSVDataSource$$anonfun$4$$anonfun$apply$2.apply(CSVDataSource.scala:200)
	at org.apache.spark.TaskContext$$anon$1.onTaskCompletion(TaskContext.scala:131)
	at org.apache.spark.TaskContextImpl$$anonfun$markTaskCompleted$1.apply(TaskContextImpl.scala:117)
	at org.apache.spark.TaskContextImpl$$anonfun$markTaskCompleted$1.apply(TaskContextImpl.scala:117)
	at org.apache.spark.TaskContextImpl$$anonfun$invokeListeners$1.apply(TaskContextImpl.scala:130)
	at org.apache.spark.TaskContextImpl$$anonfun$invokeListeners$1.apply(TaskContextImpl.scala:128)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.TaskContextImpl.invokeListeners(TaskContextImpl.scala:128)
	at org.apache.spark.TaskContextImpl.markTaskCompleted(TaskContextImpl.scala:116)
	at org.apache.spark.scheduler.Task.run(Task.scala:131)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:402)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:408)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2021-05-19 02:46:08 ERROR Executor:91 - Exception in task 6.0 in stage 7.0 (TID 367)
org.apache.spark.util.TaskCompletionListenerException: Filesystem closed

Previous exception in task: Filesystem closed
	org.apache.hadoop.hdfs.DFSClient.checkOpen(DFSClient.java:808)
	org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:868)
	org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:934)
	java.io.DataInputStream.read(DataInputStream.java:149)
	org.apache.hadoop.mapreduce.lib.input.UncompressedSplitLineReader.fillBuffer(UncompressedSplitLineReader.java:62)
	org.apache.hadoop.util.LineReader.readDefaultLine(LineReader.java:216)
	org.apache.hadoop.util.LineReader.readLine(LineReader.java:174)
	org.apache.hadoop.mapreduce.lib.input.UncompressedSplitLineReader.readLine(UncompressedSplitLineReader.java:94)
	org.apache.hadoop.mapreduce.lib.input.LineRecordReader.nextKeyValue(LineRecordReader.java:186)
	org.apache.spark.sql.execution.datasources.RecordReaderIterator.hasNext(RecordReaderIterator.scala:39)
	org.apache.spark.sql.execution.datasources.HadoopFileLinesReader.hasNext(HadoopFileLinesReader.scala:69)
	scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:462)
	scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:101)
	org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source)
	org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$11$$anon$1.hasNext(WholeStageCodegenExec.scala:619)
	scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	scala.collection.Iterator$GroupedIterator.takeDestructively(Iterator.scala:1073)
	scala.collection.Iterator$GroupedIterator.go(Iterator.scala:1089)
	scala.collection.Iterator$GroupedIterator.fill(Iterator.scala:1127)
	scala.collection.Iterator$GroupedIterator.hasNext(Iterator.scala:1130)
	scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	scala.collection.Iterator$class.foreach(Iterator.scala:891)
	scala.collection.AbstractIterator.foreach(Iterator.scala:1334)
	org.apache.spark.api.python.PythonRDD$.writeIteratorToStream(PythonRDD.scala:224)
	org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$2.writeIteratorToStream(PythonUDFRunner.scala:50)
	org.apache.spark.api.python.BasePythonRunner$WriterThread$$anonfun$run$1.apply(PythonRunner.scala:345)
	org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1945)
	org.apache.spark.api.python.BasePythonRunner$WriterThread.run(PythonRunner.scala:194)
	at org.apache.spark.TaskContextImpl.invokeListeners(TaskContextImpl.scala:138)
	at org.apache.spark.TaskContextImpl.markTaskCompleted(TaskContextImpl.scala:116)
	at org.apache.spark.scheduler.Task.run(Task.scala:131)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:402)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:408)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2021-05-19 02:46:08 INFO  Executor:54 - Not reporting error to driver during JVM shutdown.
2021-05-19 02:46:08 ERROR TaskContextImpl:91 - Error in TaskCompletionListener
java.io.IOException: Filesystem closed
	at org.apache.hadoop.hdfs.DFSClient.checkOpen(DFSClient.java:808)
	at org.apache.hadoop.hdfs.DFSInputStream.close(DFSInputStream.java:710)
	at java.io.FilterInputStream.close(FilterInputStream.java:181)
	at org.apache.hadoop.util.LineReader.close(LineReader.java:150)
	at org.apache.hadoop.mapreduce.lib.input.LineRecordReader.close(LineRecordReader.java:231)
	at org.apache.spark.sql.execution.datasources.RecordReaderIterator.close(RecordReaderIterator.scala:62)
	at org.apache.spark.sql.execution.datasources.HadoopFileLinesReader.close(HadoopFileLinesReader.scala:73)
	at org.apache.spark.sql.execution.datasources.csv.TextInputCSVDataSource$$anonfun$4$$anonfun$apply$2.apply(CSVDataSource.scala:200)
	at org.apache.spark.sql.execution.datasources.csv.TextInputCSVDataSource$$anonfun$4$$anonfun$apply$2.apply(CSVDataSource.scala:200)
	at org.apache.spark.TaskContext$$anon$1.onTaskCompletion(TaskContext.scala:131)
	at org.apache.spark.TaskContextImpl$$anonfun$markTaskCompleted$1.apply(TaskContextImpl.scala:117)
	at org.apache.spark.TaskContextImpl$$anonfun$markTaskCompleted$1.apply(TaskContextImpl.scala:117)
	at org.apache.spark.TaskContextImpl$$anonfun$invokeListeners$1.apply(TaskContextImpl.scala:130)
	at org.apache.spark.TaskContextImpl$$anonfun$invokeListeners$1.apply(TaskContextImpl.scala:128)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.TaskContextImpl.invokeListeners(TaskContextImpl.scala:128)
	at org.apache.spark.TaskContextImpl.markTaskCompleted(TaskContextImpl.scala:116)
	at org.apache.spark.scheduler.Task.run(Task.scala:131)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:402)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:408)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2021-05-19 02:46:08 ERROR Executor:91 - Exception in task 8.0 in stage 7.0 (TID 368)
org.apache.spark.util.TaskCompletionListenerException: Filesystem closed

Previous exception in task: Filesystem closed
	org.apache.hadoop.hdfs.DFSClient.checkOpen(DFSClient.java:808)
	org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:868)
	org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:934)
	java.io.DataInputStream.read(DataInputStream.java:149)
	org.apache.hadoop.mapreduce.lib.input.UncompressedSplitLineReader.fillBuffer(UncompressedSplitLineReader.java:62)
	org.apache.hadoop.util.LineReader.readDefaultLine(LineReader.java:216)
	org.apache.hadoop.util.LineReader.readLine(LineReader.java:174)
	org.apache.hadoop.mapreduce.lib.input.UncompressedSplitLineReader.readLine(UncompressedSplitLineReader.java:94)
	org.apache.hadoop.mapreduce.lib.input.LineRecordReader.nextKeyValue(LineRecordReader.java:186)
	org.apache.spark.sql.execution.datasources.RecordReaderIterator.hasNext(RecordReaderIterator.scala:39)
	org.apache.spark.sql.execution.datasources.HadoopFileLinesReader.hasNext(HadoopFileLinesReader.scala:69)
	scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:462)
	scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:101)
	org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source)
	org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$11$$anon$1.hasNext(WholeStageCodegenExec.scala:619)
	scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	scala.collection.Iterator$GroupedIterator.takeDestructively(Iterator.scala:1073)
	scala.collection.Iterator$GroupedIterator.go(Iterator.scala:1089)
	scala.collection.Iterator$GroupedIterator.fill(Iterator.scala:1127)
	scala.collection.Iterator$GroupedIterator.hasNext(Iterator.scala:1130)
	scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	scala.collection.Iterator$class.foreach(Iterator.scala:891)
	scala.collection.AbstractIterator.foreach(Iterator.scala:1334)
	org.apache.spark.api.python.PythonRDD$.writeIteratorToStream(PythonRDD.scala:224)
	org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$2.writeIteratorToStream(PythonUDFRunner.scala:50)
	org.apache.spark.api.python.BasePythonRunner$WriterThread$$anonfun$run$1.apply(PythonRunner.scala:345)
	org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1945)
	org.apache.spark.api.python.BasePythonRunner$WriterThread.run(PythonRunner.scala:194)
	at org.apache.spark.TaskContextImpl.invokeListeners(TaskContextImpl.scala:138)
	at org.apache.spark.TaskContextImpl.markTaskCompleted(TaskContextImpl.scala:116)
	at org.apache.spark.scheduler.Task.run(Task.scala:131)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:402)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:408)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2021-05-19 02:46:08 INFO  Executor:54 - Not reporting error to driver during JVM shutdown.
2021-05-19 02:46:08 INFO  PythonUDFRunner:54 - Times: total = 12416, boot = -5543, init = 6298, finish = 11661

End of LogType:stdout
***********************************************************************

Container: container_e10_1609183734776_5900_01_000002 on hadoop09.cusp.nyu.edu_8041
LogAggregationType: AGGREGATED
===================================================================================
LogType:container-localizer-syslog
LogLastModifiedTime:Wed May 19 02:48:18 -0400 2021
LogLength:506
LogContents:
2021-05-19 02:45:27,065 INFO [main] org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ContainerLocalizer: Disk Validator: yarn.nodemanager.disk-validator is loaded.
2021-05-19 02:45:28,351 WARN [ContainerLocalizer Downloader] org.apache.hadoop.ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ipc.StandbyException): Operation category READ is not supported in state standby. Visit https://s.apache.org/sbnn-error

End of LogType:container-localizer-syslog
*******************************************************************************************


End of LogType:prelaunch.err
******************************************************************************

Container: container_e10_1609183734776_5900_01_000002 on hadoop09.cusp.nyu.edu_8041
LogAggregationType: AGGREGATED
===================================================================================
LogType:prelaunch.out
LogLastModifiedTime:Wed May 19 02:48:18 -0400 2021
LogLength:70
LogContents:
Setting up env variables
Setting up job resources
Launching container

End of LogType:prelaunch.out
******************************************************************************

Container: container_e10_1609183734776_5900_01_000002 on hadoop09.cusp.nyu.edu_8041
LogAggregationType: AGGREGATED
===================================================================================
LogType:stderr
LogLastModifiedTime:Wed May 19 02:48:18 -0400 2021
LogLength:529
LogContents:
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/localhome/cdp/yarn/nm/filecache/26/spark-jars-2.4.0-hadoop2.7.jar/slf4j-log4j12-1.7.16.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-6.1.0-1.cdh6.1.0.p0.770702/jars/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]

End of LogType:stderr
***********************************************************************

Container: container_e10_1609183734776_5900_01_000002 on hadoop09.cusp.nyu.edu_8041
LogAggregationType: AGGREGATED
===================================================================================
LogType:stdout
LogLastModifiedTime:Wed May 19 02:48:18 -0400 2021
LogLength:46740
LogContents:
2021-05-19 02:45:29 INFO  CoarseGrainedExecutorBackend:2566 - Started daemon with process name: 52254@hadoop09.cusp.nyu.edu
2021-05-19 02:45:29 INFO  SignalUtils:54 - Registered signal handler for TERM
2021-05-19 02:45:29 INFO  SignalUtils:54 - Registered signal handler for HUP
2021-05-19 02:45:29 INFO  SignalUtils:54 - Registered signal handler for INT
2021-05-19 02:45:30 INFO  SecurityManager:54 - Changing view acls to: catherine.ng60
2021-05-19 02:45:30 INFO  SecurityManager:54 - Changing modify acls to: catherine.ng60
2021-05-19 02:45:30 INFO  SecurityManager:54 - Changing view acls groups to: 
2021-05-19 02:45:30 INFO  SecurityManager:54 - Changing modify acls groups to: 
2021-05-19 02:45:30 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(catherine.ng60); groups with view permissions: Set(); users  with modify permissions: Set(catherine.ng60); groups with modify permissions: Set()
2021-05-19 02:45:31 INFO  TransportClientFactory:267 - Successfully created connection to hadoop05.cusp.nyu.edu/192.168.72.175:47481 after 105 ms (0 ms spent in bootstraps)
2021-05-19 02:45:31 INFO  SecurityManager:54 - Changing view acls to: catherine.ng60
2021-05-19 02:45:31 INFO  SecurityManager:54 - Changing modify acls to: catherine.ng60
2021-05-19 02:45:31 INFO  SecurityManager:54 - Changing view acls groups to: 
2021-05-19 02:45:31 INFO  SecurityManager:54 - Changing modify acls groups to: 
2021-05-19 02:45:31 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(catherine.ng60); groups with view permissions: Set(); users  with modify permissions: Set(catherine.ng60); groups with modify permissions: Set()
2021-05-19 02:45:31 INFO  TransportClientFactory:267 - Successfully created connection to hadoop05.cusp.nyu.edu/192.168.72.175:47481 after 4 ms (0 ms spent in bootstraps)
2021-05-19 02:45:31 INFO  DiskBlockManager:54 - Created local directory at /localhome/cdp/yarn/nm/usercache/catherine.ng60/appcache/application_1609183734776_5900/blockmgr-7fa5631b-aad9-4833-9b63-35423fcf6a14
2021-05-19 02:45:32 INFO  MemoryStore:54 - MemoryStore started with capacity 366.3 MB
2021-05-19 02:45:32 INFO  CoarseGrainedExecutorBackend:54 - Connecting to driver: spark://CoarseGrainedScheduler@hadoop05.cusp.nyu.edu:47481
2021-05-19 02:45:32 INFO  CoarseGrainedExecutorBackend:54 - Successfully registered with driver
2021-05-19 02:45:32 INFO  Executor:54 - Starting executor ID 1 on host hadoop09.cusp.nyu.edu
2021-05-19 02:45:32 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 44190.
2021-05-19 02:45:32 INFO  NettyBlockTransferService:54 - Server created on hadoop09.cusp.nyu.edu:44190
2021-05-19 02:45:32 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2021-05-19 02:45:32 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(1, hadoop09.cusp.nyu.edu, 44190, None)
2021-05-19 02:45:32 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(1, hadoop09.cusp.nyu.edu, 44190, None)
2021-05-19 02:45:32 INFO  BlockManager:54 - external shuffle service port = 7337
2021-05-19 02:45:32 INFO  BlockManager:54 - Registering executor with local external shuffle service.
2021-05-19 02:45:32 INFO  TransportClientFactory:267 - Successfully created connection to hadoop09.cusp.nyu.edu/192.168.72.179:7337 after 2 ms (0 ms spent in bootstraps)
2021-05-19 02:45:32 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(1, hadoop09.cusp.nyu.edu, 44190, None)
2021-05-19 02:45:42 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 3
2021-05-19 02:45:42 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 8
2021-05-19 02:45:42 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 13
2021-05-19 02:45:42 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 18
2021-05-19 02:45:42 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 23
2021-05-19 02:45:42 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 28
2021-05-19 02:45:42 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 33
2021-05-19 02:45:42 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 38
2021-05-19 02:45:42 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 43
2021-05-19 02:45:42 INFO  Executor:54 - Running task 37.0 in stage 1.0 (TID 38)
2021-05-19 02:45:42 INFO  Executor:54 - Running task 7.0 in stage 1.0 (TID 8)
2021-05-19 02:45:42 INFO  Executor:54 - Running task 12.0 in stage 1.0 (TID 13)
2021-05-19 02:45:42 INFO  Executor:54 - Running task 32.0 in stage 1.0 (TID 33)
2021-05-19 02:45:42 INFO  Executor:54 - Running task 17.0 in stage 1.0 (TID 18)
2021-05-19 02:45:42 INFO  Executor:54 - Running task 22.0 in stage 1.0 (TID 23)
2021-05-19 02:45:42 INFO  Executor:54 - Running task 2.0 in stage 1.0 (TID 3)
2021-05-19 02:45:42 INFO  Executor:54 - Running task 27.0 in stage 1.0 (TID 28)
2021-05-19 02:45:42 INFO  Executor:54 - Running task 42.0 in stage 1.0 (TID 43)
2021-05-19 02:45:42 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 48
2021-05-19 02:45:42 INFO  Executor:54 - Running task 47.0 in stage 1.0 (TID 48)
2021-05-19 02:45:43 INFO  TorrentBroadcast:54 - Started reading broadcast variable 3
2021-05-19 02:45:43 INFO  TransportClientFactory:267 - Successfully created connection to hadoop10.cusp.nyu.edu/192.168.72.180:51710 after 6 ms (0 ms spent in bootstraps)
2021-05-19 02:45:43 INFO  MemoryStore:54 - Block broadcast_3_piece0 stored as bytes in memory (estimated size 35.0 KB, free 366.3 MB)
2021-05-19 02:45:43 INFO  TorrentBroadcast:54 - Reading broadcast variable 3 took 269 ms
2021-05-19 02:45:43 INFO  MemoryStore:54 - Block broadcast_3 stored as values in memory (estimated size 129.0 KB, free 366.1 MB)
2021-05-19 02:45:45 INFO  Executor:54 - Finished task 37.0 in stage 1.0 (TID 38). 1492 bytes result sent to driver
2021-05-19 02:45:45 INFO  Executor:54 - Finished task 17.0 in stage 1.0 (TID 18). 1492 bytes result sent to driver
2021-05-19 02:45:45 INFO  Executor:54 - Finished task 42.0 in stage 1.0 (TID 43). 1492 bytes result sent to driver
2021-05-19 02:45:45 INFO  Executor:54 - Finished task 22.0 in stage 1.0 (TID 23). 1492 bytes result sent to driver
2021-05-19 02:45:45 INFO  Executor:54 - Finished task 7.0 in stage 1.0 (TID 8). 1492 bytes result sent to driver
2021-05-19 02:45:45 INFO  Executor:54 - Finished task 27.0 in stage 1.0 (TID 28). 1492 bytes result sent to driver
2021-05-19 02:45:45 INFO  Executor:54 - Finished task 12.0 in stage 1.0 (TID 13). 1492 bytes result sent to driver
2021-05-19 02:45:45 INFO  Executor:54 - Finished task 32.0 in stage 1.0 (TID 33). 1492 bytes result sent to driver
2021-05-19 02:45:45 INFO  Executor:54 - Finished task 47.0 in stage 1.0 (TID 48). 1492 bytes result sent to driver
2021-05-19 02:45:45 INFO  Executor:54 - Finished task 2.0 in stage 1.0 (TID 3). 1492 bytes result sent to driver
2021-05-19 02:45:45 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 51
2021-05-19 02:45:45 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 56
2021-05-19 02:45:45 INFO  Executor:54 - Running task 0.0 in stage 2.0 (TID 51)
2021-05-19 02:45:45 INFO  Executor:54 - Running task 5.0 in stage 2.0 (TID 56)
2021-05-19 02:45:45 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 61
2021-05-19 02:45:45 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 66
2021-05-19 02:45:45 INFO  Executor:54 - Running task 10.0 in stage 2.0 (TID 61)
2021-05-19 02:45:45 INFO  Executor:54 - Running task 15.0 in stage 2.0 (TID 66)
2021-05-19 02:45:45 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 71
2021-05-19 02:45:45 INFO  Executor:54 - Running task 20.0 in stage 2.0 (TID 71)
2021-05-19 02:45:45 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 76
2021-05-19 02:45:45 INFO  Executor:54 - Running task 25.0 in stage 2.0 (TID 76)
2021-05-19 02:45:45 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 81
2021-05-19 02:45:45 INFO  Executor:54 - Running task 30.0 in stage 2.0 (TID 81)
2021-05-19 02:45:45 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 86
2021-05-19 02:45:45 INFO  Executor:54 - Running task 35.0 in stage 2.0 (TID 86)
2021-05-19 02:45:45 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 91
2021-05-19 02:45:45 INFO  Executor:54 - Running task 40.0 in stage 2.0 (TID 91)
2021-05-19 02:45:45 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 96
2021-05-19 02:45:45 INFO  Executor:54 - Running task 45.0 in stage 2.0 (TID 96)
2021-05-19 02:45:45 INFO  TorrentBroadcast:54 - Started reading broadcast variable 4
2021-05-19 02:45:45 INFO  TransportClientFactory:267 - Successfully created connection to hadoop05.cusp.nyu.edu/192.168.72.175:36982 after 4 ms (0 ms spent in bootstraps)
2021-05-19 02:45:45 INFO  MemoryStore:54 - Block broadcast_4_piece0 stored as bytes in memory (estimated size 35.0 KB, free 366.1 MB)
2021-05-19 02:45:45 INFO  TorrentBroadcast:54 - Reading broadcast variable 4 took 50 ms
2021-05-19 02:45:45 INFO  MemoryStore:54 - Block broadcast_4 stored as values in memory (estimated size 129.0 KB, free 366.0 MB)
2021-05-19 02:45:45 INFO  Executor:54 - Finished task 10.0 in stage 2.0 (TID 61). 1449 bytes result sent to driver
2021-05-19 02:45:45 INFO  Executor:54 - Finished task 5.0 in stage 2.0 (TID 56). 1449 bytes result sent to driver
2021-05-19 02:45:45 INFO  Executor:54 - Finished task 20.0 in stage 2.0 (TID 71). 1449 bytes result sent to driver
2021-05-19 02:45:45 INFO  Executor:54 - Finished task 40.0 in stage 2.0 (TID 91). 1449 bytes result sent to driver
2021-05-19 02:45:45 INFO  Executor:54 - Finished task 35.0 in stage 2.0 (TID 86). 1449 bytes result sent to driver
2021-05-19 02:45:45 INFO  Executor:54 - Finished task 15.0 in stage 2.0 (TID 66). 1449 bytes result sent to driver
2021-05-19 02:45:45 INFO  Executor:54 - Finished task 0.0 in stage 2.0 (TID 51). 1449 bytes result sent to driver
2021-05-19 02:45:45 INFO  Executor:54 - Finished task 25.0 in stage 2.0 (TID 76). 1406 bytes result sent to driver
2021-05-19 02:45:45 INFO  Executor:54 - Finished task 45.0 in stage 2.0 (TID 96). 1449 bytes result sent to driver
2021-05-19 02:45:45 INFO  Executor:54 - Finished task 30.0 in stage 2.0 (TID 81). 1449 bytes result sent to driver
2021-05-19 02:45:51 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 121
2021-05-19 02:45:51 INFO  Executor:54 - Running task 4.0 in stage 5.0 (TID 121)
2021-05-19 02:45:51 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 126
2021-05-19 02:45:51 INFO  MapOutputTrackerWorker:54 - Updating epoch to 1 and clearing cache
2021-05-19 02:45:51 INFO  Executor:54 - Running task 9.0 in stage 5.0 (TID 126)
2021-05-19 02:45:51 INFO  TorrentBroadcast:54 - Started reading broadcast variable 10
2021-05-19 02:45:51 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 130
2021-05-19 02:45:51 INFO  Executor:54 - Running task 13.0 in stage 5.0 (TID 130)
2021-05-19 02:45:51 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 134
2021-05-19 02:45:51 INFO  Executor:54 - Running task 17.0 in stage 5.0 (TID 134)
2021-05-19 02:45:51 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 138
2021-05-19 02:45:51 INFO  Executor:54 - Running task 22.0 in stage 5.0 (TID 138)
2021-05-19 02:45:51 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 142
2021-05-19 02:45:51 INFO  Executor:54 - Running task 27.0 in stage 5.0 (TID 142)
2021-05-19 02:45:51 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 146
2021-05-19 02:45:51 INFO  Executor:54 - Running task 31.0 in stage 5.0 (TID 146)
2021-05-19 02:45:51 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 150
2021-05-19 02:45:51 INFO  Executor:54 - Running task 36.0 in stage 5.0 (TID 150)
2021-05-19 02:45:51 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 154
2021-05-19 02:45:51 INFO  Executor:54 - Running task 40.0 in stage 5.0 (TID 154)
2021-05-19 02:45:51 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 158
2021-05-19 02:45:51 INFO  Executor:54 - Running task 44.0 in stage 5.0 (TID 158)
2021-05-19 02:45:51 INFO  MemoryStore:54 - Block broadcast_10_piece0 stored as bytes in memory (estimated size 20.4 KB, free 366.3 MB)
2021-05-19 02:45:51 INFO  TorrentBroadcast:54 - Reading broadcast variable 10 took 35 ms
2021-05-19 02:45:51 INFO  MemoryStore:54 - Block broadcast_10 stored as values in memory (estimated size 40.9 KB, free 366.2 MB)
2021-05-19 02:45:52 INFO  MapOutputTrackerWorker:54 - Don't have map outputs for shuffle 0, fetching them
2021-05-19 02:45:52 INFO  MapOutputTrackerWorker:54 - Don't have map outputs for shuffle 0, fetching them
2021-05-19 02:45:52 INFO  MapOutputTrackerWorker:54 - Don't have map outputs for shuffle 0, fetching them
2021-05-19 02:45:52 INFO  MapOutputTrackerWorker:54 - Don't have map outputs for shuffle 0, fetching them
2021-05-19 02:45:52 INFO  MapOutputTrackerWorker:54 - Don't have map outputs for shuffle 0, fetching them
2021-05-19 02:45:52 INFO  MapOutputTrackerWorker:54 - Don't have map outputs for shuffle 0, fetching them
2021-05-19 02:45:52 INFO  MapOutputTrackerWorker:54 - Don't have map outputs for shuffle 0, fetching them
2021-05-19 02:45:52 INFO  MapOutputTrackerWorker:54 - Don't have map outputs for shuffle 0, fetching them
2021-05-19 02:45:52 INFO  MapOutputTrackerWorker:54 - Don't have map outputs for shuffle 0, fetching them
2021-05-19 02:45:52 INFO  MapOutputTrackerWorker:54 - Don't have map outputs for shuffle 0, fetching them
2021-05-19 02:45:52 INFO  MapOutputTrackerWorker:54 - Doing the fetch; tracker endpoint = NettyRpcEndpointRef(spark://MapOutputTracker@hadoop05.cusp.nyu.edu:47481)
2021-05-19 02:45:52 INFO  MapOutputTrackerWorker:54 - Got the output locations
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 12 ms
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 14 ms
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 14 ms
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 13 ms
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 12 ms
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 12 ms
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 12 ms
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 12 ms
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 15 ms
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 20 ms
2021-05-19 02:45:52 INFO  CodeGenerator:54 - Code generated in 416.883032 ms
2021-05-19 02:45:53 INFO  CodeGenerator:54 - Code generated in 27.26591 ms
2021-05-19 02:45:53 INFO  CodeGenerator:54 - Code generated in 24.549386 ms
2021-05-19 02:45:53 INFO  CodeGenerator:54 - Code generated in 26.560199 ms
2021-05-19 02:45:53 INFO  Executor:54 - Finished task 44.0 in stage 5.0 (TID 158). 3776 bytes result sent to driver
2021-05-19 02:45:53 INFO  Executor:54 - Finished task 13.0 in stage 5.0 (TID 130). 3819 bytes result sent to driver
2021-05-19 02:45:53 INFO  Executor:54 - Finished task 31.0 in stage 5.0 (TID 146). 3819 bytes result sent to driver
2021-05-19 02:45:53 INFO  Executor:54 - Finished task 4.0 in stage 5.0 (TID 121). 3776 bytes result sent to driver
2021-05-19 02:45:53 INFO  Executor:54 - Finished task 17.0 in stage 5.0 (TID 134). 3776 bytes result sent to driver
2021-05-19 02:45:53 INFO  Executor:54 - Finished task 22.0 in stage 5.0 (TID 138). 3776 bytes result sent to driver
2021-05-19 02:45:53 INFO  Executor:54 - Finished task 40.0 in stage 5.0 (TID 154). 3819 bytes result sent to driver
2021-05-19 02:45:53 INFO  Executor:54 - Finished task 9.0 in stage 5.0 (TID 126). 3776 bytes result sent to driver
2021-05-19 02:45:53 INFO  Executor:54 - Finished task 27.0 in stage 5.0 (TID 142). 3776 bytes result sent to driver
2021-05-19 02:45:53 INFO  Executor:54 - Finished task 36.0 in stage 5.0 (TID 150). 3776 bytes result sent to driver
2021-05-19 02:45:56 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 318
2021-05-19 02:45:56 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 323
2021-05-19 02:45:56 INFO  Executor:54 - Running task 19.0 in stage 7.0 (TID 318)
2021-05-19 02:45:56 INFO  Executor:54 - Running task 21.0 in stage 7.0 (TID 323)
2021-05-19 02:45:56 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 328
2021-05-19 02:45:56 INFO  Executor:54 - Running task 27.0 in stage 7.0 (TID 328)
2021-05-19 02:45:56 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 333
2021-05-19 02:45:56 INFO  Executor:54 - Running task 28.0 in stage 7.0 (TID 333)
2021-05-19 02:45:56 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 338
2021-05-19 02:45:56 INFO  Executor:54 - Running task 30.0 in stage 7.0 (TID 338)
2021-05-19 02:45:56 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 343
2021-05-19 02:45:56 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 348
2021-05-19 02:45:56 INFO  Executor:54 - Running task 44.0 in stage 7.0 (TID 343)
2021-05-19 02:45:56 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 353
2021-05-19 02:45:56 INFO  Executor:54 - Running task 57.0 in stage 7.0 (TID 348)
2021-05-19 02:45:56 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 358
2021-05-19 02:45:56 INFO  Executor:54 - Running task 59.0 in stage 7.0 (TID 353)
2021-05-19 02:45:56 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 362
2021-05-19 02:45:56 INFO  Executor:54 - Running task 62.0 in stage 7.0 (TID 358)
2021-05-19 02:45:56 INFO  Executor:54 - Running task 66.0 in stage 7.0 (TID 362)
2021-05-19 02:45:56 INFO  TorrentBroadcast:54 - Started reading broadcast variable 14
2021-05-19 02:45:56 INFO  TransportClientFactory:267 - Successfully created connection to hadoop08.cusp.nyu.edu/192.168.72.178:54817 after 5 ms (0 ms spent in bootstraps)
2021-05-19 02:45:56 INFO  MemoryStore:54 - Block broadcast_14_piece0 stored as bytes in memory (estimated size 22.9 KB, free 366.3 MB)
2021-05-19 02:45:56 INFO  TorrentBroadcast:54 - Reading broadcast variable 14 took 56 ms
2021-05-19 02:45:56 INFO  MemoryStore:54 - Block broadcast_14 stored as values in memory (estimated size 51.5 KB, free 366.2 MB)
2021-05-19 02:45:56 INFO  CodeGenerator:54 - Code generated in 54.493561 ms
2021-05-19 02:45:56 INFO  TorrentBroadcast:54 - Started reading broadcast variable 12
2021-05-19 02:45:56 INFO  TransportClientFactory:267 - Successfully created connection to hadoop07.cusp.nyu.edu/192.168.72.177:57060 after 5 ms (0 ms spent in bootstraps)
2021-05-19 02:45:56 INFO  MemoryStore:54 - Block broadcast_12_piece0 stored as bytes in memory (estimated size 580.1 KB, free 365.7 MB)
2021-05-19 02:45:56 INFO  TorrentBroadcast:54 - Reading broadcast variable 12 took 92 ms
2021-05-19 02:45:56 INFO  MemoryStore:54 - Block broadcast_12 stored as values in memory (estimated size 5.0 MB, free 360.7 MB)
2021-05-19 02:45:56 INFO  CodeGenerator:54 - Code generated in 20.828193 ms
2021-05-19 02:45:57 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00027, range: 0-134217728, partition values: [empty row]
2021-05-19 02:45:57 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00011, range: 134217728-177020723, partition values: [empty row]
2021-05-19 02:45:57 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00019, range: 0-134217728, partition values: [empty row]
2021-05-19 02:45:57 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00021, range: 0-134217728, partition values: [empty row]
2021-05-19 02:45:57 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00030, range: 0-134217728, partition values: [empty row]
2021-05-19 02:45:57 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00039, range: 134217728-175562757, partition values: [empty row]
2021-05-19 02:45:57 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00047, range: 134217728-176331317, partition values: [empty row]
2021-05-19 02:45:57 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00044, range: 0-134217728, partition values: [empty row]
2021-05-19 02:45:57 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00028, range: 134217728-177133478, partition values: [empty row]
2021-05-19 02:45:57 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00028, range: 0-134217728, partition values: [empty row]
2021-05-19 02:45:57 INFO  CodeGenerator:54 - Code generated in 42.059631 ms
2021-05-19 02:45:57 INFO  TorrentBroadcast:54 - Started reading broadcast variable 13
2021-05-19 02:45:57 INFO  CodeGenerator:54 - Code generated in 87.490669 ms
2021-05-19 02:45:57 INFO  TransportClientFactory:267 - Successfully created connection to hadoop20.cusp.nyu.edu/192.168.72.190:55825 after 5 ms (0 ms spent in bootstraps)
2021-05-19 02:45:57 INFO  CodeGenerator:54 - Code generated in 47.666845 ms
2021-05-19 02:45:57 INFO  MemoryStore:54 - Block broadcast_13_piece0 stored as bytes in memory (estimated size 33.4 KB, free 360.6 MB)
2021-05-19 02:45:57 INFO  TorrentBroadcast:54 - Reading broadcast variable 13 took 113 ms
2021-05-19 02:45:57 INFO  CodeGenerator:54 - Code generated in 41.112841 ms
2021-05-19 02:45:57 INFO  CodeGenerator:54 - Code generated in 28.732328 ms
2021-05-19 02:45:57 INFO  MemoryStore:54 - Block broadcast_13 stored as values in memory (estimated size 506.4 KB, free 360.1 MB)
2021-05-19 02:45:57 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: 22c-222@627-vv6-vvf, 2019-12-16T00:00:00-05:00, [0,0,0,0,1,0,0]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: 22c-222@627-vv6-vvf
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00019
2021-05-19 02:45:57 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: 225-222@627-wbv-ht9, 2020-06-29T00:00:00-04:00, [1,3,1,4,8,6,5]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: 225-222@627-wbv-ht9
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00027
2021-05-19 02:45:57 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: 233-222@627-s6b-5s5, 2018-12-31T00:00:00-05:00, [38,44,50,44,70,36,32]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: 233-222@627-s6b-5s5
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00021
2021-05-19 02:45:57 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: 222-222@627-wg5-389, 2019-05-13T00:00:00-04:00, [10,28,8,12,17,3,11]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: 222-222@627-wg5-389
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00030
2021-05-19 02:45:58 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: 227-222@627-s4n-x3q, 2019-06-10T00:00:00-04:00, [7,4,4,0,7,11,3]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: 227-222@627-s4n-x3q
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00044
2021-05-19 02:45:58 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: 22j-222@627-wc7-8jv, 2019-05-13T00:00:00-04:00, [1,1,0,2,2,4,1]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: 22j-222@627-wc7-8jv
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00028
2021-05-19 02:45:58 INFO  CodeGenerator:54 - Code generated in 17.352972 ms
2021-05-19 02:45:58 INFO  CodeGenerator:54 - Code generated in 46.087245 ms
2021-05-19 02:45:58 INFO  CodeGenerator:54 - Code generated in 23.192348 ms
2021-05-19 02:45:59 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:45:59 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:45:59 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:45:59 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:45:59 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:45:59 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:45:59 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:45:59 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:45:59 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:45:59 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:45:59 INFO  CodeGenerator:54 - Code generated in 35.229268 ms
2021-05-19 02:45:59 INFO  CodeGenerator:54 - Code generated in 26.747225 ms
2021-05-19 02:45:59 INFO  CodeGenerator:54 - Code generated in 14.741464 ms
2021-05-19 02:45:59 INFO  CodeGenerator:54 - Code generated in 25.735765 ms
2021-05-19 02:46:00 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00001, range: 134217728-176196294, partition values: [empty row]
2021-05-19 02:46:00 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00017, range: 134217728-176909385, partition values: [empty row]
2021-05-19 02:46:00 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00042, range: 134217728-177070408, partition values: [empty row]
2021-05-19 02:46:00 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00006, range: 134217728-175405184, partition values: [empty row]
2021-05-19 02:46:03 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00044, range: 134217728-175217045, partition values: [empty row]
2021-05-19 02:46:06 INFO  PythonUDFRunner:54 - Times: total = 10247, boot = 751, init = 1086, finish = 8410
2021-05-19 02:46:07 INFO  CodeGenerator:54 - Code generated in 26.888176 ms
2021-05-19 02:46:07 INFO  Executor:54 - Finished task 62.0 in stage 7.0 (TID 358). 4313 bytes result sent to driver
2021-05-19 02:46:07 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 370
2021-05-19 02:46:07 INFO  Executor:54 - Running task 13.0 in stage 7.0 (TID 370)
2021-05-19 02:46:07 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00013, range: 0-134217728, partition values: [empty row]
2021-05-19 02:46:07 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: 23b-222@627-wh4-vxq, 2019-01-07T00:00:00-05:00, [10,12,10,16,2,4,3]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: 23b-222@627-wh4-vxq
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00013
2021-05-19 02:46:07 INFO  PythonUDFRunner:54 - Times: total = 11051, boot = 711, init = 1130, finish = 9210
2021-05-19 02:46:07 INFO  PythonUDFRunner:54 - Times: total = 11078, boot = 771, init = 1058, finish = 9249
2021-05-19 02:46:08 INFO  Executor:54 - Finished task 59.0 in stage 7.0 (TID 353). 4270 bytes result sent to driver
2021-05-19 02:46:08 INFO  Executor:54 - Finished task 57.0 in stage 7.0 (TID 348). 4313 bytes result sent to driver
2021-05-19 02:46:08 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 374
2021-05-19 02:46:08 INFO  Executor:54 - Running task 10.1 in stage 7.0 (TID 374)
2021-05-19 02:46:08 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 375
2021-05-19 02:46:08 INFO  Executor:54 - Running task 50.1 in stage 7.0 (TID 375)
2021-05-19 02:46:08 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00010, range: 0-134217728, partition values: [empty row]
2021-05-19 02:46:08 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00010, range: 134217728-179164944, partition values: [empty row]
2021-05-19 02:46:08 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: 22x-224@627-s8r-c89, 2018-12-31T00:00:00-05:00, [21,42,46,76,70,52,8]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: 22x-224@627-s8r-c89
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00010
2021-05-19 02:46:08 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:46:08 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:46:09 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:46:09 INFO  PythonUDFRunner:54 - Times: total = 12502, boot = 731, init = 1107, finish = 10664
2021-05-19 02:46:09 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00003, range: 134217728-178774105, partition values: [empty row]
2021-05-19 02:46:09 INFO  PythonUDFRunner:54 - Times: total = 12685, boot = 698, init = 1145, finish = 10842
2021-05-19 02:46:09 INFO  PythonUDFRunner:54 - Times: total = 12813, boot = 785, init = 1056, finish = 10972
2021-05-19 02:46:09 INFO  Executor:54 - Finished task 30.0 in stage 7.0 (TID 338). 4270 bytes result sent to driver
2021-05-19 02:46:09 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 376
2021-05-19 02:46:09 INFO  Executor:54 - Running task 60.1 in stage 7.0 (TID 376)
2021-05-19 02:46:09 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00030, range: 134217728-176820246, partition values: [empty row]
2021-05-19 02:46:09 INFO  PythonUDFRunner:54 - Times: total = 12969, boot = 763, init = 1080, finish = 11126
2021-05-19 02:46:09 INFO  Executor:54 - Finished task 27.0 in stage 7.0 (TID 328). 4270 bytes result sent to driver
2021-05-19 02:46:09 ERROR CoarseGrainedExecutorBackend:43 - RECEIVED SIGNAL TERM
2021-05-19 02:46:09 INFO  DiskBlockManager:54 - Shutdown hook called
2021-05-19 02:46:09 INFO  ShutdownHookManager:54 - Shutdown hook called
2021-05-19 02:46:09 INFO  ShutdownHookManager:54 - Deleting directory /localhome/cdp/yarn/nm/usercache/catherine.ng60/appcache/application_1609183734776_5900/spark-1eafbf75-efa7-421a-8380-b49b7195bc9a
2021-05-19 02:46:09 ERROR TaskContextImpl:91 - Error in TaskCompletionListener
java.io.IOException: Filesystem closed
	at org.apache.hadoop.hdfs.DFSClient.checkOpen(DFSClient.java:808)
	at org.apache.hadoop.hdfs.DFSInputStream.close(DFSInputStream.java:710)
	at java.io.FilterInputStream.close(FilterInputStream.java:181)
	at org.apache.hadoop.util.LineReader.close(LineReader.java:150)
	at org.apache.hadoop.mapreduce.lib.input.LineRecordReader.close(LineRecordReader.java:231)
	at org.apache.spark.sql.execution.datasources.RecordReaderIterator.close(RecordReaderIterator.scala:62)
	at org.apache.spark.sql.execution.datasources.HadoopFileLinesReader.close(HadoopFileLinesReader.scala:73)
	at org.apache.spark.sql.execution.datasources.csv.TextInputCSVDataSource$$anonfun$4$$anonfun$apply$2.apply(CSVDataSource.scala:200)
	at org.apache.spark.sql.execution.datasources.csv.TextInputCSVDataSource$$anonfun$4$$anonfun$apply$2.apply(CSVDataSource.scala:200)
	at org.apache.spark.TaskContext$$anon$1.onTaskCompletion(TaskContext.scala:131)
	at org.apache.spark.TaskContextImpl$$anonfun$markTaskCompleted$1.apply(TaskContextImpl.scala:117)
	at org.apache.spark.TaskContextImpl$$anonfun$markTaskCompleted$1.apply(TaskContextImpl.scala:117)
	at org.apache.spark.TaskContextImpl$$anonfun$invokeListeners$1.apply(TaskContextImpl.scala:130)
	at org.apache.spark.TaskContextImpl$$anonfun$invokeListeners$1.apply(TaskContextImpl.scala:128)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.TaskContextImpl.invokeListeners(TaskContextImpl.scala:128)
	at org.apache.spark.TaskContextImpl.markTaskCompleted(TaskContextImpl.scala:116)
	at org.apache.spark.scheduler.Task.run(Task.scala:131)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:402)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:408)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2021-05-19 02:46:09 ERROR Executor:91 - Exception in task 60.1 in stage 7.0 (TID 376)
org.apache.spark.util.TaskCompletionListenerException: Filesystem closed

Previous exception in task: Filesystem closed
	org.apache.hadoop.hdfs.DFSClient.checkOpen(DFSClient.java:808)
	org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:868)
	org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:934)
	java.io.DataInputStream.read(DataInputStream.java:149)
	org.apache.hadoop.mapreduce.lib.input.UncompressedSplitLineReader.fillBuffer(UncompressedSplitLineReader.java:62)
	org.apache.hadoop.util.LineReader.readDefaultLine(LineReader.java:216)
	org.apache.hadoop.util.LineReader.readLine(LineReader.java:174)
	org.apache.hadoop.mapreduce.lib.input.UncompressedSplitLineReader.readLine(UncompressedSplitLineReader.java:94)
	org.apache.hadoop.mapreduce.lib.input.LineRecordReader.nextKeyValue(LineRecordReader.java:186)
	org.apache.spark.sql.execution.datasources.RecordReaderIterator.hasNext(RecordReaderIterator.scala:39)
	org.apache.spark.sql.execution.datasources.HadoopFileLinesReader.hasNext(HadoopFileLinesReader.scala:69)
	scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:462)
	scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:101)
	org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source)
	org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$11$$anon$1.hasNext(WholeStageCodegenExec.scala:619)
	scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	scala.collection.Iterator$GroupedIterator.takeDestructively(Iterator.scala:1073)
	scala.collection.Iterator$GroupedIterator.go(Iterator.scala:1089)
	scala.collection.Iterator$GroupedIterator.fill(Iterator.scala:1127)
	scala.collection.Iterator$GroupedIterator.hasNext(Iterator.scala:1130)
	scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	scala.collection.Iterator$class.foreach(Iterator.scala:891)
	scala.collection.AbstractIterator.foreach(Iterator.scala:1334)
	org.apache.spark.api.python.PythonRDD$.writeIteratorToStream(PythonRDD.scala:224)
	org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$2.writeIteratorToStream(PythonUDFRunner.scala:50)
	org.apache.spark.api.python.BasePythonRunner$WriterThread$$anonfun$run$1.apply(PythonRunner.scala:345)
	org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1945)
	org.apache.spark.api.python.BasePythonRunner$WriterThread.run(PythonRunner.scala:194)
	at org.apache.spark.TaskContextImpl.invokeListeners(TaskContextImpl.scala:138)
	at org.apache.spark.TaskContextImpl.markTaskCompleted(TaskContextImpl.scala:116)
	at org.apache.spark.scheduler.Task.run(Task.scala:131)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:402)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:408)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2021-05-19 02:46:09 INFO  Executor:54 - Not reporting error to driver during JVM shutdown.
2021-05-19 02:46:09 ERROR TaskContextImpl:91 - Error in TaskCompletionListener
java.io.IOException: Filesystem closed
	at org.apache.hadoop.hdfs.DFSClient.checkOpen(DFSClient.java:808)
	at org.apache.hadoop.hdfs.DFSInputStream.close(DFSInputStream.java:710)
	at java.io.FilterInputStream.close(FilterInputStream.java:181)
	at org.apache.hadoop.util.LineReader.close(LineReader.java:150)
	at org.apache.hadoop.mapreduce.lib.input.LineRecordReader.close(LineRecordReader.java:231)
	at org.apache.spark.sql.execution.datasources.RecordReaderIterator.close(RecordReaderIterator.scala:62)
	at org.apache.spark.sql.execution.datasources.HadoopFileLinesReader.close(HadoopFileLinesReader.scala:73)
	at org.apache.spark.sql.execution.datasources.csv.TextInputCSVDataSource$$anonfun$4$$anonfun$apply$2.apply(CSVDataSource.scala:200)
	at org.apache.spark.sql.execution.datasources.csv.TextInputCSVDataSource$$anonfun$4$$anonfun$apply$2.apply(CSVDataSource.scala:200)
	at org.apache.spark.TaskContext$$anon$1.onTaskCompletion(TaskContext.scala:131)
	at org.apache.spark.TaskContextImpl$$anonfun$markTaskCompleted$1.apply(TaskContextImpl.scala:117)
	at org.apache.spark.TaskContextImpl$$anonfun$markTaskCompleted$1.apply(TaskContextImpl.scala:117)
	at org.apache.spark.TaskContextImpl$$anonfun$invokeListeners$1.apply(TaskContextImpl.scala:130)
	at org.apache.spark.TaskContextImpl$$anonfun$invokeListeners$1.apply(TaskContextImpl.scala:128)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.TaskContextImpl.invokeListeners(TaskContextImpl.scala:128)
	at org.apache.spark.TaskContextImpl.markTaskCompleted(TaskContextImpl.scala:116)
	at org.apache.spark.scheduler.Task.run(Task.scala:131)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:402)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:408)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2021-05-19 02:46:09 ERROR Executor:91 - Exception in task 10.1 in stage 7.0 (TID 374)
org.apache.spark.util.TaskCompletionListenerException: Filesystem closed

Previous exception in task: Filesystem closed
	org.apache.hadoop.hdfs.DFSClient.checkOpen(DFSClient.java:808)
	org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:868)
	org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:934)
	java.io.DataInputStream.read(DataInputStream.java:149)
	org.apache.hadoop.mapreduce.lib.input.UncompressedSplitLineReader.fillBuffer(UncompressedSplitLineReader.java:62)
	org.apache.hadoop.util.LineReader.readDefaultLine(LineReader.java:216)
	org.apache.hadoop.util.LineReader.readLine(LineReader.java:174)
	org.apache.hadoop.mapreduce.lib.input.UncompressedSplitLineReader.readLine(UncompressedSplitLineReader.java:94)
	org.apache.hadoop.mapreduce.lib.input.LineRecordReader.nextKeyValue(LineRecordReader.java:186)
	org.apache.spark.sql.execution.datasources.RecordReaderIterator.hasNext(RecordReaderIterator.scala:39)
	org.apache.spark.sql.execution.datasources.HadoopFileLinesReader.hasNext(HadoopFileLinesReader.scala:69)
	scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:462)
	scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:101)
	org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source)
	org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$11$$anon$1.hasNext(WholeStageCodegenExec.scala:619)
	scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	scala.collection.Iterator$GroupedIterator.takeDestructively(Iterator.scala:1073)
	scala.collection.Iterator$GroupedIterator.go(Iterator.scala:1089)
	scala.collection.Iterator$GroupedIterator.fill(Iterator.scala:1127)
	scala.collection.Iterator$GroupedIterator.hasNext(Iterator.scala:1130)
	scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	scala.collection.Iterator$class.foreach(Iterator.scala:891)
	scala.collection.AbstractIterator.foreach(Iterator.scala:1334)
	org.apache.spark.api.python.PythonRDD$.writeIteratorToStream(PythonRDD.scala:224)
	org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$2.writeIteratorToStream(PythonUDFRunner.scala:50)
	org.apache.spark.api.python.BasePythonRunner$WriterThread$$anonfun$run$1.apply(PythonRunner.scala:345)
	org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1945)
	org.apache.spark.api.python.BasePythonRunner$WriterThread.run(PythonRunner.scala:194)
	at org.apache.spark.TaskContextImpl.invokeListeners(TaskContextImpl.scala:138)
	at org.apache.spark.TaskContextImpl.markTaskCompleted(TaskContextImpl.scala:116)
	at org.apache.spark.scheduler.Task.run(Task.scala:131)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:402)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:408)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2021-05-19 02:46:09 INFO  Executor:54 - Not reporting error to driver during JVM shutdown.

End of LogType:stdout
***********************************************************************

Container: container_e10_1609183734776_5900_01_000003 on hadoop10.cusp.nyu.edu_8041
LogAggregationType: AGGREGATED
===================================================================================
LogType:container-localizer-syslog
LogLastModifiedTime:Wed May 19 02:48:18 -0400 2021
LogLength:506
LogContents:
2021-05-19 02:45:27,070 INFO [main] org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ContainerLocalizer: Disk Validator: yarn.nodemanager.disk-validator is loaded.
2021-05-19 02:45:28,357 WARN [ContainerLocalizer Downloader] org.apache.hadoop.ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ipc.StandbyException): Operation category READ is not supported in state standby. Visit https://s.apache.org/sbnn-error

End of LogType:container-localizer-syslog
*******************************************************************************************


End of LogType:prelaunch.err
******************************************************************************

Container: container_e10_1609183734776_5900_01_000003 on hadoop10.cusp.nyu.edu_8041
LogAggregationType: AGGREGATED
===================================================================================
LogType:prelaunch.out
LogLastModifiedTime:Wed May 19 02:48:18 -0400 2021
LogLength:70
LogContents:
Setting up env variables
Setting up job resources
Launching container

End of LogType:prelaunch.out
******************************************************************************

Container: container_e10_1609183734776_5900_01_000003 on hadoop10.cusp.nyu.edu_8041
LogAggregationType: AGGREGATED
===================================================================================
LogType:stderr
LogLastModifiedTime:Wed May 19 02:48:18 -0400 2021
LogLength:529
LogContents:
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/localhome/cdp/yarn/nm/filecache/23/spark-jars-2.4.0-hadoop2.7.jar/slf4j-log4j12-1.7.16.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-6.1.0-1.cdh6.1.0.p0.770702/jars/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]

End of LogType:stderr
***********************************************************************

Container: container_e10_1609183734776_5900_01_000003 on hadoop10.cusp.nyu.edu_8041
LogAggregationType: AGGREGATED
===================================================================================
LogType:stdout
LogLastModifiedTime:Wed May 19 02:48:18 -0400 2021
LogLength:43896
LogContents:
2021-05-19 02:45:29 INFO  CoarseGrainedExecutorBackend:2566 - Started daemon with process name: 64228@hadoop10.cusp.nyu.edu
2021-05-19 02:45:29 INFO  SignalUtils:54 - Registered signal handler for TERM
2021-05-19 02:45:29 INFO  SignalUtils:54 - Registered signal handler for HUP
2021-05-19 02:45:29 INFO  SignalUtils:54 - Registered signal handler for INT
2021-05-19 02:45:30 INFO  SecurityManager:54 - Changing view acls to: catherine.ng60
2021-05-19 02:45:30 INFO  SecurityManager:54 - Changing modify acls to: catherine.ng60
2021-05-19 02:45:30 INFO  SecurityManager:54 - Changing view acls groups to: 
2021-05-19 02:45:30 INFO  SecurityManager:54 - Changing modify acls groups to: 
2021-05-19 02:45:30 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(catherine.ng60); groups with view permissions: Set(); users  with modify permissions: Set(catherine.ng60); groups with modify permissions: Set()
2021-05-19 02:45:31 INFO  TransportClientFactory:267 - Successfully created connection to hadoop05.cusp.nyu.edu/192.168.72.175:47481 after 97 ms (0 ms spent in bootstraps)
2021-05-19 02:45:31 INFO  SecurityManager:54 - Changing view acls to: catherine.ng60
2021-05-19 02:45:31 INFO  SecurityManager:54 - Changing modify acls to: catherine.ng60
2021-05-19 02:45:31 INFO  SecurityManager:54 - Changing view acls groups to: 
2021-05-19 02:45:31 INFO  SecurityManager:54 - Changing modify acls groups to: 
2021-05-19 02:45:31 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(catherine.ng60); groups with view permissions: Set(); users  with modify permissions: Set(catherine.ng60); groups with modify permissions: Set()
2021-05-19 02:45:31 INFO  TransportClientFactory:267 - Successfully created connection to hadoop05.cusp.nyu.edu/192.168.72.175:47481 after 4 ms (0 ms spent in bootstraps)
2021-05-19 02:45:32 INFO  DiskBlockManager:54 - Created local directory at /localhome/cdp/yarn/nm/usercache/catherine.ng60/appcache/application_1609183734776_5900/blockmgr-e25217f9-a45d-40e2-87e4-7b5b3dd56c0e
2021-05-19 02:45:32 INFO  MemoryStore:54 - MemoryStore started with capacity 366.3 MB
2021-05-19 02:45:32 INFO  CoarseGrainedExecutorBackend:54 - Connecting to driver: spark://CoarseGrainedScheduler@hadoop05.cusp.nyu.edu:47481
2021-05-19 02:45:32 INFO  CoarseGrainedExecutorBackend:54 - Successfully registered with driver
2021-05-19 02:45:32 INFO  Executor:54 - Starting executor ID 2 on host hadoop10.cusp.nyu.edu
2021-05-19 02:45:32 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 51710.
2021-05-19 02:45:32 INFO  NettyBlockTransferService:54 - Server created on hadoop10.cusp.nyu.edu:51710
2021-05-19 02:45:32 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2021-05-19 02:45:32 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(2, hadoop10.cusp.nyu.edu, 51710, None)
2021-05-19 02:45:32 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(2, hadoop10.cusp.nyu.edu, 51710, None)
2021-05-19 02:45:32 INFO  BlockManager:54 - external shuffle service port = 7337
2021-05-19 02:45:32 INFO  BlockManager:54 - Registering executor with local external shuffle service.
2021-05-19 02:45:32 INFO  TransportClientFactory:267 - Successfully created connection to hadoop10.cusp.nyu.edu/192.168.72.180:7337 after 3 ms (0 ms spent in bootstraps)
2021-05-19 02:45:32 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(2, hadoop10.cusp.nyu.edu, 51710, None)
2021-05-19 02:45:42 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 4
2021-05-19 02:45:42 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 9
2021-05-19 02:45:42 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 14
2021-05-19 02:45:42 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 19
2021-05-19 02:45:42 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 24
2021-05-19 02:45:42 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 29
2021-05-19 02:45:42 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 34
2021-05-19 02:45:42 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 39
2021-05-19 02:45:42 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 44
2021-05-19 02:45:42 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 49
2021-05-19 02:45:42 INFO  Executor:54 - Running task 38.0 in stage 1.0 (TID 39)
2021-05-19 02:45:42 INFO  Executor:54 - Running task 8.0 in stage 1.0 (TID 9)
2021-05-19 02:45:42 INFO  Executor:54 - Running task 28.0 in stage 1.0 (TID 29)
2021-05-19 02:45:42 INFO  Executor:54 - Running task 48.0 in stage 1.0 (TID 49)
2021-05-19 02:45:42 INFO  Executor:54 - Running task 3.0 in stage 1.0 (TID 4)
2021-05-19 02:45:42 INFO  Executor:54 - Running task 18.0 in stage 1.0 (TID 19)
2021-05-19 02:45:42 INFO  Executor:54 - Running task 33.0 in stage 1.0 (TID 34)
2021-05-19 02:45:42 INFO  Executor:54 - Running task 13.0 in stage 1.0 (TID 14)
2021-05-19 02:45:42 INFO  Executor:54 - Running task 43.0 in stage 1.0 (TID 44)
2021-05-19 02:45:42 INFO  Executor:54 - Running task 23.0 in stage 1.0 (TID 24)
2021-05-19 02:45:43 INFO  TorrentBroadcast:54 - Started reading broadcast variable 3
2021-05-19 02:45:43 INFO  TransportClientFactory:267 - Successfully created connection to hadoop05.cusp.nyu.edu/192.168.72.175:36982 after 3 ms (0 ms spent in bootstraps)
2021-05-19 02:45:43 INFO  MemoryStore:54 - Block broadcast_3_piece0 stored as bytes in memory (estimated size 35.0 KB, free 366.3 MB)
2021-05-19 02:45:43 INFO  TorrentBroadcast:54 - Reading broadcast variable 3 took 138 ms
2021-05-19 02:45:43 INFO  MemoryStore:54 - Block broadcast_3 stored as values in memory (estimated size 129.0 KB, free 366.1 MB)
2021-05-19 02:45:44 INFO  Executor:54 - Finished task 28.0 in stage 1.0 (TID 29). 1492 bytes result sent to driver
2021-05-19 02:45:44 INFO  Executor:54 - Finished task 43.0 in stage 1.0 (TID 44). 1492 bytes result sent to driver
2021-05-19 02:45:44 INFO  Executor:54 - Finished task 3.0 in stage 1.0 (TID 4). 1492 bytes result sent to driver
2021-05-19 02:45:44 INFO  Executor:54 - Finished task 23.0 in stage 1.0 (TID 24). 1492 bytes result sent to driver
2021-05-19 02:45:44 INFO  Executor:54 - Finished task 18.0 in stage 1.0 (TID 19). 1492 bytes result sent to driver
2021-05-19 02:45:44 INFO  Executor:54 - Finished task 13.0 in stage 1.0 (TID 14). 1492 bytes result sent to driver
2021-05-19 02:45:44 INFO  Executor:54 - Finished task 48.0 in stage 1.0 (TID 49). 1492 bytes result sent to driver
2021-05-19 02:45:44 INFO  Executor:54 - Finished task 38.0 in stage 1.0 (TID 39). 1492 bytes result sent to driver
2021-05-19 02:45:44 INFO  Executor:54 - Finished task 33.0 in stage 1.0 (TID 34). 1492 bytes result sent to driver
2021-05-19 02:45:44 INFO  Executor:54 - Finished task 8.0 in stage 1.0 (TID 9). 1492 bytes result sent to driver
2021-05-19 02:45:45 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 53
2021-05-19 02:45:45 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 58
2021-05-19 02:45:45 INFO  Executor:54 - Running task 2.0 in stage 2.0 (TID 53)
2021-05-19 02:45:45 INFO  Executor:54 - Running task 7.0 in stage 2.0 (TID 58)
2021-05-19 02:45:45 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 63
2021-05-19 02:45:45 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 68
2021-05-19 02:45:45 INFO  Executor:54 - Running task 12.0 in stage 2.0 (TID 63)
2021-05-19 02:45:45 INFO  Executor:54 - Running task 17.0 in stage 2.0 (TID 68)
2021-05-19 02:45:45 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 73
2021-05-19 02:45:45 INFO  Executor:54 - Running task 22.0 in stage 2.0 (TID 73)
2021-05-19 02:45:45 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 78
2021-05-19 02:45:45 INFO  Executor:54 - Running task 27.0 in stage 2.0 (TID 78)
2021-05-19 02:45:45 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 83
2021-05-19 02:45:45 INFO  Executor:54 - Running task 32.0 in stage 2.0 (TID 83)
2021-05-19 02:45:45 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 88
2021-05-19 02:45:45 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 93
2021-05-19 02:45:45 INFO  Executor:54 - Running task 37.0 in stage 2.0 (TID 88)
2021-05-19 02:45:45 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 98
2021-05-19 02:45:45 INFO  Executor:54 - Running task 42.0 in stage 2.0 (TID 93)
2021-05-19 02:45:45 INFO  Executor:54 - Running task 47.0 in stage 2.0 (TID 98)
2021-05-19 02:45:45 INFO  TorrentBroadcast:54 - Started reading broadcast variable 4
2021-05-19 02:45:45 INFO  MemoryStore:54 - Block broadcast_4_piece0 stored as bytes in memory (estimated size 35.0 KB, free 366.1 MB)
2021-05-19 02:45:45 INFO  TorrentBroadcast:54 - Reading broadcast variable 4 took 24 ms
2021-05-19 02:45:45 INFO  MemoryStore:54 - Block broadcast_4 stored as values in memory (estimated size 129.0 KB, free 366.0 MB)
2021-05-19 02:45:45 INFO  Executor:54 - Finished task 7.0 in stage 2.0 (TID 58). 1449 bytes result sent to driver
2021-05-19 02:45:45 INFO  Executor:54 - Finished task 17.0 in stage 2.0 (TID 68). 1449 bytes result sent to driver
2021-05-19 02:45:45 INFO  Executor:54 - Finished task 42.0 in stage 2.0 (TID 93). 1449 bytes result sent to driver
2021-05-19 02:45:45 INFO  Executor:54 - Finished task 2.0 in stage 2.0 (TID 53). 1449 bytes result sent to driver
2021-05-19 02:45:45 INFO  Executor:54 - Finished task 12.0 in stage 2.0 (TID 63). 1449 bytes result sent to driver
2021-05-19 02:45:45 INFO  Executor:54 - Finished task 32.0 in stage 2.0 (TID 83). 1449 bytes result sent to driver
2021-05-19 02:45:45 INFO  Executor:54 - Finished task 47.0 in stage 2.0 (TID 98). 1406 bytes result sent to driver
2021-05-19 02:45:45 INFO  Executor:54 - Finished task 22.0 in stage 2.0 (TID 73). 1406 bytes result sent to driver
2021-05-19 02:45:45 INFO  Executor:54 - Finished task 37.0 in stage 2.0 (TID 88). 1406 bytes result sent to driver
2021-05-19 02:45:45 INFO  Executor:54 - Finished task 27.0 in stage 2.0 (TID 78). 1449 bytes result sent to driver
2021-05-19 02:45:51 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 120
2021-05-19 02:45:51 INFO  Executor:54 - Running task 2.0 in stage 5.0 (TID 120)
2021-05-19 02:45:51 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 125
2021-05-19 02:45:51 INFO  Executor:54 - Running task 8.0 in stage 5.0 (TID 125)
2021-05-19 02:45:51 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 129
2021-05-19 02:45:51 INFO  MapOutputTrackerWorker:54 - Updating epoch to 1 and clearing cache
2021-05-19 02:45:51 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 133
2021-05-19 02:45:51 INFO  Executor:54 - Running task 12.0 in stage 5.0 (TID 129)
2021-05-19 02:45:51 INFO  TorrentBroadcast:54 - Started reading broadcast variable 10
2021-05-19 02:45:51 INFO  Executor:54 - Running task 16.0 in stage 5.0 (TID 133)
2021-05-19 02:45:51 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 137
2021-05-19 02:45:51 INFO  Executor:54 - Running task 21.0 in stage 5.0 (TID 137)
2021-05-19 02:45:51 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 141
2021-05-19 02:45:51 INFO  Executor:54 - Running task 25.0 in stage 5.0 (TID 141)
2021-05-19 02:45:51 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 145
2021-05-19 02:45:51 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 149
2021-05-19 02:45:51 INFO  Executor:54 - Running task 30.0 in stage 5.0 (TID 145)
2021-05-19 02:45:51 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 153
2021-05-19 02:45:51 INFO  Executor:54 - Running task 34.0 in stage 5.0 (TID 149)
2021-05-19 02:45:51 INFO  Executor:54 - Running task 39.0 in stage 5.0 (TID 153)
2021-05-19 02:45:51 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 157
2021-05-19 02:45:51 INFO  Executor:54 - Running task 43.0 in stage 5.0 (TID 157)
2021-05-19 02:45:51 INFO  MemoryStore:54 - Block broadcast_10_piece0 stored as bytes in memory (estimated size 20.4 KB, free 366.3 MB)
2021-05-19 02:45:51 INFO  TorrentBroadcast:54 - Reading broadcast variable 10 took 30 ms
2021-05-19 02:45:51 INFO  MemoryStore:54 - Block broadcast_10 stored as values in memory (estimated size 40.9 KB, free 366.2 MB)
2021-05-19 02:45:52 INFO  MapOutputTrackerWorker:54 - Don't have map outputs for shuffle 0, fetching them
2021-05-19 02:45:52 INFO  MapOutputTrackerWorker:54 - Don't have map outputs for shuffle 0, fetching them
2021-05-19 02:45:52 INFO  MapOutputTrackerWorker:54 - Don't have map outputs for shuffle 0, fetching them
2021-05-19 02:45:52 INFO  MapOutputTrackerWorker:54 - Don't have map outputs for shuffle 0, fetching them
2021-05-19 02:45:52 INFO  MapOutputTrackerWorker:54 - Don't have map outputs for shuffle 0, fetching them
2021-05-19 02:45:52 INFO  MapOutputTrackerWorker:54 - Don't have map outputs for shuffle 0, fetching them
2021-05-19 02:45:52 INFO  MapOutputTrackerWorker:54 - Don't have map outputs for shuffle 0, fetching them
2021-05-19 02:45:52 INFO  MapOutputTrackerWorker:54 - Don't have map outputs for shuffle 0, fetching them
2021-05-19 02:45:52 INFO  MapOutputTrackerWorker:54 - Don't have map outputs for shuffle 0, fetching them
2021-05-19 02:45:52 INFO  MapOutputTrackerWorker:54 - Don't have map outputs for shuffle 0, fetching them
2021-05-19 02:45:52 INFO  MapOutputTrackerWorker:54 - Doing the fetch; tracker endpoint = NettyRpcEndpointRef(spark://MapOutputTracker@hadoop05.cusp.nyu.edu:47481)
2021-05-19 02:45:52 INFO  MapOutputTrackerWorker:54 - Got the output locations
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 10 ms
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 11 ms
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 11 ms
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 11 ms
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 11 ms
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 15 ms
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 16 ms
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 16 ms
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 12 ms
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 16 ms
2021-05-19 02:45:52 INFO  CodeGenerator:54 - Code generated in 448.604538 ms
2021-05-19 02:45:53 INFO  CodeGenerator:54 - Code generated in 32.494187 ms
2021-05-19 02:45:53 INFO  CodeGenerator:54 - Code generated in 27.208702 ms
2021-05-19 02:45:53 INFO  CodeGenerator:54 - Code generated in 36.862877 ms
2021-05-19 02:45:53 INFO  Executor:54 - Finished task 39.0 in stage 5.0 (TID 153). 3776 bytes result sent to driver
2021-05-19 02:45:53 INFO  Executor:54 - Finished task 34.0 in stage 5.0 (TID 149). 3776 bytes result sent to driver
2021-05-19 02:45:53 INFO  Executor:54 - Finished task 8.0 in stage 5.0 (TID 125). 3776 bytes result sent to driver
2021-05-19 02:45:53 INFO  Executor:54 - Finished task 25.0 in stage 5.0 (TID 141). 3776 bytes result sent to driver
2021-05-19 02:45:53 INFO  Executor:54 - Finished task 30.0 in stage 5.0 (TID 145). 3776 bytes result sent to driver
2021-05-19 02:45:53 INFO  Executor:54 - Finished task 21.0 in stage 5.0 (TID 137). 3776 bytes result sent to driver
2021-05-19 02:45:53 INFO  Executor:54 - Finished task 43.0 in stage 5.0 (TID 157). 3819 bytes result sent to driver
2021-05-19 02:45:53 INFO  Executor:54 - Finished task 2.0 in stage 5.0 (TID 120). 3819 bytes result sent to driver
2021-05-19 02:45:53 INFO  Executor:54 - Finished task 12.0 in stage 5.0 (TID 129). 3776 bytes result sent to driver
2021-05-19 02:45:53 INFO  Executor:54 - Finished task 16.0 in stage 5.0 (TID 133). 3776 bytes result sent to driver
2021-05-19 02:45:56 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 321
2021-05-19 02:45:56 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 326
2021-05-19 02:45:56 INFO  Executor:54 - Running task 1.0 in stage 7.0 (TID 321)
2021-05-19 02:45:56 INFO  Executor:54 - Running task 3.0 in stage 7.0 (TID 326)
2021-05-19 02:45:56 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 331
2021-05-19 02:45:56 INFO  Executor:54 - Running task 4.0 in stage 7.0 (TID 331)
2021-05-19 02:45:56 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 336
2021-05-19 02:45:56 INFO  Executor:54 - Running task 9.0 in stage 7.0 (TID 336)
2021-05-19 02:45:56 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 341
2021-05-19 02:45:56 INFO  Executor:54 - Running task 14.0 in stage 7.0 (TID 341)
2021-05-19 02:45:56 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 346
2021-05-19 02:45:56 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 351
2021-05-19 02:45:56 INFO  Executor:54 - Running task 20.0 in stage 7.0 (TID 346)
2021-05-19 02:45:56 INFO  Executor:54 - Running task 29.0 in stage 7.0 (TID 351)
2021-05-19 02:45:56 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 356
2021-05-19 02:45:56 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 361
2021-05-19 02:45:56 INFO  Executor:54 - Running task 40.0 in stage 7.0 (TID 356)
2021-05-19 02:45:56 INFO  Executor:54 - Running task 54.0 in stage 7.0 (TID 361)
2021-05-19 02:45:56 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 365
2021-05-19 02:45:56 INFO  Executor:54 - Running task 55.0 in stage 7.0 (TID 365)
2021-05-19 02:45:56 INFO  TorrentBroadcast:54 - Started reading broadcast variable 14
2021-05-19 02:45:56 INFO  MemoryStore:54 - Block broadcast_14_piece0 stored as bytes in memory (estimated size 22.9 KB, free 366.3 MB)
2021-05-19 02:45:56 INFO  TorrentBroadcast:54 - Reading broadcast variable 14 took 22 ms
2021-05-19 02:45:56 INFO  MemoryStore:54 - Block broadcast_14 stored as values in memory (estimated size 51.5 KB, free 366.2 MB)
2021-05-19 02:45:56 INFO  CodeGenerator:54 - Code generated in 57.784636 ms
2021-05-19 02:45:56 INFO  TorrentBroadcast:54 - Started reading broadcast variable 12
2021-05-19 02:45:56 INFO  TransportClientFactory:267 - Successfully created connection to hadoop08.cusp.nyu.edu/192.168.72.178:54817 after 5 ms (0 ms spent in bootstraps)
2021-05-19 02:45:56 INFO  MemoryStore:54 - Block broadcast_12_piece0 stored as bytes in memory (estimated size 580.1 KB, free 365.7 MB)
2021-05-19 02:45:56 INFO  TorrentBroadcast:54 - Reading broadcast variable 12 took 59 ms
2021-05-19 02:45:56 INFO  MemoryStore:54 - Block broadcast_12 stored as values in memory (estimated size 5.0 MB, free 360.7 MB)
2021-05-19 02:45:56 INFO  CodeGenerator:54 - Code generated in 20.883456 ms
2021-05-19 02:45:57 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00040, range: 134217728-177901153, partition values: [empty row]
2021-05-19 02:45:57 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00040, range: 0-134217728, partition values: [empty row]
2021-05-19 02:45:57 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00004, range: 0-134217728, partition values: [empty row]
2021-05-19 02:45:57 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00009, range: 0-134217728, partition values: [empty row]
2021-05-19 02:45:57 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00014, range: 0-134217728, partition values: [empty row]
2021-05-19 02:45:57 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00003, range: 0-134217728, partition values: [empty row]
2021-05-19 02:45:57 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00032, range: 134217728-177884607, partition values: [empty row]
2021-05-19 02:45:57 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00029, range: 0-134217728, partition values: [empty row]
2021-05-19 02:45:57 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00020, range: 0-134217728, partition values: [empty row]
2021-05-19 02:45:57 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00001, range: 0-134217728, partition values: [empty row]
2021-05-19 02:45:57 INFO  CodeGenerator:54 - Code generated in 50.513878 ms
2021-05-19 02:45:57 INFO  TorrentBroadcast:54 - Started reading broadcast variable 13
2021-05-19 02:45:57 INFO  CodeGenerator:54 - Code generated in 71.291339 ms
2021-05-19 02:45:57 INFO  MemoryStore:54 - Block broadcast_13_piece0 stored as bytes in memory (estimated size 33.4 KB, free 360.6 MB)
2021-05-19 02:45:57 INFO  TorrentBroadcast:54 - Reading broadcast variable 13 took 22 ms
2021-05-19 02:45:57 INFO  CodeGenerator:54 - Code generated in 40.305579 ms
2021-05-19 02:45:57 INFO  MemoryStore:54 - Block broadcast_13 stored as values in memory (estimated size 506.4 KB, free 360.1 MB)
2021-05-19 02:45:57 INFO  CodeGenerator:54 - Code generated in 42.307378 ms
2021-05-19 02:45:57 INFO  CodeGenerator:54 - Code generated in 21.520377 ms
2021-05-19 02:45:57 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: 223-222@627-s6d-9vf, 2018-12-31T00:00:00-05:00, [57,70,74,72,80,86,66]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: 223-222@627-s6d-9vf
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00004
2021-05-19 02:45:57 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: zzy-222@627-s93-26k, 2019-12-02T00:00:00-05:00, [4,6,9,13,8,11,4]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: zzy-222@627-s93-26k
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00029
2021-05-19 02:45:57 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: 22t-224@627-s8k-2zf, 2019-09-09T00:00:00-04:00, [9,7,9,3,7,4,5]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: 22t-224@627-s8k-2zf
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00020
2021-05-19 02:45:57 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: 222-222@627-wgb-qxq, 2019-01-07T00:00:00-05:00, [408,482,574,546,236,93,103]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: 222-222@627-wgb-qxq
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00014
2021-05-19 02:45:57 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: 226-225@627-wc8-73q, 2018-12-31T00:00:00-05:00, [1,6,18,10,12,12,18]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: 226-225@627-wc8-73q
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00009
2021-05-19 02:45:57 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: 22z-222@627-rw8-28v, 2018-12-31T00:00:00-05:00, [5,22,30,30,30,14,16]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: 22z-222@627-rw8-28v
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00003
2021-05-19 02:45:57 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: 22k-223@627-s8w-b49, 2018-12-31T00:00:00-05:00, [9,0,10,6,6,8,4]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: 22k-223@627-s8w-b49
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00001
2021-05-19 02:45:57 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: zzw-222@627-s4s-nqz, 2019-04-22T00:00:00-04:00, [6,10,4,9,4,6,2]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: zzw-222@627-s4s-nqz
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00040
2021-05-19 02:45:58 INFO  CodeGenerator:54 - Code generated in 14.414628 ms
2021-05-19 02:45:58 INFO  CodeGenerator:54 - Code generated in 25.632803 ms
2021-05-19 02:45:58 INFO  CodeGenerator:54 - Code generated in 59.302285 ms
2021-05-19 02:45:59 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:45:59 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:45:59 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:45:59 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:45:59 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:45:59 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:45:59 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:45:59 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:45:59 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:45:59 INFO  CodeGenerator:54 - Code generated in 36.546109 ms
2021-05-19 02:45:59 INFO  CodeGenerator:54 - Code generated in 32.347379 ms
2021-05-19 02:45:59 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:45:59 INFO  CodeGenerator:54 - Code generated in 19.100115 ms
2021-05-19 02:45:59 INFO  CodeGenerator:54 - Code generated in 45.599453 ms
2021-05-19 02:45:59 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00023, range: 134217728-177753533, partition values: [empty row]
2021-05-19 02:45:59 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00015, range: 134217728-177898804, partition values: [empty row]
2021-05-19 02:46:07 INFO  PythonUDFRunner:54 - Times: total = 10791, boot = 682, init = 1126, finish = 8983
2021-05-19 02:46:07 INFO  CodeGenerator:54 - Code generated in 20.39577 ms
2021-05-19 02:46:07 INFO  PythonUDFRunner:54 - Times: total = 11267, boot = 749, init = 1060, finish = 9458
2021-05-19 02:46:07 INFO  Executor:54 - Finished task 54.0 in stage 7.0 (TID 361). 4270 bytes result sent to driver
2021-05-19 02:46:07 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 371
2021-05-19 02:46:07 INFO  Executor:54 - Running task 46.1 in stage 7.0 (TID 371)
2021-05-19 02:46:07 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00046, range: 0-134217728, partition values: [empty row]
2021-05-19 02:46:08 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: 22h-223@627-s96-73q, 2019-10-07T00:00:00-04:00, [5,3,1,1,5,1,3]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: 22h-223@627-s96-73q
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00046
2021-05-19 02:46:08 INFO  Executor:54 - Finished task 55.0 in stage 7.0 (TID 365). 4313 bytes result sent to driver
2021-05-19 02:46:08 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 373
2021-05-19 02:46:08 INFO  Executor:54 - Running task 64.0 in stage 7.0 (TID 373)
2021-05-19 02:46:08 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00020, range: 134217728-175942625, partition values: [empty row]
2021-05-19 02:46:08 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:46:09 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:46:09 ERROR CoarseGrainedExecutorBackend:43 - RECEIVED SIGNAL TERM
2021-05-19 02:46:09 INFO  DiskBlockManager:54 - Shutdown hook called
2021-05-19 02:46:09 INFO  ShutdownHookManager:54 - Shutdown hook called
2021-05-19 02:46:09 INFO  ShutdownHookManager:54 - Deleting directory /localhome/cdp/yarn/nm/usercache/catherine.ng60/appcache/application_1609183734776_5900/spark-fabf467b-c68a-4910-b81f-bc41841e8a8b
2021-05-19 02:46:09 ERROR TaskContextImpl:91 - Error in TaskCompletionListener
java.io.IOException: Filesystem closed
	at org.apache.hadoop.hdfs.DFSClient.checkOpen(DFSClient.java:808)
	at org.apache.hadoop.hdfs.DFSInputStream.close(DFSInputStream.java:710)
	at java.io.FilterInputStream.close(FilterInputStream.java:181)
	at org.apache.hadoop.util.LineReader.close(LineReader.java:150)
	at org.apache.hadoop.mapreduce.lib.input.LineRecordReader.close(LineRecordReader.java:231)
	at org.apache.spark.sql.execution.datasources.RecordReaderIterator.close(RecordReaderIterator.scala:62)
	at org.apache.spark.sql.execution.datasources.HadoopFileLinesReader.close(HadoopFileLinesReader.scala:73)
	at org.apache.spark.sql.execution.datasources.csv.TextInputCSVDataSource$$anonfun$4$$anonfun$apply$2.apply(CSVDataSource.scala:200)
	at org.apache.spark.sql.execution.datasources.csv.TextInputCSVDataSource$$anonfun$4$$anonfun$apply$2.apply(CSVDataSource.scala:200)
	at org.apache.spark.TaskContext$$anon$1.onTaskCompletion(TaskContext.scala:131)
	at org.apache.spark.TaskContextImpl$$anonfun$markTaskCompleted$1.apply(TaskContextImpl.scala:117)
	at org.apache.spark.TaskContextImpl$$anonfun$markTaskCompleted$1.apply(TaskContextImpl.scala:117)
	at org.apache.spark.TaskContextImpl$$anonfun$invokeListeners$1.apply(TaskContextImpl.scala:130)
	at org.apache.spark.TaskContextImpl$$anonfun$invokeListeners$1.apply(TaskContextImpl.scala:128)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.TaskContextImpl.invokeListeners(TaskContextImpl.scala:128)
	at org.apache.spark.TaskContextImpl.markTaskCompleted(TaskContextImpl.scala:116)
	at org.apache.spark.scheduler.Task.run(Task.scala:131)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:402)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:408)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2021-05-19 02:46:09 ERROR TaskContextImpl:91 - Error in TaskCompletionListener
java.io.IOException: Filesystem closed
	at org.apache.hadoop.hdfs.DFSClient.checkOpen(DFSClient.java:808)
	at org.apache.hadoop.hdfs.DFSInputStream.close(DFSInputStream.java:710)
	at java.io.FilterInputStream.close(FilterInputStream.java:181)
	at org.apache.hadoop.util.LineReader.close(LineReader.java:150)
	at org.apache.hadoop.mapreduce.lib.input.LineRecordReader.close(LineRecordReader.java:231)
	at org.apache.spark.sql.execution.datasources.RecordReaderIterator.close(RecordReaderIterator.scala:62)
	at org.apache.spark.sql.execution.datasources.HadoopFileLinesReader.close(HadoopFileLinesReader.scala:73)
	at org.apache.spark.sql.execution.datasources.csv.TextInputCSVDataSource$$anonfun$4$$anonfun$apply$2.apply(CSVDataSource.scala:200)
	at org.apache.spark.sql.execution.datasources.csv.TextInputCSVDataSource$$anonfun$4$$anonfun$apply$2.apply(CSVDataSource.scala:200)
	at org.apache.spark.TaskContext$$anon$1.onTaskCompletion(TaskContext.scala:131)
	at org.apache.spark.TaskContextImpl$$anonfun$markTaskCompleted$1.apply(TaskContextImpl.scala:117)
	at org.apache.spark.TaskContextImpl$$anonfun$markTaskCompleted$1.apply(TaskContextImpl.scala:117)
	at org.apache.spark.TaskContextImpl$$anonfun$invokeListeners$1.apply(TaskContextImpl.scala:130)
	at org.apache.spark.TaskContextImpl$$anonfun$invokeListeners$1.apply(TaskContextImpl.scala:128)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.TaskContextImpl.invokeListeners(TaskContextImpl.scala:128)
	at org.apache.spark.TaskContextImpl.markTaskCompleted(TaskContextImpl.scala:116)
	at org.apache.spark.scheduler.Task.run(Task.scala:131)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:402)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:408)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2021-05-19 02:46:09 ERROR Executor:91 - Exception in task 64.0 in stage 7.0 (TID 373)
org.apache.spark.util.TaskCompletionListenerException: Filesystem closed

Previous exception in task: Filesystem closed
	org.apache.hadoop.hdfs.DFSClient.checkOpen(DFSClient.java:808)
	org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:868)
	org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:934)
	java.io.DataInputStream.read(DataInputStream.java:149)
	org.apache.hadoop.mapreduce.lib.input.UncompressedSplitLineReader.fillBuffer(UncompressedSplitLineReader.java:62)
	org.apache.hadoop.util.LineReader.readDefaultLine(LineReader.java:216)
	org.apache.hadoop.util.LineReader.readLine(LineReader.java:174)
	org.apache.hadoop.mapreduce.lib.input.UncompressedSplitLineReader.readLine(UncompressedSplitLineReader.java:94)
	org.apache.hadoop.mapreduce.lib.input.LineRecordReader.nextKeyValue(LineRecordReader.java:186)
	org.apache.spark.sql.execution.datasources.RecordReaderIterator.hasNext(RecordReaderIterator.scala:39)
	org.apache.spark.sql.execution.datasources.HadoopFileLinesReader.hasNext(HadoopFileLinesReader.scala:69)
	scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:462)
	scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:101)
	org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source)
	org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$11$$anon$1.hasNext(WholeStageCodegenExec.scala:619)
	scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	scala.collection.Iterator$GroupedIterator.takeDestructively(Iterator.scala:1073)
	scala.collection.Iterator$GroupedIterator.go(Iterator.scala:1089)
	scala.collection.Iterator$GroupedIterator.fill(Iterator.scala:1127)
	scala.collection.Iterator$GroupedIterator.hasNext(Iterator.scala:1130)
	scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	scala.collection.Iterator$class.foreach(Iterator.scala:891)
	scala.collection.AbstractIterator.foreach(Iterator.scala:1334)
	org.apache.spark.api.python.PythonRDD$.writeIteratorToStream(PythonRDD.scala:224)
	org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$2.writeIteratorToStream(PythonUDFRunner.scala:50)
	org.apache.spark.api.python.BasePythonRunner$WriterThread$$anonfun$run$1.apply(PythonRunner.scala:345)
	org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1945)
	org.apache.spark.api.python.BasePythonRunner$WriterThread.run(PythonRunner.scala:194)
	at org.apache.spark.TaskContextImpl.invokeListeners(TaskContextImpl.scala:138)
	at org.apache.spark.TaskContextImpl.markTaskCompleted(TaskContextImpl.scala:116)
	at org.apache.spark.scheduler.Task.run(Task.scala:131)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:402)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:408)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2021-05-19 02:46:09 ERROR Executor:91 - Exception in task 46.1 in stage 7.0 (TID 371)
org.apache.spark.util.TaskCompletionListenerException: Filesystem closed

Previous exception in task: Filesystem closed
	org.apache.hadoop.hdfs.DFSClient.checkOpen(DFSClient.java:808)
	org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:868)
	org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:934)
	java.io.DataInputStream.read(DataInputStream.java:149)
	org.apache.hadoop.mapreduce.lib.input.UncompressedSplitLineReader.fillBuffer(UncompressedSplitLineReader.java:62)
	org.apache.hadoop.util.LineReader.readDefaultLine(LineReader.java:216)
	org.apache.hadoop.util.LineReader.readLine(LineReader.java:174)
	org.apache.hadoop.mapreduce.lib.input.UncompressedSplitLineReader.readLine(UncompressedSplitLineReader.java:94)
	org.apache.hadoop.mapreduce.lib.input.LineRecordReader.nextKeyValue(LineRecordReader.java:186)
	org.apache.spark.sql.execution.datasources.RecordReaderIterator.hasNext(RecordReaderIterator.scala:39)
	org.apache.spark.sql.execution.datasources.HadoopFileLinesReader.hasNext(HadoopFileLinesReader.scala:69)
	scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:462)
	scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:101)
	org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source)
	org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$11$$anon$1.hasNext(WholeStageCodegenExec.scala:619)
	scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	scala.collection.Iterator$GroupedIterator.takeDestructively(Iterator.scala:1073)
	scala.collection.Iterator$GroupedIterator.go(Iterator.scala:1089)
	scala.collection.Iterator$GroupedIterator.fill(Iterator.scala:1127)
	scala.collection.Iterator$GroupedIterator.hasNext(Iterator.scala:1130)
	scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	scala.collection.Iterator$class.foreach(Iterator.scala:891)
	scala.collection.AbstractIterator.foreach(Iterator.scala:1334)
	org.apache.spark.api.python.PythonRDD$.writeIteratorToStream(PythonRDD.scala:224)
	org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$2.writeIteratorToStream(PythonUDFRunner.scala:50)
	org.apache.spark.api.python.BasePythonRunner$WriterThread$$anonfun$run$1.apply(PythonRunner.scala:345)
	org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1945)
	org.apache.spark.api.python.BasePythonRunner$WriterThread.run(PythonRunner.scala:194)
	at org.apache.spark.TaskContextImpl.invokeListeners(TaskContextImpl.scala:138)
	at org.apache.spark.TaskContextImpl.markTaskCompleted(TaskContextImpl.scala:116)
	at org.apache.spark.scheduler.Task.run(Task.scala:131)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:402)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:408)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2021-05-19 02:46:09 INFO  Executor:54 - Not reporting error to driver during JVM shutdown.
2021-05-19 02:46:09 INFO  Executor:54 - Not reporting error to driver during JVM shutdown.

End of LogType:stdout
***********************************************************************


End of LogType:prelaunch.err
******************************************************************************

Container: container_e10_1609183734776_5900_01_000017 on hadoop13.cusp.nyu.edu_8041
LogAggregationType: AGGREGATED
===================================================================================
LogType:prelaunch.out
LogLastModifiedTime:Wed May 19 02:48:18 -0400 2021
LogLength:70
LogContents:
Setting up env variables
Setting up job resources
Launching container

End of LogType:prelaunch.out
******************************************************************************

Container: container_e10_1609183734776_5900_01_000017 on hadoop13.cusp.nyu.edu_8041
LogAggregationType: AGGREGATED
===================================================================================
LogType:stderr
LogLastModifiedTime:Wed May 19 02:48:18 -0400 2021
LogLength:529
LogContents:
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/localhome/cdp/yarn/nm/filecache/23/spark-jars-2.4.0-hadoop2.7.jar/slf4j-log4j12-1.7.16.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-6.1.0-1.cdh6.1.0.p0.770702/jars/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]

End of LogType:stderr
***********************************************************************

Container: container_e10_1609183734776_5900_01_000017 on hadoop13.cusp.nyu.edu_8041
LogAggregationType: AGGREGATED
===================================================================================
LogType:stdout
LogLastModifiedTime:Wed May 19 02:48:18 -0400 2021
LogLength:1053
LogContents:
2021-05-19 02:46:39 INFO  CoarseGrainedExecutorBackend:2566 - Started daemon with process name: 14750@hadoop13.cusp.nyu.edu
2021-05-19 02:46:39 INFO  SignalUtils:54 - Registered signal handler for TERM
2021-05-19 02:46:40 INFO  SignalUtils:54 - Registered signal handler for HUP
2021-05-19 02:46:40 INFO  SignalUtils:54 - Registered signal handler for INT
2021-05-19 02:46:40 INFO  SecurityManager:54 - Changing view acls to: catherine.ng60
2021-05-19 02:46:40 INFO  SecurityManager:54 - Changing modify acls to: catherine.ng60
2021-05-19 02:46:40 INFO  SecurityManager:54 - Changing view acls groups to: 
2021-05-19 02:46:40 INFO  SecurityManager:54 - Changing modify acls groups to: 
2021-05-19 02:46:40 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(catherine.ng60); groups with view permissions: Set(); users  with modify permissions: Set(catherine.ng60); groups with modify permissions: Set()
2021-05-19 02:46:41 ERROR CoarseGrainedExecutorBackend:43 - RECEIVED SIGNAL TERM

End of LogType:stdout
***********************************************************************


End of LogType:prelaunch.err
******************************************************************************

Container: container_e10_1609183734776_5900_02_000002 on hadoop13.cusp.nyu.edu_8041
LogAggregationType: AGGREGATED
===================================================================================
LogType:prelaunch.out
LogLastModifiedTime:Wed May 19 02:48:18 -0400 2021
LogLength:70
LogContents:
Setting up env variables
Setting up job resources
Launching container

End of LogType:prelaunch.out
******************************************************************************

Container: container_e10_1609183734776_5900_02_000002 on hadoop13.cusp.nyu.edu_8041
LogAggregationType: AGGREGATED
===================================================================================
LogType:stderr
LogLastModifiedTime:Wed May 19 02:48:18 -0400 2021
LogLength:529
LogContents:
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/localhome/cdp/yarn/nm/filecache/23/spark-jars-2.4.0-hadoop2.7.jar/slf4j-log4j12-1.7.16.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-6.1.0-1.cdh6.1.0.p0.770702/jars/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]

End of LogType:stderr
***********************************************************************

Container: container_e10_1609183734776_5900_02_000002 on hadoop13.cusp.nyu.edu_8041
LogAggregationType: AGGREGATED
===================================================================================
LogType:stdout
LogLastModifiedTime:Wed May 19 02:48:18 -0400 2021
LogLength:52873
LogContents:
2021-05-19 02:46:52 INFO  CoarseGrainedExecutorBackend:2566 - Started daemon with process name: 14975@hadoop13.cusp.nyu.edu
2021-05-19 02:46:52 INFO  SignalUtils:54 - Registered signal handler for TERM
2021-05-19 02:46:52 INFO  SignalUtils:54 - Registered signal handler for HUP
2021-05-19 02:46:52 INFO  SignalUtils:54 - Registered signal handler for INT
2021-05-19 02:46:53 INFO  SecurityManager:54 - Changing view acls to: catherine.ng60
2021-05-19 02:46:53 INFO  SecurityManager:54 - Changing modify acls to: catherine.ng60
2021-05-19 02:46:53 INFO  SecurityManager:54 - Changing view acls groups to: 
2021-05-19 02:46:53 INFO  SecurityManager:54 - Changing modify acls groups to: 
2021-05-19 02:46:53 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(catherine.ng60); groups with view permissions: Set(); users  with modify permissions: Set(catherine.ng60); groups with modify permissions: Set()
2021-05-19 02:46:54 INFO  TransportClientFactory:267 - Successfully created connection to hadoop02.cusp.nyu.edu/192.168.72.172:60108 after 117 ms (0 ms spent in bootstraps)
2021-05-19 02:46:54 INFO  SecurityManager:54 - Changing view acls to: catherine.ng60
2021-05-19 02:46:54 INFO  SecurityManager:54 - Changing modify acls to: catherine.ng60
2021-05-19 02:46:54 INFO  SecurityManager:54 - Changing view acls groups to: 
2021-05-19 02:46:54 INFO  SecurityManager:54 - Changing modify acls groups to: 
2021-05-19 02:46:54 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(catherine.ng60); groups with view permissions: Set(); users  with modify permissions: Set(catherine.ng60); groups with modify permissions: Set()
2021-05-19 02:46:54 INFO  TransportClientFactory:267 - Successfully created connection to hadoop02.cusp.nyu.edu/192.168.72.172:60108 after 4 ms (0 ms spent in bootstraps)
2021-05-19 02:46:55 INFO  DiskBlockManager:54 - Created local directory at /localhome/cdp/yarn/nm/usercache/catherine.ng60/appcache/application_1609183734776_5900/blockmgr-225283d5-83fc-4b22-bf2a-249f96fbb811
2021-05-19 02:46:55 INFO  MemoryStore:54 - MemoryStore started with capacity 366.3 MB
2021-05-19 02:46:55 INFO  CoarseGrainedExecutorBackend:54 - Connecting to driver: spark://CoarseGrainedScheduler@hadoop02.cusp.nyu.edu:60108
2021-05-19 02:46:55 INFO  CoarseGrainedExecutorBackend:54 - Successfully registered with driver
2021-05-19 02:46:55 INFO  Executor:54 - Starting executor ID 1 on host hadoop13.cusp.nyu.edu
2021-05-19 02:46:55 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 32809.
2021-05-19 02:46:55 INFO  NettyBlockTransferService:54 - Server created on hadoop13.cusp.nyu.edu:32809
2021-05-19 02:46:55 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2021-05-19 02:46:55 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(1, hadoop13.cusp.nyu.edu, 32809, None)
2021-05-19 02:46:55 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(1, hadoop13.cusp.nyu.edu, 32809, None)
2021-05-19 02:46:55 INFO  BlockManager:54 - external shuffle service port = 7337
2021-05-19 02:46:55 INFO  BlockManager:54 - Registering executor with local external shuffle service.
2021-05-19 02:46:55 INFO  TransportClientFactory:267 - Successfully created connection to hadoop13.cusp.nyu.edu/192.168.72.183:7337 after 2 ms (0 ms spent in bootstraps)
2021-05-19 02:46:55 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(1, hadoop13.cusp.nyu.edu, 32809, None)
2021-05-19 02:47:04 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 4
2021-05-19 02:47:04 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 9
2021-05-19 02:47:04 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 14
2021-05-19 02:47:04 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 19
2021-05-19 02:47:04 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 24
2021-05-19 02:47:04 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 29
2021-05-19 02:47:04 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 34
2021-05-19 02:47:04 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 39
2021-05-19 02:47:04 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 44
2021-05-19 02:47:04 INFO  Executor:54 - Running task 38.0 in stage 1.0 (TID 39)
2021-05-19 02:47:04 INFO  Executor:54 - Running task 28.0 in stage 1.0 (TID 29)
2021-05-19 02:47:04 INFO  Executor:54 - Running task 33.0 in stage 1.0 (TID 34)
2021-05-19 02:47:04 INFO  Executor:54 - Running task 13.0 in stage 1.0 (TID 14)
2021-05-19 02:47:04 INFO  Executor:54 - Running task 8.0 in stage 1.0 (TID 9)
2021-05-19 02:47:04 INFO  Executor:54 - Running task 23.0 in stage 1.0 (TID 24)
2021-05-19 02:47:04 INFO  Executor:54 - Running task 18.0 in stage 1.0 (TID 19)
2021-05-19 02:47:04 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 49
2021-05-19 02:47:04 INFO  Executor:54 - Running task 3.0 in stage 1.0 (TID 4)
2021-05-19 02:47:04 INFO  Executor:54 - Running task 43.0 in stage 1.0 (TID 44)
2021-05-19 02:47:04 INFO  Executor:54 - Running task 48.0 in stage 1.0 (TID 49)
2021-05-19 02:47:05 INFO  TorrentBroadcast:54 - Started reading broadcast variable 3
2021-05-19 02:47:05 INFO  TransportClientFactory:267 - Successfully created connection to hadoop02.cusp.nyu.edu/192.168.72.172:49352 after 6 ms (0 ms spent in bootstraps)
2021-05-19 02:47:05 INFO  MemoryStore:54 - Block broadcast_3_piece0 stored as bytes in memory (estimated size 35.0 KB, free 366.3 MB)
2021-05-19 02:47:05 INFO  TorrentBroadcast:54 - Reading broadcast variable 3 took 199 ms
2021-05-19 02:47:05 INFO  MemoryStore:54 - Block broadcast_3 stored as values in memory (estimated size 129.0 KB, free 366.1 MB)
2021-05-19 02:47:07 INFO  Executor:54 - Finished task 38.0 in stage 1.0 (TID 39). 1492 bytes result sent to driver
2021-05-19 02:47:07 INFO  Executor:54 - Finished task 18.0 in stage 1.0 (TID 19). 1492 bytes result sent to driver
2021-05-19 02:47:07 INFO  Executor:54 - Finished task 23.0 in stage 1.0 (TID 24). 1492 bytes result sent to driver
2021-05-19 02:47:07 INFO  Executor:54 - Finished task 13.0 in stage 1.0 (TID 14). 1492 bytes result sent to driver
2021-05-19 02:47:07 INFO  Executor:54 - Finished task 3.0 in stage 1.0 (TID 4). 1492 bytes result sent to driver
2021-05-19 02:47:07 INFO  Executor:54 - Finished task 33.0 in stage 1.0 (TID 34). 1492 bytes result sent to driver
2021-05-19 02:47:07 INFO  Executor:54 - Finished task 8.0 in stage 1.0 (TID 9). 1492 bytes result sent to driver
2021-05-19 02:47:07 INFO  Executor:54 - Finished task 43.0 in stage 1.0 (TID 44). 1492 bytes result sent to driver
2021-05-19 02:47:07 INFO  Executor:54 - Finished task 28.0 in stage 1.0 (TID 29). 1492 bytes result sent to driver
2021-05-19 02:47:07 INFO  Executor:54 - Finished task 48.0 in stage 1.0 (TID 49). 1492 bytes result sent to driver
2021-05-19 02:47:08 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 53
2021-05-19 02:47:08 INFO  Executor:54 - Running task 2.0 in stage 2.0 (TID 53)
2021-05-19 02:47:08 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 58
2021-05-19 02:47:08 INFO  Executor:54 - Running task 7.0 in stage 2.0 (TID 58)
2021-05-19 02:47:08 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 63
2021-05-19 02:47:08 INFO  Executor:54 - Running task 12.0 in stage 2.0 (TID 63)
2021-05-19 02:47:08 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 68
2021-05-19 02:47:08 INFO  Executor:54 - Running task 17.0 in stage 2.0 (TID 68)
2021-05-19 02:47:08 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 73
2021-05-19 02:47:08 INFO  Executor:54 - Running task 22.0 in stage 2.0 (TID 73)
2021-05-19 02:47:08 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 78
2021-05-19 02:47:08 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 83
2021-05-19 02:47:08 INFO  Executor:54 - Running task 27.0 in stage 2.0 (TID 78)
2021-05-19 02:47:08 INFO  Executor:54 - Running task 32.0 in stage 2.0 (TID 83)
2021-05-19 02:47:08 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 88
2021-05-19 02:47:08 INFO  Executor:54 - Running task 37.0 in stage 2.0 (TID 88)
2021-05-19 02:47:08 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 93
2021-05-19 02:47:08 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 98
2021-05-19 02:47:08 INFO  Executor:54 - Running task 42.0 in stage 2.0 (TID 93)
2021-05-19 02:47:08 INFO  Executor:54 - Running task 47.0 in stage 2.0 (TID 98)
2021-05-19 02:47:08 INFO  TorrentBroadcast:54 - Started reading broadcast variable 4
2021-05-19 02:47:08 INFO  TransportClientFactory:267 - Successfully created connection to hadoop17.cusp.nyu.edu/192.168.72.187:39842 after 4 ms (0 ms spent in bootstraps)
2021-05-19 02:47:08 INFO  MemoryStore:54 - Block broadcast_4_piece0 stored as bytes in memory (estimated size 35.0 KB, free 366.1 MB)
2021-05-19 02:47:08 INFO  TorrentBroadcast:54 - Reading broadcast variable 4 took 56 ms
2021-05-19 02:47:08 INFO  MemoryStore:54 - Block broadcast_4 stored as values in memory (estimated size 129.0 KB, free 366.0 MB)
2021-05-19 02:47:08 INFO  Executor:54 - Finished task 22.0 in stage 2.0 (TID 73). 1406 bytes result sent to driver
2021-05-19 02:47:08 INFO  Executor:54 - Finished task 32.0 in stage 2.0 (TID 83). 1449 bytes result sent to driver
2021-05-19 02:47:08 INFO  Executor:54 - Finished task 37.0 in stage 2.0 (TID 88). 1449 bytes result sent to driver
2021-05-19 02:47:08 INFO  Executor:54 - Finished task 12.0 in stage 2.0 (TID 63). 1449 bytes result sent to driver
2021-05-19 02:47:08 INFO  Executor:54 - Finished task 47.0 in stage 2.0 (TID 98). 1449 bytes result sent to driver
2021-05-19 02:47:08 INFO  Executor:54 - Finished task 7.0 in stage 2.0 (TID 58). 1449 bytes result sent to driver
2021-05-19 02:47:08 INFO  Executor:54 - Finished task 27.0 in stage 2.0 (TID 78). 1449 bytes result sent to driver
2021-05-19 02:47:08 INFO  Executor:54 - Finished task 2.0 in stage 2.0 (TID 53). 1406 bytes result sent to driver
2021-05-19 02:47:08 INFO  Executor:54 - Finished task 42.0 in stage 2.0 (TID 93). 1449 bytes result sent to driver
2021-05-19 02:47:08 INFO  Executor:54 - Finished task 17.0 in stage 2.0 (TID 68). 1449 bytes result sent to driver
2021-05-19 02:47:14 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 122
2021-05-19 02:47:14 INFO  Executor:54 - Running task 5.0 in stage 5.0 (TID 122)
2021-05-19 02:47:14 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 126
2021-05-19 02:47:14 INFO  Executor:54 - Running task 9.0 in stage 5.0 (TID 126)
2021-05-19 02:47:14 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 130
2021-05-19 02:47:14 INFO  Executor:54 - Running task 13.0 in stage 5.0 (TID 130)
2021-05-19 02:47:14 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 134
2021-05-19 02:47:14 INFO  Executor:54 - Running task 17.0 in stage 5.0 (TID 134)
2021-05-19 02:47:14 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 138
2021-05-19 02:47:14 INFO  Executor:54 - Running task 22.0 in stage 5.0 (TID 138)
2021-05-19 02:47:14 INFO  MapOutputTrackerWorker:54 - Updating epoch to 1 and clearing cache
2021-05-19 02:47:14 INFO  TorrentBroadcast:54 - Started reading broadcast variable 10
2021-05-19 02:47:14 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 142
2021-05-19 02:47:14 INFO  Executor:54 - Running task 27.0 in stage 5.0 (TID 142)
2021-05-19 02:47:14 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 146
2021-05-19 02:47:14 INFO  Executor:54 - Running task 31.0 in stage 5.0 (TID 146)
2021-05-19 02:47:14 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 150
2021-05-19 02:47:14 INFO  Executor:54 - Running task 36.0 in stage 5.0 (TID 150)
2021-05-19 02:47:14 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 154
2021-05-19 02:47:14 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 158
2021-05-19 02:47:14 INFO  Executor:54 - Running task 40.0 in stage 5.0 (TID 154)
2021-05-19 02:47:14 INFO  Executor:54 - Running task 44.0 in stage 5.0 (TID 158)
2021-05-19 02:47:14 INFO  MemoryStore:54 - Block broadcast_10_piece0 stored as bytes in memory (estimated size 20.4 KB, free 366.3 MB)
2021-05-19 02:47:14 INFO  TorrentBroadcast:54 - Reading broadcast variable 10 took 34 ms
2021-05-19 02:47:14 INFO  MemoryStore:54 - Block broadcast_10 stored as values in memory (estimated size 40.9 KB, free 366.2 MB)
2021-05-19 02:47:14 INFO  MapOutputTrackerWorker:54 - Don't have map outputs for shuffle 0, fetching them
2021-05-19 02:47:14 INFO  MapOutputTrackerWorker:54 - Don't have map outputs for shuffle 0, fetching them
2021-05-19 02:47:14 INFO  MapOutputTrackerWorker:54 - Don't have map outputs for shuffle 0, fetching them
2021-05-19 02:47:14 INFO  MapOutputTrackerWorker:54 - Don't have map outputs for shuffle 0, fetching them
2021-05-19 02:47:14 INFO  MapOutputTrackerWorker:54 - Don't have map outputs for shuffle 0, fetching them
2021-05-19 02:47:14 INFO  MapOutputTrackerWorker:54 - Don't have map outputs for shuffle 0, fetching them
2021-05-19 02:47:14 INFO  MapOutputTrackerWorker:54 - Don't have map outputs for shuffle 0, fetching them
2021-05-19 02:47:14 INFO  MapOutputTrackerWorker:54 - Don't have map outputs for shuffle 0, fetching them
2021-05-19 02:47:14 INFO  MapOutputTrackerWorker:54 - Don't have map outputs for shuffle 0, fetching them
2021-05-19 02:47:14 INFO  MapOutputTrackerWorker:54 - Don't have map outputs for shuffle 0, fetching them
2021-05-19 02:47:14 INFO  MapOutputTrackerWorker:54 - Doing the fetch; tracker endpoint = NettyRpcEndpointRef(spark://MapOutputTracker@hadoop02.cusp.nyu.edu:60108)
2021-05-19 02:47:14 INFO  MapOutputTrackerWorker:54 - Got the output locations
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 16 ms
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 18 ms
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 17 ms
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 16 ms
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 15 ms
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 15 ms
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 15 ms
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 15 ms
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 15 ms
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 19 ms
2021-05-19 02:47:15 INFO  CodeGenerator:54 - Code generated in 335.972562 ms
2021-05-19 02:47:15 INFO  CodeGenerator:54 - Code generated in 39.411391 ms
2021-05-19 02:47:15 INFO  CodeGenerator:54 - Code generated in 22.821513 ms
2021-05-19 02:47:15 INFO  CodeGenerator:54 - Code generated in 27.539032 ms
2021-05-19 02:47:15 INFO  Executor:54 - Finished task 22.0 in stage 5.0 (TID 138). 3776 bytes result sent to driver
2021-05-19 02:47:15 INFO  Executor:54 - Finished task 13.0 in stage 5.0 (TID 130). 3819 bytes result sent to driver
2021-05-19 02:47:15 INFO  Executor:54 - Finished task 40.0 in stage 5.0 (TID 154). 3776 bytes result sent to driver
2021-05-19 02:47:15 INFO  Executor:54 - Finished task 36.0 in stage 5.0 (TID 150). 3776 bytes result sent to driver
2021-05-19 02:47:15 INFO  Executor:54 - Finished task 17.0 in stage 5.0 (TID 134). 3776 bytes result sent to driver
2021-05-19 02:47:15 INFO  Executor:54 - Finished task 5.0 in stage 5.0 (TID 122). 3776 bytes result sent to driver
2021-05-19 02:47:15 INFO  Executor:54 - Finished task 31.0 in stage 5.0 (TID 146). 3776 bytes result sent to driver
2021-05-19 02:47:15 INFO  Executor:54 - Finished task 44.0 in stage 5.0 (TID 158). 3776 bytes result sent to driver
2021-05-19 02:47:15 INFO  Executor:54 - Finished task 9.0 in stage 5.0 (TID 126). 3819 bytes result sent to driver
2021-05-19 02:47:15 INFO  Executor:54 - Finished task 27.0 in stage 5.0 (TID 142). 3776 bytes result sent to driver
2021-05-19 02:47:18 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 319
2021-05-19 02:47:18 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 323
2021-05-19 02:47:18 INFO  Executor:54 - Running task 4.0 in stage 7.0 (TID 319)
2021-05-19 02:47:18 INFO  Executor:54 - Running task 5.0 in stage 7.0 (TID 323)
2021-05-19 02:47:18 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 327
2021-05-19 02:47:18 INFO  Executor:54 - Running task 14.0 in stage 7.0 (TID 327)
2021-05-19 02:47:19 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 331
2021-05-19 02:47:19 INFO  Executor:54 - Running task 20.0 in stage 7.0 (TID 331)
2021-05-19 02:47:19 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 335
2021-05-19 02:47:19 INFO  Executor:54 - Running task 23.0 in stage 7.0 (TID 335)
2021-05-19 02:47:19 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 339
2021-05-19 02:47:19 INFO  Executor:54 - Running task 34.0 in stage 7.0 (TID 339)
2021-05-19 02:47:19 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 343
2021-05-19 02:47:19 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 347
2021-05-19 02:47:19 INFO  Executor:54 - Running task 41.0 in stage 7.0 (TID 343)
2021-05-19 02:47:19 INFO  Executor:54 - Running task 52.0 in stage 7.0 (TID 347)
2021-05-19 02:47:19 INFO  TorrentBroadcast:54 - Started reading broadcast variable 14
2021-05-19 02:47:19 INFO  MemoryStore:54 - Block broadcast_14_piece0 stored as bytes in memory (estimated size 22.9 KB, free 366.3 MB)
2021-05-19 02:47:19 INFO  TorrentBroadcast:54 - Reading broadcast variable 14 took 23 ms
2021-05-19 02:47:19 INFO  MemoryStore:54 - Block broadcast_14 stored as values in memory (estimated size 51.4 KB, free 366.2 MB)
2021-05-19 02:47:19 INFO  CodeGenerator:54 - Code generated in 69.284734 ms
2021-05-19 02:47:19 INFO  TorrentBroadcast:54 - Started reading broadcast variable 12
2021-05-19 02:47:19 INFO  MemoryStore:54 - Block broadcast_12_piece0 stored as bytes in memory (estimated size 580.1 KB, free 365.7 MB)
2021-05-19 02:47:19 INFO  TorrentBroadcast:54 - Reading broadcast variable 12 took 31 ms
2021-05-19 02:47:19 INFO  MemoryStore:54 - Block broadcast_12 stored as values in memory (estimated size 5.0 MB, free 360.7 MB)
2021-05-19 02:47:19 INFO  CodeGenerator:54 - Code generated in 23.415736 ms
2021-05-19 02:47:20 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00014, range: 0-134217728, partition values: [empty row]
2021-05-19 02:47:20 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00004, range: 134217728-178480909, partition values: [empty row]
2021-05-19 02:47:20 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00034, range: 0-134217728, partition values: [empty row]
2021-05-19 02:47:20 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00020, range: 0-134217728, partition values: [empty row]
2021-05-19 02:47:20 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00041, range: 0-134217728, partition values: [empty row]
2021-05-19 02:47:20 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00004, range: 0-134217728, partition values: [empty row]
2021-05-19 02:47:20 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00023, range: 0-134217728, partition values: [empty row]
2021-05-19 02:47:20 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00005, range: 0-134217728, partition values: [empty row]
2021-05-19 02:47:20 INFO  CodeGenerator:54 - Code generated in 27.145306 ms
2021-05-19 02:47:20 INFO  TorrentBroadcast:54 - Started reading broadcast variable 13
2021-05-19 02:47:20 INFO  MemoryStore:54 - Block broadcast_13_piece0 stored as bytes in memory (estimated size 33.4 KB, free 360.6 MB)
2021-05-19 02:47:20 INFO  CodeGenerator:54 - Code generated in 82.839243 ms
2021-05-19 02:47:20 INFO  TorrentBroadcast:54 - Reading broadcast variable 13 took 18 ms
2021-05-19 02:47:20 INFO  CodeGenerator:54 - Code generated in 42.273868 ms
2021-05-19 02:47:20 INFO  CodeGenerator:54 - Code generated in 39.425024 ms
2021-05-19 02:47:20 INFO  MemoryStore:54 - Block broadcast_13 stored as values in memory (estimated size 506.4 KB, free 360.1 MB)
2021-05-19 02:47:20 INFO  CodeGenerator:54 - Code generated in 29.505774 ms
2021-05-19 02:47:20 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: zzw-222@627-s6d-wx5, 2019-12-02T00:00:00-05:00, [1,1,0,0,0,4,5]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: zzw-222@627-s6d-wx5
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00034
2021-05-19 02:47:20 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: 22b-222@627-s4r-s3q, 2019-11-04T00:00:00-05:00, [20,15,14,25,21,16,15]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: 22b-222@627-s4r-s3q
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00023
2021-05-19 02:47:20 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: 222-222@627-wgb-qxq, 2019-01-07T00:00:00-05:00, [408,482,574,546,236,93,103]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: 222-222@627-wgb-qxq
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00014
2021-05-19 02:47:20 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: 22t-224@627-s8k-2zf, 2019-09-09T00:00:00-04:00, [9,7,9,3,7,4,5]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: 22t-224@627-s8k-2zf
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00020
2021-05-19 02:47:20 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: 222-222@627-s95-rc5, 2018-12-31T00:00:00-05:00, [5,6,50,52,24,0,0]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: 222-222@627-s95-rc5
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00005
2021-05-19 02:47:20 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: 223-222@627-s6d-9vf, 2018-12-31T00:00:00-05:00, [57,70,74,72,80,86,66]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: 223-222@627-s6d-9vf
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00004
2021-05-19 02:47:20 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: zzw-222@627-s65-bx5, 2020-09-28T00:00:00-04:00, [0,1,0,2,0,0,0]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: zzw-222@627-s65-bx5
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00041
2021-05-19 02:47:21 INFO  CodeGenerator:54 - Code generated in 18.703657 ms
2021-05-19 02:47:21 INFO  CodeGenerator:54 - Code generated in 33.804687 ms
2021-05-19 02:47:21 INFO  CodeGenerator:54 - Code generated in 22.144424 ms
2021-05-19 02:47:22 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:47:22 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:47:22 INFO  CodeGenerator:54 - Code generated in 33.646447 ms
2021-05-19 02:47:22 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 356
2021-05-19 02:47:22 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 358
2021-05-19 02:47:22 INFO  Executor:54 - Running task 11.0 in stage 7.0 (TID 356)
2021-05-19 02:47:22 INFO  Executor:54 - Running task 19.0 in stage 7.0 (TID 358)
2021-05-19 02:47:22 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:47:22 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:47:22 INFO  CodeGenerator:54 - Code generated in 63.979218 ms
2021-05-19 02:47:22 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00011, range: 0-134217728, partition values: [empty row]
2021-05-19 02:47:22 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:47:22 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00019, range: 0-134217728, partition values: [empty row]
2021-05-19 02:47:22 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:47:22 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:47:22 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: 22c-222@627-vv6-vvf, 2019-12-16T00:00:00-05:00, [0,0,0,0,1,0,0]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: 22c-222@627-vv6-vvf
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00019
2021-05-19 02:47:22 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: 238-222@627-s8g-tqf, 2018-12-31T00:00:00-05:00, [0,2,2,4,2,2,2]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: 238-222@627-s8g-tqf
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00011
2021-05-19 02:47:22 INFO  CodeGenerator:54 - Code generated in 27.337296 ms
2021-05-19 02:47:22 INFO  CodeGenerator:54 - Code generated in 22.251199 ms
2021-05-19 02:47:22 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:47:22 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:47:22 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00037, range: 134217728-178478348, partition values: [empty row]
2021-05-19 02:47:23 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:47:30 INFO  PythonUDFRunner:54 - Times: total = 10958, boot = 689, init = 1123, finish = 9146
2021-05-19 02:47:30 INFO  CodeGenerator:54 - Code generated in 33.254753 ms
2021-05-19 02:47:31 INFO  Executor:54 - Finished task 52.0 in stage 7.0 (TID 347). 4270 bytes result sent to driver
2021-05-19 02:47:31 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 367
2021-05-19 02:47:31 INFO  Executor:54 - Running task 9.1 in stage 7.0 (TID 367)
2021-05-19 02:47:31 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00009, range: 0-134217728, partition values: [empty row]
2021-05-19 02:47:31 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: 226-225@627-wc8-73q, 2018-12-31T00:00:00-05:00, [1,6,18,10,12,12,18]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: 226-225@627-wc8-73q
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00009
2021-05-19 02:47:31 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:47:31 INFO  PythonUDFRunner:54 - Times: total = 12436, boot = 712, init = 1099, finish = 10625
2021-05-19 02:47:31 INFO  PythonUDFRunner:54 - Times: total = 12546, boot = 702, init = 1117, finish = 10727
2021-05-19 02:47:32 INFO  PythonUDFRunner:54 - Times: total = 12719, boot = 745, init = 1068, finish = 10906
2021-05-19 02:47:32 INFO  Executor:54 - Finished task 20.0 in stage 7.0 (TID 331). 4313 bytes result sent to driver
2021-05-19 02:47:32 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 369
2021-05-19 02:47:32 INFO  Executor:54 - Running task 26.1 in stage 7.0 (TID 369)
2021-05-19 02:47:32 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00026, range: 0-134217728, partition values: [empty row]
2021-05-19 02:47:32 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: 22h-223@627-s84-6hq, 2019-08-05T00:00:00-04:00, [2,2,0,2,1,3,1]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: 22h-223@627-s84-6hq
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00026
2021-05-19 02:47:32 INFO  Executor:54 - Finished task 34.0 in stage 7.0 (TID 339). 4270 bytes result sent to driver
2021-05-19 02:47:32 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 370
2021-05-19 02:47:32 INFO  Executor:54 - Running task 43.1 in stage 7.0 (TID 370)
2021-05-19 02:47:32 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00043, range: 0-134217728, partition values: [empty row]
2021-05-19 02:47:32 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: 25p-222@627-s8j-94v, 2020-06-08T00:00:00-04:00, [1,1,0,2,0,0,0]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: 25p-222@627-s8j-94v
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00043
2021-05-19 02:47:32 INFO  PythonUDFRunner:54 - Times: total = 13106, boot = 758, init = 1055, finish = 11293
2021-05-19 02:47:32 INFO  PythonUDFRunner:54 - Times: total = 13174, boot = 723, init = 1087, finish = 11364
2021-05-19 02:47:32 INFO  Executor:54 - Finished task 23.0 in stage 7.0 (TID 335). 4270 bytes result sent to driver
2021-05-19 02:47:32 INFO  PythonUDFRunner:54 - Times: total = 13254, boot = 734, init = 1080, finish = 11440
2021-05-19 02:47:32 INFO  PythonUDFRunner:54 - Times: total = 13265, boot = 767, init = 1052, finish = 11446
2021-05-19 02:47:33 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:47:33 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:47:33 INFO  Executor:54 - Finished task 41.0 in stage 7.0 (TID 343). 4313 bytes result sent to driver
2021-05-19 02:47:33 INFO  Executor:54 - Finished task 4.0 in stage 7.0 (TID 319). 4270 bytes result sent to driver
2021-05-19 02:47:33 INFO  PythonUDFRunner:54 - Times: total = 11085, boot = 11, init = 262, finish = 10812
2021-05-19 02:47:33 INFO  Executor:54 - Finished task 14.0 in stage 7.0 (TID 327). 4270 bytes result sent to driver
2021-05-19 02:47:33 INFO  Executor:54 - Finished task 5.0 in stage 7.0 (TID 323). 4270 bytes result sent to driver
2021-05-19 02:47:33 INFO  Executor:54 - Finished task 11.0 in stage 7.0 (TID 356). 4313 bytes result sent to driver
2021-05-19 02:47:33 ERROR CoarseGrainedExecutorBackend:43 - RECEIVED SIGNAL TERM
2021-05-19 02:47:33 INFO  DiskBlockManager:54 - Shutdown hook called
2021-05-19 02:47:33 INFO  ShutdownHookManager:54 - Shutdown hook called
2021-05-19 02:47:33 INFO  ShutdownHookManager:54 - Deleting directory /localhome/cdp/yarn/nm/usercache/catherine.ng60/appcache/application_1609183734776_5900/spark-fefd3283-c5a0-4423-b4a3-24ddf06f4bd1
2021-05-19 02:47:34 ERROR TaskContextImpl:91 - Error in TaskCompletionListener
java.io.IOException: Filesystem closed
	at org.apache.hadoop.hdfs.DFSClient.checkOpen(DFSClient.java:808)
	at org.apache.hadoop.hdfs.DFSInputStream.close(DFSInputStream.java:710)
	at java.io.FilterInputStream.close(FilterInputStream.java:181)
	at org.apache.hadoop.util.LineReader.close(LineReader.java:150)
	at org.apache.hadoop.mapreduce.lib.input.LineRecordReader.close(LineRecordReader.java:231)
	at org.apache.spark.sql.execution.datasources.RecordReaderIterator.close(RecordReaderIterator.scala:62)
	at org.apache.spark.sql.execution.datasources.HadoopFileLinesReader.close(HadoopFileLinesReader.scala:73)
	at org.apache.spark.sql.execution.datasources.csv.TextInputCSVDataSource$$anonfun$4$$anonfun$apply$2.apply(CSVDataSource.scala:200)
	at org.apache.spark.sql.execution.datasources.csv.TextInputCSVDataSource$$anonfun$4$$anonfun$apply$2.apply(CSVDataSource.scala:200)
	at org.apache.spark.TaskContext$$anon$1.onTaskCompletion(TaskContext.scala:131)
	at org.apache.spark.TaskContextImpl$$anonfun$markTaskCompleted$1.apply(TaskContextImpl.scala:117)
	at org.apache.spark.TaskContextImpl$$anonfun$markTaskCompleted$1.apply(TaskContextImpl.scala:117)
	at org.apache.spark.TaskContextImpl$$anonfun$invokeListeners$1.apply(TaskContextImpl.scala:130)
	at org.apache.spark.TaskContextImpl$$anonfun$invokeListeners$1.apply(TaskContextImpl.scala:128)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.TaskContextImpl.invokeListeners(TaskContextImpl.scala:128)
	at org.apache.spark.TaskContextImpl.markTaskCompleted(TaskContextImpl.scala:116)
	at org.apache.spark.scheduler.Task.run(Task.scala:131)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:402)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:408)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2021-05-19 02:47:34 ERROR TaskContextImpl:91 - Error in TaskCompletionListener
java.io.IOException: Filesystem closed
	at org.apache.hadoop.hdfs.DFSClient.checkOpen(DFSClient.java:808)
	at org.apache.hadoop.hdfs.DFSInputStream.close(DFSInputStream.java:710)
	at java.io.FilterInputStream.close(FilterInputStream.java:181)
	at org.apache.hadoop.util.LineReader.close(LineReader.java:150)
	at org.apache.hadoop.mapreduce.lib.input.LineRecordReader.close(LineRecordReader.java:231)
	at org.apache.spark.sql.execution.datasources.RecordReaderIterator.close(RecordReaderIterator.scala:62)
	at org.apache.spark.sql.execution.datasources.HadoopFileLinesReader.close(HadoopFileLinesReader.scala:73)
	at org.apache.spark.sql.execution.datasources.csv.TextInputCSVDataSource$$anonfun$4$$anonfun$apply$2.apply(CSVDataSource.scala:200)
	at org.apache.spark.sql.execution.datasources.csv.TextInputCSVDataSource$$anonfun$4$$anonfun$apply$2.apply(CSVDataSource.scala:200)
	at org.apache.spark.TaskContext$$anon$1.onTaskCompletion(TaskContext.scala:131)
	at org.apache.spark.TaskContextImpl$$anonfun$markTaskCompleted$1.apply(TaskContextImpl.scala:117)
	at org.apache.spark.TaskContextImpl$$anonfun$markTaskCompleted$1.apply(TaskContextImpl.scala:117)
	at org.apache.spark.TaskContextImpl$$anonfun$invokeListeners$1.apply(TaskContextImpl.scala:130)
	at org.apache.spark.TaskContextImpl$$anonfun$invokeListeners$1.apply(TaskContextImpl.scala:128)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.TaskContextImpl.invokeListeners(TaskContextImpl.scala:128)
	at org.apache.spark.TaskContextImpl.markTaskCompleted(TaskContextImpl.scala:116)
	at org.apache.spark.scheduler.Task.run(Task.scala:131)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:402)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:408)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2021-05-19 02:47:34 ERROR Executor:91 - Exception in task 26.1 in stage 7.0 (TID 369)
org.apache.spark.util.TaskCompletionListenerException: Filesystem closed

Previous exception in task: Filesystem closed
	org.apache.hadoop.hdfs.DFSClient.checkOpen(DFSClient.java:808)
	org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:868)
	org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:934)
	java.io.DataInputStream.read(DataInputStream.java:149)
	org.apache.hadoop.mapreduce.lib.input.UncompressedSplitLineReader.fillBuffer(UncompressedSplitLineReader.java:62)
	org.apache.hadoop.util.LineReader.readDefaultLine(LineReader.java:216)
	org.apache.hadoop.util.LineReader.readLine(LineReader.java:174)
	org.apache.hadoop.mapreduce.lib.input.UncompressedSplitLineReader.readLine(UncompressedSplitLineReader.java:94)
	org.apache.hadoop.mapreduce.lib.input.LineRecordReader.nextKeyValue(LineRecordReader.java:186)
	org.apache.spark.sql.execution.datasources.RecordReaderIterator.hasNext(RecordReaderIterator.scala:39)
	org.apache.spark.sql.execution.datasources.HadoopFileLinesReader.hasNext(HadoopFileLinesReader.scala:69)
	scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:462)
	scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:101)
	org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source)
	org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$11$$anon$1.hasNext(WholeStageCodegenExec.scala:619)
	scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	scala.collection.Iterator$GroupedIterator.takeDestructively(Iterator.scala:1073)
	scala.collection.Iterator$GroupedIterator.go(Iterator.scala:1089)
	scala.collection.Iterator$GroupedIterator.fill(Iterator.scala:1127)
	scala.collection.Iterator$GroupedIterator.hasNext(Iterator.scala:1130)
	scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	scala.collection.Iterator$class.foreach(Iterator.scala:891)
	scala.collection.AbstractIterator.foreach(Iterator.scala:1334)
	org.apache.spark.api.python.PythonRDD$.writeIteratorToStream(PythonRDD.scala:224)
	org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$2.writeIteratorToStream(PythonUDFRunner.scala:50)
	org.apache.spark.api.python.BasePythonRunner$WriterThread$$anonfun$run$1.apply(PythonRunner.scala:345)
	org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1945)
	org.apache.spark.api.python.BasePythonRunner$WriterThread.run(PythonRunner.scala:194)
	at org.apache.spark.TaskContextImpl.invokeListeners(TaskContextImpl.scala:138)
	at org.apache.spark.TaskContextImpl.markTaskCompleted(TaskContextImpl.scala:116)
	at org.apache.spark.scheduler.Task.run(Task.scala:131)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:402)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:408)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2021-05-19 02:47:34 ERROR Executor:91 - Exception in task 9.1 in stage 7.0 (TID 367)
org.apache.spark.util.TaskCompletionListenerException: Filesystem closed

Previous exception in task: Filesystem closed
	org.apache.hadoop.hdfs.DFSClient.checkOpen(DFSClient.java:808)
	org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:868)
	org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:934)
	java.io.DataInputStream.read(DataInputStream.java:149)
	org.apache.hadoop.mapreduce.lib.input.UncompressedSplitLineReader.fillBuffer(UncompressedSplitLineReader.java:62)
	org.apache.hadoop.util.LineReader.readDefaultLine(LineReader.java:216)
	org.apache.hadoop.util.LineReader.readLine(LineReader.java:174)
	org.apache.hadoop.mapreduce.lib.input.UncompressedSplitLineReader.readLine(UncompressedSplitLineReader.java:94)
	org.apache.hadoop.mapreduce.lib.input.LineRecordReader.nextKeyValue(LineRecordReader.java:186)
	org.apache.spark.sql.execution.datasources.RecordReaderIterator.hasNext(RecordReaderIterator.scala:39)
	org.apache.spark.sql.execution.datasources.HadoopFileLinesReader.hasNext(HadoopFileLinesReader.scala:69)
	scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:462)
	scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:101)
	org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source)
	org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$11$$anon$1.hasNext(WholeStageCodegenExec.scala:619)
	scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	scala.collection.Iterator$GroupedIterator.takeDestructively(Iterator.scala:1073)
	scala.collection.Iterator$GroupedIterator.go(Iterator.scala:1089)
	scala.collection.Iterator$GroupedIterator.fill(Iterator.scala:1127)
	scala.collection.Iterator$GroupedIterator.hasNext(Iterator.scala:1130)
	scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	scala.collection.Iterator$class.foreach(Iterator.scala:891)
	scala.collection.AbstractIterator.foreach(Iterator.scala:1334)
	org.apache.spark.api.python.PythonRDD$.writeIteratorToStream(PythonRDD.scala:224)
	org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$2.writeIteratorToStream(PythonUDFRunner.scala:50)
	org.apache.spark.api.python.BasePythonRunner$WriterThread$$anonfun$run$1.apply(PythonRunner.scala:345)
	org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1945)
	org.apache.spark.api.python.BasePythonRunner$WriterThread.run(PythonRunner.scala:194)
	at org.apache.spark.TaskContextImpl.invokeListeners(TaskContextImpl.scala:138)
	at org.apache.spark.TaskContextImpl.markTaskCompleted(TaskContextImpl.scala:116)
	at org.apache.spark.scheduler.Task.run(Task.scala:131)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:402)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:408)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2021-05-19 02:47:34 INFO  Executor:54 - Not reporting error to driver during JVM shutdown.
2021-05-19 02:47:34 INFO  Executor:54 - Not reporting error to driver during JVM shutdown.
2021-05-19 02:47:34 ERROR TaskContextImpl:91 - Error in TaskCompletionListener
java.io.IOException: Filesystem closed
	at org.apache.hadoop.hdfs.DFSClient.checkOpen(DFSClient.java:808)
	at org.apache.hadoop.hdfs.DFSInputStream.close(DFSInputStream.java:710)
	at java.io.FilterInputStream.close(FilterInputStream.java:181)
	at org.apache.hadoop.util.LineReader.close(LineReader.java:150)
	at org.apache.hadoop.mapreduce.lib.input.LineRecordReader.close(LineRecordReader.java:231)
	at org.apache.spark.sql.execution.datasources.RecordReaderIterator.close(RecordReaderIterator.scala:62)
	at org.apache.spark.sql.execution.datasources.HadoopFileLinesReader.close(HadoopFileLinesReader.scala:73)
	at org.apache.spark.sql.execution.datasources.csv.TextInputCSVDataSource$$anonfun$4$$anonfun$apply$2.apply(CSVDataSource.scala:200)
	at org.apache.spark.sql.execution.datasources.csv.TextInputCSVDataSource$$anonfun$4$$anonfun$apply$2.apply(CSVDataSource.scala:200)
	at org.apache.spark.TaskContext$$anon$1.onTaskCompletion(TaskContext.scala:131)
	at org.apache.spark.TaskContextImpl$$anonfun$markTaskCompleted$1.apply(TaskContextImpl.scala:117)
	at org.apache.spark.TaskContextImpl$$anonfun$markTaskCompleted$1.apply(TaskContextImpl.scala:117)
	at org.apache.spark.TaskContextImpl$$anonfun$invokeListeners$1.apply(TaskContextImpl.scala:130)
	at org.apache.spark.TaskContextImpl$$anonfun$invokeListeners$1.apply(TaskContextImpl.scala:128)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.TaskContextImpl.invokeListeners(TaskContextImpl.scala:128)
	at org.apache.spark.TaskContextImpl.markTaskCompleted(TaskContextImpl.scala:116)
	at org.apache.spark.scheduler.Task.run(Task.scala:131)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:402)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:408)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2021-05-19 02:47:34 ERROR Executor:91 - Exception in task 43.1 in stage 7.0 (TID 370)
org.apache.spark.util.TaskCompletionListenerException: Filesystem closed

Previous exception in task: Filesystem closed
	org.apache.hadoop.hdfs.DFSClient.checkOpen(DFSClient.java:808)
	org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:868)
	org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:934)
	java.io.DataInputStream.read(DataInputStream.java:149)
	org.apache.hadoop.mapreduce.lib.input.UncompressedSplitLineReader.fillBuffer(UncompressedSplitLineReader.java:62)
	org.apache.hadoop.util.LineReader.readDefaultLine(LineReader.java:216)
	org.apache.hadoop.util.LineReader.readLine(LineReader.java:174)
	org.apache.hadoop.mapreduce.lib.input.UncompressedSplitLineReader.readLine(UncompressedSplitLineReader.java:94)
	org.apache.hadoop.mapreduce.lib.input.LineRecordReader.nextKeyValue(LineRecordReader.java:186)
	org.apache.spark.sql.execution.datasources.RecordReaderIterator.hasNext(RecordReaderIterator.scala:39)
	org.apache.spark.sql.execution.datasources.HadoopFileLinesReader.hasNext(HadoopFileLinesReader.scala:69)
	scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:462)
	scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:101)
	org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source)
	org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$11$$anon$1.hasNext(WholeStageCodegenExec.scala:619)
	scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	scala.collection.Iterator$GroupedIterator.takeDestructively(Iterator.scala:1073)
	scala.collection.Iterator$GroupedIterator.go(Iterator.scala:1089)
	scala.collection.Iterator$GroupedIterator.fill(Iterator.scala:1127)
	scala.collection.Iterator$GroupedIterator.hasNext(Iterator.scala:1130)
	scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	scala.collection.Iterator$class.foreach(Iterator.scala:891)
	scala.collection.AbstractIterator.foreach(Iterator.scala:1334)
	org.apache.spark.api.python.PythonRDD$.writeIteratorToStream(PythonRDD.scala:224)
	org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$2.writeIteratorToStream(PythonUDFRunner.scala:50)
	org.apache.spark.api.python.BasePythonRunner$WriterThread$$anonfun$run$1.apply(PythonRunner.scala:345)
	org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1945)
	org.apache.spark.api.python.BasePythonRunner$WriterThread.run(PythonRunner.scala:194)
	at org.apache.spark.TaskContextImpl.invokeListeners(TaskContextImpl.scala:138)
	at org.apache.spark.TaskContextImpl.markTaskCompleted(TaskContextImpl.scala:116)
	at org.apache.spark.scheduler.Task.run(Task.scala:131)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:402)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:408)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2021-05-19 02:47:34 INFO  Executor:54 - Not reporting error to driver during JVM shutdown.

End of LogType:stdout
***********************************************************************


End of LogType:prelaunch.err
******************************************************************************

Container: container_e10_1609183734776_5900_02_000016 on hadoop13.cusp.nyu.edu_8041
LogAggregationType: AGGREGATED
===================================================================================
LogType:prelaunch.out
LogLastModifiedTime:Wed May 19 02:48:18 -0400 2021
LogLength:70
LogContents:
Setting up env variables
Setting up job resources
Launching container

End of LogType:prelaunch.out
******************************************************************************

Container: container_e10_1609183734776_5900_02_000016 on hadoop13.cusp.nyu.edu_8041
LogAggregationType: AGGREGATED
===================================================================================
LogType:stderr
LogLastModifiedTime:Wed May 19 02:48:18 -0400 2021
LogLength:529
LogContents:
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/localhome/cdp/yarn/nm/filecache/23/spark-jars-2.4.0-hadoop2.7.jar/slf4j-log4j12-1.7.16.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-6.1.0-1.cdh6.1.0.p0.770702/jars/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]

End of LogType:stderr
***********************************************************************

Container: container_e10_1609183734776_5900_02_000016 on hadoop13.cusp.nyu.edu_8041
LogAggregationType: AGGREGATED
===================================================================================
LogType:stdout
LogLastModifiedTime:Wed May 19 02:48:18 -0400 2021
LogLength:19157
LogContents:
2021-05-19 02:47:58 INFO  CoarseGrainedExecutorBackend:2566 - Started daemon with process name: 15679@hadoop13.cusp.nyu.edu
2021-05-19 02:47:58 INFO  SignalUtils:54 - Registered signal handler for TERM
2021-05-19 02:47:58 INFO  SignalUtils:54 - Registered signal handler for HUP
2021-05-19 02:47:58 INFO  SignalUtils:54 - Registered signal handler for INT
2021-05-19 02:47:59 INFO  SecurityManager:54 - Changing view acls to: catherine.ng60
2021-05-19 02:47:59 INFO  SecurityManager:54 - Changing modify acls to: catherine.ng60
2021-05-19 02:47:59 INFO  SecurityManager:54 - Changing view acls groups to: 
2021-05-19 02:47:59 INFO  SecurityManager:54 - Changing modify acls groups to: 
2021-05-19 02:47:59 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(catherine.ng60); groups with view permissions: Set(); users  with modify permissions: Set(catherine.ng60); groups with modify permissions: Set()
2021-05-19 02:47:59 INFO  TransportClientFactory:267 - Successfully created connection to hadoop02.cusp.nyu.edu/192.168.72.172:60108 after 116 ms (0 ms spent in bootstraps)
2021-05-19 02:47:59 INFO  SecurityManager:54 - Changing view acls to: catherine.ng60
2021-05-19 02:47:59 INFO  SecurityManager:54 - Changing modify acls to: catherine.ng60
2021-05-19 02:47:59 INFO  SecurityManager:54 - Changing view acls groups to: 
2021-05-19 02:47:59 INFO  SecurityManager:54 - Changing modify acls groups to: 
2021-05-19 02:47:59 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(catherine.ng60); groups with view permissions: Set(); users  with modify permissions: Set(catherine.ng60); groups with modify permissions: Set()
2021-05-19 02:48:00 INFO  TransportClientFactory:267 - Successfully created connection to hadoop02.cusp.nyu.edu/192.168.72.172:60108 after 4 ms (0 ms spent in bootstraps)
2021-05-19 02:48:00 INFO  DiskBlockManager:54 - Created local directory at /localhome/cdp/yarn/nm/usercache/catherine.ng60/appcache/application_1609183734776_5900/blockmgr-b598474b-9d5c-4460-8d13-bd18624937c5
2021-05-19 02:48:00 INFO  MemoryStore:54 - MemoryStore started with capacity 366.3 MB
2021-05-19 02:48:00 INFO  CoarseGrainedExecutorBackend:54 - Connecting to driver: spark://CoarseGrainedScheduler@hadoop02.cusp.nyu.edu:60108
2021-05-19 02:48:00 INFO  CoarseGrainedExecutorBackend:54 - Successfully registered with driver
2021-05-19 02:48:00 INFO  Executor:54 - Starting executor ID 13 on host hadoop13.cusp.nyu.edu
2021-05-19 02:48:00 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 43962.
2021-05-19 02:48:00 INFO  NettyBlockTransferService:54 - Server created on hadoop13.cusp.nyu.edu:43962
2021-05-19 02:48:00 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2021-05-19 02:48:00 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(13, hadoop13.cusp.nyu.edu, 43962, None)
2021-05-19 02:48:00 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(13, hadoop13.cusp.nyu.edu, 43962, None)
2021-05-19 02:48:00 INFO  BlockManager:54 - external shuffle service port = 7337
2021-05-19 02:48:00 INFO  BlockManager:54 - Registering executor with local external shuffle service.
2021-05-19 02:48:00 INFO  TransportClientFactory:267 - Successfully created connection to hadoop13.cusp.nyu.edu/192.168.72.183:7337 after 3 ms (0 ms spent in bootstraps)
2021-05-19 02:48:00 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(13, hadoop13.cusp.nyu.edu, 43962, None)
2021-05-19 02:48:00 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 442
2021-05-19 02:48:00 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 443
2021-05-19 02:48:00 INFO  Executor:54 - Running task 9.3 in stage 7.0 (TID 442)
2021-05-19 02:48:00 INFO  Executor:54 - Running task 43.3 in stage 7.0 (TID 443)
2021-05-19 02:48:00 INFO  MapOutputTrackerWorker:54 - Updating epoch to 1 and clearing cache
2021-05-19 02:48:00 INFO  TorrentBroadcast:54 - Started reading broadcast variable 14
2021-05-19 02:48:00 INFO  TransportClientFactory:267 - Successfully created connection to hadoop18.cusp.nyu.edu/192.168.72.188:38556 after 3 ms (0 ms spent in bootstraps)
2021-05-19 02:48:00 INFO  MemoryStore:54 - Block broadcast_14_piece0 stored as bytes in memory (estimated size 22.9 KB, free 366.3 MB)
2021-05-19 02:48:00 INFO  TorrentBroadcast:54 - Reading broadcast variable 14 took 184 ms
2021-05-19 02:48:01 INFO  MemoryStore:54 - Block broadcast_14 stored as values in memory (estimated size 51.4 KB, free 366.2 MB)
2021-05-19 02:48:02 INFO  CodeGenerator:54 - Code generated in 342.687553 ms
2021-05-19 02:48:02 INFO  TorrentBroadcast:54 - Started reading broadcast variable 12
2021-05-19 02:48:02 INFO  TransportClientFactory:267 - Successfully created connection to hadoop02.cusp.nyu.edu/192.168.72.172:49352 after 5 ms (0 ms spent in bootstraps)
2021-05-19 02:48:02 INFO  MemoryStore:54 - Block broadcast_12_piece0 stored as bytes in memory (estimated size 580.1 KB, free 365.7 MB)
2021-05-19 02:48:02 INFO  TorrentBroadcast:54 - Reading broadcast variable 12 took 54 ms
2021-05-19 02:48:02 INFO  MemoryStore:54 - Block broadcast_12 stored as values in memory (estimated size 5.0 MB, free 360.7 MB)
2021-05-19 02:48:02 INFO  CodeGenerator:54 - Code generated in 31.682418 ms
2021-05-19 02:48:03 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00009, range: 0-134217728, partition values: [empty row]
2021-05-19 02:48:03 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00043, range: 0-134217728, partition values: [empty row]
2021-05-19 02:48:03 INFO  CodeGenerator:54 - Code generated in 53.440933 ms
2021-05-19 02:48:03 INFO  TorrentBroadcast:54 - Started reading broadcast variable 13
2021-05-19 02:48:03 INFO  MemoryStore:54 - Block broadcast_13_piece0 stored as bytes in memory (estimated size 33.4 KB, free 360.6 MB)
2021-05-19 02:48:03 INFO  TorrentBroadcast:54 - Reading broadcast variable 13 took 22 ms
2021-05-19 02:48:03 INFO  CodeGenerator:54 - Code generated in 88.209475 ms
2021-05-19 02:48:03 INFO  CodeGenerator:54 - Code generated in 26.870503 ms
2021-05-19 02:48:03 INFO  CodeGenerator:54 - Code generated in 34.778339 ms
2021-05-19 02:48:03 INFO  CodeGenerator:54 - Code generated in 22.33792 ms
2021-05-19 02:48:03 INFO  MemoryStore:54 - Block broadcast_13 stored as values in memory (estimated size 506.4 KB, free 360.1 MB)
2021-05-19 02:48:04 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 454
2021-05-19 02:48:04 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 455
2021-05-19 02:48:04 INFO  Executor:54 - Running task 19.2 in stage 7.0 (TID 454)
2021-05-19 02:48:04 INFO  Executor:54 - Running task 29.2 in stage 7.0 (TID 455)
2021-05-19 02:48:04 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 456
2021-05-19 02:48:04 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 457
2021-05-19 02:48:04 INFO  Executor:54 - Running task 42.2 in stage 7.0 (TID 456)
2021-05-19 02:48:04 INFO  Executor:54 - Running task 8.2 in stage 7.0 (TID 457)
2021-05-19 02:48:04 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 458
2021-05-19 02:48:04 INFO  Executor:54 - Running task 22.2 in stage 7.0 (TID 458)
2021-05-19 02:48:04 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 459
2021-05-19 02:48:04 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 460
2021-05-19 02:48:04 INFO  Executor:54 - Running task 28.2 in stage 7.0 (TID 459)
2021-05-19 02:48:04 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 461
2021-05-19 02:48:04 INFO  Executor:54 - Running task 24.2 in stage 7.0 (TID 460)
2021-05-19 02:48:04 INFO  Executor:54 - Running task 12.2 in stage 7.0 (TID 461)
2021-05-19 02:48:04 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00012, range: 0-134217728, partition values: [empty row]
2021-05-19 02:48:04 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00042, range: 0-134217728, partition values: [empty row]
2021-05-19 02:48:04 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00028, range: 0-134217728, partition values: [empty row]
2021-05-19 02:48:04 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00024, range: 0-134217728, partition values: [empty row]
2021-05-19 02:48:04 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00008, range: 0-134217728, partition values: [empty row]
2021-05-19 02:48:04 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00019, range: 0-134217728, partition values: [empty row]
2021-05-19 02:48:04 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00029, range: 0-134217728, partition values: [empty row]
2021-05-19 02:48:04 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00022, range: 0-134217728, partition values: [empty row]
2021-05-19 02:48:05 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: 22f-222@627-s8x-c5z, 2020-10-26T00:00:00-04:00, [1,0,0,0,0,0,0]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: 22f-222@627-s8x-c5z
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00042
2021-05-19 02:48:05 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: 22n-224@627-wc7-qfz, 2018-12-31T00:00:00-05:00, [4,2,14,28,22,22,26]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: 22n-224@627-wc7-qfz
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00008
2021-05-19 02:48:05 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: 226-225@627-wc8-73q, 2018-12-31T00:00:00-05:00, [1,6,18,10,12,12,18]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: 226-225@627-wc8-73q
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00009
2021-05-19 02:48:05 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: zzw-226@627-wc7-49z, 2019-02-11T00:00:00-05:00, [26,15,15,20,33,6,11]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: zzw-226@627-wc7-49z
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00022
2021-05-19 02:48:05 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: 22j-222@627-wc7-8jv, 2019-05-13T00:00:00-04:00, [1,1,0,2,2,4,1]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: 22j-222@627-wc7-8jv
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00028
2021-05-19 02:48:05 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: 25p-222@627-s8j-94v, 2020-06-08T00:00:00-04:00, [1,1,0,2,0,0,0]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: 25p-222@627-s8j-94v
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00043
2021-05-19 02:48:05 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: 22c-222@627-vv6-vvf, 2019-12-16T00:00:00-05:00, [0,0,0,0,1,0,0]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: 22c-222@627-vv6-vvf
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00019
2021-05-19 02:48:05 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: zzy-222@627-s93-26k, 2019-12-02T00:00:00-05:00, [4,6,9,13,8,11,4]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: zzy-222@627-s93-26k
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00029
2021-05-19 02:48:05 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: 22p-222@627-s5x-c3q, 2018-12-31T00:00:00-05:00, [3,2,4,4,4,6,0]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: 22p-222@627-s5x-c3q
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00012
2021-05-19 02:48:05 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: 224-222@627-s8r-975, 2019-12-02T00:00:00-05:00, [15,24,17,27,24,13,21]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: 224-222@627-s8r-975
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00024
2021-05-19 02:48:06 INFO  CodeGenerator:54 - Code generated in 16.466528 ms
2021-05-19 02:48:06 INFO  CodeGenerator:54 - Code generated in 54.306936 ms
2021-05-19 02:48:06 INFO  CodeGenerator:54 - Code generated in 31.297718 ms
2021-05-19 02:48:06 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:48:06 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:48:06 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:48:06 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:48:06 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:48:06 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:48:06 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:48:06 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:48:06 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:48:06 INFO  CodeGenerator:54 - Code generated in 50.873623 ms
2021-05-19 02:48:06 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:48:06 INFO  CodeGenerator:54 - Code generated in 28.118863 ms
2021-05-19 02:48:07 INFO  CodeGenerator:54 - Code generated in 20.840399 ms
2021-05-19 02:48:07 INFO  CodeGenerator:54 - Code generated in 21.788977 ms
2021-05-19 02:48:16 INFO  Executor:54 - Executor is trying to kill task 22.2 in stage 7.0 (TID 458), reason: Stage cancelled
2021-05-19 02:48:16 INFO  Executor:54 - Executor is trying to kill task 28.2 in stage 7.0 (TID 459), reason: Stage cancelled
2021-05-19 02:48:16 INFO  Executor:54 - Executor is trying to kill task 24.2 in stage 7.0 (TID 460), reason: Stage cancelled
2021-05-19 02:48:16 INFO  Executor:54 - Executor is trying to kill task 12.2 in stage 7.0 (TID 461), reason: Stage cancelled
2021-05-19 02:48:16 INFO  Executor:54 - Executor is trying to kill task 19.2 in stage 7.0 (TID 454), reason: Stage cancelled
2021-05-19 02:48:16 INFO  Executor:54 - Executor is trying to kill task 29.2 in stage 7.0 (TID 455), reason: Stage cancelled
2021-05-19 02:48:16 INFO  Executor:54 - Executor is trying to kill task 42.2 in stage 7.0 (TID 456), reason: Stage cancelled
2021-05-19 02:48:16 INFO  Executor:54 - Executor is trying to kill task 9.3 in stage 7.0 (TID 442), reason: Stage cancelled
2021-05-19 02:48:16 INFO  Executor:54 - Executor is trying to kill task 43.3 in stage 7.0 (TID 443), reason: Stage cancelled
2021-05-19 02:48:16 INFO  Executor:54 - Executor is trying to kill task 8.2 in stage 7.0 (TID 457), reason: Stage cancelled
2021-05-19 02:48:16 INFO  Executor:54 - Executor killed task 29.2 in stage 7.0 (TID 455), reason: Stage cancelled
2021-05-19 02:48:16 INFO  Executor:54 - Executor killed task 28.2 in stage 7.0 (TID 459), reason: Stage cancelled
2021-05-19 02:48:16 INFO  Executor:54 - Executor killed task 9.3 in stage 7.0 (TID 442), reason: Stage cancelled
2021-05-19 02:48:16 INFO  Executor:54 - Executor killed task 43.3 in stage 7.0 (TID 443), reason: Stage cancelled
2021-05-19 02:48:16 INFO  Executor:54 - Executor killed task 19.2 in stage 7.0 (TID 454), reason: Stage cancelled
2021-05-19 02:48:16 INFO  Executor:54 - Executor killed task 24.2 in stage 7.0 (TID 460), reason: Stage cancelled
2021-05-19 02:48:16 INFO  Executor:54 - Executor killed task 8.2 in stage 7.0 (TID 457), reason: Stage cancelled
2021-05-19 02:48:16 INFO  Executor:54 - Executor killed task 42.2 in stage 7.0 (TID 456), reason: Stage cancelled
2021-05-19 02:48:16 INFO  Executor:54 - Executor killed task 12.2 in stage 7.0 (TID 461), reason: Stage cancelled
2021-05-19 02:48:16 INFO  Executor:54 - Executor killed task 22.2 in stage 7.0 (TID 458), reason: Stage cancelled
2021-05-19 02:48:16 INFO  CoarseGrainedExecutorBackend:54 - Driver commanded a shutdown
2021-05-19 02:48:16 INFO  MemoryStore:54 - MemoryStore cleared
2021-05-19 02:48:16 INFO  BlockManager:54 - BlockManager stopped
2021-05-19 02:48:16 INFO  ShutdownHookManager:54 - Shutdown hook called
2021-05-19 02:48:16 INFO  ShutdownHookManager:54 - Deleting directory /localhome/cdp/yarn/nm/usercache/catherine.ng60/appcache/application_1609183734776_5900/spark-66120037-ec77-4fa5-b77e-cae0f9c5635d

End of LogType:stdout
***********************************************************************

Container: container_e10_1609183734776_5900_01_000009 on hadoop13.cusp.nyu.edu_8041
LogAggregationType: AGGREGATED
===================================================================================
LogType:container-localizer-syslog
LogLastModifiedTime:Wed May 19 02:48:18 -0400 2021
LogLength:506
LogContents:
2021-05-19 02:46:11,388 INFO [main] org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ContainerLocalizer: Disk Validator: yarn.nodemanager.disk-validator is loaded.
2021-05-19 02:46:12,645 WARN [ContainerLocalizer Downloader] org.apache.hadoop.ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ipc.StandbyException): Operation category READ is not supported in state standby. Visit https://s.apache.org/sbnn-error

End of LogType:container-localizer-syslog
*******************************************************************************************


End of LogType:prelaunch.err
******************************************************************************

Container: container_e10_1609183734776_5900_01_000009 on hadoop13.cusp.nyu.edu_8041
LogAggregationType: AGGREGATED
===================================================================================
LogType:prelaunch.out
LogLastModifiedTime:Wed May 19 02:48:18 -0400 2021
LogLength:70
LogContents:
Setting up env variables
Setting up job resources
Launching container

End of LogType:prelaunch.out
******************************************************************************

Container: container_e10_1609183734776_5900_01_000009 on hadoop13.cusp.nyu.edu_8041
LogAggregationType: AGGREGATED
===================================================================================
LogType:stderr
LogLastModifiedTime:Wed May 19 02:48:18 -0400 2021
LogLength:529
LogContents:
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/localhome/cdp/yarn/nm/filecache/23/spark-jars-2.4.0-hadoop2.7.jar/slf4j-log4j12-1.7.16.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-6.1.0-1.cdh6.1.0.p0.770702/jars/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]

End of LogType:stderr
***********************************************************************

Container: container_e10_1609183734776_5900_01_000009 on hadoop13.cusp.nyu.edu_8041
LogAggregationType: AGGREGATED
===================================================================================
LogType:stdout
LogLastModifiedTime:Wed May 19 02:48:18 -0400 2021
LogLength:48387
LogContents:
2021-05-19 02:46:14 INFO  CoarseGrainedExecutorBackend:2566 - Started daemon with process name: 14328@hadoop13.cusp.nyu.edu
2021-05-19 02:46:14 INFO  SignalUtils:54 - Registered signal handler for TERM
2021-05-19 02:46:14 INFO  SignalUtils:54 - Registered signal handler for HUP
2021-05-19 02:46:14 INFO  SignalUtils:54 - Registered signal handler for INT
2021-05-19 02:46:15 INFO  SecurityManager:54 - Changing view acls to: catherine.ng60
2021-05-19 02:46:15 INFO  SecurityManager:54 - Changing modify acls to: catherine.ng60
2021-05-19 02:46:15 INFO  SecurityManager:54 - Changing view acls groups to: 
2021-05-19 02:46:15 INFO  SecurityManager:54 - Changing modify acls groups to: 
2021-05-19 02:46:15 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(catherine.ng60); groups with view permissions: Set(); users  with modify permissions: Set(catherine.ng60); groups with modify permissions: Set()
2021-05-19 02:46:15 INFO  TransportClientFactory:267 - Successfully created connection to hadoop05.cusp.nyu.edu/192.168.72.175:47481 after 119 ms (0 ms spent in bootstraps)
2021-05-19 02:46:15 INFO  SecurityManager:54 - Changing view acls to: catherine.ng60
2021-05-19 02:46:15 INFO  SecurityManager:54 - Changing modify acls to: catherine.ng60
2021-05-19 02:46:15 INFO  SecurityManager:54 - Changing view acls groups to: 
2021-05-19 02:46:15 INFO  SecurityManager:54 - Changing modify acls groups to: 
2021-05-19 02:46:15 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(catherine.ng60); groups with view permissions: Set(); users  with modify permissions: Set(catherine.ng60); groups with modify permissions: Set()
2021-05-19 02:46:16 INFO  TransportClientFactory:267 - Successfully created connection to hadoop05.cusp.nyu.edu/192.168.72.175:47481 after 4 ms (0 ms spent in bootstraps)
2021-05-19 02:46:16 INFO  DiskBlockManager:54 - Created local directory at /localhome/cdp/yarn/nm/usercache/catherine.ng60/appcache/application_1609183734776_5900/blockmgr-c3e35176-3ca5-47c1-8dc8-bab45de6a719
2021-05-19 02:46:16 INFO  MemoryStore:54 - MemoryStore started with capacity 366.3 MB
2021-05-19 02:46:16 INFO  CoarseGrainedExecutorBackend:54 - Connecting to driver: spark://CoarseGrainedScheduler@hadoop05.cusp.nyu.edu:47481
2021-05-19 02:46:16 INFO  CoarseGrainedExecutorBackend:54 - Successfully registered with driver
2021-05-19 02:46:16 INFO  Executor:54 - Starting executor ID 8 on host hadoop13.cusp.nyu.edu
2021-05-19 02:46:16 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 38130.
2021-05-19 02:46:16 INFO  NettyBlockTransferService:54 - Server created on hadoop13.cusp.nyu.edu:38130
2021-05-19 02:46:16 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2021-05-19 02:46:16 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(8, hadoop13.cusp.nyu.edu, 38130, None)
2021-05-19 02:46:16 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(8, hadoop13.cusp.nyu.edu, 38130, None)
2021-05-19 02:46:16 INFO  BlockManager:54 - external shuffle service port = 7337
2021-05-19 02:46:16 INFO  BlockManager:54 - Registering executor with local external shuffle service.
2021-05-19 02:46:16 INFO  TransportClientFactory:267 - Successfully created connection to hadoop13.cusp.nyu.edu/192.168.72.183:7337 after 3 ms (0 ms spent in bootstraps)
2021-05-19 02:46:16 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(8, hadoop13.cusp.nyu.edu, 38130, None)
2021-05-19 02:46:16 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 397
2021-05-19 02:46:16 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 398
2021-05-19 02:46:16 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 399
2021-05-19 02:46:16 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 400
2021-05-19 02:46:16 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 401
2021-05-19 02:46:16 INFO  Executor:54 - Running task 9.1 in stage 7.0 (TID 397)
2021-05-19 02:46:16 INFO  Executor:54 - Running task 4.1 in stage 7.0 (TID 398)
2021-05-19 02:46:16 INFO  Executor:54 - Running task 20.1 in stage 7.0 (TID 399)
2021-05-19 02:46:16 INFO  Executor:54 - Running task 43.1 in stage 7.0 (TID 400)
2021-05-19 02:46:16 INFO  Executor:54 - Running task 52.0 in stage 7.0 (TID 401)
2021-05-19 02:46:16 INFO  MapOutputTrackerWorker:54 - Updating epoch to 1 and clearing cache
2021-05-19 02:46:16 INFO  TorrentBroadcast:54 - Started reading broadcast variable 14
2021-05-19 02:46:16 INFO  TransportClientFactory:267 - Successfully created connection to hadoop05.cusp.nyu.edu/192.168.72.175:36982 after 5 ms (0 ms spent in bootstraps)
2021-05-19 02:46:16 INFO  MemoryStore:54 - Block broadcast_14_piece0 stored as bytes in memory (estimated size 22.9 KB, free 366.3 MB)
2021-05-19 02:46:16 INFO  TorrentBroadcast:54 - Reading broadcast variable 14 took 130 ms
2021-05-19 02:46:17 INFO  MemoryStore:54 - Block broadcast_14 stored as values in memory (estimated size 51.5 KB, free 366.2 MB)
2021-05-19 02:46:18 INFO  CodeGenerator:54 - Code generated in 313.426195 ms
2021-05-19 02:46:18 INFO  TorrentBroadcast:54 - Started reading broadcast variable 12
2021-05-19 02:46:18 INFO  MemoryStore:54 - Block broadcast_12_piece0 stored as bytes in memory (estimated size 580.1 KB, free 365.7 MB)
2021-05-19 02:46:18 INFO  TorrentBroadcast:54 - Reading broadcast variable 12 took 38 ms
2021-05-19 02:46:18 INFO  MemoryStore:54 - Block broadcast_12 stored as values in memory (estimated size 5.0 MB, free 360.7 MB)
2021-05-19 02:46:18 INFO  CodeGenerator:54 - Code generated in 32.651156 ms
2021-05-19 02:46:19 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00004, range: 0-134217728, partition values: [empty row]
2021-05-19 02:46:19 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00043, range: 0-134217728, partition values: [empty row]
2021-05-19 02:46:19 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00020, range: 0-134217728, partition values: [empty row]
2021-05-19 02:46:19 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00009, range: 0-134217728, partition values: [empty row]
2021-05-19 02:46:19 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00004, range: 134217728-178480909, partition values: [empty row]
2021-05-19 02:46:19 INFO  CodeGenerator:54 - Code generated in 52.035977 ms
2021-05-19 02:46:19 INFO  TorrentBroadcast:54 - Started reading broadcast variable 13
2021-05-19 02:46:19 INFO  CodeGenerator:54 - Code generated in 61.770895 ms
2021-05-19 02:46:19 INFO  TransportClientFactory:267 - Successfully created connection to hadoop02.cusp.nyu.edu/192.168.72.172:45477 after 4 ms (0 ms spent in bootstraps)
2021-05-19 02:46:19 INFO  CodeGenerator:54 - Code generated in 31.831119 ms
2021-05-19 02:46:19 INFO  CodeGenerator:54 - Code generated in 35.959127 ms
2021-05-19 02:46:19 INFO  CodeGenerator:54 - Code generated in 19.971654 ms
2021-05-19 02:46:19 INFO  MemoryStore:54 - Block broadcast_13_piece0 stored as bytes in memory (estimated size 33.4 KB, free 360.6 MB)
2021-05-19 02:46:19 INFO  TorrentBroadcast:54 - Reading broadcast variable 13 took 165 ms
2021-05-19 02:46:19 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 411
2021-05-19 02:46:19 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 414
2021-05-19 02:46:19 INFO  Executor:54 - Running task 10.2 in stage 7.0 (TID 411)
2021-05-19 02:46:19 INFO  Executor:54 - Running task 50.2 in stage 7.0 (TID 414)
2021-05-19 02:46:19 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 416
2021-05-19 02:46:19 INFO  Executor:54 - Running task 44.1 in stage 7.0 (TID 416)
2021-05-19 02:46:19 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 418
2021-05-19 02:46:19 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 420
2021-05-19 02:46:19 INFO  Executor:54 - Running task 40.1 in stage 7.0 (TID 418)
2021-05-19 02:46:19 INFO  Executor:54 - Running task 3.1 in stage 7.0 (TID 420)
2021-05-19 02:46:20 INFO  MemoryStore:54 - Block broadcast_13 stored as values in memory (estimated size 506.4 KB, free 360.1 MB)
2021-05-19 02:46:20 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00040, range: 0-134217728, partition values: [empty row]
2021-05-19 02:46:20 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00003, range: 0-134217728, partition values: [empty row]
2021-05-19 02:46:20 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00010, range: 0-134217728, partition values: [empty row]
2021-05-19 02:46:20 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00010, range: 134217728-179164944, partition values: [empty row]
2021-05-19 02:46:20 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00044, range: 0-134217728, partition values: [empty row]
2021-05-19 02:46:21 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: 226-225@627-wc8-73q, 2018-12-31T00:00:00-05:00, [1,6,18,10,12,12,18]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: 226-225@627-wc8-73q
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00009
2021-05-19 02:46:21 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: 22z-222@627-rw8-28v, 2018-12-31T00:00:00-05:00, [5,22,30,30,30,14,16]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: 22z-222@627-rw8-28v
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00003
2021-05-19 02:46:21 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: 22x-224@627-s8r-c89, 2018-12-31T00:00:00-05:00, [21,42,46,76,70,52,8]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: 22x-224@627-s8r-c89
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00010
2021-05-19 02:46:21 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: 25p-222@627-s8j-94v, 2020-06-08T00:00:00-04:00, [1,1,0,2,0,0,0]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: 25p-222@627-s8j-94v
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00043
2021-05-19 02:46:21 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: 227-222@627-s4n-x3q, 2019-06-10T00:00:00-04:00, [7,4,4,0,7,11,3]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: 227-222@627-s4n-x3q
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00044
2021-05-19 02:46:21 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: 22t-224@627-s8k-2zf, 2019-09-09T00:00:00-04:00, [9,7,9,3,7,4,5]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: 22t-224@627-s8k-2zf
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00020
2021-05-19 02:46:21 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: 223-222@627-s6d-9vf, 2018-12-31T00:00:00-05:00, [57,70,74,72,80,86,66]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: 223-222@627-s6d-9vf
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00004
2021-05-19 02:46:21 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: zzw-222@627-s4s-nqz, 2019-04-22T00:00:00-04:00, [6,10,4,9,4,6,2]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: zzw-222@627-s4s-nqz
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00040
2021-05-19 02:46:22 INFO  CodeGenerator:54 - Code generated in 53.464802 ms
2021-05-19 02:46:22 INFO  CodeGenerator:54 - Code generated in 28.203138 ms
2021-05-19 02:46:22 INFO  CodeGenerator:54 - Code generated in 26.630188 ms
2021-05-19 02:46:23 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:46:23 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:46:23 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:46:23 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:46:23 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:46:23 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:46:23 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:46:23 INFO  CodeGenerator:54 - Code generated in 76.64128 ms
2021-05-19 02:46:23 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:46:23 INFO  CodeGenerator:54 - Code generated in 28.225507 ms
2021-05-19 02:46:23 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:46:23 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:46:23 INFO  CodeGenerator:54 - Code generated in 24.289918 ms
2021-05-19 02:46:23 INFO  CodeGenerator:54 - Code generated in 17.932841 ms
2021-05-19 02:46:23 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00003, range: 134217728-178774105, partition values: [empty row]
2021-05-19 02:46:24 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00037, range: 134217728-178478348, partition values: [empty row]
2021-05-19 02:46:31 INFO  PythonUDFRunner:54 - Times: total = 13080, boot = 751, init = 2604, finish = 9725
2021-05-19 02:46:32 INFO  PythonUDFRunner:54 - Times: total = 12041, boot = 27, init = 2126, finish = 9888
2021-05-19 02:46:32 INFO  CodeGenerator:54 - Code generated in 28.895923 ms
2021-05-19 02:46:32 INFO  Executor:54 - Finished task 52.0 in stage 7.0 (TID 401). 4313 bytes result sent to driver
2021-05-19 02:46:32 INFO  Executor:54 - Finished task 50.2 in stage 7.0 (TID 414). 4270 bytes result sent to driver
2021-05-19 02:46:32 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 428
2021-05-19 02:46:32 INFO  Executor:54 - Running task 41.2 in stage 7.0 (TID 428)
2021-05-19 02:46:32 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 429
2021-05-19 02:46:32 INFO  Executor:54 - Running task 5.2 in stage 7.0 (TID 429)
2021-05-19 02:46:32 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00041, range: 0-134217728, partition values: [empty row]
2021-05-19 02:46:32 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00005, range: 0-134217728, partition values: [empty row]
2021-05-19 02:46:32 INFO  PythonUDFRunner:54 - Times: total = 12811, boot = 17, init = 2136, finish = 10658
2021-05-19 02:46:32 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: zzw-222@627-s65-bx5, 2020-09-28T00:00:00-04:00, [0,1,0,2,0,0,0]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: zzw-222@627-s65-bx5
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00041
2021-05-19 02:46:32 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: 222-222@627-s95-rc5, 2018-12-31T00:00:00-05:00, [5,6,50,52,24,0,0]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: 222-222@627-s95-rc5
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00005
2021-05-19 02:46:33 INFO  PythonUDFRunner:54 - Times: total = 13313, boot = 11, init = 2144, finish = 11158
2021-05-19 02:46:33 INFO  PythonUDFRunner:54 - Times: total = 14555, boot = 718, init = 2676, finish = 11161
2021-05-19 02:46:33 INFO  Executor:54 - Finished task 10.2 in stage 7.0 (TID 411). 4270 bytes result sent to driver
2021-05-19 02:46:33 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 431
2021-05-19 02:46:33 INFO  Executor:54 - Running task 14.2 in stage 7.0 (TID 431)
2021-05-19 02:46:33 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00014, range: 0-134217728, partition values: [empty row]
2021-05-19 02:46:33 INFO  PythonUDFRunner:54 - Times: total = 14604, boot = 739, init = 2653, finish = 11212
2021-05-19 02:46:33 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: 222-222@627-wgb-qxq, 2019-01-07T00:00:00-05:00, [408,482,574,546,236,93,103]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: 222-222@627-wgb-qxq
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00014
2021-05-19 02:46:33 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:46:33 INFO  PythonUDFRunner:54 - Times: total = 14787, boot = 703, init = 2694, finish = 11390
2021-05-19 02:46:33 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:46:33 INFO  Executor:54 - Finished task 4.1 in stage 7.0 (TID 398). 4313 bytes result sent to driver
2021-05-19 02:46:33 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 432
2021-05-19 02:46:33 INFO  Executor:54 - Running task 26.1 in stage 7.0 (TID 432)
2021-05-19 02:46:33 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00026, range: 0-134217728, partition values: [empty row]
2021-05-19 02:46:33 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: 22h-223@627-s84-6hq, 2019-08-05T00:00:00-04:00, [2,2,0,2,1,3,1]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: 22h-223@627-s84-6hq
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00026
2021-05-19 02:46:34 INFO  Executor:54 - Finished task 40.1 in stage 7.0 (TID 418). 4270 bytes result sent to driver
2021-05-19 02:46:34 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 433
2021-05-19 02:46:34 INFO  Executor:54 - Running task 23.2 in stage 7.0 (TID 433)
2021-05-19 02:46:34 INFO  PythonUDFRunner:54 - Times: total = 13944, boot = 38, init = 2113, finish = 11793
2021-05-19 02:46:34 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00023, range: 0-134217728, partition values: [empty row]
2021-05-19 02:46:34 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: 22b-222@627-s4r-s3q, 2019-11-04T00:00:00-05:00, [20,15,14,25,21,16,15]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: 22b-222@627-s4r-s3q
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00023
2021-05-19 02:46:34 INFO  Executor:54 - Finished task 43.1 in stage 7.0 (TID 400). 4313 bytes result sent to driver
2021-05-19 02:46:34 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 434
2021-05-19 02:46:34 INFO  Executor:54 - Running task 34.2 in stage 7.0 (TID 434)
2021-05-19 02:46:34 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00034, range: 0-134217728, partition values: [empty row]
2021-05-19 02:46:34 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: zzw-222@627-s6d-wx5, 2019-12-02T00:00:00-05:00, [1,1,0,0,0,4,5]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: zzw-222@627-s6d-wx5
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00034
2021-05-19 02:46:34 INFO  Executor:54 - Finished task 20.1 in stage 7.0 (TID 399). 4270 bytes result sent to driver
2021-05-19 02:46:34 INFO  PythonUDFRunner:54 - Times: total = 15363, boot = 728, init = 2631, finish = 12004
2021-05-19 02:46:34 INFO  PythonUDFRunner:54 - Times: total = 14416, boot = 16, init = 2181, finish = 12219
2021-05-19 02:46:34 INFO  Executor:54 - Finished task 44.1 in stage 7.0 (TID 416). 4270 bytes result sent to driver
2021-05-19 02:46:34 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:46:34 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:46:34 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:46:34 INFO  Executor:54 - Finished task 9.1 in stage 7.0 (TID 397). 4270 bytes result sent to driver
2021-05-19 02:46:34 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:46:34 INFO  Executor:54 - Finished task 3.1 in stage 7.0 (TID 420). 4270 bytes result sent to driver
2021-05-19 02:46:35 ERROR CoarseGrainedExecutorBackend:43 - RECEIVED SIGNAL TERM
2021-05-19 02:46:35 INFO  DiskBlockManager:54 - Shutdown hook called
2021-05-19 02:46:35 INFO  ShutdownHookManager:54 - Shutdown hook called
2021-05-19 02:46:35 INFO  ShutdownHookManager:54 - Deleting directory /localhome/cdp/yarn/nm/usercache/catherine.ng60/appcache/application_1609183734776_5900/spark-a0130b5d-a311-424e-a3ff-7ea577a1a586
2021-05-19 02:46:35 ERROR TaskContextImpl:91 - Error in TaskCompletionListener
java.io.IOException: Filesystem closed
	at org.apache.hadoop.hdfs.DFSClient.checkOpen(DFSClient.java:808)
	at org.apache.hadoop.hdfs.DFSInputStream.close(DFSInputStream.java:710)
	at java.io.FilterInputStream.close(FilterInputStream.java:181)
	at org.apache.hadoop.util.LineReader.close(LineReader.java:150)
	at org.apache.hadoop.mapreduce.lib.input.LineRecordReader.close(LineRecordReader.java:231)
	at org.apache.spark.sql.execution.datasources.RecordReaderIterator.close(RecordReaderIterator.scala:62)
	at org.apache.spark.sql.execution.datasources.HadoopFileLinesReader.close(HadoopFileLinesReader.scala:73)
	at org.apache.spark.sql.execution.datasources.csv.TextInputCSVDataSource$$anonfun$4$$anonfun$apply$2.apply(CSVDataSource.scala:200)
	at org.apache.spark.sql.execution.datasources.csv.TextInputCSVDataSource$$anonfun$4$$anonfun$apply$2.apply(CSVDataSource.scala:200)
	at org.apache.spark.TaskContext$$anon$1.onTaskCompletion(TaskContext.scala:131)
	at org.apache.spark.TaskContextImpl$$anonfun$markTaskCompleted$1.apply(TaskContextImpl.scala:117)
	at org.apache.spark.TaskContextImpl$$anonfun$markTaskCompleted$1.apply(TaskContextImpl.scala:117)
	at org.apache.spark.TaskContextImpl$$anonfun$invokeListeners$1.apply(TaskContextImpl.scala:130)
	at org.apache.spark.TaskContextImpl$$anonfun$invokeListeners$1.apply(TaskContextImpl.scala:128)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.TaskContextImpl.invokeListeners(TaskContextImpl.scala:128)
	at org.apache.spark.TaskContextImpl.markTaskCompleted(TaskContextImpl.scala:116)
	at org.apache.spark.scheduler.Task.run(Task.scala:131)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:402)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:408)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2021-05-19 02:46:35 ERROR Executor:91 - Exception in task 34.2 in stage 7.0 (TID 434)
org.apache.spark.util.TaskCompletionListenerException: Filesystem closed

Previous exception in task: Filesystem closed
	org.apache.hadoop.hdfs.DFSClient.checkOpen(DFSClient.java:808)
	org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:868)
	org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:934)
	java.io.DataInputStream.read(DataInputStream.java:149)
	org.apache.hadoop.mapreduce.lib.input.UncompressedSplitLineReader.fillBuffer(UncompressedSplitLineReader.java:62)
	org.apache.hadoop.util.LineReader.readDefaultLine(LineReader.java:216)
	org.apache.hadoop.util.LineReader.readLine(LineReader.java:174)
	org.apache.hadoop.mapreduce.lib.input.UncompressedSplitLineReader.readLine(UncompressedSplitLineReader.java:94)
	org.apache.hadoop.mapreduce.lib.input.LineRecordReader.nextKeyValue(LineRecordReader.java:186)
	org.apache.spark.sql.execution.datasources.RecordReaderIterator.hasNext(RecordReaderIterator.scala:39)
	org.apache.spark.sql.execution.datasources.HadoopFileLinesReader.hasNext(HadoopFileLinesReader.scala:69)
	scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:462)
	scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:101)
	org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source)
	org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$11$$anon$1.hasNext(WholeStageCodegenExec.scala:619)
	scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	scala.collection.Iterator$GroupedIterator.takeDestructively(Iterator.scala:1073)
	scala.collection.Iterator$GroupedIterator.go(Iterator.scala:1089)
	scala.collection.Iterator$GroupedIterator.fill(Iterator.scala:1127)
	scala.collection.Iterator$GroupedIterator.hasNext(Iterator.scala:1130)
	scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	scala.collection.Iterator$class.foreach(Iterator.scala:891)
	scala.collection.AbstractIterator.foreach(Iterator.scala:1334)
	org.apache.spark.api.python.PythonRDD$.writeIteratorToStream(PythonRDD.scala:224)
	org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$2.writeIteratorToStream(PythonUDFRunner.scala:50)
	org.apache.spark.api.python.BasePythonRunner$WriterThread$$anonfun$run$1.apply(PythonRunner.scala:345)
	org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1945)
	org.apache.spark.api.python.BasePythonRunner$WriterThread.run(PythonRunner.scala:194)
	at org.apache.spark.TaskContextImpl.invokeListeners(TaskContextImpl.scala:138)
	at org.apache.spark.TaskContextImpl.markTaskCompleted(TaskContextImpl.scala:116)
	at org.apache.spark.scheduler.Task.run(Task.scala:131)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:402)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:408)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2021-05-19 02:46:35 INFO  Executor:54 - Not reporting error to driver during JVM shutdown.
2021-05-19 02:46:35 ERROR TaskContextImpl:91 - Error in TaskCompletionListener
java.io.IOException: Filesystem closed
	at org.apache.hadoop.hdfs.DFSClient.checkOpen(DFSClient.java:808)
	at org.apache.hadoop.hdfs.DFSInputStream.close(DFSInputStream.java:710)
	at java.io.FilterInputStream.close(FilterInputStream.java:181)
	at org.apache.hadoop.util.LineReader.close(LineReader.java:150)
	at org.apache.hadoop.mapreduce.lib.input.LineRecordReader.close(LineRecordReader.java:231)
	at org.apache.spark.sql.execution.datasources.RecordReaderIterator.close(RecordReaderIterator.scala:62)
	at org.apache.spark.sql.execution.datasources.HadoopFileLinesReader.close(HadoopFileLinesReader.scala:73)
	at org.apache.spark.sql.execution.datasources.csv.TextInputCSVDataSource$$anonfun$4$$anonfun$apply$2.apply(CSVDataSource.scala:200)
	at org.apache.spark.sql.execution.datasources.csv.TextInputCSVDataSource$$anonfun$4$$anonfun$apply$2.apply(CSVDataSource.scala:200)
	at org.apache.spark.TaskContext$$anon$1.onTaskCompletion(TaskContext.scala:131)
	at org.apache.spark.TaskContextImpl$$anonfun$markTaskCompleted$1.apply(TaskContextImpl.scala:117)
	at org.apache.spark.TaskContextImpl$$anonfun$markTaskCompleted$1.apply(TaskContextImpl.scala:117)
	at org.apache.spark.TaskContextImpl$$anonfun$invokeListeners$1.apply(TaskContextImpl.scala:130)
	at org.apache.spark.TaskContextImpl$$anonfun$invokeListeners$1.apply(TaskContextImpl.scala:128)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.TaskContextImpl.invokeListeners(TaskContextImpl.scala:128)
	at org.apache.spark.TaskContextImpl.markTaskCompleted(TaskContextImpl.scala:116)
	at org.apache.spark.scheduler.Task.run(Task.scala:131)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:402)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:408)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2021-05-19 02:46:35 ERROR Executor:91 - Exception in task 26.1 in stage 7.0 (TID 432)
org.apache.spark.util.TaskCompletionListenerException: Filesystem closed

Previous exception in task: Filesystem closed
	org.apache.hadoop.hdfs.DFSClient.checkOpen(DFSClient.java:808)
	org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:868)
	org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:934)
	java.io.DataInputStream.read(DataInputStream.java:149)
	org.apache.hadoop.mapreduce.lib.input.UncompressedSplitLineReader.fillBuffer(UncompressedSplitLineReader.java:62)
	org.apache.hadoop.util.LineReader.readDefaultLine(LineReader.java:216)
	org.apache.hadoop.util.LineReader.readLine(LineReader.java:174)
	org.apache.hadoop.mapreduce.lib.input.UncompressedSplitLineReader.readLine(UncompressedSplitLineReader.java:94)
	org.apache.hadoop.mapreduce.lib.input.LineRecordReader.nextKeyValue(LineRecordReader.java:186)
	org.apache.spark.sql.execution.datasources.RecordReaderIterator.hasNext(RecordReaderIterator.scala:39)
	org.apache.spark.sql.execution.datasources.HadoopFileLinesReader.hasNext(HadoopFileLinesReader.scala:69)
	scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:462)
	scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:101)
	org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source)
	org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$11$$anon$1.hasNext(WholeStageCodegenExec.scala:619)
	scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	scala.collection.Iterator$GroupedIterator.takeDestructively(Iterator.scala:1073)
	scala.collection.Iterator$GroupedIterator.go(Iterator.scala:1089)
	scala.collection.Iterator$GroupedIterator.fill(Iterator.scala:1127)
	scala.collection.Iterator$GroupedIterator.hasNext(Iterator.scala:1130)
	scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	scala.collection.Iterator$class.foreach(Iterator.scala:891)
	scala.collection.AbstractIterator.foreach(Iterator.scala:1334)
	org.apache.spark.api.python.PythonRDD$.writeIteratorToStream(PythonRDD.scala:224)
	org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$2.writeIteratorToStream(PythonUDFRunner.scala:50)
	org.apache.spark.api.python.BasePythonRunner$WriterThread$$anonfun$run$1.apply(PythonRunner.scala:345)
	org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1945)
	org.apache.spark.api.python.BasePythonRunner$WriterThread.run(PythonRunner.scala:194)
	at org.apache.spark.TaskContextImpl.invokeListeners(TaskContextImpl.scala:138)
	at org.apache.spark.TaskContextImpl.markTaskCompleted(TaskContextImpl.scala:116)
	at org.apache.spark.scheduler.Task.run(Task.scala:131)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:402)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:408)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2021-05-19 02:46:35 INFO  Executor:54 - Not reporting error to driver during JVM shutdown.
2021-05-19 02:46:35 ERROR TaskContextImpl:91 - Error in TaskCompletionListener
java.io.IOException: Filesystem closed
	at org.apache.hadoop.hdfs.DFSClient.checkOpen(DFSClient.java:808)
	at org.apache.hadoop.hdfs.DFSInputStream.close(DFSInputStream.java:710)
	at java.io.FilterInputStream.close(FilterInputStream.java:181)
	at org.apache.hadoop.util.LineReader.close(LineReader.java:150)
	at org.apache.hadoop.mapreduce.lib.input.LineRecordReader.close(LineRecordReader.java:231)
	at org.apache.spark.sql.execution.datasources.RecordReaderIterator.close(RecordReaderIterator.scala:62)
	at org.apache.spark.sql.execution.datasources.HadoopFileLinesReader.close(HadoopFileLinesReader.scala:73)
	at org.apache.spark.sql.execution.datasources.csv.TextInputCSVDataSource$$anonfun$4$$anonfun$apply$2.apply(CSVDataSource.scala:200)
	at org.apache.spark.sql.execution.datasources.csv.TextInputCSVDataSource$$anonfun$4$$anonfun$apply$2.apply(CSVDataSource.scala:200)
	at org.apache.spark.TaskContext$$anon$1.onTaskCompletion(TaskContext.scala:131)
	at org.apache.spark.TaskContextImpl$$anonfun$markTaskCompleted$1.apply(TaskContextImpl.scala:117)
	at org.apache.spark.TaskContextImpl$$anonfun$markTaskCompleted$1.apply(TaskContextImpl.scala:117)
	at org.apache.spark.TaskContextImpl$$anonfun$invokeListeners$1.apply(TaskContextImpl.scala:130)
	at org.apache.spark.TaskContextImpl$$anonfun$invokeListeners$1.apply(TaskContextImpl.scala:128)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.TaskContextImpl.invokeListeners(TaskContextImpl.scala:128)
	at org.apache.spark.TaskContextImpl.markTaskCompleted(TaskContextImpl.scala:116)
	at org.apache.spark.scheduler.Task.run(Task.scala:131)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:402)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:408)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2021-05-19 02:46:35 ERROR Executor:91 - Exception in task 5.2 in stage 7.0 (TID 429)
org.apache.spark.util.TaskCompletionListenerException: Filesystem closed

Previous exception in task: Filesystem closed
	org.apache.hadoop.hdfs.DFSClient.checkOpen(DFSClient.java:808)
	org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:868)
	org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:934)
	java.io.DataInputStream.read(DataInputStream.java:149)
	org.apache.hadoop.mapreduce.lib.input.UncompressedSplitLineReader.fillBuffer(UncompressedSplitLineReader.java:62)
	org.apache.hadoop.util.LineReader.readDefaultLine(LineReader.java:216)
	org.apache.hadoop.util.LineReader.readLine(LineReader.java:174)
	org.apache.hadoop.mapreduce.lib.input.UncompressedSplitLineReader.readLine(UncompressedSplitLineReader.java:94)
	org.apache.hadoop.mapreduce.lib.input.LineRecordReader.nextKeyValue(LineRecordReader.java:186)
	org.apache.spark.sql.execution.datasources.RecordReaderIterator.hasNext(RecordReaderIterator.scala:39)
	org.apache.spark.sql.execution.datasources.HadoopFileLinesReader.hasNext(HadoopFileLinesReader.scala:69)
	scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:462)
	scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:101)
	org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source)
	org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$11$$anon$1.hasNext(WholeStageCodegenExec.scala:619)
	scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	scala.collection.Iterator$GroupedIterator.takeDestructively(Iterator.scala:1073)
	scala.collection.Iterator$GroupedIterator.go(Iterator.scala:1089)
	scala.collection.Iterator$GroupedIterator.fill(Iterator.scala:1127)
	scala.collection.Iterator$GroupedIterator.hasNext(Iterator.scala:1130)
	scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	scala.collection.Iterator$class.foreach(Iterator.scala:891)
	scala.collection.AbstractIterator.foreach(Iterator.scala:1334)
	org.apache.spark.api.python.PythonRDD$.writeIteratorToStream(PythonRDD.scala:224)
	org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$2.writeIteratorToStream(PythonUDFRunner.scala:50)
	org.apache.spark.api.python.BasePythonRunner$WriterThread$$anonfun$run$1.apply(PythonRunner.scala:345)
	org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1945)
	org.apache.spark.api.python.BasePythonRunner$WriterThread.run(PythonRunner.scala:194)
	at org.apache.spark.TaskContextImpl.invokeListeners(TaskContextImpl.scala:138)
	at org.apache.spark.TaskContextImpl.markTaskCompleted(TaskContextImpl.scala:116)
	at org.apache.spark.scheduler.Task.run(Task.scala:131)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:402)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:408)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2021-05-19 02:46:35 ERROR TaskContextImpl:91 - Error in TaskCompletionListener
java.io.IOException: Filesystem closed
	at org.apache.hadoop.hdfs.DFSClient.checkOpen(DFSClient.java:808)
	at org.apache.hadoop.hdfs.DFSInputStream.close(DFSInputStream.java:710)
	at java.io.FilterInputStream.close(FilterInputStream.java:181)
	at org.apache.hadoop.util.LineReader.close(LineReader.java:150)
	at org.apache.hadoop.mapreduce.lib.input.LineRecordReader.close(LineRecordReader.java:231)
	at org.apache.spark.sql.execution.datasources.RecordReaderIterator.close(RecordReaderIterator.scala:62)
	at org.apache.spark.sql.execution.datasources.HadoopFileLinesReader.close(HadoopFileLinesReader.scala:73)
	at org.apache.spark.sql.execution.datasources.csv.TextInputCSVDataSource$$anonfun$4$$anonfun$apply$2.apply(CSVDataSource.scala:200)
	at org.apache.spark.sql.execution.datasources.csv.TextInputCSVDataSource$$anonfun$4$$anonfun$apply$2.apply(CSVDataSource.scala:200)
	at org.apache.spark.TaskContext$$anon$1.onTaskCompletion(TaskContext.scala:131)
	at org.apache.spark.TaskContextImpl$$anonfun$markTaskCompleted$1.apply(TaskContextImpl.scala:117)
	at org.apache.spark.TaskContextImpl$$anonfun$markTaskCompleted$1.apply(TaskContextImpl.scala:117)
	at org.apache.spark.TaskContextImpl$$anonfun$invokeListeners$1.apply(TaskContextImpl.scala:130)
	at org.apache.spark.TaskContextImpl$$anonfun$invokeListeners$1.apply(TaskContextImpl.scala:128)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.TaskContextImpl.invokeListeners(TaskContextImpl.scala:128)
	at org.apache.spark.TaskContextImpl.markTaskCompleted(TaskContextImpl.scala:116)
	at org.apache.spark.scheduler.Task.run(Task.scala:131)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:402)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:408)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2021-05-19 02:46:35 INFO  Executor:54 - Not reporting error to driver during JVM shutdown.
2021-05-19 02:46:35 ERROR Executor:91 - Exception in task 23.2 in stage 7.0 (TID 433)
org.apache.spark.util.TaskCompletionListenerException: Filesystem closed

Previous exception in task: Filesystem closed
	org.apache.hadoop.hdfs.DFSClient.checkOpen(DFSClient.java:808)
	org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:868)
	org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:934)
	java.io.DataInputStream.read(DataInputStream.java:149)
	org.apache.hadoop.mapreduce.lib.input.UncompressedSplitLineReader.fillBuffer(UncompressedSplitLineReader.java:62)
	org.apache.hadoop.util.LineReader.readDefaultLine(LineReader.java:216)
	org.apache.hadoop.util.LineReader.readLine(LineReader.java:174)
	org.apache.hadoop.mapreduce.lib.input.UncompressedSplitLineReader.readLine(UncompressedSplitLineReader.java:94)
	org.apache.hadoop.mapreduce.lib.input.LineRecordReader.nextKeyValue(LineRecordReader.java:186)
	org.apache.spark.sql.execution.datasources.RecordReaderIterator.hasNext(RecordReaderIterator.scala:39)
	org.apache.spark.sql.execution.datasources.HadoopFileLinesReader.hasNext(HadoopFileLinesReader.scala:69)
	scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:462)
	scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:101)
	org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source)
	org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$11$$anon$1.hasNext(WholeStageCodegenExec.scala:619)
	scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	scala.collection.Iterator$GroupedIterator.takeDestructively(Iterator.scala:1073)
	scala.collection.Iterator$GroupedIterator.go(Iterator.scala:1089)
	scala.collection.Iterator$GroupedIterator.fill(Iterator.scala:1127)
	scala.collection.Iterator$GroupedIterator.hasNext(Iterator.scala:1130)
	scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	scala.collection.Iterator$class.foreach(Iterator.scala:891)
	scala.collection.AbstractIterator.foreach(Iterator.scala:1334)
	org.apache.spark.api.python.PythonRDD$.writeIteratorToStream(PythonRDD.scala:224)
	org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$2.writeIteratorToStream(PythonUDFRunner.scala:50)
	org.apache.spark.api.python.BasePythonRunner$WriterThread$$anonfun$run$1.apply(PythonRunner.scala:345)
	org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1945)
	org.apache.spark.api.python.BasePythonRunner$WriterThread.run(PythonRunner.scala:194)
	at org.apache.spark.TaskContextImpl.invokeListeners(TaskContextImpl.scala:138)
	at org.apache.spark.TaskContextImpl.markTaskCompleted(TaskContextImpl.scala:116)
	at org.apache.spark.scheduler.Task.run(Task.scala:131)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:402)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:408)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2021-05-19 02:46:35 INFO  Executor:54 - Not reporting error to driver during JVM shutdown.

End of LogType:stdout
***********************************************************************


End of LogType:prelaunch.err
******************************************************************************

Container: container_e10_1609183734776_5900_02_000008 on hadoop13.cusp.nyu.edu_8041
LogAggregationType: AGGREGATED
===================================================================================
LogType:prelaunch.out
LogLastModifiedTime:Wed May 19 02:48:18 -0400 2021
LogLength:70
LogContents:
Setting up env variables
Setting up job resources
Launching container

End of LogType:prelaunch.out
******************************************************************************

Container: container_e10_1609183734776_5900_02_000008 on hadoop13.cusp.nyu.edu_8041
LogAggregationType: AGGREGATED
===================================================================================
LogType:stderr
LogLastModifiedTime:Wed May 19 02:48:18 -0400 2021
LogLength:529
LogContents:
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/localhome/cdp/yarn/nm/filecache/23/spark-jars-2.4.0-hadoop2.7.jar/slf4j-log4j12-1.7.16.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-6.1.0-1.cdh6.1.0.p0.770702/jars/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]

End of LogType:stderr
***********************************************************************

Container: container_e10_1609183734776_5900_02_000008 on hadoop13.cusp.nyu.edu_8041
LogAggregationType: AGGREGATED
===================================================================================
LogType:stdout
LogLastModifiedTime:Wed May 19 02:48:18 -0400 2021
LogLength:17473
LogContents:
2021-05-19 02:47:36 INFO  CoarseGrainedExecutorBackend:2566 - Started daemon with process name: 15353@hadoop13.cusp.nyu.edu
2021-05-19 02:47:36 INFO  SignalUtils:54 - Registered signal handler for TERM
2021-05-19 02:47:36 INFO  SignalUtils:54 - Registered signal handler for HUP
2021-05-19 02:47:36 INFO  SignalUtils:54 - Registered signal handler for INT
2021-05-19 02:47:37 INFO  SecurityManager:54 - Changing view acls to: catherine.ng60
2021-05-19 02:47:37 INFO  SecurityManager:54 - Changing modify acls to: catherine.ng60
2021-05-19 02:47:37 INFO  SecurityManager:54 - Changing view acls groups to: 
2021-05-19 02:47:37 INFO  SecurityManager:54 - Changing modify acls groups to: 
2021-05-19 02:47:37 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(catherine.ng60); groups with view permissions: Set(); users  with modify permissions: Set(catherine.ng60); groups with modify permissions: Set()
2021-05-19 02:47:37 INFO  TransportClientFactory:267 - Successfully created connection to hadoop02.cusp.nyu.edu/192.168.72.172:60108 after 113 ms (0 ms spent in bootstraps)
2021-05-19 02:47:37 INFO  SecurityManager:54 - Changing view acls to: catherine.ng60
2021-05-19 02:47:37 INFO  SecurityManager:54 - Changing modify acls to: catherine.ng60
2021-05-19 02:47:37 INFO  SecurityManager:54 - Changing view acls groups to: 
2021-05-19 02:47:37 INFO  SecurityManager:54 - Changing modify acls groups to: 
2021-05-19 02:47:37 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(catherine.ng60); groups with view permissions: Set(); users  with modify permissions: Set(catherine.ng60); groups with modify permissions: Set()
2021-05-19 02:47:38 INFO  TransportClientFactory:267 - Successfully created connection to hadoop02.cusp.nyu.edu/192.168.72.172:60108 after 3 ms (0 ms spent in bootstraps)
2021-05-19 02:47:38 INFO  DiskBlockManager:54 - Created local directory at /localhome/cdp/yarn/nm/usercache/catherine.ng60/appcache/application_1609183734776_5900/blockmgr-b033e14f-3cff-4da2-af83-c375897ba634
2021-05-19 02:47:38 INFO  MemoryStore:54 - MemoryStore started with capacity 366.3 MB
2021-05-19 02:47:38 INFO  CoarseGrainedExecutorBackend:54 - Connecting to driver: spark://CoarseGrainedScheduler@hadoop02.cusp.nyu.edu:60108
2021-05-19 02:47:38 INFO  CoarseGrainedExecutorBackend:54 - Successfully registered with driver
2021-05-19 02:47:38 INFO  Executor:54 - Starting executor ID 7 on host hadoop13.cusp.nyu.edu
2021-05-19 02:47:38 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 44397.
2021-05-19 02:47:38 INFO  NettyBlockTransferService:54 - Server created on hadoop13.cusp.nyu.edu:44397
2021-05-19 02:47:38 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2021-05-19 02:47:38 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(7, hadoop13.cusp.nyu.edu, 44397, None)
2021-05-19 02:47:38 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(7, hadoop13.cusp.nyu.edu, 44397, None)
2021-05-19 02:47:38 INFO  BlockManager:54 - external shuffle service port = 7337
2021-05-19 02:47:38 INFO  BlockManager:54 - Registering executor with local external shuffle service.
2021-05-19 02:47:38 INFO  TransportClientFactory:267 - Successfully created connection to hadoop13.cusp.nyu.edu/192.168.72.183:7337 after 3 ms (0 ms spent in bootstraps)
2021-05-19 02:47:38 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(7, hadoop13.cusp.nyu.edu, 44397, None)
2021-05-19 02:47:38 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 381
2021-05-19 02:47:38 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 382
2021-05-19 02:47:38 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 383
2021-05-19 02:47:38 INFO  Executor:54 - Running task 26.2 in stage 7.0 (TID 381)
2021-05-19 02:47:38 INFO  Executor:54 - Running task 9.2 in stage 7.0 (TID 383)
2021-05-19 02:47:38 INFO  Executor:54 - Running task 43.2 in stage 7.0 (TID 382)
2021-05-19 02:47:38 INFO  MapOutputTrackerWorker:54 - Updating epoch to 1 and clearing cache
2021-05-19 02:47:38 INFO  TorrentBroadcast:54 - Started reading broadcast variable 14
2021-05-19 02:47:38 INFO  TransportClientFactory:267 - Successfully created connection to hadoop02.cusp.nyu.edu/192.168.72.172:49352 after 3 ms (0 ms spent in bootstraps)
2021-05-19 02:47:38 INFO  MemoryStore:54 - Block broadcast_14_piece0 stored as bytes in memory (estimated size 22.9 KB, free 366.3 MB)
2021-05-19 02:47:38 INFO  TorrentBroadcast:54 - Reading broadcast variable 14 took 133 ms
2021-05-19 02:47:39 INFO  MemoryStore:54 - Block broadcast_14 stored as values in memory (estimated size 51.4 KB, free 366.2 MB)
2021-05-19 02:47:40 INFO  CodeGenerator:54 - Code generated in 346.008566 ms
2021-05-19 02:47:40 INFO  TorrentBroadcast:54 - Started reading broadcast variable 12
2021-05-19 02:47:40 INFO  MemoryStore:54 - Block broadcast_12_piece0 stored as bytes in memory (estimated size 580.1 KB, free 365.7 MB)
2021-05-19 02:47:40 INFO  TorrentBroadcast:54 - Reading broadcast variable 12 took 38 ms
2021-05-19 02:47:40 INFO  MemoryStore:54 - Block broadcast_12 stored as values in memory (estimated size 5.0 MB, free 360.7 MB)
2021-05-19 02:47:40 INFO  CodeGenerator:54 - Code generated in 32.529568 ms
2021-05-19 02:47:41 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00026, range: 0-134217728, partition values: [empty row]
2021-05-19 02:47:41 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00043, range: 0-134217728, partition values: [empty row]
2021-05-19 02:47:41 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00009, range: 0-134217728, partition values: [empty row]
2021-05-19 02:47:41 INFO  CodeGenerator:54 - Code generated in 40.877611 ms
2021-05-19 02:47:41 INFO  TorrentBroadcast:54 - Started reading broadcast variable 13
2021-05-19 02:47:41 INFO  MemoryStore:54 - Block broadcast_13_piece0 stored as bytes in memory (estimated size 33.4 KB, free 360.6 MB)
2021-05-19 02:47:41 INFO  TorrentBroadcast:54 - Reading broadcast variable 13 took 26 ms
2021-05-19 02:47:41 INFO  CodeGenerator:54 - Code generated in 60.713146 ms
2021-05-19 02:47:41 INFO  CodeGenerator:54 - Code generated in 37.590144 ms
2021-05-19 02:47:41 INFO  MemoryStore:54 - Block broadcast_13 stored as values in memory (estimated size 506.4 KB, free 360.1 MB)
2021-05-19 02:47:41 INFO  CodeGenerator:54 - Code generated in 44.782006 ms
2021-05-19 02:47:41 INFO  CodeGenerator:54 - Code generated in 28.706871 ms
2021-05-19 02:47:42 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 404
2021-05-19 02:47:42 INFO  Executor:54 - Running task 42.1 in stage 7.0 (TID 404)
2021-05-19 02:47:42 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 405
2021-05-19 02:47:42 INFO  Executor:54 - Running task 28.1 in stage 7.0 (TID 405)
2021-05-19 02:47:42 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 406
2021-05-19 02:47:42 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 407
2021-05-19 02:47:42 INFO  Executor:54 - Running task 12.1 in stage 7.0 (TID 406)
2021-05-19 02:47:42 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 408
2021-05-19 02:47:42 INFO  Executor:54 - Running task 29.1 in stage 7.0 (TID 407)
2021-05-19 02:47:42 INFO  Executor:54 - Running task 22.1 in stage 7.0 (TID 408)
2021-05-19 02:47:42 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 409
2021-05-19 02:47:42 INFO  Executor:54 - Running task 24.1 in stage 7.0 (TID 409)
2021-05-19 02:47:42 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 410
2021-05-19 02:47:42 INFO  Executor:54 - Running task 8.1 in stage 7.0 (TID 410)
2021-05-19 02:47:42 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00042, range: 0-134217728, partition values: [empty row]
2021-05-19 02:47:42 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00024, range: 0-134217728, partition values: [empty row]
2021-05-19 02:47:42 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00022, range: 0-134217728, partition values: [empty row]
2021-05-19 02:47:42 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00012, range: 0-134217728, partition values: [empty row]
2021-05-19 02:47:42 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00008, range: 0-134217728, partition values: [empty row]
2021-05-19 02:47:42 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00029, range: 0-134217728, partition values: [empty row]
2021-05-19 02:47:42 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00028, range: 0-134217728, partition values: [empty row]
2021-05-19 02:47:43 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: 224-222@627-s8r-975, 2019-12-02T00:00:00-05:00, [15,24,17,27,24,13,21]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: 224-222@627-s8r-975
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00024
2021-05-19 02:47:43 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: 22p-222@627-s5x-c3q, 2018-12-31T00:00:00-05:00, [3,2,4,4,4,6,0]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: 22p-222@627-s5x-c3q
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00012
2021-05-19 02:47:43 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: 22h-223@627-s84-6hq, 2019-08-05T00:00:00-04:00, [2,2,0,2,1,3,1]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: 22h-223@627-s84-6hq
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00026
2021-05-19 02:47:43 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: zzy-222@627-s93-26k, 2019-12-02T00:00:00-05:00, [4,6,9,13,8,11,4]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: zzy-222@627-s93-26k
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00029
2021-05-19 02:47:43 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: 22f-222@627-s8x-c5z, 2020-10-26T00:00:00-04:00, [1,0,0,0,0,0,0]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: 22f-222@627-s8x-c5z
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00042
2021-05-19 02:47:43 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: 22n-224@627-wc7-qfz, 2018-12-31T00:00:00-05:00, [4,2,14,28,22,22,26]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: 22n-224@627-wc7-qfz
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00008
2021-05-19 02:47:43 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: zzw-226@627-wc7-49z, 2019-02-11T00:00:00-05:00, [26,15,15,20,33,6,11]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: zzw-226@627-wc7-49z
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00022
2021-05-19 02:47:43 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: 226-225@627-wc8-73q, 2018-12-31T00:00:00-05:00, [1,6,18,10,12,12,18]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: 226-225@627-wc8-73q
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00009
2021-05-19 02:47:43 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: 25p-222@627-s8j-94v, 2020-06-08T00:00:00-04:00, [1,1,0,2,0,0,0]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: 25p-222@627-s8j-94v
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00043
2021-05-19 02:47:43 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: 22j-222@627-wc7-8jv, 2019-05-13T00:00:00-04:00, [1,1,0,2,2,4,1]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: 22j-222@627-wc7-8jv
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00028
2021-05-19 02:47:44 INFO  CodeGenerator:54 - Code generated in 21.232248 ms
2021-05-19 02:47:44 INFO  CodeGenerator:54 - Code generated in 49.490303 ms
2021-05-19 02:47:44 INFO  CodeGenerator:54 - Code generated in 27.520304 ms
2021-05-19 02:47:44 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:47:44 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:47:44 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:47:44 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:47:44 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:47:44 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:47:44 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:47:44 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:47:45 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:47:45 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:47:45 INFO  CodeGenerator:54 - Code generated in 39.974717 ms
2021-05-19 02:47:45 INFO  CodeGenerator:54 - Code generated in 37.168835 ms
2021-05-19 02:47:45 INFO  CodeGenerator:54 - Code generated in 21.064702 ms
2021-05-19 02:47:45 INFO  CodeGenerator:54 - Code generated in 24.195264 ms
2021-05-19 02:47:54 INFO  PythonUDFRunner:54 - Times: total = 12294, boot = 36, init = 1701, finish = 10557
2021-05-19 02:47:54 INFO  PythonUDFRunner:54 - Times: total = 12503, boot = 23, init = 1716, finish = 10764
2021-05-19 02:47:54 INFO  PythonUDFRunner:54 - Times: total = 14087, boot = 683, init = 2494, finish = 10910
2021-05-19 02:47:55 INFO  PythonUDFRunner:54 - Times: total = 14215, boot = 671, init = 2508, finish = 11036
2021-05-19 02:47:55 INFO  CodeGenerator:54 - Code generated in 32.286326 ms
2021-05-19 02:47:55 INFO  PythonUDFRunner:54 - Times: total = 13224, boot = 10, init = 1733, finish = 11481
2021-05-19 02:47:55 INFO  PythonUDFRunner:54 - Times: total = 13399, boot = 12, init = 1726, finish = 11661
2021-05-19 02:47:55 INFO  PythonUDFRunner:54 - Times: total = 13453, boot = 7, init = 1759, finish = 11687
2021-05-19 02:47:55 INFO  PythonUDFRunner:54 - Times: total = 14894, boot = 691, init = 2483, finish = 11720
2021-05-19 02:47:55 ERROR CoarseGrainedExecutorBackend:43 - RECEIVED SIGNAL TERM
2021-05-19 02:47:55 INFO  DiskBlockManager:54 - Shutdown hook called
2021-05-19 02:47:55 INFO  ShutdownHookManager:54 - Shutdown hook called
2021-05-19 02:47:55 INFO  ShutdownHookManager:54 - Deleting directory /localhome/cdp/yarn/nm/usercache/catherine.ng60/appcache/application_1609183734776_5900/spark-3b2397bc-5ab1-41a4-a56f-74859e013ba6

End of LogType:stdout
***********************************************************************


End of LogType:prelaunch.err
******************************************************************************

Container: container_e10_1609183734776_5900_02_000017 on hadoop17.cusp.nyu.edu_8041
LogAggregationType: AGGREGATED
===================================================================================
LogType:prelaunch.out
LogLastModifiedTime:Wed May 19 02:48:18 -0400 2021
LogLength:70
LogContents:
Setting up env variables
Setting up job resources
Launching container

End of LogType:prelaunch.out
******************************************************************************

Container: container_e10_1609183734776_5900_02_000017 on hadoop17.cusp.nyu.edu_8041
LogAggregationType: AGGREGATED
===================================================================================
LogType:stderr
LogLastModifiedTime:Wed May 19 02:48:18 -0400 2021
LogLength:529
LogContents:
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/localhome/cdp/yarn/nm/filecache/27/spark-jars-2.4.0-hadoop2.7.jar/slf4j-log4j12-1.7.16.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-6.1.0-1.cdh6.1.0.p0.770702/jars/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]

End of LogType:stderr
***********************************************************************

Container: container_e10_1609183734776_5900_02_000017 on hadoop17.cusp.nyu.edu_8041
LogAggregationType: AGGREGATED
===================================================================================
LogType:stdout
LogLastModifiedTime:Wed May 19 02:48:18 -0400 2021
LogLength:19121
LogContents:
2021-05-19 02:47:58 INFO  CoarseGrainedExecutorBackend:2566 - Started daemon with process name: 56014@hadoop17.cusp.nyu.edu
2021-05-19 02:47:58 INFO  SignalUtils:54 - Registered signal handler for TERM
2021-05-19 02:47:58 INFO  SignalUtils:54 - Registered signal handler for HUP
2021-05-19 02:47:58 INFO  SignalUtils:54 - Registered signal handler for INT
2021-05-19 02:47:59 INFO  SecurityManager:54 - Changing view acls to: catherine.ng60
2021-05-19 02:47:59 INFO  SecurityManager:54 - Changing modify acls to: catherine.ng60
2021-05-19 02:47:59 INFO  SecurityManager:54 - Changing view acls groups to: 
2021-05-19 02:47:59 INFO  SecurityManager:54 - Changing modify acls groups to: 
2021-05-19 02:47:59 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(catherine.ng60); groups with view permissions: Set(); users  with modify permissions: Set(catherine.ng60); groups with modify permissions: Set()
2021-05-19 02:47:59 INFO  TransportClientFactory:267 - Successfully created connection to hadoop02.cusp.nyu.edu/192.168.72.172:60108 after 108 ms (0 ms spent in bootstraps)
2021-05-19 02:48:00 INFO  SecurityManager:54 - Changing view acls to: catherine.ng60
2021-05-19 02:48:00 INFO  SecurityManager:54 - Changing modify acls to: catherine.ng60
2021-05-19 02:48:00 INFO  SecurityManager:54 - Changing view acls groups to: 
2021-05-19 02:48:00 INFO  SecurityManager:54 - Changing modify acls groups to: 
2021-05-19 02:48:00 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(catherine.ng60); groups with view permissions: Set(); users  with modify permissions: Set(catherine.ng60); groups with modify permissions: Set()
2021-05-19 02:48:00 INFO  TransportClientFactory:267 - Successfully created connection to hadoop02.cusp.nyu.edu/192.168.72.172:60108 after 4 ms (0 ms spent in bootstraps)
2021-05-19 02:48:00 INFO  DiskBlockManager:54 - Created local directory at /localhome/cdp/yarn/nm/usercache/catherine.ng60/appcache/application_1609183734776_5900/blockmgr-fbfb4ae7-48fc-4f4b-af07-88ffba9f7649
2021-05-19 02:48:00 INFO  MemoryStore:54 - MemoryStore started with capacity 366.3 MB
2021-05-19 02:48:00 INFO  CoarseGrainedExecutorBackend:54 - Connecting to driver: spark://CoarseGrainedScheduler@hadoop02.cusp.nyu.edu:60108
2021-05-19 02:48:00 INFO  CoarseGrainedExecutorBackend:54 - Successfully registered with driver
2021-05-19 02:48:00 INFO  Executor:54 - Starting executor ID 14 on host hadoop17.cusp.nyu.edu
2021-05-19 02:48:00 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 44528.
2021-05-19 02:48:00 INFO  NettyBlockTransferService:54 - Server created on hadoop17.cusp.nyu.edu:44528
2021-05-19 02:48:00 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2021-05-19 02:48:00 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(14, hadoop17.cusp.nyu.edu, 44528, None)
2021-05-19 02:48:00 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(14, hadoop17.cusp.nyu.edu, 44528, None)
2021-05-19 02:48:00 INFO  BlockManager:54 - external shuffle service port = 7337
2021-05-19 02:48:00 INFO  BlockManager:54 - Registering executor with local external shuffle service.
2021-05-19 02:48:00 INFO  TransportClientFactory:267 - Successfully created connection to hadoop17.cusp.nyu.edu/192.168.72.187:7337 after 3 ms (0 ms spent in bootstraps)
2021-05-19 02:48:00 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(14, hadoop17.cusp.nyu.edu, 44528, None)
2021-05-19 02:48:01 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 444
2021-05-19 02:48:01 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 445
2021-05-19 02:48:01 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 446
2021-05-19 02:48:01 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 447
2021-05-19 02:48:01 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 448
2021-05-19 02:48:01 INFO  Executor:54 - Running task 40.2 in stage 7.0 (TID 444)
2021-05-19 02:48:01 INFO  Executor:54 - Running task 45.2 in stage 7.0 (TID 448)
2021-05-19 02:48:01 INFO  Executor:54 - Running task 3.2 in stage 7.0 (TID 446)
2021-05-19 02:48:01 INFO  Executor:54 - Running task 10.2 in stage 7.0 (TID 447)
2021-05-19 02:48:01 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 449
2021-05-19 02:48:01 INFO  Executor:54 - Running task 30.2 in stage 7.0 (TID 445)
2021-05-19 02:48:01 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 450
2021-05-19 02:48:01 INFO  Executor:54 - Running task 44.2 in stage 7.0 (TID 449)
2021-05-19 02:48:01 INFO  Executor:54 - Running task 1.2 in stage 7.0 (TID 450)
2021-05-19 02:48:01 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 451
2021-05-19 02:48:01 INFO  Executor:54 - Running task 61.0 in stage 7.0 (TID 451)
2021-05-19 02:48:01 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 452
2021-05-19 02:48:01 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 453
2021-05-19 02:48:01 INFO  Executor:54 - Running task 64.0 in stage 7.0 (TID 452)
2021-05-19 02:48:01 INFO  Executor:54 - Running task 69.0 in stage 7.0 (TID 453)
2021-05-19 02:48:01 INFO  MapOutputTrackerWorker:54 - Updating epoch to 1 and clearing cache
2021-05-19 02:48:01 INFO  TorrentBroadcast:54 - Started reading broadcast variable 14
2021-05-19 02:48:01 INFO  TransportClientFactory:267 - Successfully created connection to hadoop13.cusp.nyu.edu/192.168.72.183:43962 after 2 ms (0 ms spent in bootstraps)
2021-05-19 02:48:01 INFO  MemoryStore:54 - Block broadcast_14_piece0 stored as bytes in memory (estimated size 22.9 KB, free 366.3 MB)
2021-05-19 02:48:01 INFO  TorrentBroadcast:54 - Reading broadcast variable 14 took 191 ms
2021-05-19 02:48:01 INFO  MemoryStore:54 - Block broadcast_14 stored as values in memory (estimated size 51.4 KB, free 366.2 MB)
2021-05-19 02:48:03 INFO  CodeGenerator:54 - Code generated in 389.961939 ms
2021-05-19 02:48:03 INFO  TorrentBroadcast:54 - Started reading broadcast variable 12
2021-05-19 02:48:03 INFO  TransportClientFactory:267 - Successfully created connection to hadoop02.cusp.nyu.edu/192.168.72.172:49352 after 6 ms (0 ms spent in bootstraps)
2021-05-19 02:48:03 INFO  MemoryStore:54 - Block broadcast_12_piece0 stored as bytes in memory (estimated size 580.1 KB, free 365.7 MB)
2021-05-19 02:48:03 INFO  TorrentBroadcast:54 - Reading broadcast variable 12 took 54 ms
2021-05-19 02:48:03 INFO  MemoryStore:54 - Block broadcast_12 stored as values in memory (estimated size 5.0 MB, free 360.7 MB)
2021-05-19 02:48:03 INFO  CodeGenerator:54 - Code generated in 42.162765 ms
2021-05-19 02:48:04 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00043, range: 134217728-176499032, partition values: [empty row]
2021-05-19 02:48:04 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00010, range: 0-134217728, partition values: [empty row]
2021-05-19 02:48:04 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00003, range: 0-134217728, partition values: [empty row]
2021-05-19 02:48:04 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00045, range: 0-134217728, partition values: [empty row]
2021-05-19 02:48:04 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00038, range: 134217728-172697253, partition values: [empty row]
2021-05-19 02:48:04 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00001, range: 0-134217728, partition values: [empty row]
2021-05-19 02:48:04 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00040, range: 0-134217728, partition values: [empty row]
2021-05-19 02:48:04 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00030, range: 0-134217728, partition values: [empty row]
2021-05-19 02:48:04 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00020, range: 134217728-175942625, partition values: [empty row]
2021-05-19 02:48:04 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00044, range: 0-134217728, partition values: [empty row]
2021-05-19 02:48:04 INFO  CodeGenerator:54 - Code generated in 55.928463 ms
2021-05-19 02:48:04 INFO  TorrentBroadcast:54 - Started reading broadcast variable 13
2021-05-19 02:48:04 INFO  CodeGenerator:54 - Code generated in 50.936422 ms
2021-05-19 02:48:04 INFO  MemoryStore:54 - Block broadcast_13_piece0 stored as bytes in memory (estimated size 33.4 KB, free 360.6 MB)
2021-05-19 02:48:04 INFO  TorrentBroadcast:54 - Reading broadcast variable 13 took 24 ms
2021-05-19 02:48:04 INFO  CodeGenerator:54 - Code generated in 46.6249 ms
2021-05-19 02:48:04 INFO  CodeGenerator:54 - Code generated in 39.77229 ms
2021-05-19 02:48:04 INFO  CodeGenerator:54 - Code generated in 33.186821 ms
2021-05-19 02:48:04 INFO  MemoryStore:54 - Block broadcast_13 stored as values in memory (estimated size 506.4 KB, free 360.1 MB)
2021-05-19 02:48:06 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: 222-222@627-wg5-389, 2019-05-13T00:00:00-04:00, [10,28,8,12,17,3,11]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: 222-222@627-wg5-389
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00030
2021-05-19 02:48:06 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: zzw-222@627-s4s-nqz, 2019-04-22T00:00:00-04:00, [6,10,4,9,4,6,2]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: zzw-222@627-s4s-nqz
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00040
2021-05-19 02:48:06 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: 22r-222@627-vvk-swk, 2019-11-18T00:00:00-05:00, [7,32,20,27,42,29,34]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: 22r-222@627-vvk-swk
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00045
2021-05-19 02:48:06 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: 22x-224@627-s8r-c89, 2018-12-31T00:00:00-05:00, [21,42,46,76,70,52,8]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: 22x-224@627-s8r-c89
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00010
2021-05-19 02:48:06 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: 227-222@627-s4n-x3q, 2019-06-10T00:00:00-04:00, [7,4,4,0,7,11,3]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: 227-222@627-s4n-x3q
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00044
2021-05-19 02:48:06 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: 22k-223@627-s8w-b49, 2018-12-31T00:00:00-05:00, [9,0,10,6,6,8,4]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: 22k-223@627-s8w-b49
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00001
2021-05-19 02:48:06 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: 22z-222@627-rw8-28v, 2018-12-31T00:00:00-05:00, [5,22,30,30,30,14,16]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: 22z-222@627-rw8-28v
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00003
2021-05-19 02:48:07 INFO  CodeGenerator:54 - Code generated in 17.451167 ms
2021-05-19 02:48:07 INFO  CodeGenerator:54 - Code generated in 24.711798 ms
2021-05-19 02:48:07 INFO  CodeGenerator:54 - Code generated in 25.995172 ms
2021-05-19 02:48:07 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:48:07 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:48:07 INFO  CodeGenerator:54 - Code generated in 52.110876 ms
2021-05-19 02:48:07 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:48:07 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:48:07 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:48:07 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:48:07 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:48:07 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:48:07 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:48:07 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:48:07 INFO  CodeGenerator:54 - Code generated in 30.597155 ms
2021-05-19 02:48:07 INFO  CodeGenerator:54 - Code generated in 20.919632 ms
2021-05-19 02:48:07 INFO  CodeGenerator:54 - Code generated in 20.623826 ms
2021-05-19 02:48:08 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00029, range: 134217728-172005177, partition values: [empty row]
2021-05-19 02:48:08 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00024, range: 134217728-175886494, partition values: [empty row]
2021-05-19 02:48:08 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00007, range: 134217728-176463914, partition values: [empty row]
2021-05-19 02:48:10 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00009, range: 134217728-175852891, partition values: [empty row]
2021-05-19 02:48:11 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00005, range: 134217728-171011271, partition values: [empty row]
2021-05-19 02:48:16 INFO  Executor:54 - Executor is trying to kill task 69.0 in stage 7.0 (TID 453), reason: Stage cancelled
2021-05-19 02:48:16 INFO  Executor:54 - Executor is trying to kill task 45.2 in stage 7.0 (TID 448), reason: Stage cancelled
2021-05-19 02:48:16 INFO  Executor:54 - Executor is trying to kill task 44.2 in stage 7.0 (TID 449), reason: Stage cancelled
2021-05-19 02:48:16 INFO  Executor:54 - Executor is trying to kill task 1.2 in stage 7.0 (TID 450), reason: Stage cancelled
2021-05-19 02:48:16 INFO  Executor:54 - Executor is trying to kill task 61.0 in stage 7.0 (TID 451), reason: Stage cancelled
2021-05-19 02:48:16 INFO  Executor:54 - Executor is trying to kill task 64.0 in stage 7.0 (TID 452), reason: Stage cancelled
2021-05-19 02:48:16 INFO  Executor:54 - Executor is trying to kill task 40.2 in stage 7.0 (TID 444), reason: Stage cancelled
2021-05-19 02:48:16 INFO  Executor:54 - Executor is trying to kill task 30.2 in stage 7.0 (TID 445), reason: Stage cancelled
2021-05-19 02:48:16 INFO  Executor:54 - Executor is trying to kill task 3.2 in stage 7.0 (TID 446), reason: Stage cancelled
2021-05-19 02:48:16 INFO  Executor:54 - Executor is trying to kill task 10.2 in stage 7.0 (TID 447), reason: Stage cancelled
2021-05-19 02:48:16 INFO  Executor:54 - Executor killed task 30.2 in stage 7.0 (TID 445), reason: Stage cancelled
2021-05-19 02:48:16 INFO  Executor:54 - Executor killed task 10.2 in stage 7.0 (TID 447), reason: Stage cancelled
2021-05-19 02:48:16 INFO  Executor:54 - Executor killed task 69.0 in stage 7.0 (TID 453), reason: Stage cancelled
2021-05-19 02:48:16 INFO  Executor:54 - Executor killed task 1.2 in stage 7.0 (TID 450), reason: Stage cancelled
2021-05-19 02:48:16 INFO  Executor:54 - Executor killed task 64.0 in stage 7.0 (TID 452), reason: Stage cancelled
2021-05-19 02:48:16 INFO  Executor:54 - Executor killed task 61.0 in stage 7.0 (TID 451), reason: Stage cancelled
2021-05-19 02:48:16 INFO  Executor:54 - Executor killed task 44.2 in stage 7.0 (TID 449), reason: Stage cancelled
2021-05-19 02:48:16 INFO  Executor:54 - Executor killed task 40.2 in stage 7.0 (TID 444), reason: Stage cancelled
2021-05-19 02:48:16 INFO  Executor:54 - Executor killed task 3.2 in stage 7.0 (TID 446), reason: Stage cancelled
2021-05-19 02:48:16 INFO  Executor:54 - Executor killed task 45.2 in stage 7.0 (TID 448), reason: Stage cancelled
2021-05-19 02:48:16 INFO  CoarseGrainedExecutorBackend:54 - Driver commanded a shutdown
2021-05-19 02:48:16 INFO  MemoryStore:54 - MemoryStore cleared
2021-05-19 02:48:16 INFO  BlockManager:54 - BlockManager stopped
2021-05-19 02:48:16 INFO  ShutdownHookManager:54 - Shutdown hook called
2021-05-19 02:48:16 INFO  ShutdownHookManager:54 - Deleting directory /localhome/cdp/yarn/nm/usercache/catherine.ng60/appcache/application_1609183734776_5900/spark-ec44ae1c-1836-4071-85d1-4d93a0098aed

End of LogType:stdout
***********************************************************************


End of LogType:prelaunch.err
******************************************************************************

Container: container_e10_1609183734776_5900_02_000010 on hadoop17.cusp.nyu.edu_8041
LogAggregationType: AGGREGATED
===================================================================================
LogType:prelaunch.out
LogLastModifiedTime:Wed May 19 02:48:18 -0400 2021
LogLength:70
LogContents:
Setting up env variables
Setting up job resources
Launching container

End of LogType:prelaunch.out
******************************************************************************

Container: container_e10_1609183734776_5900_02_000010 on hadoop17.cusp.nyu.edu_8041
LogAggregationType: AGGREGATED
===================================================================================
LogType:stderr
LogLastModifiedTime:Wed May 19 02:48:18 -0400 2021
LogLength:529
LogContents:
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/localhome/cdp/yarn/nm/filecache/27/spark-jars-2.4.0-hadoop2.7.jar/slf4j-log4j12-1.7.16.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-6.1.0-1.cdh6.1.0.p0.770702/jars/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]

End of LogType:stderr
***********************************************************************

Container: container_e10_1609183734776_5900_02_000010 on hadoop17.cusp.nyu.edu_8041
LogAggregationType: AGGREGATED
===================================================================================
LogType:stdout
LogLastModifiedTime:Wed May 19 02:48:18 -0400 2021
LogLength:17671
LogContents:
2021-05-19 02:47:36 INFO  CoarseGrainedExecutorBackend:2566 - Started daemon with process name: 55756@hadoop17.cusp.nyu.edu
2021-05-19 02:47:36 INFO  SignalUtils:54 - Registered signal handler for TERM
2021-05-19 02:47:36 INFO  SignalUtils:54 - Registered signal handler for HUP
2021-05-19 02:47:36 INFO  SignalUtils:54 - Registered signal handler for INT
2021-05-19 02:47:37 INFO  SecurityManager:54 - Changing view acls to: catherine.ng60
2021-05-19 02:47:37 INFO  SecurityManager:54 - Changing modify acls to: catherine.ng60
2021-05-19 02:47:37 INFO  SecurityManager:54 - Changing view acls groups to: 
2021-05-19 02:47:37 INFO  SecurityManager:54 - Changing modify acls groups to: 
2021-05-19 02:47:37 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(catherine.ng60); groups with view permissions: Set(); users  with modify permissions: Set(catherine.ng60); groups with modify permissions: Set()
2021-05-19 02:47:37 INFO  TransportClientFactory:267 - Successfully created connection to hadoop02.cusp.nyu.edu/192.168.72.172:60108 after 108 ms (0 ms spent in bootstraps)
2021-05-19 02:47:37 INFO  SecurityManager:54 - Changing view acls to: catherine.ng60
2021-05-19 02:47:37 INFO  SecurityManager:54 - Changing modify acls to: catherine.ng60
2021-05-19 02:47:37 INFO  SecurityManager:54 - Changing view acls groups to: 
2021-05-19 02:47:37 INFO  SecurityManager:54 - Changing modify acls groups to: 
2021-05-19 02:47:37 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(catherine.ng60); groups with view permissions: Set(); users  with modify permissions: Set(catherine.ng60); groups with modify permissions: Set()
2021-05-19 02:47:38 INFO  TransportClientFactory:267 - Successfully created connection to hadoop02.cusp.nyu.edu/192.168.72.172:60108 after 4 ms (0 ms spent in bootstraps)
2021-05-19 02:47:38 INFO  DiskBlockManager:54 - Created local directory at /localhome/cdp/yarn/nm/usercache/catherine.ng60/appcache/application_1609183734776_5900/blockmgr-0ef1d332-3483-4f42-8f47-2eaece3aa364
2021-05-19 02:47:38 INFO  MemoryStore:54 - MemoryStore started with capacity 366.3 MB
2021-05-19 02:47:38 INFO  CoarseGrainedExecutorBackend:54 - Connecting to driver: spark://CoarseGrainedScheduler@hadoop02.cusp.nyu.edu:60108
2021-05-19 02:47:38 INFO  CoarseGrainedExecutorBackend:54 - Successfully registered with driver
2021-05-19 02:47:38 INFO  Executor:54 - Starting executor ID 9 on host hadoop17.cusp.nyu.edu
2021-05-19 02:47:38 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 58642.
2021-05-19 02:47:38 INFO  NettyBlockTransferService:54 - Server created on hadoop17.cusp.nyu.edu:58642
2021-05-19 02:47:38 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2021-05-19 02:47:38 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(9, hadoop17.cusp.nyu.edu, 58642, None)
2021-05-19 02:47:38 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(9, hadoop17.cusp.nyu.edu, 58642, None)
2021-05-19 02:47:38 INFO  BlockManager:54 - external shuffle service port = 7337
2021-05-19 02:47:38 INFO  BlockManager:54 - Registering executor with local external shuffle service.
2021-05-19 02:47:38 INFO  TransportClientFactory:267 - Successfully created connection to hadoop17.cusp.nyu.edu/192.168.72.187:7337 after 2 ms (0 ms spent in bootstraps)
2021-05-19 02:47:38 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(9, hadoop17.cusp.nyu.edu, 58642, None)
2021-05-19 02:47:38 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 384
2021-05-19 02:47:38 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 385
2021-05-19 02:47:38 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 386
2021-05-19 02:47:38 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 387
2021-05-19 02:47:38 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 388
2021-05-19 02:47:38 INFO  Executor:54 - Running task 45.1 in stage 7.0 (TID 387)
2021-05-19 02:47:38 INFO  Executor:54 - Running task 16.1 in stage 7.0 (TID 385)
2021-05-19 02:47:38 INFO  Executor:54 - Running task 15.1 in stage 7.0 (TID 386)
2021-05-19 02:47:38 INFO  Executor:54 - Running task 32.2 in stage 7.0 (TID 384)
2021-05-19 02:47:38 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 389
2021-05-19 02:47:38 INFO  Executor:54 - Running task 44.1 in stage 7.0 (TID 388)
2021-05-19 02:47:38 INFO  Executor:54 - Running task 40.1 in stage 7.0 (TID 389)
2021-05-19 02:47:38 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 390
2021-05-19 02:47:38 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 391
2021-05-19 02:47:38 INFO  Executor:54 - Running task 10.1 in stage 7.0 (TID 390)
2021-05-19 02:47:38 INFO  Executor:54 - Running task 1.1 in stage 7.0 (TID 391)
2021-05-19 02:47:38 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 392
2021-05-19 02:47:38 INFO  Executor:54 - Running task 30.1 in stage 7.0 (TID 392)
2021-05-19 02:47:38 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 393
2021-05-19 02:47:38 INFO  Executor:54 - Running task 3.1 in stage 7.0 (TID 393)
2021-05-19 02:47:38 INFO  MapOutputTrackerWorker:54 - Updating epoch to 1 and clearing cache
2021-05-19 02:47:38 INFO  TorrentBroadcast:54 - Started reading broadcast variable 14
2021-05-19 02:47:38 INFO  TransportClientFactory:267 - Successfully created connection to hadoop06.cusp.nyu.edu/192.168.72.176:34178 after 3 ms (0 ms spent in bootstraps)
2021-05-19 02:47:39 INFO  MemoryStore:54 - Block broadcast_14_piece0 stored as bytes in memory (estimated size 22.9 KB, free 366.3 MB)
2021-05-19 02:47:39 INFO  TorrentBroadcast:54 - Reading broadcast variable 14 took 220 ms
2021-05-19 02:47:39 INFO  MemoryStore:54 - Block broadcast_14 stored as values in memory (estimated size 51.4 KB, free 366.2 MB)
2021-05-19 02:47:40 INFO  CodeGenerator:54 - Code generated in 356.638424 ms
2021-05-19 02:47:40 INFO  TorrentBroadcast:54 - Started reading broadcast variable 12
2021-05-19 02:47:40 INFO  TransportClientFactory:267 - Successfully created connection to hadoop13.cusp.nyu.edu/192.168.72.183:44397 after 5 ms (0 ms spent in bootstraps)
2021-05-19 02:47:40 INFO  MemoryStore:54 - Block broadcast_12_piece0 stored as bytes in memory (estimated size 580.1 KB, free 365.7 MB)
2021-05-19 02:47:40 INFO  TorrentBroadcast:54 - Reading broadcast variable 12 took 107 ms
2021-05-19 02:47:41 INFO  MemoryStore:54 - Block broadcast_12 stored as values in memory (estimated size 5.0 MB, free 360.7 MB)
2021-05-19 02:47:41 INFO  CodeGenerator:54 - Code generated in 38.722421 ms
2021-05-19 02:47:41 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00010, range: 0-134217728, partition values: [empty row]
2021-05-19 02:47:41 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00015, range: 0-134217728, partition values: [empty row]
2021-05-19 02:47:41 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00032, range: 0-134217728, partition values: [empty row]
2021-05-19 02:47:41 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00030, range: 0-134217728, partition values: [empty row]
2021-05-19 02:47:41 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00001, range: 0-134217728, partition values: [empty row]
2021-05-19 02:47:41 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00045, range: 0-134217728, partition values: [empty row]
2021-05-19 02:47:41 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00044, range: 0-134217728, partition values: [empty row]
2021-05-19 02:47:42 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00016, range: 0-134217728, partition values: [empty row]
2021-05-19 02:47:42 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00003, range: 0-134217728, partition values: [empty row]
2021-05-19 02:47:42 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00040, range: 0-134217728, partition values: [empty row]
2021-05-19 02:47:42 INFO  CodeGenerator:54 - Code generated in 65.88081 ms
2021-05-19 02:47:42 INFO  TorrentBroadcast:54 - Started reading broadcast variable 13
2021-05-19 02:47:42 INFO  MemoryStore:54 - Block broadcast_13_piece0 stored as bytes in memory (estimated size 33.4 KB, free 360.6 MB)
2021-05-19 02:47:42 INFO  TorrentBroadcast:54 - Reading broadcast variable 13 took 26 ms
2021-05-19 02:47:42 INFO  CodeGenerator:54 - Code generated in 57.869215 ms
2021-05-19 02:47:42 INFO  CodeGenerator:54 - Code generated in 36.301096 ms
2021-05-19 02:47:42 INFO  CodeGenerator:54 - Code generated in 51.600323 ms
2021-05-19 02:47:42 INFO  MemoryStore:54 - Block broadcast_13 stored as values in memory (estimated size 506.4 KB, free 360.1 MB)
2021-05-19 02:47:42 INFO  CodeGenerator:54 - Code generated in 32.000499 ms
2021-05-19 02:47:43 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: 227-222@627-s4n-x3q, 2019-06-10T00:00:00-04:00, [7,4,4,0,7,11,3]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: 227-222@627-s4n-x3q
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00044
2021-05-19 02:47:43 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: 222-222@627-wg5-389, 2019-05-13T00:00:00-04:00, [10,28,8,12,17,3,11]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: 222-222@627-wg5-389
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00030
2021-05-19 02:47:43 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: 22x-224@627-s8r-c89, 2018-12-31T00:00:00-05:00, [21,42,46,76,70,52,8]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: 22x-224@627-s8r-c89
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00010
2021-05-19 02:47:43 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: 22g-222@627-rwv-q75, 2019-07-15T00:00:00-04:00, [12,11,14,8,11,9,7]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: 22g-222@627-rwv-q75
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00032
2021-05-19 02:47:43 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: 222-222@627-s6k-dqf, 2019-01-14T00:00:00-05:00, [0,0,0,0,1,0,0]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: 222-222@627-s6k-dqf
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00016
2021-05-19 02:47:43 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: 22c-222@627-s84-mrk, 2020-04-06T00:00:00-04:00, [0,0,0,0,2,0,0]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: 22c-222@627-s84-mrk
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00015
2021-05-19 02:47:43 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: 22z-222@627-rw8-28v, 2018-12-31T00:00:00-05:00, [5,22,30,30,30,14,16]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: 22z-222@627-rw8-28v
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00003
2021-05-19 02:47:43 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: zzw-222@627-s4s-nqz, 2019-04-22T00:00:00-04:00, [6,10,4,9,4,6,2]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: zzw-222@627-s4s-nqz
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00040
2021-05-19 02:47:43 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: 22k-223@627-s8w-b49, 2018-12-31T00:00:00-05:00, [9,0,10,6,6,8,4]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: 22k-223@627-s8w-b49
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00001
2021-05-19 02:47:43 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: 22r-222@627-vvk-swk, 2019-11-18T00:00:00-05:00, [7,32,20,27,42,29,34]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: 22r-222@627-vvk-swk
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00045
2021-05-19 02:47:44 INFO  CodeGenerator:54 - Code generated in 22.016833 ms
2021-05-19 02:47:44 INFO  CodeGenerator:54 - Code generated in 25.907393 ms
2021-05-19 02:47:44 INFO  CodeGenerator:54 - Code generated in 26.030547 ms
2021-05-19 02:47:45 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:47:45 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:47:45 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:47:45 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:47:45 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:47:45 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:47:45 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:47:45 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:47:45 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:47:45 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:47:45 INFO  CodeGenerator:54 - Code generated in 58.927328 ms
2021-05-19 02:47:45 INFO  CodeGenerator:54 - Code generated in 33.53929 ms
2021-05-19 02:47:45 INFO  CodeGenerator:54 - Code generated in 22.521352 ms
2021-05-19 02:47:45 INFO  CodeGenerator:54 - Code generated in 22.289436 ms
2021-05-19 02:47:54 INFO  PythonUDFRunner:54 - Times: total = 13569, boot = 715, init = 2418, finish = 10436
2021-05-19 02:47:55 INFO  PythonUDFRunner:54 - Times: total = 13638, boot = 725, init = 2408, finish = 10505
2021-05-19 02:47:55 INFO  PythonUDFRunner:54 - Times: total = 13759, boot = 736, init = 2406, finish = 10617
2021-05-19 02:47:55 INFO  PythonUDFRunner:54 - Times: total = 14388, boot = 673, init = 2470, finish = 11245
2021-05-19 02:47:55 INFO  CodeGenerator:54 - Code generated in 30.815008 ms
2021-05-19 02:47:55 INFO  PythonUDFRunner:54 - Times: total = 14647, boot = 685, init = 2454, finish = 11508
2021-05-19 02:47:55 INFO  PythonUDFRunner:54 - Times: total = 14689, boot = 781, init = 2351, finish = 11557
2021-05-19 02:47:55 INFO  PythonUDFRunner:54 - Times: total = 14716, boot = 767, init = 2370, finish = 11579
2021-05-19 02:47:56 INFO  PythonUDFRunner:54 - Times: total = 14765, boot = 748, init = 2392, finish = 11625
2021-05-19 02:47:56 INFO  PythonUDFRunner:54 - Times: total = 14910, boot = 705, init = 2435, finish = 11770
2021-05-19 02:47:56 INFO  PythonUDFRunner:54 - Times: total = 15040, boot = 695, init = 2441, finish = 11904
2021-05-19 02:47:56 ERROR CoarseGrainedExecutorBackend:43 - RECEIVED SIGNAL TERM
2021-05-19 02:47:56 INFO  DiskBlockManager:54 - Shutdown hook called
2021-05-19 02:47:56 INFO  ShutdownHookManager:54 - Shutdown hook called

End of LogType:stdout
***********************************************************************

Container: container_e10_1609183734776_5900_02_000006 on hadoop17.cusp.nyu.edu_8041
LogAggregationType: AGGREGATED
===================================================================================
LogType:container-localizer-syslog
LogLastModifiedTime:Wed May 19 02:48:18 -0400 2021
LogLength:506
LogContents:
2021-05-19 02:46:52,969 INFO [main] org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ContainerLocalizer: Disk Validator: yarn.nodemanager.disk-validator is loaded.
2021-05-19 02:46:54,214 WARN [ContainerLocalizer Downloader] org.apache.hadoop.ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ipc.StandbyException): Operation category READ is not supported in state standby. Visit https://s.apache.org/sbnn-error

End of LogType:container-localizer-syslog
*******************************************************************************************


End of LogType:prelaunch.err
******************************************************************************

Container: container_e10_1609183734776_5900_02_000006 on hadoop17.cusp.nyu.edu_8041
LogAggregationType: AGGREGATED
===================================================================================
LogType:prelaunch.out
LogLastModifiedTime:Wed May 19 02:48:18 -0400 2021
LogLength:70
LogContents:
Setting up env variables
Setting up job resources
Launching container

End of LogType:prelaunch.out
******************************************************************************

Container: container_e10_1609183734776_5900_02_000006 on hadoop17.cusp.nyu.edu_8041
LogAggregationType: AGGREGATED
===================================================================================
LogType:stderr
LogLastModifiedTime:Wed May 19 02:48:18 -0400 2021
LogLength:529
LogContents:
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/localhome/cdp/yarn/nm/filecache/27/spark-jars-2.4.0-hadoop2.7.jar/slf4j-log4j12-1.7.16.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-6.1.0-1.cdh6.1.0.p0.770702/jars/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]

End of LogType:stderr
***********************************************************************

Container: container_e10_1609183734776_5900_02_000006 on hadoop17.cusp.nyu.edu_8041
LogAggregationType: AGGREGATED
===================================================================================
LogType:stdout
LogLastModifiedTime:Wed May 19 02:48:18 -0400 2021
LogLength:102957
LogContents:
2021-05-19 02:46:55 INFO  CoarseGrainedExecutorBackend:2566 - Started daemon with process name: 55218@hadoop17.cusp.nyu.edu
2021-05-19 02:46:55 INFO  SignalUtils:54 - Registered signal handler for TERM
2021-05-19 02:46:55 INFO  SignalUtils:54 - Registered signal handler for HUP
2021-05-19 02:46:55 INFO  SignalUtils:54 - Registered signal handler for INT
2021-05-19 02:46:56 INFO  SecurityManager:54 - Changing view acls to: catherine.ng60
2021-05-19 02:46:56 INFO  SecurityManager:54 - Changing modify acls to: catherine.ng60
2021-05-19 02:46:56 INFO  SecurityManager:54 - Changing view acls groups to: 
2021-05-19 02:46:56 INFO  SecurityManager:54 - Changing modify acls groups to: 
2021-05-19 02:46:56 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(catherine.ng60); groups with view permissions: Set(); users  with modify permissions: Set(catherine.ng60); groups with modify permissions: Set()
2021-05-19 02:46:57 INFO  TransportClientFactory:267 - Successfully created connection to hadoop02.cusp.nyu.edu/192.168.72.172:60108 after 106 ms (0 ms spent in bootstraps)
2021-05-19 02:46:57 INFO  SecurityManager:54 - Changing view acls to: catherine.ng60
2021-05-19 02:46:57 INFO  SecurityManager:54 - Changing modify acls to: catherine.ng60
2021-05-19 02:46:57 INFO  SecurityManager:54 - Changing view acls groups to: 
2021-05-19 02:46:57 INFO  SecurityManager:54 - Changing modify acls groups to: 
2021-05-19 02:46:57 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(catherine.ng60); groups with view permissions: Set(); users  with modify permissions: Set(catherine.ng60); groups with modify permissions: Set()
2021-05-19 02:46:57 INFO  TransportClientFactory:267 - Successfully created connection to hadoop02.cusp.nyu.edu/192.168.72.172:60108 after 4 ms (0 ms spent in bootstraps)
2021-05-19 02:46:57 INFO  DiskBlockManager:54 - Created local directory at /localhome/cdp/yarn/nm/usercache/catherine.ng60/appcache/application_1609183734776_5900/blockmgr-92357513-bbb9-477d-8b7d-1a21c2fe5715
2021-05-19 02:46:57 INFO  MemoryStore:54 - MemoryStore started with capacity 366.3 MB
2021-05-19 02:46:57 INFO  CoarseGrainedExecutorBackend:54 - Connecting to driver: spark://CoarseGrainedScheduler@hadoop02.cusp.nyu.edu:60108
2021-05-19 02:46:58 INFO  CoarseGrainedExecutorBackend:54 - Successfully registered with driver
2021-05-19 02:46:58 INFO  Executor:54 - Starting executor ID 5 on host hadoop17.cusp.nyu.edu
2021-05-19 02:46:58 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 39842.
2021-05-19 02:46:58 INFO  NettyBlockTransferService:54 - Server created on hadoop17.cusp.nyu.edu:39842
2021-05-19 02:46:58 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2021-05-19 02:46:58 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(5, hadoop17.cusp.nyu.edu, 39842, None)
2021-05-19 02:46:58 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(5, hadoop17.cusp.nyu.edu, 39842, None)
2021-05-19 02:46:58 INFO  BlockManager:54 - external shuffle service port = 7337
2021-05-19 02:46:58 INFO  BlockManager:54 - Registering executor with local external shuffle service.
2021-05-19 02:46:58 INFO  TransportClientFactory:267 - Successfully created connection to hadoop17.cusp.nyu.edu/192.168.72.187:7337 after 3 ms (0 ms spent in bootstraps)
2021-05-19 02:46:58 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(5, hadoop17.cusp.nyu.edu, 39842, None)
2021-05-19 02:47:00 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 0
2021-05-19 02:47:00 INFO  Executor:54 - Running task 0.0 in stage 0.0 (TID 0)
2021-05-19 02:47:01 INFO  TorrentBroadcast:54 - Started reading broadcast variable 1
2021-05-19 02:47:01 INFO  TransportClientFactory:267 - Successfully created connection to hadoop02.cusp.nyu.edu/192.168.72.172:49352 after 5 ms (0 ms spent in bootstraps)
2021-05-19 02:47:01 INFO  MemoryStore:54 - Block broadcast_1_piece0 stored as bytes in memory (estimated size 4.5 KB, free 366.3 MB)
2021-05-19 02:47:01 INFO  TorrentBroadcast:54 - Reading broadcast variable 1 took 180 ms
2021-05-19 02:47:01 INFO  MemoryStore:54 - Block broadcast_1 stored as values in memory (estimated size 8.8 KB, free 366.3 MB)
2021-05-19 02:47:02 INFO  CodeGenerator:54 - Code generated in 496.615802 ms
2021-05-19 02:47:02 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/core-places-nyc.csv, range: 0-4194304, partition values: [empty row]
2021-05-19 02:47:02 INFO  CodeGenerator:54 - Code generated in 34.657648 ms
2021-05-19 02:47:02 INFO  TorrentBroadcast:54 - Started reading broadcast variable 0
2021-05-19 02:47:02 INFO  MemoryStore:54 - Block broadcast_0_piece0 stored as bytes in memory (estimated size 33.4 KB, free 366.3 MB)
2021-05-19 02:47:02 INFO  TorrentBroadcast:54 - Reading broadcast variable 0 took 32 ms
2021-05-19 02:47:02 INFO  MemoryStore:54 - Block broadcast_0 stored as values in memory (estimated size 506.4 KB, free 365.8 MB)
2021-05-19 02:47:03 INFO  Executor:54 - Finished task 0.0 in stage 0.0 (TID 0). 1594 bytes result sent to driver
2021-05-19 02:47:04 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 5
2021-05-19 02:47:04 INFO  Executor:54 - Running task 4.0 in stage 1.0 (TID 5)
2021-05-19 02:47:04 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 10
2021-05-19 02:47:04 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 15
2021-05-19 02:47:04 INFO  Executor:54 - Running task 9.0 in stage 1.0 (TID 10)
2021-05-19 02:47:04 INFO  Executor:54 - Running task 14.0 in stage 1.0 (TID 15)
2021-05-19 02:47:04 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 20
2021-05-19 02:47:04 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 25
2021-05-19 02:47:04 INFO  Executor:54 - Running task 19.0 in stage 1.0 (TID 20)
2021-05-19 02:47:04 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 30
2021-05-19 02:47:04 INFO  Executor:54 - Running task 24.0 in stage 1.0 (TID 25)
2021-05-19 02:47:04 INFO  Executor:54 - Running task 29.0 in stage 1.0 (TID 30)
2021-05-19 02:47:04 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 35
2021-05-19 02:47:04 INFO  Executor:54 - Running task 34.0 in stage 1.0 (TID 35)
2021-05-19 02:47:04 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 40
2021-05-19 02:47:04 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 45
2021-05-19 02:47:04 INFO  Executor:54 - Running task 39.0 in stage 1.0 (TID 40)
2021-05-19 02:47:04 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 50
2021-05-19 02:47:04 INFO  Executor:54 - Running task 44.0 in stage 1.0 (TID 45)
2021-05-19 02:47:04 INFO  Executor:54 - Running task 49.0 in stage 1.0 (TID 50)
2021-05-19 02:47:05 INFO  TorrentBroadcast:54 - Started reading broadcast variable 3
2021-05-19 02:47:05 INFO  MemoryStore:54 - Block broadcast_3_piece0 stored as bytes in memory (estimated size 35.0 KB, free 365.7 MB)
2021-05-19 02:47:05 INFO  TorrentBroadcast:54 - Reading broadcast variable 3 took 25 ms
2021-05-19 02:47:05 INFO  MemoryStore:54 - Block broadcast_3 stored as values in memory (estimated size 129.0 KB, free 365.6 MB)
2021-05-19 02:47:05 INFO  Executor:54 - Finished task 19.0 in stage 1.0 (TID 20). 1492 bytes result sent to driver
2021-05-19 02:47:05 INFO  Executor:54 - Finished task 9.0 in stage 1.0 (TID 10). 1449 bytes result sent to driver
2021-05-19 02:47:05 INFO  Executor:54 - Finished task 29.0 in stage 1.0 (TID 30). 1492 bytes result sent to driver
2021-05-19 02:47:05 INFO  Executor:54 - Finished task 49.0 in stage 1.0 (TID 50). 1492 bytes result sent to driver
2021-05-19 02:47:05 INFO  Executor:54 - Finished task 14.0 in stage 1.0 (TID 15). 1492 bytes result sent to driver
2021-05-19 02:47:05 INFO  Executor:54 - Finished task 24.0 in stage 1.0 (TID 25). 1492 bytes result sent to driver
2021-05-19 02:47:05 INFO  Executor:54 - Finished task 34.0 in stage 1.0 (TID 35). 1492 bytes result sent to driver
2021-05-19 02:47:05 INFO  Executor:54 - Finished task 39.0 in stage 1.0 (TID 40). 1492 bytes result sent to driver
2021-05-19 02:47:05 INFO  Executor:54 - Finished task 4.0 in stage 1.0 (TID 5). 1492 bytes result sent to driver
2021-05-19 02:47:05 INFO  Executor:54 - Finished task 44.0 in stage 1.0 (TID 45). 1492 bytes result sent to driver
2021-05-19 02:47:08 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 52
2021-05-19 02:47:08 INFO  Executor:54 - Running task 1.0 in stage 2.0 (TID 52)
2021-05-19 02:47:08 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 57
2021-05-19 02:47:08 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 62
2021-05-19 02:47:08 INFO  Executor:54 - Running task 6.0 in stage 2.0 (TID 57)
2021-05-19 02:47:08 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 67
2021-05-19 02:47:08 INFO  Executor:54 - Running task 11.0 in stage 2.0 (TID 62)
2021-05-19 02:47:08 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 72
2021-05-19 02:47:08 INFO  Executor:54 - Running task 16.0 in stage 2.0 (TID 67)
2021-05-19 02:47:08 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 77
2021-05-19 02:47:08 INFO  Executor:54 - Running task 21.0 in stage 2.0 (TID 72)
2021-05-19 02:47:08 INFO  Executor:54 - Running task 26.0 in stage 2.0 (TID 77)
2021-05-19 02:47:08 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 82
2021-05-19 02:47:08 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 87
2021-05-19 02:47:08 INFO  Executor:54 - Running task 31.0 in stage 2.0 (TID 82)
2021-05-19 02:47:08 INFO  Executor:54 - Running task 36.0 in stage 2.0 (TID 87)
2021-05-19 02:47:08 INFO  TorrentBroadcast:54 - Started reading broadcast variable 4
2021-05-19 02:47:08 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 92
2021-05-19 02:47:08 INFO  Executor:54 - Running task 41.0 in stage 2.0 (TID 92)
2021-05-19 02:47:08 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 97
2021-05-19 02:47:08 INFO  Executor:54 - Running task 46.0 in stage 2.0 (TID 97)
2021-05-19 02:47:08 INFO  MemoryStore:54 - Block broadcast_4_piece0 stored as bytes in memory (estimated size 35.0 KB, free 366.1 MB)
2021-05-19 02:47:08 INFO  TorrentBroadcast:54 - Reading broadcast variable 4 took 35 ms
2021-05-19 02:47:08 INFO  MemoryStore:54 - Block broadcast_4 stored as values in memory (estimated size 129.0 KB, free 366.0 MB)
2021-05-19 02:47:08 INFO  Executor:54 - Finished task 41.0 in stage 2.0 (TID 92). 1449 bytes result sent to driver
2021-05-19 02:47:08 INFO  Executor:54 - Finished task 31.0 in stage 2.0 (TID 82). 1449 bytes result sent to driver
2021-05-19 02:47:08 INFO  Executor:54 - Finished task 6.0 in stage 2.0 (TID 57). 1449 bytes result sent to driver
2021-05-19 02:47:08 INFO  Executor:54 - Finished task 46.0 in stage 2.0 (TID 97). 1449 bytes result sent to driver
2021-05-19 02:47:08 INFO  Executor:54 - Finished task 1.0 in stage 2.0 (TID 52). 1449 bytes result sent to driver
2021-05-19 02:47:08 INFO  Executor:54 - Finished task 21.0 in stage 2.0 (TID 72). 1449 bytes result sent to driver
2021-05-19 02:47:08 INFO  Executor:54 - Finished task 11.0 in stage 2.0 (TID 62). 1449 bytes result sent to driver
2021-05-19 02:47:08 INFO  Executor:54 - Finished task 36.0 in stage 2.0 (TID 87). 1449 bytes result sent to driver
2021-05-19 02:47:08 INFO  Executor:54 - Finished task 16.0 in stage 2.0 (TID 67). 1449 bytes result sent to driver
2021-05-19 02:47:08 INFO  Executor:54 - Finished task 26.0 in stage 2.0 (TID 77). 1449 bytes result sent to driver
2021-05-19 02:47:11 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 101
2021-05-19 02:47:11 INFO  Executor:54 - Running task 0.0 in stage 4.0 (TID 101)
2021-05-19 02:47:11 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 102
2021-05-19 02:47:11 INFO  Executor:54 - Running task 1.0 in stage 4.0 (TID 102)
2021-05-19 02:47:11 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 103
2021-05-19 02:47:11 INFO  Executor:54 - Running task 2.0 in stage 4.0 (TID 103)
2021-05-19 02:47:11 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 104
2021-05-19 02:47:11 INFO  Executor:54 - Running task 3.0 in stage 4.0 (TID 104)
2021-05-19 02:47:11 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 105
2021-05-19 02:47:11 INFO  Executor:54 - Running task 4.0 in stage 4.0 (TID 105)
2021-05-19 02:47:11 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 106
2021-05-19 02:47:11 INFO  TorrentBroadcast:54 - Started reading broadcast variable 9
2021-05-19 02:47:11 INFO  Executor:54 - Running task 5.0 in stage 4.0 (TID 106)
2021-05-19 02:47:11 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 107
2021-05-19 02:47:11 INFO  Executor:54 - Running task 6.0 in stage 4.0 (TID 107)
2021-05-19 02:47:11 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 108
2021-05-19 02:47:11 INFO  Executor:54 - Running task 7.0 in stage 4.0 (TID 108)
2021-05-19 02:47:11 INFO  MemoryStore:54 - Block broadcast_9_piece0 stored as bytes in memory (estimated size 20.3 KB, free 366.3 MB)
2021-05-19 02:47:11 INFO  TorrentBroadcast:54 - Reading broadcast variable 9 took 27 ms
2021-05-19 02:47:11 INFO  MemoryStore:54 - Block broadcast_9 stored as values in memory (estimated size 42.3 KB, free 366.2 MB)
2021-05-19 02:47:11 INFO  CodeGenerator:54 - Code generated in 47.232631 ms
2021-05-19 02:47:11 INFO  CodeGenerator:54 - Code generated in 35.003281 ms
2021-05-19 02:47:12 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/core-places-nyc.csv, range: 20971520-25165824, partition values: [empty row]
2021-05-19 02:47:12 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/core-places-nyc.csv, range: 4194304-8388608, partition values: [empty row]
2021-05-19 02:47:12 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/core-places-nyc.csv, range: 25165824-29360128, partition values: [empty row]
2021-05-19 02:47:12 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/core-places-nyc.csv, range: 0-4194304, partition values: [empty row]
2021-05-19 02:47:12 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/core-places-nyc.csv, range: 29360128-31553829, partition values: [empty row]
2021-05-19 02:47:12 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/core-places-nyc.csv, range: 12582912-16777216, partition values: [empty row]
2021-05-19 02:47:12 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/core-places-nyc.csv, range: 8388608-12582912, partition values: [empty row]
2021-05-19 02:47:12 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/core-places-nyc.csv, range: 16777216-20971520, partition values: [empty row]
2021-05-19 02:47:12 INFO  CodeGenerator:54 - Code generated in 44.381728 ms
2021-05-19 02:47:12 INFO  CodeGenerator:54 - Code generated in 50.084137 ms
2021-05-19 02:47:12 INFO  TorrentBroadcast:54 - Started reading broadcast variable 8
2021-05-19 02:47:12 INFO  CodeGenerator:54 - Code generated in 47.528063 ms
2021-05-19 02:47:12 INFO  MemoryStore:54 - Block broadcast_8_piece0 stored as bytes in memory (estimated size 33.4 KB, free 366.2 MB)
2021-05-19 02:47:12 INFO  TorrentBroadcast:54 - Reading broadcast variable 8 took 30 ms
2021-05-19 02:47:12 INFO  MemoryStore:54 - Block broadcast_8 stored as values in memory (estimated size 506.4 KB, free 365.7 MB)
2021-05-19 02:47:13 INFO  PythonUDFRunner:54 - Times: total = 1525, boot = 734, init = 782, finish = 9
2021-05-19 02:47:13 INFO  MemoryStore:54 - Block rdd_29_7 stored as values in memory (estimated size 47.3 KB, free 349.7 MB)
2021-05-19 02:47:13 INFO  PythonUDFRunner:54 - Times: total = 1598, boot = 755, init = 827, finish = 16
2021-05-19 02:47:13 INFO  PythonUDFRunner:54 - Times: total = 1628, boot = 765, init = 850, finish = 13
2021-05-19 02:47:13 INFO  PythonUDFRunner:54 - Times: total = 1634, boot = 712, init = 908, finish = 14
2021-05-19 02:47:13 INFO  MemoryStore:54 - Block rdd_29_2 stored as values in memory (estimated size 91.5 KB, free 349.6 MB)
2021-05-19 02:47:13 INFO  PythonUDFRunner:54 - Times: total = 1631, boot = 701, init = 921, finish = 9
2021-05-19 02:47:13 INFO  MemoryStore:54 - Block rdd_29_4 stored as values in memory (estimated size 88.8 KB, free 349.5 MB)
2021-05-19 02:47:13 INFO  PythonUDFRunner:54 - Times: total = 1623, boot = 687, init = 922, finish = 14
2021-05-19 02:47:13 INFO  PythonUDFRunner:54 - Times: total = 1623, boot = 723, init = 885, finish = 15
2021-05-19 02:47:13 INFO  PythonUDFRunner:54 - Times: total = 1633, boot = 745, init = 871, finish = 17
2021-05-19 02:47:13 INFO  CodeGenerator:54 - Code generated in 14.696029 ms
2021-05-19 02:47:13 INFO  MemoryStore:54 - Block rdd_29_0 stored as values in memory (estimated size 90.4 KB, free 349.4 MB)
2021-05-19 02:47:13 INFO  MemoryStore:54 - Block rdd_29_1 stored as values in memory (estimated size 90.8 KB, free 349.1 MB)
2021-05-19 02:47:13 INFO  MemoryStore:54 - Block rdd_29_5 stored as values in memory (estimated size 91.5 KB, free 349.1 MB)
2021-05-19 02:47:13 INFO  MemoryStore:54 - Block rdd_29_6 stored as values in memory (estimated size 90.2 KB, free 349.0 MB)
2021-05-19 02:47:13 INFO  MemoryStore:54 - Block rdd_29_3 stored as values in memory (estimated size 89.5 KB, free 349.0 MB)
2021-05-19 02:47:13 INFO  CodeGenerator:54 - Code generated in 48.61728 ms
2021-05-19 02:47:13 INFO  CodeGenerator:54 - Code generated in 84.396332 ms
2021-05-19 02:47:13 INFO  CodeGenerator:54 - Code generated in 17.246376 ms
2021-05-19 02:47:13 INFO  CodeGenerator:54 - Code generated in 20.398386 ms
2021-05-19 02:47:14 INFO  CodeGenerator:54 - Code generated in 29.105607 ms
2021-05-19 02:47:14 INFO  Executor:54 - Finished task 5.0 in stage 4.0 (TID 106). 3433 bytes result sent to driver
2021-05-19 02:47:14 INFO  Executor:54 - Finished task 4.0 in stage 4.0 (TID 105). 3476 bytes result sent to driver
2021-05-19 02:47:14 INFO  Executor:54 - Finished task 6.0 in stage 4.0 (TID 107). 3433 bytes result sent to driver
2021-05-19 02:47:14 INFO  Executor:54 - Finished task 0.0 in stage 4.0 (TID 101). 3433 bytes result sent to driver
2021-05-19 02:47:14 INFO  Executor:54 - Finished task 2.0 in stage 4.0 (TID 103). 3433 bytes result sent to driver
2021-05-19 02:47:14 INFO  Executor:54 - Finished task 3.0 in stage 4.0 (TID 104). 3433 bytes result sent to driver
2021-05-19 02:47:14 INFO  Executor:54 - Finished task 1.0 in stage 4.0 (TID 102). 3433 bytes result sent to driver
2021-05-19 02:47:14 INFO  Executor:54 - Finished task 7.0 in stage 4.0 (TID 108). 3433 bytes result sent to driver
2021-05-19 02:47:14 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 109
2021-05-19 02:47:14 INFO  Executor:54 - Running task 3.0 in stage 5.0 (TID 109)
2021-05-19 02:47:14 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 110
2021-05-19 02:47:14 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 111
2021-05-19 02:47:14 INFO  Executor:54 - Running task 18.0 in stage 5.0 (TID 110)
2021-05-19 02:47:14 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 112
2021-05-19 02:47:14 INFO  Executor:54 - Running task 26.0 in stage 5.0 (TID 111)
2021-05-19 02:47:14 INFO  Executor:54 - Running task 35.0 in stage 5.0 (TID 112)
2021-05-19 02:47:14 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 113
2021-05-19 02:47:14 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 114
2021-05-19 02:47:14 INFO  Executor:54 - Running task 49.0 in stage 5.0 (TID 113)
2021-05-19 02:47:14 INFO  Executor:54 - Running task 75.0 in stage 5.0 (TID 114)
2021-05-19 02:47:14 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 115
2021-05-19 02:47:14 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 116
2021-05-19 02:47:14 INFO  Executor:54 - Running task 144.0 in stage 5.0 (TID 115)
2021-05-19 02:47:14 INFO  Executor:54 - Running task 166.0 in stage 5.0 (TID 116)
2021-05-19 02:47:14 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 117
2021-05-19 02:47:14 INFO  Executor:54 - Running task 189.0 in stage 5.0 (TID 117)
2021-05-19 02:47:14 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 121
2021-05-19 02:47:14 INFO  Executor:54 - Running task 4.0 in stage 5.0 (TID 121)
2021-05-19 02:47:14 INFO  MapOutputTrackerWorker:54 - Updating epoch to 1 and clearing cache
2021-05-19 02:47:14 INFO  TorrentBroadcast:54 - Started reading broadcast variable 10
2021-05-19 02:47:14 INFO  MemoryStore:54 - Block broadcast_10_piece0 stored as bytes in memory (estimated size 20.4 KB, free 365.0 MB)
2021-05-19 02:47:14 INFO  TorrentBroadcast:54 - Reading broadcast variable 10 took 17 ms
2021-05-19 02:47:14 INFO  MemoryStore:54 - Block broadcast_10 stored as values in memory (estimated size 40.9 KB, free 365.0 MB)
2021-05-19 02:47:14 INFO  MapOutputTrackerWorker:54 - Don't have map outputs for shuffle 0, fetching them
2021-05-19 02:47:14 INFO  MapOutputTrackerWorker:54 - Don't have map outputs for shuffle 0, fetching them
2021-05-19 02:47:14 INFO  MapOutputTrackerWorker:54 - Don't have map outputs for shuffle 0, fetching them
2021-05-19 02:47:14 INFO  MapOutputTrackerWorker:54 - Don't have map outputs for shuffle 0, fetching them
2021-05-19 02:47:14 INFO  MapOutputTrackerWorker:54 - Don't have map outputs for shuffle 0, fetching them
2021-05-19 02:47:14 INFO  MapOutputTrackerWorker:54 - Don't have map outputs for shuffle 0, fetching them
2021-05-19 02:47:14 INFO  MapOutputTrackerWorker:54 - Doing the fetch; tracker endpoint = NettyRpcEndpointRef(spark://MapOutputTracker@hadoop02.cusp.nyu.edu:60108)
2021-05-19 02:47:14 INFO  MapOutputTrackerWorker:54 - Don't have map outputs for shuffle 0, fetching them
2021-05-19 02:47:14 INFO  MapOutputTrackerWorker:54 - Don't have map outputs for shuffle 0, fetching them
2021-05-19 02:47:14 INFO  MapOutputTrackerWorker:54 - Don't have map outputs for shuffle 0, fetching them
2021-05-19 02:47:14 INFO  MapOutputTrackerWorker:54 - Don't have map outputs for shuffle 0, fetching them
2021-05-19 02:47:14 INFO  MapOutputTrackerWorker:54 - Got the output locations
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Getting 8 non-empty blocks including 8 local blocks and 0 remote blocks
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Getting 8 non-empty blocks including 8 local blocks and 0 remote blocks
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Getting 8 non-empty blocks including 8 local blocks and 0 remote blocks
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Getting 8 non-empty blocks including 8 local blocks and 0 remote blocks
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Getting 8 non-empty blocks including 8 local blocks and 0 remote blocks
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Getting 8 non-empty blocks including 8 local blocks and 0 remote blocks
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 24 ms
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Getting 8 non-empty blocks including 8 local blocks and 0 remote blocks
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 24 ms
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 23 ms
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 23 ms
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Getting 8 non-empty blocks including 8 local blocks and 0 remote blocks
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 28 ms
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 22 ms
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 22 ms
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 22 ms
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Getting 8 non-empty blocks including 8 local blocks and 0 remote blocks
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 31 ms
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 25 ms
2021-05-19 02:47:14 INFO  CodeGenerator:54 - Code generated in 55.633068 ms
2021-05-19 02:47:14 INFO  Executor:54 - Finished task 4.0 in stage 5.0 (TID 121). 3733 bytes result sent to driver
2021-05-19 02:47:14 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 159
2021-05-19 02:47:14 INFO  Executor:54 - Running task 45.0 in stage 5.0 (TID 159)
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2021-05-19 02:47:14 INFO  Executor:54 - Finished task 166.0 in stage 5.0 (TID 116). 3763 bytes result sent to driver
2021-05-19 02:47:14 INFO  Executor:54 - Finished task 49.0 in stage 5.0 (TID 113). 3763 bytes result sent to driver
2021-05-19 02:47:14 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 160
2021-05-19 02:47:14 INFO  Executor:54 - Finished task 189.0 in stage 5.0 (TID 117). 3763 bytes result sent to driver
2021-05-19 02:47:14 INFO  Executor:54 - Running task 46.0 in stage 5.0 (TID 160)
2021-05-19 02:47:14 INFO  Executor:54 - Finished task 3.0 in stage 5.0 (TID 109). 3763 bytes result sent to driver
2021-05-19 02:47:14 INFO  Executor:54 - Finished task 75.0 in stage 5.0 (TID 114). 3763 bytes result sent to driver
2021-05-19 02:47:14 INFO  Executor:54 - Finished task 18.0 in stage 5.0 (TID 110). 3806 bytes result sent to driver
2021-05-19 02:47:14 INFO  Executor:54 - Finished task 35.0 in stage 5.0 (TID 112). 3762 bytes result sent to driver
2021-05-19 02:47:14 INFO  Executor:54 - Finished task 26.0 in stage 5.0 (TID 111). 3763 bytes result sent to driver
2021-05-19 02:47:14 INFO  Executor:54 - Finished task 45.0 in stage 5.0 (TID 159). 3776 bytes result sent to driver
2021-05-19 02:47:14 INFO  Executor:54 - Finished task 144.0 in stage 5.0 (TID 115). 3763 bytes result sent to driver
2021-05-19 02:47:14 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 161
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:47:14 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 162
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2021-05-19 02:47:14 INFO  Executor:54 - Running task 47.0 in stage 5.0 (TID 161)
2021-05-19 02:47:14 INFO  Executor:54 - Running task 48.0 in stage 5.0 (TID 162)
2021-05-19 02:47:14 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 163
2021-05-19 02:47:14 INFO  Executor:54 - Running task 50.0 in stage 5.0 (TID 163)
2021-05-19 02:47:14 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 164
2021-05-19 02:47:14 INFO  Executor:54 - Running task 51.0 in stage 5.0 (TID 164)
2021-05-19 02:47:14 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 165
2021-05-19 02:47:14 INFO  Executor:54 - Running task 52.0 in stage 5.0 (TID 165)
2021-05-19 02:47:14 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 166
2021-05-19 02:47:14 INFO  Executor:54 - Running task 53.0 in stage 5.0 (TID 166)
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:47:14 INFO  Executor:54 - Finished task 46.0 in stage 5.0 (TID 160). 3733 bytes result sent to driver
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2021-05-19 02:47:14 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 167
2021-05-19 02:47:14 INFO  Executor:54 - Running task 54.0 in stage 5.0 (TID 167)
2021-05-19 02:47:14 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 168
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:47:14 INFO  Executor:54 - Running task 55.0 in stage 5.0 (TID 168)
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 4 ms
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2021-05-19 02:47:14 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 169
2021-05-19 02:47:14 INFO  Executor:54 - Running task 56.0 in stage 5.0 (TID 169)
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:47:14 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 170
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2021-05-19 02:47:14 INFO  Executor:54 - Running task 57.0 in stage 5.0 (TID 170)
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:47:14 INFO  Executor:54 - Finished task 47.0 in stage 5.0 (TID 161). 3733 bytes result sent to driver
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2021-05-19 02:47:14 INFO  Executor:54 - Finished task 50.0 in stage 5.0 (TID 163). 3733 bytes result sent to driver
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2021-05-19 02:47:14 INFO  Executor:54 - Finished task 52.0 in stage 5.0 (TID 165). 3733 bytes result sent to driver
2021-05-19 02:47:14 INFO  Executor:54 - Finished task 48.0 in stage 5.0 (TID 162). 3733 bytes result sent to driver
2021-05-19 02:47:14 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 171
2021-05-19 02:47:14 INFO  Executor:54 - Running task 58.0 in stage 5.0 (TID 171)
2021-05-19 02:47:14 INFO  Executor:54 - Finished task 51.0 in stage 5.0 (TID 164). 3733 bytes result sent to driver
2021-05-19 02:47:14 INFO  Executor:54 - Finished task 53.0 in stage 5.0 (TID 166). 3733 bytes result sent to driver
2021-05-19 02:47:14 INFO  Executor:54 - Finished task 54.0 in stage 5.0 (TID 167). 3733 bytes result sent to driver
2021-05-19 02:47:14 INFO  Executor:54 - Finished task 55.0 in stage 5.0 (TID 168). 3733 bytes result sent to driver
2021-05-19 02:47:14 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 172
2021-05-19 02:47:14 INFO  Executor:54 - Running task 59.0 in stage 5.0 (TID 172)
2021-05-19 02:47:14 INFO  Executor:54 - Finished task 57.0 in stage 5.0 (TID 170). 3733 bytes result sent to driver
2021-05-19 02:47:14 INFO  Executor:54 - Finished task 56.0 in stage 5.0 (TID 169). 3733 bytes result sent to driver
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2021-05-19 02:47:14 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 173
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:47:14 INFO  Executor:54 - Running task 60.0 in stage 5.0 (TID 173)
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2021-05-19 02:47:14 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 174
2021-05-19 02:47:14 INFO  Executor:54 - Running task 61.0 in stage 5.0 (TID 174)
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2021-05-19 02:47:14 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 175
2021-05-19 02:47:14 INFO  Executor:54 - Running task 62.0 in stage 5.0 (TID 175)
2021-05-19 02:47:14 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 176
2021-05-19 02:47:14 INFO  Executor:54 - Running task 63.0 in stage 5.0 (TID 176)
2021-05-19 02:47:14 INFO  Executor:54 - Finished task 58.0 in stage 5.0 (TID 171). 3733 bytes result sent to driver
2021-05-19 02:47:14 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 177
2021-05-19 02:47:14 INFO  Executor:54 - Finished task 59.0 in stage 5.0 (TID 172). 3733 bytes result sent to driver
2021-05-19 02:47:14 INFO  Executor:54 - Running task 64.0 in stage 5.0 (TID 177)
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2021-05-19 02:47:14 INFO  Executor:54 - Finished task 60.0 in stage 5.0 (TID 173). 3733 bytes result sent to driver
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:47:14 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 178
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2021-05-19 02:47:14 INFO  Executor:54 - Running task 65.0 in stage 5.0 (TID 178)
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2021-05-19 02:47:14 INFO  Executor:54 - Finished task 61.0 in stage 5.0 (TID 174). 3733 bytes result sent to driver
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2021-05-19 02:47:14 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 179
2021-05-19 02:47:14 INFO  Executor:54 - Finished task 63.0 in stage 5.0 (TID 176). 3776 bytes result sent to driver
2021-05-19 02:47:14 INFO  Executor:54 - Running task 66.0 in stage 5.0 (TID 179)
2021-05-19 02:47:14 INFO  Executor:54 - Finished task 64.0 in stage 5.0 (TID 177). 3733 bytes result sent to driver
2021-05-19 02:47:14 INFO  Executor:54 - Finished task 62.0 in stage 5.0 (TID 175). 3733 bytes result sent to driver
2021-05-19 02:47:14 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 180
2021-05-19 02:47:14 INFO  Executor:54 - Running task 67.0 in stage 5.0 (TID 180)
2021-05-19 02:47:14 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 181
2021-05-19 02:47:14 INFO  Executor:54 - Running task 68.0 in stage 5.0 (TID 181)
2021-05-19 02:47:14 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 182
2021-05-19 02:47:14 INFO  Executor:54 - Running task 69.0 in stage 5.0 (TID 182)
2021-05-19 02:47:14 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 183
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:47:14 INFO  Executor:54 - Running task 70.0 in stage 5.0 (TID 183)
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2021-05-19 02:47:14 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 184
2021-05-19 02:47:14 INFO  Executor:54 - Finished task 65.0 in stage 5.0 (TID 178). 3733 bytes result sent to driver
2021-05-19 02:47:14 INFO  Executor:54 - Running task 71.0 in stage 5.0 (TID 184)
2021-05-19 02:47:14 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 185
2021-05-19 02:47:14 INFO  Executor:54 - Running task 72.0 in stage 5.0 (TID 185)
2021-05-19 02:47:14 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 186
2021-05-19 02:47:14 INFO  Executor:54 - Running task 73.0 in stage 5.0 (TID 186)
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2021-05-19 02:47:14 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 187
2021-05-19 02:47:14 INFO  Executor:54 - Running task 74.0 in stage 5.0 (TID 187)
2021-05-19 02:47:14 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 188
2021-05-19 02:47:14 INFO  Executor:54 - Running task 76.0 in stage 5.0 (TID 188)
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2021-05-19 02:47:14 INFO  Executor:54 - Finished task 66.0 in stage 5.0 (TID 179). 3733 bytes result sent to driver
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:47:14 INFO  Executor:54 - Finished task 68.0 in stage 5.0 (TID 181). 3733 bytes result sent to driver
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2021-05-19 02:47:14 INFO  Executor:54 - Finished task 67.0 in stage 5.0 (TID 180). 3733 bytes result sent to driver
2021-05-19 02:47:14 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 189
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:47:14 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 190
2021-05-19 02:47:14 INFO  Executor:54 - Running task 77.0 in stage 5.0 (TID 189)
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2021-05-19 02:47:14 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 191
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2021-05-19 02:47:14 INFO  Executor:54 - Running task 79.0 in stage 5.0 (TID 191)
2021-05-19 02:47:14 INFO  Executor:54 - Running task 78.0 in stage 5.0 (TID 190)
2021-05-19 02:47:14 INFO  Executor:54 - Finished task 72.0 in stage 5.0 (TID 185). 3733 bytes result sent to driver
2021-05-19 02:47:14 INFO  Executor:54 - Finished task 71.0 in stage 5.0 (TID 184). 3733 bytes result sent to driver
2021-05-19 02:47:14 INFO  Executor:54 - Finished task 69.0 in stage 5.0 (TID 182). 3733 bytes result sent to driver
2021-05-19 02:47:14 INFO  Executor:54 - Finished task 70.0 in stage 5.0 (TID 183). 3733 bytes result sent to driver
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2021-05-19 02:47:14 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 192
2021-05-19 02:47:14 INFO  Executor:54 - Running task 80.0 in stage 5.0 (TID 192)
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2021-05-19 02:47:14 INFO  Executor:54 - Finished task 73.0 in stage 5.0 (TID 186). 3733 bytes result sent to driver
2021-05-19 02:47:14 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 193
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:47:14 INFO  Executor:54 - Running task 81.0 in stage 5.0 (TID 193)
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2021-05-19 02:47:14 INFO  Executor:54 - Finished task 76.0 in stage 5.0 (TID 188). 3733 bytes result sent to driver
2021-05-19 02:47:14 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 194
2021-05-19 02:47:14 INFO  Executor:54 - Finished task 77.0 in stage 5.0 (TID 189). 3733 bytes result sent to driver
2021-05-19 02:47:14 INFO  Executor:54 - Running task 82.0 in stage 5.0 (TID 194)
2021-05-19 02:47:14 INFO  Executor:54 - Finished task 74.0 in stage 5.0 (TID 187). 3733 bytes result sent to driver
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:47:14 INFO  Executor:54 - Finished task 79.0 in stage 5.0 (TID 191). 3733 bytes result sent to driver
2021-05-19 02:47:14 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 195
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 4 ms
2021-05-19 02:47:14 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 196
2021-05-19 02:47:14 INFO  Executor:54 - Running task 83.0 in stage 5.0 (TID 195)
2021-05-19 02:47:14 INFO  Executor:54 - Running task 84.0 in stage 5.0 (TID 196)
2021-05-19 02:47:14 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 197
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2021-05-19 02:47:14 INFO  Executor:54 - Running task 85.0 in stage 5.0 (TID 197)
2021-05-19 02:47:14 INFO  Executor:54 - Finished task 78.0 in stage 5.0 (TID 190). 3776 bytes result sent to driver
2021-05-19 02:47:14 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 198
2021-05-19 02:47:14 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 199
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:47:14 INFO  Executor:54 - Running task 86.0 in stage 5.0 (TID 198)
2021-05-19 02:47:14 INFO  Executor:54 - Running task 87.0 in stage 5.0 (TID 199)
2021-05-19 02:47:14 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 200
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2021-05-19 02:47:14 INFO  Executor:54 - Running task 88.0 in stage 5.0 (TID 200)
2021-05-19 02:47:14 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 201
2021-05-19 02:47:14 INFO  Executor:54 - Running task 89.0 in stage 5.0 (TID 201)
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2021-05-19 02:47:14 INFO  Executor:54 - Finished task 80.0 in stage 5.0 (TID 192). 3776 bytes result sent to driver
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:47:14 INFO  Executor:54 - Finished task 81.0 in stage 5.0 (TID 193). 3819 bytes result sent to driver
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:47:14 INFO  Executor:54 - Finished task 82.0 in stage 5.0 (TID 194). 3776 bytes result sent to driver
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2021-05-19 02:47:14 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 202
2021-05-19 02:47:14 INFO  Executor:54 - Running task 90.0 in stage 5.0 (TID 202)
2021-05-19 02:47:14 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 203
2021-05-19 02:47:14 INFO  Executor:54 - Running task 91.0 in stage 5.0 (TID 203)
2021-05-19 02:47:14 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 204
2021-05-19 02:47:14 INFO  Executor:54 - Running task 92.0 in stage 5.0 (TID 204)
2021-05-19 02:47:14 INFO  Executor:54 - Finished task 83.0 in stage 5.0 (TID 195). 3733 bytes result sent to driver
2021-05-19 02:47:14 INFO  Executor:54 - Finished task 86.0 in stage 5.0 (TID 198). 3733 bytes result sent to driver
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:47:14 INFO  Executor:54 - Finished task 84.0 in stage 5.0 (TID 196). 3733 bytes result sent to driver
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2021-05-19 02:47:14 INFO  Executor:54 - Finished task 88.0 in stage 5.0 (TID 200). 3733 bytes result sent to driver
2021-05-19 02:47:14 INFO  Executor:54 - Finished task 85.0 in stage 5.0 (TID 197). 3733 bytes result sent to driver
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2021-05-19 02:47:14 INFO  Executor:54 - Finished task 87.0 in stage 5.0 (TID 199). 3733 bytes result sent to driver
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:47:14 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 205
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2021-05-19 02:47:14 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 206
2021-05-19 02:47:14 INFO  Executor:54 - Running task 93.0 in stage 5.0 (TID 205)
2021-05-19 02:47:14 INFO  Executor:54 - Running task 94.0 in stage 5.0 (TID 206)
2021-05-19 02:47:14 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 207
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:47:14 INFO  Executor:54 - Running task 95.0 in stage 5.0 (TID 207)
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2021-05-19 02:47:14 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 208
2021-05-19 02:47:14 INFO  Executor:54 - Running task 96.0 in stage 5.0 (TID 208)
2021-05-19 02:47:14 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 209
2021-05-19 02:47:14 INFO  Executor:54 - Running task 97.0 in stage 5.0 (TID 209)
2021-05-19 02:47:14 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 210
2021-05-19 02:47:14 INFO  Executor:54 - Running task 98.0 in stage 5.0 (TID 210)
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2021-05-19 02:47:14 INFO  Executor:54 - Finished task 91.0 in stage 5.0 (TID 203). 3733 bytes result sent to driver
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2021-05-19 02:47:14 INFO  Executor:54 - Finished task 89.0 in stage 5.0 (TID 201). 3733 bytes result sent to driver
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2021-05-19 02:47:14 INFO  Executor:54 - Finished task 90.0 in stage 5.0 (TID 202). 3733 bytes result sent to driver
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2021-05-19 02:47:14 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 211
2021-05-19 02:47:14 INFO  Executor:54 - Running task 99.0 in stage 5.0 (TID 211)
2021-05-19 02:47:14 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 212
2021-05-19 02:47:14 INFO  Executor:54 - Running task 100.0 in stage 5.0 (TID 212)
2021-05-19 02:47:14 INFO  Executor:54 - Finished task 95.0 in stage 5.0 (TID 207). 3733 bytes result sent to driver
2021-05-19 02:47:14 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 213
2021-05-19 02:47:14 INFO  Executor:54 - Finished task 92.0 in stage 5.0 (TID 204). 3733 bytes result sent to driver
2021-05-19 02:47:14 INFO  Executor:54 - Running task 101.0 in stage 5.0 (TID 213)
2021-05-19 02:47:14 INFO  Executor:54 - Finished task 94.0 in stage 5.0 (TID 206). 3733 bytes result sent to driver
2021-05-19 02:47:14 INFO  Executor:54 - Finished task 96.0 in stage 5.0 (TID 208). 3733 bytes result sent to driver
2021-05-19 02:47:14 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 214
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:47:14 INFO  Executor:54 - Running task 102.0 in stage 5.0 (TID 214)
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2021-05-19 02:47:14 INFO  Executor:54 - Finished task 93.0 in stage 5.0 (TID 205). 3733 bytes result sent to driver
2021-05-19 02:47:14 INFO  Executor:54 - Finished task 97.0 in stage 5.0 (TID 209). 3733 bytes result sent to driver
2021-05-19 02:47:14 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 215
2021-05-19 02:47:14 INFO  Executor:54 - Finished task 98.0 in stage 5.0 (TID 210). 3733 bytes result sent to driver
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:47:14 INFO  Executor:54 - Running task 103.0 in stage 5.0 (TID 215)
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:47:14 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 216
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2021-05-19 02:47:14 INFO  Executor:54 - Running task 104.0 in stage 5.0 (TID 216)
2021-05-19 02:47:14 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 217
2021-05-19 02:47:14 INFO  Executor:54 - Running task 105.0 in stage 5.0 (TID 217)
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:47:14 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 218
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2021-05-19 02:47:14 INFO  Executor:54 - Running task 106.0 in stage 5.0 (TID 218)
2021-05-19 02:47:14 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 219
2021-05-19 02:47:14 INFO  Executor:54 - Running task 107.0 in stage 5.0 (TID 219)
2021-05-19 02:47:14 INFO  Executor:54 - Finished task 99.0 in stage 5.0 (TID 211). 3733 bytes result sent to driver
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:47:14 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 220
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2021-05-19 02:47:14 INFO  Executor:54 - Running task 108.0 in stage 5.0 (TID 220)
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2021-05-19 02:47:14 INFO  Executor:54 - Finished task 101.0 in stage 5.0 (TID 213). 3733 bytes result sent to driver
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2021-05-19 02:47:14 INFO  Executor:54 - Finished task 100.0 in stage 5.0 (TID 212). 3776 bytes result sent to driver
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:47:14 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 221
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2021-05-19 02:47:14 INFO  Executor:54 - Running task 109.0 in stage 5.0 (TID 221)
2021-05-19 02:47:14 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 222
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2021-05-19 02:47:14 INFO  Executor:54 - Running task 110.0 in stage 5.0 (TID 222)
2021-05-19 02:47:14 INFO  Executor:54 - Finished task 102.0 in stage 5.0 (TID 214). 3733 bytes result sent to driver
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2021-05-19 02:47:14 INFO  Executor:54 - Finished task 104.0 in stage 5.0 (TID 216). 3733 bytes result sent to driver
2021-05-19 02:47:14 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 223
2021-05-19 02:47:14 INFO  Executor:54 - Running task 111.0 in stage 5.0 (TID 223)
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:47:14 INFO  Executor:54 - Finished task 103.0 in stage 5.0 (TID 215). 3733 bytes result sent to driver
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2021-05-19 02:47:14 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 224
2021-05-19 02:47:14 INFO  Executor:54 - Running task 112.0 in stage 5.0 (TID 224)
2021-05-19 02:47:14 INFO  Executor:54 - Finished task 105.0 in stage 5.0 (TID 217). 3733 bytes result sent to driver
2021-05-19 02:47:14 INFO  Executor:54 - Finished task 106.0 in stage 5.0 (TID 218). 3733 bytes result sent to driver
2021-05-19 02:47:14 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 225
2021-05-19 02:47:14 INFO  Executor:54 - Running task 113.0 in stage 5.0 (TID 225)
2021-05-19 02:47:14 INFO  Executor:54 - Finished task 107.0 in stage 5.0 (TID 219). 3733 bytes result sent to driver
2021-05-19 02:47:14 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 226
2021-05-19 02:47:14 INFO  Executor:54 - Running task 114.0 in stage 5.0 (TID 226)
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2021-05-19 02:47:14 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 227
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2021-05-19 02:47:14 INFO  Executor:54 - Running task 115.0 in stage 5.0 (TID 227)
2021-05-19 02:47:14 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 228
2021-05-19 02:47:14 INFO  Executor:54 - Running task 116.0 in stage 5.0 (TID 228)
2021-05-19 02:47:14 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 229
2021-05-19 02:47:15 INFO  Executor:54 - Running task 117.0 in stage 5.0 (TID 229)
2021-05-19 02:47:15 INFO  Executor:54 - Finished task 108.0 in stage 5.0 (TID 220). 3776 bytes result sent to driver
2021-05-19 02:47:15 INFO  Executor:54 - Finished task 110.0 in stage 5.0 (TID 222). 3733 bytes result sent to driver
2021-05-19 02:47:15 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:47:15 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2021-05-19 02:47:15 INFO  Executor:54 - Finished task 109.0 in stage 5.0 (TID 221). 3776 bytes result sent to driver
2021-05-19 02:47:15 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:47:15 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:47:15 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2021-05-19 02:47:15 INFO  Executor:54 - Finished task 112.0 in stage 5.0 (TID 224). 3733 bytes result sent to driver
2021-05-19 02:47:15 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2021-05-19 02:47:15 INFO  Executor:54 - Finished task 111.0 in stage 5.0 (TID 223). 3733 bytes result sent to driver
2021-05-19 02:47:15 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:47:15 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2021-05-19 02:47:15 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 230
2021-05-19 02:47:15 INFO  Executor:54 - Running task 118.0 in stage 5.0 (TID 230)
2021-05-19 02:47:15 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 231
2021-05-19 02:47:15 INFO  Executor:54 - Running task 119.0 in stage 5.0 (TID 231)
2021-05-19 02:47:15 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:47:15 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2021-05-19 02:47:15 INFO  Executor:54 - Finished task 114.0 in stage 5.0 (TID 226). 3733 bytes result sent to driver
2021-05-19 02:47:15 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 232
2021-05-19 02:47:15 INFO  Executor:54 - Running task 120.0 in stage 5.0 (TID 232)
2021-05-19 02:47:15 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 233
2021-05-19 02:47:15 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:47:15 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:47:15 INFO  Executor:54 - Running task 121.0 in stage 5.0 (TID 233)
2021-05-19 02:47:15 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2021-05-19 02:47:15 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2021-05-19 02:47:15 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 234
2021-05-19 02:47:15 INFO  Executor:54 - Finished task 116.0 in stage 5.0 (TID 228). 3733 bytes result sent to driver
2021-05-19 02:47:15 INFO  Executor:54 - Finished task 115.0 in stage 5.0 (TID 227). 3733 bytes result sent to driver
2021-05-19 02:47:15 INFO  Executor:54 - Running task 122.0 in stage 5.0 (TID 234)
2021-05-19 02:47:15 INFO  Executor:54 - Finished task 113.0 in stage 5.0 (TID 225). 3733 bytes result sent to driver
2021-05-19 02:47:15 INFO  Executor:54 - Finished task 117.0 in stage 5.0 (TID 229). 3733 bytes result sent to driver
2021-05-19 02:47:15 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 235
2021-05-19 02:47:15 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:47:15 INFO  Executor:54 - Running task 123.0 in stage 5.0 (TID 235)
2021-05-19 02:47:15 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2021-05-19 02:47:15 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:47:15 INFO  Executor:54 - Finished task 119.0 in stage 5.0 (TID 231). 3733 bytes result sent to driver
2021-05-19 02:47:15 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2021-05-19 02:47:15 INFO  Executor:54 - Finished task 118.0 in stage 5.0 (TID 230). 3733 bytes result sent to driver
2021-05-19 02:47:15 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:47:15 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2021-05-19 02:47:15 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 239
2021-05-19 02:47:15 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:47:15 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2021-05-19 02:47:15 INFO  Executor:54 - Running task 127.0 in stage 5.0 (TID 239)
2021-05-19 02:47:15 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 241
2021-05-19 02:47:15 INFO  Executor:54 - Finished task 121.0 in stage 5.0 (TID 233). 3733 bytes result sent to driver
2021-05-19 02:47:15 INFO  Executor:54 - Running task 129.0 in stage 5.0 (TID 241)
2021-05-19 02:47:15 INFO  Executor:54 - Finished task 120.0 in stage 5.0 (TID 232). 3733 bytes result sent to driver
2021-05-19 02:47:15 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 243
2021-05-19 02:47:15 INFO  Executor:54 - Running task 131.0 in stage 5.0 (TID 243)
2021-05-19 02:47:15 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 244
2021-05-19 02:47:15 INFO  Executor:54 - Running task 132.0 in stage 5.0 (TID 244)
2021-05-19 02:47:15 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:47:15 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2021-05-19 02:47:15 INFO  Executor:54 - Finished task 122.0 in stage 5.0 (TID 234). 3733 bytes result sent to driver
2021-05-19 02:47:15 INFO  Executor:54 - Finished task 123.0 in stage 5.0 (TID 235). 3733 bytes result sent to driver
2021-05-19 02:47:15 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:47:15 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 246
2021-05-19 02:47:15 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2021-05-19 02:47:15 INFO  Executor:54 - Running task 134.0 in stage 5.0 (TID 246)
2021-05-19 02:47:15 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:47:15 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2021-05-19 02:47:15 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:47:15 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2021-05-19 02:47:15 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:47:15 INFO  Executor:54 - Finished task 127.0 in stage 5.0 (TID 239). 3733 bytes result sent to driver
2021-05-19 02:47:15 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2021-05-19 02:47:15 INFO  Executor:54 - Finished task 129.0 in stage 5.0 (TID 241). 3733 bytes result sent to driver
2021-05-19 02:47:15 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 251
2021-05-19 02:47:15 INFO  Executor:54 - Finished task 131.0 in stage 5.0 (TID 243). 3733 bytes result sent to driver
2021-05-19 02:47:15 INFO  Executor:54 - Running task 139.0 in stage 5.0 (TID 251)
2021-05-19 02:47:15 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 252
2021-05-19 02:47:15 INFO  Executor:54 - Running task 140.0 in stage 5.0 (TID 252)
2021-05-19 02:47:15 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 253
2021-05-19 02:47:15 INFO  Executor:54 - Running task 141.0 in stage 5.0 (TID 253)
2021-05-19 02:47:15 INFO  Executor:54 - Finished task 132.0 in stage 5.0 (TID 244). 3733 bytes result sent to driver
2021-05-19 02:47:15 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 254
2021-05-19 02:47:15 INFO  Executor:54 - Running task 142.0 in stage 5.0 (TID 254)
2021-05-19 02:47:15 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:47:15 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2021-05-19 02:47:15 INFO  Executor:54 - Finished task 134.0 in stage 5.0 (TID 246). 3733 bytes result sent to driver
2021-05-19 02:47:15 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 255
2021-05-19 02:47:15 INFO  Executor:54 - Running task 143.0 in stage 5.0 (TID 255)
2021-05-19 02:47:15 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 256
2021-05-19 02:47:15 INFO  Executor:54 - Running task 145.0 in stage 5.0 (TID 256)
2021-05-19 02:47:15 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:47:15 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2021-05-19 02:47:15 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:47:15 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2021-05-19 02:47:15 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:47:15 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:47:15 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2021-05-19 02:47:15 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2021-05-19 02:47:15 INFO  Executor:54 - Finished task 139.0 in stage 5.0 (TID 251). 3733 bytes result sent to driver
2021-05-19 02:47:15 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:47:15 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2021-05-19 02:47:15 INFO  Executor:54 - Finished task 140.0 in stage 5.0 (TID 252). 3733 bytes result sent to driver
2021-05-19 02:47:15 INFO  Executor:54 - Finished task 141.0 in stage 5.0 (TID 253). 3733 bytes result sent to driver
2021-05-19 02:47:15 INFO  Executor:54 - Finished task 142.0 in stage 5.0 (TID 254). 3733 bytes result sent to driver
2021-05-19 02:47:15 INFO  Executor:54 - Finished task 143.0 in stage 5.0 (TID 255). 3733 bytes result sent to driver
2021-05-19 02:47:15 INFO  Executor:54 - Finished task 145.0 in stage 5.0 (TID 256). 3733 bytes result sent to driver
2021-05-19 02:47:15 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 257
2021-05-19 02:47:15 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 258
2021-05-19 02:47:15 INFO  Executor:54 - Running task 146.0 in stage 5.0 (TID 257)
2021-05-19 02:47:15 INFO  Executor:54 - Running task 147.0 in stage 5.0 (TID 258)
2021-05-19 02:47:15 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 259
2021-05-19 02:47:15 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 260
2021-05-19 02:47:15 INFO  Executor:54 - Running task 148.0 in stage 5.0 (TID 259)
2021-05-19 02:47:15 INFO  Executor:54 - Running task 149.0 in stage 5.0 (TID 260)
2021-05-19 02:47:15 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 264
2021-05-19 02:47:15 INFO  Executor:54 - Running task 153.0 in stage 5.0 (TID 264)
2021-05-19 02:47:15 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:47:15 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:47:15 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:47:15 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2021-05-19 02:47:15 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 266
2021-05-19 02:47:15 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:47:15 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2021-05-19 02:47:15 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2021-05-19 02:47:15 INFO  Executor:54 - Running task 155.0 in stage 5.0 (TID 266)
2021-05-19 02:47:15 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2021-05-19 02:47:15 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 268
2021-05-19 02:47:15 INFO  Executor:54 - Running task 157.0 in stage 5.0 (TID 268)
2021-05-19 02:47:15 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:47:15 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2021-05-19 02:47:15 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 269
2021-05-19 02:47:15 INFO  Executor:54 - Running task 158.0 in stage 5.0 (TID 269)
2021-05-19 02:47:15 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:47:15 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2021-05-19 02:47:15 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 272
2021-05-19 02:47:15 INFO  Executor:54 - Running task 161.0 in stage 5.0 (TID 272)
2021-05-19 02:47:15 INFO  Executor:54 - Finished task 148.0 in stage 5.0 (TID 259). 3733 bytes result sent to driver
2021-05-19 02:47:15 INFO  Executor:54 - Finished task 149.0 in stage 5.0 (TID 260). 3733 bytes result sent to driver
2021-05-19 02:47:15 INFO  Executor:54 - Finished task 146.0 in stage 5.0 (TID 257). 3733 bytes result sent to driver
2021-05-19 02:47:15 INFO  Executor:54 - Finished task 147.0 in stage 5.0 (TID 258). 3733 bytes result sent to driver
2021-05-19 02:47:15 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:47:15 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:47:15 INFO  Executor:54 - Finished task 153.0 in stage 5.0 (TID 264). 3733 bytes result sent to driver
2021-05-19 02:47:15 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2021-05-19 02:47:15 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2021-05-19 02:47:15 INFO  Executor:54 - Finished task 155.0 in stage 5.0 (TID 266). 3733 bytes result sent to driver
2021-05-19 02:47:15 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 274
2021-05-19 02:47:15 INFO  Executor:54 - Running task 163.0 in stage 5.0 (TID 274)
2021-05-19 02:47:15 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 277
2021-05-19 02:47:15 INFO  Executor:54 - Running task 167.0 in stage 5.0 (TID 277)
2021-05-19 02:47:15 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:47:15 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 278
2021-05-19 02:47:15 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2021-05-19 02:47:15 INFO  Executor:54 - Running task 168.0 in stage 5.0 (TID 278)
2021-05-19 02:47:15 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:47:15 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 279
2021-05-19 02:47:15 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2021-05-19 02:47:15 INFO  Executor:54 - Running task 169.0 in stage 5.0 (TID 279)
2021-05-19 02:47:15 INFO  Executor:54 - Finished task 157.0 in stage 5.0 (TID 268). 3733 bytes result sent to driver
2021-05-19 02:47:15 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 280
2021-05-19 02:47:15 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:47:15 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:47:15 INFO  Executor:54 - Finished task 158.0 in stage 5.0 (TID 269). 3733 bytes result sent to driver
2021-05-19 02:47:15 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2021-05-19 02:47:15 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2021-05-19 02:47:15 INFO  Executor:54 - Running task 170.0 in stage 5.0 (TID 280)
2021-05-19 02:47:15 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 281
2021-05-19 02:47:15 INFO  Executor:54 - Running task 171.0 in stage 5.0 (TID 281)
2021-05-19 02:47:15 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:47:15 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 282
2021-05-19 02:47:15 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2021-05-19 02:47:15 INFO  Executor:54 - Running task 172.0 in stage 5.0 (TID 282)
2021-05-19 02:47:15 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 283
2021-05-19 02:47:15 INFO  Executor:54 - Running task 173.0 in stage 5.0 (TID 283)
2021-05-19 02:47:15 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 284
2021-05-19 02:47:15 INFO  Executor:54 - Running task 174.0 in stage 5.0 (TID 284)
2021-05-19 02:47:15 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:47:15 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2021-05-19 02:47:15 INFO  Executor:54 - Finished task 163.0 in stage 5.0 (TID 274). 3733 bytes result sent to driver
2021-05-19 02:47:15 INFO  Executor:54 - Finished task 161.0 in stage 5.0 (TID 272). 3733 bytes result sent to driver
2021-05-19 02:47:15 INFO  Executor:54 - Finished task 168.0 in stage 5.0 (TID 278). 3733 bytes result sent to driver
2021-05-19 02:47:15 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:47:15 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2021-05-19 02:47:15 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:47:15 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2021-05-19 02:47:15 INFO  Executor:54 - Finished task 167.0 in stage 5.0 (TID 277). 3733 bytes result sent to driver
2021-05-19 02:47:15 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:47:15 INFO  Executor:54 - Finished task 169.0 in stage 5.0 (TID 279). 3733 bytes result sent to driver
2021-05-19 02:47:15 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2021-05-19 02:47:15 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 285
2021-05-19 02:47:15 INFO  Executor:54 - Running task 175.0 in stage 5.0 (TID 285)
2021-05-19 02:47:15 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:47:15 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2021-05-19 02:47:15 INFO  Executor:54 - Finished task 170.0 in stage 5.0 (TID 280). 3733 bytes result sent to driver
2021-05-19 02:47:15 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 287
2021-05-19 02:47:15 INFO  Executor:54 - Running task 177.0 in stage 5.0 (TID 287)
2021-05-19 02:47:15 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 288
2021-05-19 02:47:15 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 289
2021-05-19 02:47:15 INFO  Executor:54 - Running task 178.0 in stage 5.0 (TID 288)
2021-05-19 02:47:15 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 290
2021-05-19 02:47:15 INFO  Executor:54 - Running task 179.0 in stage 5.0 (TID 289)
2021-05-19 02:47:15 INFO  Executor:54 - Running task 180.0 in stage 5.0 (TID 290)
2021-05-19 02:47:15 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 291
2021-05-19 02:47:15 INFO  Executor:54 - Finished task 172.0 in stage 5.0 (TID 282). 3776 bytes result sent to driver
2021-05-19 02:47:15 INFO  Executor:54 - Running task 181.0 in stage 5.0 (TID 291)
2021-05-19 02:47:15 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:47:15 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2021-05-19 02:47:15 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:47:15 INFO  Executor:54 - Finished task 173.0 in stage 5.0 (TID 283). 3776 bytes result sent to driver
2021-05-19 02:47:15 INFO  Executor:54 - Finished task 171.0 in stage 5.0 (TID 281). 3776 bytes result sent to driver
2021-05-19 02:47:15 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2021-05-19 02:47:15 INFO  Executor:54 - Finished task 174.0 in stage 5.0 (TID 284). 3776 bytes result sent to driver
2021-05-19 02:47:15 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:47:15 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 301
2021-05-19 02:47:15 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2021-05-19 02:47:15 INFO  Executor:54 - Running task 192.0 in stage 5.0 (TID 301)
2021-05-19 02:47:15 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:47:15 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2021-05-19 02:47:15 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 302
2021-05-19 02:47:15 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:47:15 INFO  Executor:54 - Running task 193.0 in stage 5.0 (TID 302)
2021-05-19 02:47:15 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2021-05-19 02:47:15 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 303
2021-05-19 02:47:15 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:47:15 INFO  Executor:54 - Running task 194.0 in stage 5.0 (TID 303)
2021-05-19 02:47:15 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2021-05-19 02:47:15 INFO  Executor:54 - Finished task 175.0 in stage 5.0 (TID 285). 3776 bytes result sent to driver
2021-05-19 02:47:15 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 304
2021-05-19 02:47:15 INFO  Executor:54 - Running task 195.0 in stage 5.0 (TID 304)
2021-05-19 02:47:15 INFO  Executor:54 - Finished task 177.0 in stage 5.0 (TID 287). 3819 bytes result sent to driver
2021-05-19 02:47:15 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:47:15 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2021-05-19 02:47:15 INFO  Executor:54 - Finished task 178.0 in stage 5.0 (TID 288). 3733 bytes result sent to driver
2021-05-19 02:47:15 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:47:15 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2021-05-19 02:47:15 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:47:15 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2021-05-19 02:47:15 INFO  Executor:54 - Finished task 180.0 in stage 5.0 (TID 290). 3733 bytes result sent to driver
2021-05-19 02:47:15 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:47:15 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 306
2021-05-19 02:47:15 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2021-05-19 02:47:15 INFO  Executor:54 - Finished task 179.0 in stage 5.0 (TID 289). 3733 bytes result sent to driver
2021-05-19 02:47:15 INFO  Executor:54 - Finished task 181.0 in stage 5.0 (TID 291). 3733 bytes result sent to driver
2021-05-19 02:47:15 INFO  Executor:54 - Running task 197.0 in stage 5.0 (TID 306)
2021-05-19 02:47:15 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 307
2021-05-19 02:47:15 INFO  Executor:54 - Running task 198.0 in stage 5.0 (TID 307)
2021-05-19 02:47:15 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 308
2021-05-19 02:47:15 INFO  Executor:54 - Running task 199.0 in stage 5.0 (TID 308)
2021-05-19 02:47:15 INFO  Executor:54 - Finished task 192.0 in stage 5.0 (TID 301). 3733 bytes result sent to driver
2021-05-19 02:47:15 INFO  Executor:54 - Finished task 195.0 in stage 5.0 (TID 304). 3733 bytes result sent to driver
2021-05-19 02:47:15 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:47:15 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2021-05-19 02:47:15 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:47:15 INFO  Executor:54 - Finished task 193.0 in stage 5.0 (TID 302). 3733 bytes result sent to driver
2021-05-19 02:47:15 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2021-05-19 02:47:15 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:47:15 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2021-05-19 02:47:15 INFO  Executor:54 - Finished task 194.0 in stage 5.0 (TID 303). 3733 bytes result sent to driver
2021-05-19 02:47:15 INFO  Executor:54 - Finished task 198.0 in stage 5.0 (TID 307). 3733 bytes result sent to driver
2021-05-19 02:47:15 INFO  Executor:54 - Finished task 197.0 in stage 5.0 (TID 306). 3733 bytes result sent to driver
2021-05-19 02:47:15 INFO  Executor:54 - Finished task 199.0 in stage 5.0 (TID 308). 3733 bytes result sent to driver
2021-05-19 02:47:17 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 309
2021-05-19 02:47:17 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 310
2021-05-19 02:47:17 INFO  Executor:54 - Running task 0.0 in stage 6.0 (TID 309)
2021-05-19 02:47:17 INFO  Executor:54 - Running task 1.0 in stage 6.0 (TID 310)
2021-05-19 02:47:17 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 311
2021-05-19 02:47:17 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 312
2021-05-19 02:47:17 INFO  Executor:54 - Running task 2.0 in stage 6.0 (TID 311)
2021-05-19 02:47:17 INFO  Executor:54 - Running task 3.0 in stage 6.0 (TID 312)
2021-05-19 02:47:17 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 313
2021-05-19 02:47:17 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 314
2021-05-19 02:47:17 INFO  Executor:54 - Running task 4.0 in stage 6.0 (TID 313)
2021-05-19 02:47:17 INFO  Executor:54 - Running task 5.0 in stage 6.0 (TID 314)
2021-05-19 02:47:17 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 315
2021-05-19 02:47:17 INFO  TorrentBroadcast:54 - Started reading broadcast variable 11
2021-05-19 02:47:17 INFO  Executor:54 - Running task 6.0 in stage 6.0 (TID 315)
2021-05-19 02:47:17 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 316
2021-05-19 02:47:17 INFO  Executor:54 - Running task 7.0 in stage 6.0 (TID 316)
2021-05-19 02:47:17 INFO  MemoryStore:54 - Block broadcast_11_piece0 stored as bytes in memory (estimated size 14.1 KB, free 365.1 MB)
2021-05-19 02:47:17 INFO  TorrentBroadcast:54 - Reading broadcast variable 11 took 25 ms
2021-05-19 02:47:17 INFO  MemoryStore:54 - Block broadcast_11 stored as values in memory (estimated size 29.9 KB, free 365.1 MB)
2021-05-19 02:47:17 INFO  BlockManager:54 - Found block rdd_29_5 locally
2021-05-19 02:47:17 INFO  BlockManager:54 - Found block rdd_29_7 locally
2021-05-19 02:47:17 INFO  BlockManager:54 - Found block rdd_29_4 locally
2021-05-19 02:47:17 INFO  BlockManager:54 - Found block rdd_29_3 locally
2021-05-19 02:47:17 INFO  BlockManager:54 - Found block rdd_29_0 locally
2021-05-19 02:47:17 INFO  BlockManager:54 - Found block rdd_29_6 locally
2021-05-19 02:47:17 INFO  BlockManager:54 - Found block rdd_29_2 locally
2021-05-19 02:47:17 INFO  BlockManager:54 - Found block rdd_29_1 locally
2021-05-19 02:47:17 INFO  InMemoryTableScanExec:54 - Predicate isnotnull(placekey#10) generates partition filter: ((placekey.count#263 - placekey.nullCount#262) > 0)
2021-05-19 02:47:17 INFO  InMemoryTableScanExec:54 - Predicate isnotnull(placekey#10) generates partition filter: ((placekey.count#263 - placekey.nullCount#262) > 0)
2021-05-19 02:47:17 INFO  InMemoryTableScanExec:54 - Predicate isnotnull(placekey#10) generates partition filter: ((placekey.count#263 - placekey.nullCount#262) > 0)
2021-05-19 02:47:17 INFO  InMemoryTableScanExec:54 - Predicate isnotnull(placekey#10) generates partition filter: ((placekey.count#263 - placekey.nullCount#262) > 0)
2021-05-19 02:47:17 INFO  InMemoryTableScanExec:54 - Predicate isnotnull(placekey#10) generates partition filter: ((placekey.count#263 - placekey.nullCount#262) > 0)
2021-05-19 02:47:17 INFO  InMemoryTableScanExec:54 - Predicate isnotnull(placekey#10) generates partition filter: ((placekey.count#263 - placekey.nullCount#262) > 0)
2021-05-19 02:47:17 INFO  InMemoryTableScanExec:54 - Predicate isnotnull(placekey#10) generates partition filter: ((placekey.count#263 - placekey.nullCount#262) > 0)
2021-05-19 02:47:17 INFO  InMemoryTableScanExec:54 - Predicate isnotnull(placekey#10) generates partition filter: ((placekey.count#263 - placekey.nullCount#262) > 0)
2021-05-19 02:47:17 INFO  CodeGenerator:54 - Code generated in 11.673504 ms
2021-05-19 02:47:18 INFO  CodeGenerator:54 - Code generated in 29.52101 ms
2021-05-19 02:47:18 INFO  CodeGenerator:54 - Code generated in 13.330357 ms
2021-05-19 02:47:18 INFO  Executor:54 - Finished task 7.0 in stage 6.0 (TID 316). 30798 bytes result sent to driver
2021-05-19 02:47:18 INFO  Executor:54 - Finished task 6.0 in stage 6.0 (TID 315). 56873 bytes result sent to driver
2021-05-19 02:47:18 INFO  Executor:54 - Finished task 3.0 in stage 6.0 (TID 312). 56165 bytes result sent to driver
2021-05-19 02:47:18 INFO  Executor:54 - Finished task 0.0 in stage 6.0 (TID 309). 56818 bytes result sent to driver
2021-05-19 02:47:18 INFO  Executor:54 - Finished task 1.0 in stage 6.0 (TID 310). 56955 bytes result sent to driver
2021-05-19 02:47:18 INFO  Executor:54 - Finished task 2.0 in stage 6.0 (TID 311). 57587 bytes result sent to driver
2021-05-19 02:47:18 INFO  Executor:54 - Finished task 5.0 in stage 6.0 (TID 314). 57359 bytes result sent to driver
2021-05-19 02:47:18 INFO  Executor:54 - Finished task 4.0 in stage 6.0 (TID 313). 55801 bytes result sent to driver
2021-05-19 02:47:18 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 318
2021-05-19 02:47:18 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 322
2021-05-19 02:47:18 INFO  Executor:54 - Running task 1.0 in stage 7.0 (TID 318)
2021-05-19 02:47:18 INFO  Executor:54 - Running task 3.0 in stage 7.0 (TID 322)
2021-05-19 02:47:18 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 326
2021-05-19 02:47:18 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 330
2021-05-19 02:47:18 INFO  Executor:54 - Running task 9.0 in stage 7.0 (TID 326)
2021-05-19 02:47:18 INFO  Executor:54 - Running task 10.0 in stage 7.0 (TID 330)
2021-05-19 02:47:18 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 334
2021-05-19 02:47:18 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 338
2021-05-19 02:47:18 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 342
2021-05-19 02:47:18 INFO  TorrentBroadcast:54 - Started reading broadcast variable 14
2021-05-19 02:47:18 INFO  Executor:54 - Running task 30.0 in stage 7.0 (TID 334)
2021-05-19 02:47:18 INFO  Executor:54 - Running task 40.0 in stage 7.0 (TID 342)
2021-05-19 02:47:18 INFO  Executor:54 - Running task 32.0 in stage 7.0 (TID 338)
2021-05-19 02:47:18 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 346
2021-05-19 02:47:18 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 350
2021-05-19 02:47:18 INFO  Executor:54 - Running task 43.0 in stage 7.0 (TID 346)
2021-05-19 02:47:18 INFO  Executor:54 - Running task 44.0 in stage 7.0 (TID 350)
2021-05-19 02:47:18 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 353
2021-05-19 02:47:18 INFO  Executor:54 - Running task 45.0 in stage 7.0 (TID 353)
2021-05-19 02:47:19 INFO  MemoryStore:54 - Block broadcast_14_piece0 stored as bytes in memory (estimated size 22.9 KB, free 365.1 MB)
2021-05-19 02:47:19 INFO  TorrentBroadcast:54 - Reading broadcast variable 14 took 19 ms
2021-05-19 02:47:19 INFO  MemoryStore:54 - Block broadcast_14 stored as values in memory (estimated size 51.4 KB, free 365.0 MB)
2021-05-19 02:47:19 INFO  CodeGenerator:54 - Code generated in 47.842156 ms
2021-05-19 02:47:19 INFO  TorrentBroadcast:54 - Started reading broadcast variable 12
2021-05-19 02:47:19 INFO  MemoryStore:54 - Block broadcast_12_piece0 stored as bytes in memory (estimated size 580.1 KB, free 364.5 MB)
2021-05-19 02:47:19 INFO  TorrentBroadcast:54 - Reading broadcast variable 12 took 20 ms
2021-05-19 02:47:19 INFO  MemoryStore:54 - Block broadcast_12 stored as values in memory (estimated size 5.0 MB, free 359.5 MB)
2021-05-19 02:47:19 INFO  CodeGenerator:54 - Code generated in 28.799746 ms
2021-05-19 02:47:19 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00010, range: 0-134217728, partition values: [empty row]
2021-05-19 02:47:19 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00032, range: 0-134217728, partition values: [empty row]
2021-05-19 02:47:19 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00044, range: 0-134217728, partition values: [empty row]
2021-05-19 02:47:19 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00030, range: 0-134217728, partition values: [empty row]
2021-05-19 02:47:19 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00045, range: 0-134217728, partition values: [empty row]
2021-05-19 02:47:19 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00043, range: 0-134217728, partition values: [empty row]
2021-05-19 02:47:19 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00003, range: 0-134217728, partition values: [empty row]
2021-05-19 02:47:19 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00009, range: 0-134217728, partition values: [empty row]
2021-05-19 02:47:19 INFO  TorrentBroadcast:54 - Started reading broadcast variable 13
2021-05-19 02:47:19 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00040, range: 0-134217728, partition values: [empty row]
2021-05-19 02:47:19 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00001, range: 0-134217728, partition values: [empty row]
2021-05-19 02:47:19 INFO  MemoryStore:54 - Block broadcast_13_piece0 stored as bytes in memory (estimated size 33.4 KB, free 359.4 MB)
2021-05-19 02:47:19 INFO  TorrentBroadcast:54 - Reading broadcast variable 13 took 18 ms
2021-05-19 02:47:19 INFO  MemoryStore:54 - Block broadcast_13 stored as values in memory (estimated size 506.4 KB, free 358.9 MB)
2021-05-19 02:47:19 INFO  CodeGenerator:54 - Code generated in 32.754352 ms
2021-05-19 02:47:19 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: 227-222@627-s4n-x3q, 2019-06-10T00:00:00-04:00, [7,4,4,0,7,11,3]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: 227-222@627-s4n-x3q
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00044
2021-05-19 02:47:19 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: 22z-222@627-rw8-28v, 2018-12-31T00:00:00-05:00, [5,22,30,30,30,14,16]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: 22z-222@627-rw8-28v
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00003
2021-05-19 02:47:19 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: 25p-222@627-s8j-94v, 2020-06-08T00:00:00-04:00, [1,1,0,2,0,0,0]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: 25p-222@627-s8j-94v
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00043
2021-05-19 02:47:19 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: 22x-224@627-s8r-c89, 2018-12-31T00:00:00-05:00, [21,42,46,76,70,52,8]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: 22x-224@627-s8r-c89
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00010
2021-05-19 02:47:19 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: 22r-222@627-vvk-swk, 2019-11-18T00:00:00-05:00, [7,32,20,27,42,29,34]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: 22r-222@627-vvk-swk
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00045
2021-05-19 02:47:19 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: 22k-223@627-s8w-b49, 2018-12-31T00:00:00-05:00, [9,0,10,6,6,8,4]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: 22k-223@627-s8w-b49
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00001
2021-05-19 02:47:19 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: 22g-222@627-rwv-q75, 2019-07-15T00:00:00-04:00, [12,11,14,8,11,9,7]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: 22g-222@627-rwv-q75
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00032
2021-05-19 02:47:19 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: 226-225@627-wc8-73q, 2018-12-31T00:00:00-05:00, [1,6,18,10,12,12,18]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: 226-225@627-wc8-73q
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00009
2021-05-19 02:47:19 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: zzw-222@627-s4s-nqz, 2019-04-22T00:00:00-04:00, [6,10,4,9,4,6,2]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: zzw-222@627-s4s-nqz
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00040
2021-05-19 02:47:19 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: 222-222@627-wg5-389, 2019-05-13T00:00:00-04:00, [10,28,8,12,17,3,11]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: 222-222@627-wg5-389
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00030
2021-05-19 02:47:19 INFO  CodeGenerator:54 - Code generated in 51.641913 ms
2021-05-19 02:47:19 INFO  CodeGenerator:54 - Code generated in 31.057419 ms
2021-05-19 02:47:19 INFO  CodeGenerator:54 - Code generated in 18.202391 ms
2021-05-19 02:47:20 INFO  CodeGenerator:54 - Code generated in 13.321043 ms
2021-05-19 02:47:20 INFO  CodeGenerator:54 - Code generated in 11.83688 ms
2021-05-19 02:47:20 INFO  CodeGenerator:54 - Code generated in 27.915368 ms
2021-05-19 02:47:20 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:47:20 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:47:20 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:47:20 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:47:20 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:47:20 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:47:20 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:47:20 INFO  CodeGenerator:54 - Code generated in 46.345653 ms
2021-05-19 02:47:20 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:47:20 INFO  CodeGenerator:54 - Code generated in 23.699375 ms
2021-05-19 02:47:20 INFO  CodeGenerator:54 - Code generated in 33.977166 ms
2021-05-19 02:47:20 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:47:21 INFO  CodeGenerator:54 - Code generated in 11.479829 ms
2021-05-19 02:47:21 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:47:28 ERROR CoarseGrainedExecutorBackend:43 - RECEIVED SIGNAL TERM
2021-05-19 02:47:28 INFO  DiskBlockManager:54 - Shutdown hook called
2021-05-19 02:47:28 INFO  ShutdownHookManager:54 - Shutdown hook called
2021-05-19 02:47:28 INFO  ShutdownHookManager:54 - Deleting directory /localhome/cdp/yarn/nm/usercache/catherine.ng60/appcache/application_1609183734776_5900/spark-b281e551-9043-4e9c-8de0-063ee1a4a317

End of LogType:stdout
***********************************************************************


End of LogType:prelaunch.err
******************************************************************************

Container: container_e10_1609183734776_5900_02_000003 on hadoop18.cusp.nyu.edu_8041
LogAggregationType: AGGREGATED
===================================================================================
LogType:prelaunch.out
LogLastModifiedTime:Wed May 19 02:48:18 -0400 2021
LogLength:70
LogContents:
Setting up env variables
Setting up job resources
Launching container

End of LogType:prelaunch.out
******************************************************************************

Container: container_e10_1609183734776_5900_02_000003 on hadoop18.cusp.nyu.edu_8041
LogAggregationType: AGGREGATED
===================================================================================
LogType:stderr
LogLastModifiedTime:Wed May 19 02:48:18 -0400 2021
LogLength:529
LogContents:
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/localhome/cdp/yarn/nm/filecache/25/spark-jars-2.4.0-hadoop2.7.jar/slf4j-log4j12-1.7.16.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-6.1.0-1.cdh6.1.0.p0.770702/jars/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]

End of LogType:stderr
***********************************************************************

Container: container_e10_1609183734776_5900_02_000003 on hadoop18.cusp.nyu.edu_8041
LogAggregationType: AGGREGATED
===================================================================================
LogType:stdout
LogLastModifiedTime:Wed May 19 02:48:18 -0400 2021
LogLength:37323
LogContents:
2021-05-19 02:46:52 INFO  CoarseGrainedExecutorBackend:2566 - Started daemon with process name: 38651@hadoop18.cusp.nyu.edu
2021-05-19 02:46:52 INFO  SignalUtils:54 - Registered signal handler for TERM
2021-05-19 02:46:52 INFO  SignalUtils:54 - Registered signal handler for HUP
2021-05-19 02:46:52 INFO  SignalUtils:54 - Registered signal handler for INT
2021-05-19 02:46:53 INFO  SecurityManager:54 - Changing view acls to: catherine.ng60
2021-05-19 02:46:53 INFO  SecurityManager:54 - Changing modify acls to: catherine.ng60
2021-05-19 02:46:53 INFO  SecurityManager:54 - Changing view acls groups to: 
2021-05-19 02:46:53 INFO  SecurityManager:54 - Changing modify acls groups to: 
2021-05-19 02:46:53 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(catherine.ng60); groups with view permissions: Set(); users  with modify permissions: Set(catherine.ng60); groups with modify permissions: Set()
2021-05-19 02:46:54 INFO  TransportClientFactory:267 - Successfully created connection to hadoop02.cusp.nyu.edu/192.168.72.172:60108 after 111 ms (0 ms spent in bootstraps)
2021-05-19 02:46:54 INFO  SecurityManager:54 - Changing view acls to: catherine.ng60
2021-05-19 02:46:54 INFO  SecurityManager:54 - Changing modify acls to: catherine.ng60
2021-05-19 02:46:54 INFO  SecurityManager:54 - Changing view acls groups to: 
2021-05-19 02:46:54 INFO  SecurityManager:54 - Changing modify acls groups to: 
2021-05-19 02:46:54 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(catherine.ng60); groups with view permissions: Set(); users  with modify permissions: Set(catherine.ng60); groups with modify permissions: Set()
2021-05-19 02:46:54 INFO  TransportClientFactory:267 - Successfully created connection to hadoop02.cusp.nyu.edu/192.168.72.172:60108 after 5 ms (0 ms spent in bootstraps)
2021-05-19 02:46:54 INFO  DiskBlockManager:54 - Created local directory at /localhome/cdp/yarn/nm/usercache/catherine.ng60/appcache/application_1609183734776_5900/blockmgr-0ab4507a-1f59-4357-a9bd-2954d957504a
2021-05-19 02:46:55 INFO  MemoryStore:54 - MemoryStore started with capacity 366.3 MB
2021-05-19 02:46:55 INFO  CoarseGrainedExecutorBackend:54 - Connecting to driver: spark://CoarseGrainedScheduler@hadoop02.cusp.nyu.edu:60108
2021-05-19 02:46:55 INFO  CoarseGrainedExecutorBackend:54 - Successfully registered with driver
2021-05-19 02:46:55 INFO  Executor:54 - Starting executor ID 2 on host hadoop18.cusp.nyu.edu
2021-05-19 02:46:55 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 37819.
2021-05-19 02:46:55 INFO  NettyBlockTransferService:54 - Server created on hadoop18.cusp.nyu.edu:37819
2021-05-19 02:46:55 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2021-05-19 02:46:55 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(2, hadoop18.cusp.nyu.edu, 37819, None)
2021-05-19 02:46:55 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(2, hadoop18.cusp.nyu.edu, 37819, None)
2021-05-19 02:46:55 INFO  BlockManager:54 - external shuffle service port = 7337
2021-05-19 02:46:55 INFO  BlockManager:54 - Registering executor with local external shuffle service.
2021-05-19 02:46:55 INFO  TransportClientFactory:267 - Successfully created connection to hadoop18.cusp.nyu.edu/192.168.72.188:7337 after 3 ms (0 ms spent in bootstraps)
2021-05-19 02:46:55 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(2, hadoop18.cusp.nyu.edu, 37819, None)
2021-05-19 02:47:04 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 3
2021-05-19 02:47:04 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 8
2021-05-19 02:47:04 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 13
2021-05-19 02:47:04 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 18
2021-05-19 02:47:04 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 23
2021-05-19 02:47:04 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 28
2021-05-19 02:47:04 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 33
2021-05-19 02:47:04 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 38
2021-05-19 02:47:04 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 43
2021-05-19 02:47:04 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 48
2021-05-19 02:47:04 INFO  Executor:54 - Running task 37.0 in stage 1.0 (TID 38)
2021-05-19 02:47:04 INFO  Executor:54 - Running task 17.0 in stage 1.0 (TID 18)
2021-05-19 02:47:04 INFO  Executor:54 - Running task 27.0 in stage 1.0 (TID 28)
2021-05-19 02:47:04 INFO  Executor:54 - Running task 32.0 in stage 1.0 (TID 33)
2021-05-19 02:47:04 INFO  Executor:54 - Running task 22.0 in stage 1.0 (TID 23)
2021-05-19 02:47:04 INFO  Executor:54 - Running task 42.0 in stage 1.0 (TID 43)
2021-05-19 02:47:04 INFO  Executor:54 - Running task 7.0 in stage 1.0 (TID 8)
2021-05-19 02:47:04 INFO  Executor:54 - Running task 2.0 in stage 1.0 (TID 3)
2021-05-19 02:47:04 INFO  Executor:54 - Running task 12.0 in stage 1.0 (TID 13)
2021-05-19 02:47:04 INFO  Executor:54 - Running task 47.0 in stage 1.0 (TID 48)
2021-05-19 02:47:05 INFO  TorrentBroadcast:54 - Started reading broadcast variable 3
2021-05-19 02:47:05 INFO  TransportClientFactory:267 - Successfully created connection to hadoop02.cusp.nyu.edu/192.168.72.172:49352 after 4 ms (0 ms spent in bootstraps)
2021-05-19 02:47:05 INFO  MemoryStore:54 - Block broadcast_3_piece0 stored as bytes in memory (estimated size 35.0 KB, free 366.3 MB)
2021-05-19 02:47:05 INFO  TorrentBroadcast:54 - Reading broadcast variable 3 took 199 ms
2021-05-19 02:47:05 INFO  MemoryStore:54 - Block broadcast_3 stored as values in memory (estimated size 129.0 KB, free 366.1 MB)
2021-05-19 02:47:07 INFO  Executor:54 - Finished task 42.0 in stage 1.0 (TID 43). 1492 bytes result sent to driver
2021-05-19 02:47:07 INFO  Executor:54 - Finished task 17.0 in stage 1.0 (TID 18). 1492 bytes result sent to driver
2021-05-19 02:47:07 INFO  Executor:54 - Finished task 22.0 in stage 1.0 (TID 23). 1492 bytes result sent to driver
2021-05-19 02:47:07 INFO  Executor:54 - Finished task 37.0 in stage 1.0 (TID 38). 1492 bytes result sent to driver
2021-05-19 02:47:07 INFO  Executor:54 - Finished task 7.0 in stage 1.0 (TID 8). 1492 bytes result sent to driver
2021-05-19 02:47:07 INFO  Executor:54 - Finished task 47.0 in stage 1.0 (TID 48). 1492 bytes result sent to driver
2021-05-19 02:47:07 INFO  Executor:54 - Finished task 32.0 in stage 1.0 (TID 33). 1492 bytes result sent to driver
2021-05-19 02:47:07 INFO  Executor:54 - Finished task 2.0 in stage 1.0 (TID 3). 1492 bytes result sent to driver
2021-05-19 02:47:07 INFO  Executor:54 - Finished task 12.0 in stage 1.0 (TID 13). 1492 bytes result sent to driver
2021-05-19 02:47:07 INFO  Executor:54 - Finished task 27.0 in stage 1.0 (TID 28). 1492 bytes result sent to driver
2021-05-19 02:47:08 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 55
2021-05-19 02:47:08 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 60
2021-05-19 02:47:08 INFO  Executor:54 - Running task 4.0 in stage 2.0 (TID 55)
2021-05-19 02:47:08 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 65
2021-05-19 02:47:08 INFO  Executor:54 - Running task 9.0 in stage 2.0 (TID 60)
2021-05-19 02:47:08 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 70
2021-05-19 02:47:08 INFO  Executor:54 - Running task 19.0 in stage 2.0 (TID 70)
2021-05-19 02:47:08 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 75
2021-05-19 02:47:08 INFO  Executor:54 - Running task 24.0 in stage 2.0 (TID 75)
2021-05-19 02:47:08 INFO  Executor:54 - Running task 14.0 in stage 2.0 (TID 65)
2021-05-19 02:47:08 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 80
2021-05-19 02:47:08 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 85
2021-05-19 02:47:08 INFO  Executor:54 - Running task 29.0 in stage 2.0 (TID 80)
2021-05-19 02:47:08 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 90
2021-05-19 02:47:08 INFO  Executor:54 - Running task 34.0 in stage 2.0 (TID 85)
2021-05-19 02:47:08 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 95
2021-05-19 02:47:08 INFO  Executor:54 - Running task 44.0 in stage 2.0 (TID 95)
2021-05-19 02:47:08 INFO  Executor:54 - Running task 39.0 in stage 2.0 (TID 90)
2021-05-19 02:47:08 INFO  TorrentBroadcast:54 - Started reading broadcast variable 4
2021-05-19 02:47:08 INFO  TransportClientFactory:267 - Successfully created connection to hadoop17.cusp.nyu.edu/192.168.72.187:39842 after 4 ms (0 ms spent in bootstraps)
2021-05-19 02:47:08 INFO  MemoryStore:54 - Block broadcast_4_piece0 stored as bytes in memory (estimated size 35.0 KB, free 366.1 MB)
2021-05-19 02:47:08 INFO  TorrentBroadcast:54 - Reading broadcast variable 4 took 57 ms
2021-05-19 02:47:08 INFO  MemoryStore:54 - Block broadcast_4 stored as values in memory (estimated size 129.0 KB, free 366.0 MB)
2021-05-19 02:47:08 INFO  Executor:54 - Finished task 14.0 in stage 2.0 (TID 65). 1406 bytes result sent to driver
2021-05-19 02:47:08 INFO  Executor:54 - Finished task 19.0 in stage 2.0 (TID 70). 1449 bytes result sent to driver
2021-05-19 02:47:08 INFO  Executor:54 - Finished task 9.0 in stage 2.0 (TID 60). 1449 bytes result sent to driver
2021-05-19 02:47:08 INFO  Executor:54 - Finished task 44.0 in stage 2.0 (TID 95). 1406 bytes result sent to driver
2021-05-19 02:47:08 INFO  Executor:54 - Finished task 39.0 in stage 2.0 (TID 90). 1449 bytes result sent to driver
2021-05-19 02:47:08 INFO  Executor:54 - Finished task 24.0 in stage 2.0 (TID 75). 1449 bytes result sent to driver
2021-05-19 02:47:08 INFO  Executor:54 - Finished task 4.0 in stage 2.0 (TID 55). 1449 bytes result sent to driver
2021-05-19 02:47:08 INFO  Executor:54 - Finished task 34.0 in stage 2.0 (TID 85). 1449 bytes result sent to driver
2021-05-19 02:47:08 INFO  Executor:54 - Finished task 29.0 in stage 2.0 (TID 80). 1449 bytes result sent to driver
2021-05-19 02:47:14 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 120
2021-05-19 02:47:14 INFO  Executor:54 - Running task 2.0 in stage 5.0 (TID 120)
2021-05-19 02:47:14 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 125
2021-05-19 02:47:14 INFO  Executor:54 - Running task 8.0 in stage 5.0 (TID 125)
2021-05-19 02:47:14 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 129
2021-05-19 02:47:14 INFO  Executor:54 - Running task 12.0 in stage 5.0 (TID 129)
2021-05-19 02:47:14 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 133
2021-05-19 02:47:14 INFO  Executor:54 - Running task 16.0 in stage 5.0 (TID 133)
2021-05-19 02:47:14 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 137
2021-05-19 02:47:14 INFO  Executor:54 - Running task 21.0 in stage 5.0 (TID 137)
2021-05-19 02:47:14 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 141
2021-05-19 02:47:14 INFO  Executor:54 - Running task 25.0 in stage 5.0 (TID 141)
2021-05-19 02:47:14 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 145
2021-05-19 02:47:14 INFO  Executor:54 - Running task 30.0 in stage 5.0 (TID 145)
2021-05-19 02:47:14 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 149
2021-05-19 02:47:14 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 153
2021-05-19 02:47:14 INFO  MapOutputTrackerWorker:54 - Updating epoch to 1 and clearing cache
2021-05-19 02:47:14 INFO  Executor:54 - Running task 34.0 in stage 5.0 (TID 149)
2021-05-19 02:47:14 INFO  Executor:54 - Running task 39.0 in stage 5.0 (TID 153)
2021-05-19 02:47:14 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 157
2021-05-19 02:47:14 INFO  Executor:54 - Running task 43.0 in stage 5.0 (TID 157)
2021-05-19 02:47:14 INFO  TorrentBroadcast:54 - Started reading broadcast variable 10
2021-05-19 02:47:14 INFO  MemoryStore:54 - Block broadcast_10_piece0 stored as bytes in memory (estimated size 20.4 KB, free 366.3 MB)
2021-05-19 02:47:14 INFO  TorrentBroadcast:54 - Reading broadcast variable 10 took 23 ms
2021-05-19 02:47:14 INFO  MemoryStore:54 - Block broadcast_10 stored as values in memory (estimated size 40.9 KB, free 366.2 MB)
2021-05-19 02:47:14 INFO  MapOutputTrackerWorker:54 - Don't have map outputs for shuffle 0, fetching them
2021-05-19 02:47:14 INFO  MapOutputTrackerWorker:54 - Don't have map outputs for shuffle 0, fetching them
2021-05-19 02:47:14 INFO  MapOutputTrackerWorker:54 - Don't have map outputs for shuffle 0, fetching them
2021-05-19 02:47:14 INFO  MapOutputTrackerWorker:54 - Don't have map outputs for shuffle 0, fetching them
2021-05-19 02:47:14 INFO  MapOutputTrackerWorker:54 - Don't have map outputs for shuffle 0, fetching them
2021-05-19 02:47:14 INFO  MapOutputTrackerWorker:54 - Don't have map outputs for shuffle 0, fetching them
2021-05-19 02:47:14 INFO  MapOutputTrackerWorker:54 - Don't have map outputs for shuffle 0, fetching them
2021-05-19 02:47:14 INFO  MapOutputTrackerWorker:54 - Don't have map outputs for shuffle 0, fetching them
2021-05-19 02:47:14 INFO  MapOutputTrackerWorker:54 - Don't have map outputs for shuffle 0, fetching them
2021-05-19 02:47:14 INFO  MapOutputTrackerWorker:54 - Don't have map outputs for shuffle 0, fetching them
2021-05-19 02:47:14 INFO  MapOutputTrackerWorker:54 - Doing the fetch; tracker endpoint = NettyRpcEndpointRef(spark://MapOutputTracker@hadoop02.cusp.nyu.edu:60108)
2021-05-19 02:47:14 INFO  MapOutputTrackerWorker:54 - Got the output locations
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 61 ms
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 60 ms
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 60 ms
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 59 ms
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 59 ms
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 59 ms
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 59 ms
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 59 ms
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 59 ms
2021-05-19 02:47:14 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 62 ms
2021-05-19 02:47:15 INFO  CodeGenerator:54 - Code generated in 353.74658 ms
2021-05-19 02:47:15 INFO  CodeGenerator:54 - Code generated in 45.848434 ms
2021-05-19 02:47:15 INFO  CodeGenerator:54 - Code generated in 39.188179 ms
2021-05-19 02:47:15 INFO  CodeGenerator:54 - Code generated in 28.39244 ms
2021-05-19 02:47:15 INFO  Executor:54 - Finished task 21.0 in stage 5.0 (TID 137). 3776 bytes result sent to driver
2021-05-19 02:47:15 INFO  Executor:54 - Finished task 34.0 in stage 5.0 (TID 149). 3776 bytes result sent to driver
2021-05-19 02:47:15 INFO  Executor:54 - Finished task 12.0 in stage 5.0 (TID 129). 3776 bytes result sent to driver
2021-05-19 02:47:15 INFO  Executor:54 - Finished task 8.0 in stage 5.0 (TID 125). 3776 bytes result sent to driver
2021-05-19 02:47:15 INFO  Executor:54 - Finished task 16.0 in stage 5.0 (TID 133). 3776 bytes result sent to driver
2021-05-19 02:47:15 INFO  Executor:54 - Finished task 25.0 in stage 5.0 (TID 141). 3776 bytes result sent to driver
2021-05-19 02:47:15 INFO  Executor:54 - Finished task 2.0 in stage 5.0 (TID 120). 3776 bytes result sent to driver
2021-05-19 02:47:15 INFO  Executor:54 - Finished task 39.0 in stage 5.0 (TID 153). 3776 bytes result sent to driver
2021-05-19 02:47:15 INFO  Executor:54 - Finished task 30.0 in stage 5.0 (TID 145). 3776 bytes result sent to driver
2021-05-19 02:47:15 INFO  Executor:54 - Finished task 43.0 in stage 5.0 (TID 157). 3776 bytes result sent to driver
2021-05-19 02:47:18 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 320
2021-05-19 02:47:18 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 324
2021-05-19 02:47:18 INFO  Executor:54 - Running task 6.0 in stage 7.0 (TID 320)
2021-05-19 02:47:18 INFO  Executor:54 - Running task 13.0 in stage 7.0 (TID 324)
2021-05-19 02:47:18 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 328
2021-05-19 02:47:18 INFO  Executor:54 - Running task 15.0 in stage 7.0 (TID 328)
2021-05-19 02:47:18 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 332
2021-05-19 02:47:19 INFO  Executor:54 - Running task 16.0 in stage 7.0 (TID 332)
2021-05-19 02:47:19 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 336
2021-05-19 02:47:19 INFO  Executor:54 - Running task 26.0 in stage 7.0 (TID 336)
2021-05-19 02:47:19 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 340
2021-05-19 02:47:19 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 344
2021-05-19 02:47:19 INFO  Executor:54 - Running task 27.0 in stage 7.0 (TID 340)
2021-05-19 02:47:19 INFO  Executor:54 - Running task 31.0 in stage 7.0 (TID 344)
2021-05-19 02:47:19 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 348
2021-05-19 02:47:19 INFO  TorrentBroadcast:54 - Started reading broadcast variable 14
2021-05-19 02:47:19 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 351
2021-05-19 02:47:19 INFO  Executor:54 - Running task 35.0 in stage 7.0 (TID 348)
2021-05-19 02:47:19 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 354
2021-05-19 02:47:19 INFO  Executor:54 - Running task 38.0 in stage 7.0 (TID 351)
2021-05-19 02:47:19 INFO  Executor:54 - Running task 51.0 in stage 7.0 (TID 354)
2021-05-19 02:47:19 INFO  MemoryStore:54 - Block broadcast_14_piece0 stored as bytes in memory (estimated size 22.9 KB, free 366.3 MB)
2021-05-19 02:47:19 INFO  TorrentBroadcast:54 - Reading broadcast variable 14 took 26 ms
2021-05-19 02:47:19 INFO  MemoryStore:54 - Block broadcast_14 stored as values in memory (estimated size 51.4 KB, free 366.2 MB)
2021-05-19 02:47:19 INFO  CodeGenerator:54 - Code generated in 63.022138 ms
2021-05-19 02:47:19 INFO  TorrentBroadcast:54 - Started reading broadcast variable 12
2021-05-19 02:47:19 INFO  MemoryStore:54 - Block broadcast_12_piece0 stored as bytes in memory (estimated size 580.1 KB, free 365.7 MB)
2021-05-19 02:47:19 INFO  TorrentBroadcast:54 - Reading broadcast variable 12 took 26 ms
2021-05-19 02:47:19 INFO  MemoryStore:54 - Block broadcast_12 stored as values in memory (estimated size 5.0 MB, free 360.7 MB)
2021-05-19 02:47:19 INFO  CodeGenerator:54 - Code generated in 24.516467 ms
2021-05-19 02:47:20 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00027, range: 0-134217728, partition values: [empty row]
2021-05-19 02:47:20 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00031, range: 0-134217728, partition values: [empty row]
2021-05-19 02:47:20 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00016, range: 134217728-178714481, partition values: [empty row]
2021-05-19 02:47:20 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00013, range: 0-134217728, partition values: [empty row]
2021-05-19 02:47:20 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00016, range: 0-134217728, partition values: [empty row]
2021-05-19 02:47:20 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00026, range: 0-134217728, partition values: [empty row]
2021-05-19 02:47:20 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00006, range: 0-134217728, partition values: [empty row]
2021-05-19 02:47:20 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00015, range: 0-134217728, partition values: [empty row]
2021-05-19 02:47:20 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00035, range: 0-134217728, partition values: [empty row]
2021-05-19 02:47:20 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00038, range: 0-134217728, partition values: [empty row]
2021-05-19 02:47:20 INFO  CodeGenerator:54 - Code generated in 63.438482 ms
2021-05-19 02:47:20 INFO  TorrentBroadcast:54 - Started reading broadcast variable 13
2021-05-19 02:47:20 INFO  CodeGenerator:54 - Code generated in 63.32218 ms
2021-05-19 02:47:20 INFO  TransportClientFactory:267 - Successfully created connection to hadoop13.cusp.nyu.edu/192.168.72.183:32809 after 5 ms (0 ms spent in bootstraps)
2021-05-19 02:47:20 INFO  CodeGenerator:54 - Code generated in 33.304937 ms
2021-05-19 02:47:20 INFO  MemoryStore:54 - Block broadcast_13_piece0 stored as bytes in memory (estimated size 33.4 KB, free 360.6 MB)
2021-05-19 02:47:20 INFO  TorrentBroadcast:54 - Reading broadcast variable 13 took 111 ms
2021-05-19 02:47:20 INFO  CodeGenerator:54 - Code generated in 36.787601 ms
2021-05-19 02:47:20 INFO  CodeGenerator:54 - Code generated in 27.189262 ms
2021-05-19 02:47:20 INFO  MemoryStore:54 - Block broadcast_13 stored as values in memory (estimated size 506.4 KB, free 360.1 MB)
2021-05-19 02:47:20 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: 22q-222@627-s8x-bzf, 2019-12-16T00:00:00-05:00, [1,0,0,0,0,1,0]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: 22q-222@627-s8x-bzf
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00031
2021-05-19 02:47:20 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: 22h-222@627-wfy-m8v, 2019-08-05T00:00:00-04:00, [3,1,1,2,0,1,0]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: 22h-222@627-wfy-m8v
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00035
2021-05-19 02:47:20 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: 225-222@627-wbv-ht9, 2020-06-29T00:00:00-04:00, [1,3,1,4,8,6,5]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: 225-222@627-wbv-ht9
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00027
2021-05-19 02:47:20 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: 23b-222@627-wh4-vxq, 2019-01-07T00:00:00-05:00, [10,12,10,16,2,4,3]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: 23b-222@627-wh4-vxq
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00013
2021-05-19 02:47:20 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: 22h-223@627-s84-6hq, 2019-08-05T00:00:00-04:00, [2,2,0,2,1,3,1]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: 22h-223@627-s84-6hq
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00026
2021-05-19 02:47:20 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: 22f-222@627-wdh-sdv, 2019-06-10T00:00:00-04:00, [4,2,3,3,3,1,0]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: 22f-222@627-wdh-sdv
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00038
2021-05-19 02:47:20 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: 237-224@627-rwx-wtv, 2018-12-31T00:00:00-05:00, [1,0,12,14,0,4,4]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: 237-224@627-rwx-wtv
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00006
2021-05-19 02:47:20 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: 22c-222@627-s84-mrk, 2020-04-06T00:00:00-04:00, [0,0,0,0,2,0,0]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: 22c-222@627-s84-mrk
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00015
2021-05-19 02:47:20 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: 222-222@627-s6k-dqf, 2019-01-14T00:00:00-05:00, [0,0,0,0,1,0,0]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: 222-222@627-s6k-dqf
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00016
2021-05-19 02:47:21 INFO  CodeGenerator:54 - Code generated in 20.480746 ms
2021-05-19 02:47:21 INFO  CodeGenerator:54 - Code generated in 23.391627 ms
2021-05-19 02:47:21 INFO  CodeGenerator:54 - Code generated in 55.097501 ms
2021-05-19 02:47:22 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:47:22 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:47:22 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:47:22 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:47:22 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:47:22 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:47:22 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:47:22 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:47:22 INFO  CodeGenerator:54 - Code generated in 53.563808 ms
2021-05-19 02:47:22 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:47:22 INFO  CodeGenerator:54 - Code generated in 37.054541 ms
2021-05-19 02:47:22 INFO  CodeGenerator:54 - Code generated in 19.822447 ms
2021-05-19 02:47:22 INFO  CodeGenerator:54 - Code generated in 21.95978 ms
2021-05-19 02:47:22 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:47:23 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00021, range: 134217728-178612317, partition values: [empty row]
2021-05-19 02:47:30 INFO  PythonUDFRunner:54 - Times: total = 11014, boot = 713, init = 1262, finish = 9039
2021-05-19 02:47:30 INFO  CodeGenerator:54 - Code generated in 24.834255 ms
2021-05-19 02:47:31 INFO  Executor:54 - Finished task 51.0 in stage 7.0 (TID 354). 4270 bytes result sent to driver
2021-05-19 02:47:31 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 368
2021-05-19 02:47:31 INFO  Executor:54 - Running task 32.1 in stage 7.0 (TID 368)
2021-05-19 02:47:31 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00032, range: 0-134217728, partition values: [empty row]
2021-05-19 02:47:31 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: 22g-222@627-rwv-q75, 2019-07-15T00:00:00-04:00, [12,11,14,8,11,9,7]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: 22g-222@627-rwv-q75
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00032
2021-05-19 02:47:31 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:47:32 ERROR CoarseGrainedExecutorBackend:43 - RECEIVED SIGNAL TERM
2021-05-19 02:47:32 INFO  DiskBlockManager:54 - Shutdown hook called
2021-05-19 02:47:32 INFO  ShutdownHookManager:54 - Shutdown hook called
2021-05-19 02:47:32 INFO  ShutdownHookManager:54 - Deleting directory /localhome/cdp/yarn/nm/usercache/catherine.ng60/appcache/application_1609183734776_5900/spark-586071fc-553a-419e-ad42-e7b5ac300fa3
2021-05-19 02:47:32 ERROR TaskContextImpl:91 - Error in TaskCompletionListener
java.io.IOException: Filesystem closed
	at org.apache.hadoop.hdfs.DFSClient.checkOpen(DFSClient.java:808)
	at org.apache.hadoop.hdfs.DFSInputStream.close(DFSInputStream.java:710)
	at java.io.FilterInputStream.close(FilterInputStream.java:181)
	at org.apache.hadoop.util.LineReader.close(LineReader.java:150)
	at org.apache.hadoop.mapreduce.lib.input.LineRecordReader.close(LineRecordReader.java:231)
	at org.apache.spark.sql.execution.datasources.RecordReaderIterator.close(RecordReaderIterator.scala:62)
	at org.apache.spark.sql.execution.datasources.HadoopFileLinesReader.close(HadoopFileLinesReader.scala:73)
	at org.apache.spark.sql.execution.datasources.csv.TextInputCSVDataSource$$anonfun$4$$anonfun$apply$2.apply(CSVDataSource.scala:200)
	at org.apache.spark.sql.execution.datasources.csv.TextInputCSVDataSource$$anonfun$4$$anonfun$apply$2.apply(CSVDataSource.scala:200)
	at org.apache.spark.TaskContext$$anon$1.onTaskCompletion(TaskContext.scala:131)
	at org.apache.spark.TaskContextImpl$$anonfun$markTaskCompleted$1.apply(TaskContextImpl.scala:117)
	at org.apache.spark.TaskContextImpl$$anonfun$markTaskCompleted$1.apply(TaskContextImpl.scala:117)
	at org.apache.spark.TaskContextImpl$$anonfun$invokeListeners$1.apply(TaskContextImpl.scala:130)
	at org.apache.spark.TaskContextImpl$$anonfun$invokeListeners$1.apply(TaskContextImpl.scala:128)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.TaskContextImpl.invokeListeners(TaskContextImpl.scala:128)
	at org.apache.spark.TaskContextImpl.markTaskCompleted(TaskContextImpl.scala:116)
	at org.apache.spark.scheduler.Task.run(Task.scala:131)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:402)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:408)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2021-05-19 02:47:32 ERROR Executor:91 - Exception in task 32.1 in stage 7.0 (TID 368)
org.apache.spark.util.TaskCompletionListenerException: Filesystem closed

Previous exception in task: Filesystem closed
	org.apache.hadoop.hdfs.DFSClient.checkOpen(DFSClient.java:808)
	org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:868)
	org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:934)
	java.io.DataInputStream.read(DataInputStream.java:149)
	org.apache.hadoop.mapreduce.lib.input.UncompressedSplitLineReader.fillBuffer(UncompressedSplitLineReader.java:62)
	org.apache.hadoop.util.LineReader.readDefaultLine(LineReader.java:216)
	org.apache.hadoop.util.LineReader.readLine(LineReader.java:174)
	org.apache.hadoop.mapreduce.lib.input.UncompressedSplitLineReader.readLine(UncompressedSplitLineReader.java:94)
	org.apache.hadoop.mapreduce.lib.input.LineRecordReader.nextKeyValue(LineRecordReader.java:186)
	org.apache.spark.sql.execution.datasources.RecordReaderIterator.hasNext(RecordReaderIterator.scala:39)
	org.apache.spark.sql.execution.datasources.HadoopFileLinesReader.hasNext(HadoopFileLinesReader.scala:69)
	scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:462)
	scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:101)
	org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source)
	org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$11$$anon$1.hasNext(WholeStageCodegenExec.scala:619)
	scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	scala.collection.Iterator$GroupedIterator.takeDestructively(Iterator.scala:1073)
	scala.collection.Iterator$GroupedIterator.go(Iterator.scala:1089)
	scala.collection.Iterator$GroupedIterator.fill(Iterator.scala:1127)
	scala.collection.Iterator$GroupedIterator.hasNext(Iterator.scala:1130)
	scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	scala.collection.Iterator$class.foreach(Iterator.scala:891)
	scala.collection.AbstractIterator.foreach(Iterator.scala:1334)
	org.apache.spark.api.python.PythonRDD$.writeIteratorToStream(PythonRDD.scala:224)
	org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$2.writeIteratorToStream(PythonUDFRunner.scala:50)
	org.apache.spark.api.python.BasePythonRunner$WriterThread$$anonfun$run$1.apply(PythonRunner.scala:345)
	org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1945)
	org.apache.spark.api.python.BasePythonRunner$WriterThread.run(PythonRunner.scala:194)
	at org.apache.spark.TaskContextImpl.invokeListeners(TaskContextImpl.scala:138)
	at org.apache.spark.TaskContextImpl.markTaskCompleted(TaskContextImpl.scala:116)
	at org.apache.spark.scheduler.Task.run(Task.scala:131)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:402)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:408)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2021-05-19 02:47:32 INFO  Executor:54 - Not reporting error to driver during JVM shutdown.
2021-05-19 02:47:32 INFO  CoarseGrainedExecutorBackend:54 - Driver commanded a shutdown
2021-05-19 02:47:32 INFO  MemoryStore:54 - MemoryStore cleared
2021-05-19 02:47:32 INFO  BlockManager:54 - BlockManager stopped

End of LogType:stdout
***********************************************************************


End of LogType:prelaunch.err
******************************************************************************

Container: container_e10_1609183734776_5900_02_000009 on hadoop18.cusp.nyu.edu_8041
LogAggregationType: AGGREGATED
===================================================================================
LogType:prelaunch.out
LogLastModifiedTime:Wed May 19 02:48:18 -0400 2021
LogLength:70
LogContents:
Setting up env variables
Setting up job resources
Launching container

End of LogType:prelaunch.out
******************************************************************************

Container: container_e10_1609183734776_5900_02_000009 on hadoop18.cusp.nyu.edu_8041
LogAggregationType: AGGREGATED
===================================================================================
LogType:stderr
LogLastModifiedTime:Wed May 19 02:48:18 -0400 2021
LogLength:529
LogContents:
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/localhome/cdp/yarn/nm/filecache/25/spark-jars-2.4.0-hadoop2.7.jar/slf4j-log4j12-1.7.16.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-6.1.0-1.cdh6.1.0.p0.770702/jars/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]

End of LogType:stderr
***********************************************************************

Container: container_e10_1609183734776_5900_02_000009 on hadoop18.cusp.nyu.edu_8041
LogAggregationType: AGGREGATED
===================================================================================
LogType:stdout
LogLastModifiedTime:Wed May 19 02:48:18 -0400 2021
LogLength:45012
LogContents:
2021-05-19 02:47:36 INFO  CoarseGrainedExecutorBackend:2566 - Started daemon with process name: 39116@hadoop18.cusp.nyu.edu
2021-05-19 02:47:36 INFO  SignalUtils:54 - Registered signal handler for TERM
2021-05-19 02:47:36 INFO  SignalUtils:54 - Registered signal handler for HUP
2021-05-19 02:47:36 INFO  SignalUtils:54 - Registered signal handler for INT
2021-05-19 02:47:37 INFO  SecurityManager:54 - Changing view acls to: catherine.ng60
2021-05-19 02:47:37 INFO  SecurityManager:54 - Changing modify acls to: catherine.ng60
2021-05-19 02:47:37 INFO  SecurityManager:54 - Changing view acls groups to: 
2021-05-19 02:47:37 INFO  SecurityManager:54 - Changing modify acls groups to: 
2021-05-19 02:47:37 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(catherine.ng60); groups with view permissions: Set(); users  with modify permissions: Set(catherine.ng60); groups with modify permissions: Set()
2021-05-19 02:47:37 INFO  TransportClientFactory:267 - Successfully created connection to hadoop02.cusp.nyu.edu/192.168.72.172:60108 after 173 ms (0 ms spent in bootstraps)
2021-05-19 02:47:38 INFO  SecurityManager:54 - Changing view acls to: catherine.ng60
2021-05-19 02:47:38 INFO  SecurityManager:54 - Changing modify acls to: catherine.ng60
2021-05-19 02:47:38 INFO  SecurityManager:54 - Changing view acls groups to: 
2021-05-19 02:47:38 INFO  SecurityManager:54 - Changing modify acls groups to: 
2021-05-19 02:47:38 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(catherine.ng60); groups with view permissions: Set(); users  with modify permissions: Set(catherine.ng60); groups with modify permissions: Set()
2021-05-19 02:47:38 INFO  TransportClientFactory:267 - Successfully created connection to hadoop02.cusp.nyu.edu/192.168.72.172:60108 after 4 ms (0 ms spent in bootstraps)
2021-05-19 02:47:38 INFO  DiskBlockManager:54 - Created local directory at /localhome/cdp/yarn/nm/usercache/catherine.ng60/appcache/application_1609183734776_5900/blockmgr-2cdb0f98-67a5-4695-bd73-8ca5c820cac4
2021-05-19 02:47:38 INFO  MemoryStore:54 - MemoryStore started with capacity 366.3 MB
2021-05-19 02:47:38 INFO  CoarseGrainedExecutorBackend:54 - Connecting to driver: spark://CoarseGrainedScheduler@hadoop02.cusp.nyu.edu:60108
2021-05-19 02:47:38 INFO  CoarseGrainedExecutorBackend:54 - Successfully registered with driver
2021-05-19 02:47:38 INFO  Executor:54 - Starting executor ID 8 on host hadoop18.cusp.nyu.edu
2021-05-19 02:47:38 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 38463.
2021-05-19 02:47:38 INFO  NettyBlockTransferService:54 - Server created on hadoop18.cusp.nyu.edu:38463
2021-05-19 02:47:38 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2021-05-19 02:47:38 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(8, hadoop18.cusp.nyu.edu, 38463, None)
2021-05-19 02:47:38 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(8, hadoop18.cusp.nyu.edu, 38463, None)
2021-05-19 02:47:38 INFO  BlockManager:54 - external shuffle service port = 7337
2021-05-19 02:47:38 INFO  BlockManager:54 - Registering executor with local external shuffle service.
2021-05-19 02:47:38 INFO  TransportClientFactory:267 - Successfully created connection to hadoop18.cusp.nyu.edu/192.168.72.188:7337 after 3 ms (0 ms spent in bootstraps)
2021-05-19 02:47:38 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(8, hadoop18.cusp.nyu.edu, 38463, None)
2021-05-19 02:47:38 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 394
2021-05-19 02:47:38 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 395
2021-05-19 02:47:38 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 396
2021-05-19 02:47:38 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 397
2021-05-19 02:47:38 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 398
2021-05-19 02:47:38 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 399
2021-05-19 02:47:38 INFO  Executor:54 - Running task 27.1 in stage 7.0 (TID 399)
2021-05-19 02:47:38 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 400
2021-05-19 02:47:38 INFO  Executor:54 - Running task 6.1 in stage 7.0 (TID 394)
2021-05-19 02:47:38 INFO  Executor:54 - Running task 38.1 in stage 7.0 (TID 396)
2021-05-19 02:47:38 INFO  Executor:54 - Running task 13.1 in stage 7.0 (TID 397)
2021-05-19 02:47:38 INFO  Executor:54 - Running task 31.1 in stage 7.0 (TID 395)
2021-05-19 02:47:38 INFO  Executor:54 - Running task 35.1 in stage 7.0 (TID 398)
2021-05-19 02:47:38 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 401
2021-05-19 02:47:38 INFO  Executor:54 - Running task 53.0 in stage 7.0 (TID 400)
2021-05-19 02:47:38 INFO  Executor:54 - Running task 58.0 in stage 7.0 (TID 401)
2021-05-19 02:47:38 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 402
2021-05-19 02:47:38 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 403
2021-05-19 02:47:38 INFO  Executor:54 - Running task 60.0 in stage 7.0 (TID 402)
2021-05-19 02:47:38 INFO  Executor:54 - Running task 62.0 in stage 7.0 (TID 403)
2021-05-19 02:47:38 INFO  MapOutputTrackerWorker:54 - Updating epoch to 1 and clearing cache
2021-05-19 02:47:38 INFO  TorrentBroadcast:54 - Started reading broadcast variable 14
2021-05-19 02:47:39 INFO  TransportClientFactory:267 - Successfully created connection to hadoop06.cusp.nyu.edu/192.168.72.176:34178 after 2 ms (0 ms spent in bootstraps)
2021-05-19 02:47:39 INFO  MemoryStore:54 - Block broadcast_14_piece0 stored as bytes in memory (estimated size 22.9 KB, free 366.3 MB)
2021-05-19 02:47:39 INFO  TorrentBroadcast:54 - Reading broadcast variable 14 took 139 ms
2021-05-19 02:47:39 INFO  MemoryStore:54 - Block broadcast_14 stored as values in memory (estimated size 51.4 KB, free 366.2 MB)
2021-05-19 02:47:40 INFO  CodeGenerator:54 - Code generated in 353.676806 ms
2021-05-19 02:47:40 INFO  TorrentBroadcast:54 - Started reading broadcast variable 12
2021-05-19 02:47:40 INFO  TransportClientFactory:267 - Successfully created connection to hadoop02.cusp.nyu.edu/192.168.72.172:49352 after 4 ms (0 ms spent in bootstraps)
2021-05-19 02:47:40 INFO  MemoryStore:54 - Block broadcast_12_piece0 stored as bytes in memory (estimated size 580.1 KB, free 365.7 MB)
2021-05-19 02:47:40 INFO  TorrentBroadcast:54 - Reading broadcast variable 12 took 61 ms
2021-05-19 02:47:41 INFO  MemoryStore:54 - Block broadcast_12 stored as values in memory (estimated size 5.0 MB, free 360.7 MB)
2021-05-19 02:47:41 INFO  CodeGenerator:54 - Code generated in 38.551463 ms
2021-05-19 02:47:42 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00026, range: 134217728-178435909, partition values: [empty row]
2021-05-19 02:47:42 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00013, range: 134217728-177061523, partition values: [empty row]
2021-05-19 02:47:42 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00035, range: 0-134217728, partition values: [empty row]
2021-05-19 02:47:42 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00006, range: 0-134217728, partition values: [empty row]
2021-05-19 02:47:42 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00038, range: 0-134217728, partition values: [empty row]
2021-05-19 02:47:42 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00031, range: 0-134217728, partition values: [empty row]
2021-05-19 02:47:42 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00047, range: 134217728-176331317, partition values: [empty row]
2021-05-19 02:47:42 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00027, range: 0-134217728, partition values: [empty row]
2021-05-19 02:47:42 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00013, range: 0-134217728, partition values: [empty row]
2021-05-19 02:47:42 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00030, range: 134217728-176820246, partition values: [empty row]
2021-05-19 02:47:42 INFO  CodeGenerator:54 - Code generated in 69.003087 ms
2021-05-19 02:47:42 INFO  TorrentBroadcast:54 - Started reading broadcast variable 13
2021-05-19 02:47:42 INFO  MemoryStore:54 - Block broadcast_13_piece0 stored as bytes in memory (estimated size 33.4 KB, free 360.6 MB)
2021-05-19 02:47:42 INFO  TorrentBroadcast:54 - Reading broadcast variable 13 took 55 ms
2021-05-19 02:47:42 INFO  CodeGenerator:54 - Code generated in 80.384867 ms
2021-05-19 02:47:42 INFO  CodeGenerator:54 - Code generated in 69.29508 ms
2021-05-19 02:47:42 INFO  CodeGenerator:54 - Code generated in 66.357399 ms
2021-05-19 02:47:42 INFO  MemoryStore:54 - Block broadcast_13 stored as values in memory (estimated size 506.4 KB, free 360.1 MB)
2021-05-19 02:47:42 INFO  CodeGenerator:54 - Code generated in 38.807245 ms
2021-05-19 02:47:43 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: 22q-222@627-s8x-bzf, 2019-12-16T00:00:00-05:00, [1,0,0,0,0,1,0]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: 22q-222@627-s8x-bzf
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00031
2021-05-19 02:47:43 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: 23b-222@627-wh4-vxq, 2019-01-07T00:00:00-05:00, [10,12,10,16,2,4,3]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: 23b-222@627-wh4-vxq
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00013
2021-05-19 02:47:43 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: 237-224@627-rwx-wtv, 2018-12-31T00:00:00-05:00, [1,0,12,14,0,4,4]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: 237-224@627-rwx-wtv
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00006
2021-05-19 02:47:43 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: 225-222@627-wbv-ht9, 2020-06-29T00:00:00-04:00, [1,3,1,4,8,6,5]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: 225-222@627-wbv-ht9
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00027
2021-05-19 02:47:43 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: 22h-222@627-wfy-m8v, 2019-08-05T00:00:00-04:00, [3,1,1,2,0,1,0]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: 22h-222@627-wfy-m8v
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00035
2021-05-19 02:47:43 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: 22f-222@627-wdh-sdv, 2019-06-10T00:00:00-04:00, [4,2,3,3,3,1,0]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: 22f-222@627-wdh-sdv
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00038
2021-05-19 02:47:44 INFO  CodeGenerator:54 - Code generated in 19.53643 ms
2021-05-19 02:47:44 INFO  CodeGenerator:54 - Code generated in 56.850056 ms
2021-05-19 02:47:44 INFO  CodeGenerator:54 - Code generated in 26.068829 ms
2021-05-19 02:47:45 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:47:45 INFO  CodeGenerator:54 - Code generated in 32.456143 ms
2021-05-19 02:47:45 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:47:45 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:47:45 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:47:45 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:47:45 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:47:45 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:47:45 INFO  CodeGenerator:54 - Code generated in 61.108297 ms
2021-05-19 02:47:45 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:47:45 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:47:45 INFO  CodeGenerator:54 - Code generated in 18.268765 ms
2021-05-19 02:47:45 INFO  CodeGenerator:54 - Code generated in 21.445837 ms
2021-05-19 02:47:45 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:47:45 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00012, range: 134217728-176612852, partition values: [empty row]
2021-05-19 02:47:45 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00035, range: 134217728-177038143, partition values: [empty row]
2021-05-19 02:47:46 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00001, range: 134217728-176196294, partition values: [empty row]
2021-05-19 02:47:46 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00027, range: 134217728-178418906, partition values: [empty row]
2021-05-19 02:47:52 INFO  PythonUDFRunner:54 - Times: total = 11449, boot = 748, init = 2342, finish = 8359
2021-05-19 02:47:53 INFO  CodeGenerator:54 - Code generated in 25.968204 ms
2021-05-19 02:47:53 INFO  Executor:54 - Finished task 62.0 in stage 7.0 (TID 403). 4313 bytes result sent to driver
2021-05-19 02:47:53 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 421
2021-05-19 02:47:53 INFO  Executor:54 - Running task 47.2 in stage 7.0 (TID 421)
2021-05-19 02:47:53 INFO  PythonUDFRunner:54 - Times: total = 12067, boot = 783, init = 2301, finish = 8983
2021-05-19 02:47:53 INFO  PythonUDFRunner:54 - Times: total = 12070, boot = 677, init = 2410, finish = 8983
2021-05-19 02:47:53 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00047, range: 0-134217728, partition values: [empty row]
2021-05-19 02:47:53 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: 222-222@627-vsg-8n5, 2020-05-04T00:00:00-04:00, [3,1,2,2,5,3,2]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: 222-222@627-vsg-8n5
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00047
2021-05-19 02:47:53 INFO  PythonUDFRunner:54 - Times: total = 12540, boot = 703, init = 2383, finish = 9454
2021-05-19 02:47:54 ERROR CoarseGrainedExecutorBackend:43 - RECEIVED SIGNAL TERM
2021-05-19 02:47:54 INFO  DiskBlockManager:54 - Shutdown hook called
2021-05-19 02:47:54 INFO  ShutdownHookManager:54 - Shutdown hook called
2021-05-19 02:47:54 INFO  ShutdownHookManager:54 - Deleting directory /localhome/cdp/yarn/nm/usercache/catherine.ng60/appcache/application_1609183734776_5900/spark-f902b3e0-9c26-490f-88c4-c84e7c5c6ecf
2021-05-19 02:47:54 ERROR TaskContextImpl:91 - Error in TaskCompletionListener
java.io.IOException: Filesystem closed
	at org.apache.hadoop.hdfs.DFSClient.checkOpen(DFSClient.java:808)
	at org.apache.hadoop.hdfs.DFSInputStream.close(DFSInputStream.java:710)
	at java.io.FilterInputStream.close(FilterInputStream.java:181)
	at org.apache.hadoop.util.LineReader.close(LineReader.java:150)
	at org.apache.hadoop.mapreduce.lib.input.LineRecordReader.close(LineRecordReader.java:231)
	at org.apache.spark.sql.execution.datasources.RecordReaderIterator.close(RecordReaderIterator.scala:62)
	at org.apache.spark.sql.execution.datasources.HadoopFileLinesReader.close(HadoopFileLinesReader.scala:73)
	at org.apache.spark.sql.execution.datasources.csv.TextInputCSVDataSource$$anonfun$4$$anonfun$apply$2.apply(CSVDataSource.scala:200)
	at org.apache.spark.sql.execution.datasources.csv.TextInputCSVDataSource$$anonfun$4$$anonfun$apply$2.apply(CSVDataSource.scala:200)
	at org.apache.spark.TaskContext$$anon$1.onTaskCompletion(TaskContext.scala:131)
	at org.apache.spark.TaskContextImpl$$anonfun$markTaskCompleted$1.apply(TaskContextImpl.scala:117)
	at org.apache.spark.TaskContextImpl$$anonfun$markTaskCompleted$1.apply(TaskContextImpl.scala:117)
	at org.apache.spark.TaskContextImpl$$anonfun$invokeListeners$1.apply(TaskContextImpl.scala:130)
	at org.apache.spark.TaskContextImpl$$anonfun$invokeListeners$1.apply(TaskContextImpl.scala:128)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.TaskContextImpl.invokeListeners(TaskContextImpl.scala:128)
	at org.apache.spark.TaskContextImpl.markTaskCompleted(TaskContextImpl.scala:116)
	at org.apache.spark.scheduler.Task.run(Task.scala:131)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:402)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:408)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2021-05-19 02:47:54 INFO  CoarseGrainedExecutorBackend:54 - Driver commanded a shutdown
2021-05-19 02:47:54 ERROR Executor:91 - Exception in task 47.2 in stage 7.0 (TID 421)
org.apache.spark.util.TaskCompletionListenerException: Filesystem closed

Previous exception in task: Filesystem closed
	org.apache.hadoop.hdfs.DFSClient.checkOpen(DFSClient.java:808)
	org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:868)
	org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:934)
	java.io.DataInputStream.read(DataInputStream.java:149)
	org.apache.hadoop.mapreduce.lib.input.UncompressedSplitLineReader.fillBuffer(UncompressedSplitLineReader.java:62)
	org.apache.hadoop.util.LineReader.readDefaultLine(LineReader.java:216)
	org.apache.hadoop.util.LineReader.readLine(LineReader.java:174)
	org.apache.hadoop.mapreduce.lib.input.UncompressedSplitLineReader.readLine(UncompressedSplitLineReader.java:94)
	org.apache.hadoop.mapreduce.lib.input.LineRecordReader.nextKeyValue(LineRecordReader.java:186)
	org.apache.spark.sql.execution.datasources.RecordReaderIterator.hasNext(RecordReaderIterator.scala:39)
	org.apache.spark.sql.execution.datasources.HadoopFileLinesReader.hasNext(HadoopFileLinesReader.scala:69)
	scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:462)
	scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:101)
	org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source)
	org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$11$$anon$1.hasNext(WholeStageCodegenExec.scala:619)
	scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	scala.collection.Iterator$GroupedIterator.takeDestructively(Iterator.scala:1073)
	scala.collection.Iterator$GroupedIterator.go(Iterator.scala:1089)
	scala.collection.Iterator$GroupedIterator.fill(Iterator.scala:1127)
	scala.collection.Iterator$GroupedIterator.hasNext(Iterator.scala:1130)
	scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	scala.collection.Iterator$class.foreach(Iterator.scala:891)
	scala.collection.AbstractIterator.foreach(Iterator.scala:1334)
	org.apache.spark.api.python.PythonRDD$.writeIteratorToStream(PythonRDD.scala:224)
	org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$2.writeIteratorToStream(PythonUDFRunner.scala:50)
	org.apache.spark.api.python.BasePythonRunner$WriterThread$$anonfun$run$1.apply(PythonRunner.scala:345)
	org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1945)
	org.apache.spark.api.python.BasePythonRunner$WriterThread.run(PythonRunner.scala:194)
	at org.apache.spark.TaskContextImpl.invokeListeners(TaskContextImpl.scala:138)
	at org.apache.spark.TaskContextImpl.markTaskCompleted(TaskContextImpl.scala:116)
	at org.apache.spark.scheduler.Task.run(Task.scala:131)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:402)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:408)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2021-05-19 02:47:54 INFO  Executor:54 - Not reporting error to driver during JVM shutdown.
2021-05-19 02:47:54 ERROR Executor:91 - Exception in task 38.1 in stage 7.0 (TID 396)
java.net.SocketException: Connection reset
	at java.net.SocketInputStream.read(SocketInputStream.java:210)
	at java.net.SocketInputStream.read(SocketInputStream.java:141)
	at java.io.BufferedInputStream.fill(BufferedInputStream.java:246)
	at java.io.BufferedInputStream.read1(BufferedInputStream.java:286)
	at java.io.BufferedInputStream.read(BufferedInputStream.java:345)
	at java.io.DataInputStream.readFully(DataInputStream.java:195)
	at java.io.DataInputStream.readFully(DataInputStream.java:169)
	at org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$1.read(PythonUDFRunner.scala:74)
	at org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$1.read(PythonUDFRunner.scala:64)
	at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:406)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$JoinIterator.hasNext(Iterator.scala:212)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage3.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$11$$anon$1.hasNext(WholeStageCodegenExec.scala:619)
	at org.apache.spark.sql.execution.aggregate.ObjectAggregationIterator.processInputs(ObjectAggregationIterator.scala:188)
	at org.apache.spark.sql.execution.aggregate.ObjectAggregationIterator.<init>(ObjectAggregationIterator.scala:78)
	at org.apache.spark.sql.execution.aggregate.ObjectHashAggregateExec$$anonfun$doExecute$1$$anonfun$2.apply(ObjectHashAggregateExec.scala:114)
	at org.apache.spark.sql.execution.aggregate.ObjectHashAggregateExec$$anonfun$doExecute$1$$anonfun$2.apply(ObjectHashAggregateExec.scala:105)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndexInternal$1$$anonfun$12.apply(RDD.scala:823)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndexInternal$1$$anonfun$12.apply(RDD.scala:823)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:402)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:408)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2021-05-19 02:47:54 ERROR Executor:91 - Exception in task 31.1 in stage 7.0 (TID 395)
java.net.SocketException: Connection reset
	at java.net.SocketInputStream.read(SocketInputStream.java:210)
	at java.net.SocketInputStream.read(SocketInputStream.java:141)
	at java.io.BufferedInputStream.fill(BufferedInputStream.java:246)
	at java.io.BufferedInputStream.read1(BufferedInputStream.java:286)
	at java.io.BufferedInputStream.read(BufferedInputStream.java:345)
	at java.io.DataInputStream.readFully(DataInputStream.java:195)
	at java.io.DataInputStream.readFully(DataInputStream.java:169)
	at org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$1.read(PythonUDFRunner.scala:74)
	at org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$1.read(PythonUDFRunner.scala:64)
	at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:406)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$JoinIterator.hasNext(Iterator.scala:212)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage3.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$11$$anon$1.hasNext(WholeStageCodegenExec.scala:619)
	at org.apache.spark.sql.execution.aggregate.ObjectAggregationIterator.processInputs(ObjectAggregationIterator.scala:188)
	at org.apache.spark.sql.execution.aggregate.ObjectAggregationIterator.<init>(ObjectAggregationIterator.scala:78)
	at org.apache.spark.sql.execution.aggregate.ObjectHashAggregateExec$$anonfun$doExecute$1$$anonfun$2.apply(ObjectHashAggregateExec.scala:114)
	at org.apache.spark.sql.execution.aggregate.ObjectHashAggregateExec$$anonfun$doExecute$1$$anonfun$2.apply(ObjectHashAggregateExec.scala:105)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndexInternal$1$$anonfun$12.apply(RDD.scala:823)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndexInternal$1$$anonfun$12.apply(RDD.scala:823)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:402)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:408)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2021-05-19 02:47:54 ERROR Executor:91 - Exception in task 13.1 in stage 7.0 (TID 397)
java.net.SocketException: Connection reset
	at java.net.SocketInputStream.read(SocketInputStream.java:210)
	at java.net.SocketInputStream.read(SocketInputStream.java:141)
	at java.io.BufferedInputStream.fill(BufferedInputStream.java:246)
	at java.io.BufferedInputStream.read1(BufferedInputStream.java:286)
	at java.io.BufferedInputStream.read(BufferedInputStream.java:345)
	at java.io.DataInputStream.readFully(DataInputStream.java:195)
	at java.io.DataInputStream.readFully(DataInputStream.java:169)
	at org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$1.read(PythonUDFRunner.scala:74)
	at org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$1.read(PythonUDFRunner.scala:64)
	at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:406)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$JoinIterator.hasNext(Iterator.scala:212)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage3.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$11$$anon$1.hasNext(WholeStageCodegenExec.scala:619)
	at org.apache.spark.sql.execution.aggregate.ObjectAggregationIterator.processInputs(ObjectAggregationIterator.scala:188)
	at org.apache.spark.sql.execution.aggregate.ObjectAggregationIterator.<init>(ObjectAggregationIterator.scala:78)
	at org.apache.spark.sql.execution.aggregate.ObjectHashAggregateExec$$anonfun$doExecute$1$$anonfun$2.apply(ObjectHashAggregateExec.scala:114)
	at org.apache.spark.sql.execution.aggregate.ObjectHashAggregateExec$$anonfun$doExecute$1$$anonfun$2.apply(ObjectHashAggregateExec.scala:105)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndexInternal$1$$anonfun$12.apply(RDD.scala:823)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndexInternal$1$$anonfun$12.apply(RDD.scala:823)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:402)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:408)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2021-05-19 02:47:54 ERROR Executor:91 - Exception in task 35.1 in stage 7.0 (TID 398)
java.net.SocketException: Connection reset
	at java.net.SocketInputStream.read(SocketInputStream.java:210)
	at java.net.SocketInputStream.read(SocketInputStream.java:141)
	at java.io.BufferedInputStream.fill(BufferedInputStream.java:246)
	at java.io.BufferedInputStream.read1(BufferedInputStream.java:286)
	at java.io.BufferedInputStream.read(BufferedInputStream.java:345)
	at java.io.DataInputStream.readFully(DataInputStream.java:195)
	at java.io.DataInputStream.readFully(DataInputStream.java:169)
	at org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$1.read(PythonUDFRunner.scala:74)
	at org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$1.read(PythonUDFRunner.scala:64)
	at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:406)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$JoinIterator.hasNext(Iterator.scala:212)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage3.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$11$$anon$1.hasNext(WholeStageCodegenExec.scala:619)
	at org.apache.spark.sql.execution.aggregate.ObjectAggregationIterator.processInputs(ObjectAggregationIterator.scala:188)
	at org.apache.spark.sql.execution.aggregate.ObjectAggregationIterator.<init>(ObjectAggregationIterator.scala:78)
	at org.apache.spark.sql.execution.aggregate.ObjectHashAggregateExec$$anonfun$doExecute$1$$anonfun$2.apply(ObjectHashAggregateExec.scala:114)
	at org.apache.spark.sql.execution.aggregate.ObjectHashAggregateExec$$anonfun$doExecute$1$$anonfun$2.apply(ObjectHashAggregateExec.scala:105)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndexInternal$1$$anonfun$12.apply(RDD.scala:823)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndexInternal$1$$anonfun$12.apply(RDD.scala:823)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:402)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:408)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2021-05-19 02:47:54 ERROR Executor:91 - Exception in task 6.1 in stage 7.0 (TID 394)
java.net.SocketException: Connection reset
	at java.net.SocketInputStream.read(SocketInputStream.java:210)
	at java.net.SocketInputStream.read(SocketInputStream.java:141)
	at java.io.BufferedInputStream.fill(BufferedInputStream.java:246)
	at java.io.BufferedInputStream.read1(BufferedInputStream.java:286)
	at java.io.BufferedInputStream.read(BufferedInputStream.java:345)
	at java.io.DataInputStream.readFully(DataInputStream.java:195)
	at java.io.DataInputStream.readFully(DataInputStream.java:169)
	at org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$1.read(PythonUDFRunner.scala:74)
	at org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$1.read(PythonUDFRunner.scala:64)
	at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:406)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$JoinIterator.hasNext(Iterator.scala:212)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage3.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$11$$anon$1.hasNext(WholeStageCodegenExec.scala:619)
	at org.apache.spark.sql.execution.aggregate.ObjectAggregationIterator.processInputs(ObjectAggregationIterator.scala:188)
	at org.apache.spark.sql.execution.aggregate.ObjectAggregationIterator.<init>(ObjectAggregationIterator.scala:78)
	at org.apache.spark.sql.execution.aggregate.ObjectHashAggregateExec$$anonfun$doExecute$1$$anonfun$2.apply(ObjectHashAggregateExec.scala:114)
	at org.apache.spark.sql.execution.aggregate.ObjectHashAggregateExec$$anonfun$doExecute$1$$anonfun$2.apply(ObjectHashAggregateExec.scala:105)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndexInternal$1$$anonfun$12.apply(RDD.scala:823)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndexInternal$1$$anonfun$12.apply(RDD.scala:823)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:402)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:408)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2021-05-19 02:47:54 INFO  Executor:54 - Not reporting error to driver during JVM shutdown.
2021-05-19 02:47:54 ERROR Executor:91 - Exception in task 27.1 in stage 7.0 (TID 399)
java.net.SocketException: Connection reset
	at java.net.SocketInputStream.read(SocketInputStream.java:210)
	at java.net.SocketInputStream.read(SocketInputStream.java:141)
	at java.io.BufferedInputStream.fill(BufferedInputStream.java:246)
	at java.io.BufferedInputStream.read1(BufferedInputStream.java:286)
	at java.io.BufferedInputStream.read(BufferedInputStream.java:345)
	at java.io.DataInputStream.readFully(DataInputStream.java:195)
	at java.io.DataInputStream.readFully(DataInputStream.java:169)
	at org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$1.read(PythonUDFRunner.scala:74)
	at org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$1.read(PythonUDFRunner.scala:64)
	at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:406)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$JoinIterator.hasNext(Iterator.scala:212)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage3.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$11$$anon$1.hasNext(WholeStageCodegenExec.scala:619)
	at org.apache.spark.sql.execution.aggregate.ObjectAggregationIterator.processInputs(ObjectAggregationIterator.scala:188)
	at org.apache.spark.sql.execution.aggregate.ObjectAggregationIterator.<init>(ObjectAggregationIterator.scala:78)
	at org.apache.spark.sql.execution.aggregate.ObjectHashAggregateExec$$anonfun$doExecute$1$$anonfun$2.apply(ObjectHashAggregateExec.scala:114)
	at org.apache.spark.sql.execution.aggregate.ObjectHashAggregateExec$$anonfun$doExecute$1$$anonfun$2.apply(ObjectHashAggregateExec.scala:105)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndexInternal$1$$anonfun$12.apply(RDD.scala:823)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndexInternal$1$$anonfun$12.apply(RDD.scala:823)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:402)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:408)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2021-05-19 02:47:54 INFO  Executor:54 - Not reporting error to driver during JVM shutdown.
2021-05-19 02:47:54 INFO  Executor:54 - Not reporting error to driver during JVM shutdown.
2021-05-19 02:47:54 INFO  MemoryStore:54 - MemoryStore cleared
2021-05-19 02:47:54 INFO  Executor:54 - Not reporting error to driver during JVM shutdown.
2021-05-19 02:47:54 INFO  Executor:54 - Not reporting error to driver during JVM shutdown.
2021-05-19 02:47:54 INFO  Executor:54 - Not reporting error to driver during JVM shutdown.
2021-05-19 02:47:54 INFO  BlockManager:54 - BlockManager stopped

End of LogType:stdout
***********************************************************************


End of LogType:prelaunch.err
******************************************************************************

Container: container_e10_1609183734776_5900_01_000011 on hadoop18.cusp.nyu.edu_8041
LogAggregationType: AGGREGATED
===================================================================================
LogType:prelaunch.out
LogLastModifiedTime:Wed May 19 02:48:18 -0400 2021
LogLength:70
LogContents:
Setting up env variables
Setting up job resources
Launching container

End of LogType:prelaunch.out
******************************************************************************

Container: container_e10_1609183734776_5900_01_000011 on hadoop18.cusp.nyu.edu_8041
LogAggregationType: AGGREGATED
===================================================================================
LogType:stderr
LogLastModifiedTime:Wed May 19 02:48:18 -0400 2021
LogLength:529
LogContents:
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/localhome/cdp/yarn/nm/filecache/25/spark-jars-2.4.0-hadoop2.7.jar/slf4j-log4j12-1.7.16.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-6.1.0-1.cdh6.1.0.p0.770702/jars/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]

End of LogType:stderr
***********************************************************************

Container: container_e10_1609183734776_5900_01_000011 on hadoop18.cusp.nyu.edu_8041
LogAggregationType: AGGREGATED
===================================================================================
LogType:stdout
LogLastModifiedTime:Wed May 19 02:48:18 -0400 2021
LogLength:72317
LogContents:
2021-05-19 02:46:14 INFO  CoarseGrainedExecutorBackend:2566 - Started daemon with process name: 38028@hadoop18.cusp.nyu.edu
2021-05-19 02:46:14 INFO  SignalUtils:54 - Registered signal handler for TERM
2021-05-19 02:46:14 INFO  SignalUtils:54 - Registered signal handler for HUP
2021-05-19 02:46:14 INFO  SignalUtils:54 - Registered signal handler for INT
2021-05-19 02:46:15 INFO  SecurityManager:54 - Changing view acls to: catherine.ng60
2021-05-19 02:46:15 INFO  SecurityManager:54 - Changing modify acls to: catherine.ng60
2021-05-19 02:46:15 INFO  SecurityManager:54 - Changing view acls groups to: 
2021-05-19 02:46:15 INFO  SecurityManager:54 - Changing modify acls groups to: 
2021-05-19 02:46:15 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(catherine.ng60); groups with view permissions: Set(); users  with modify permissions: Set(catherine.ng60); groups with modify permissions: Set()
2021-05-19 02:46:16 INFO  TransportClientFactory:267 - Successfully created connection to hadoop05.cusp.nyu.edu/192.168.72.175:47481 after 132 ms (0 ms spent in bootstraps)
2021-05-19 02:46:16 INFO  SecurityManager:54 - Changing view acls to: catherine.ng60
2021-05-19 02:46:16 INFO  SecurityManager:54 - Changing modify acls to: catherine.ng60
2021-05-19 02:46:16 INFO  SecurityManager:54 - Changing view acls groups to: 
2021-05-19 02:46:16 INFO  SecurityManager:54 - Changing modify acls groups to: 
2021-05-19 02:46:16 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(catherine.ng60); groups with view permissions: Set(); users  with modify permissions: Set(catherine.ng60); groups with modify permissions: Set()
2021-05-19 02:46:16 INFO  TransportClientFactory:267 - Successfully created connection to hadoop05.cusp.nyu.edu/192.168.72.175:47481 after 4 ms (0 ms spent in bootstraps)
2021-05-19 02:46:16 INFO  DiskBlockManager:54 - Created local directory at /localhome/cdp/yarn/nm/usercache/catherine.ng60/appcache/application_1609183734776_5900/blockmgr-3775fd5c-fc95-404e-8c71-0ec953d7f37e
2021-05-19 02:46:16 INFO  MemoryStore:54 - MemoryStore started with capacity 366.3 MB
2021-05-19 02:46:16 INFO  CoarseGrainedExecutorBackend:54 - Connecting to driver: spark://CoarseGrainedScheduler@hadoop05.cusp.nyu.edu:47481
2021-05-19 02:46:16 INFO  CoarseGrainedExecutorBackend:54 - Successfully registered with driver
2021-05-19 02:46:16 INFO  Executor:54 - Starting executor ID 10 on host hadoop18.cusp.nyu.edu
2021-05-19 02:46:16 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 48269.
2021-05-19 02:46:16 INFO  NettyBlockTransferService:54 - Server created on hadoop18.cusp.nyu.edu:48269
2021-05-19 02:46:17 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2021-05-19 02:46:17 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(10, hadoop18.cusp.nyu.edu, 48269, None)
2021-05-19 02:46:17 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(10, hadoop18.cusp.nyu.edu, 48269, None)
2021-05-19 02:46:17 INFO  BlockManager:54 - external shuffle service port = 7337
2021-05-19 02:46:17 INFO  BlockManager:54 - Registering executor with local external shuffle service.
2021-05-19 02:46:17 INFO  TransportClientFactory:267 - Successfully created connection to hadoop18.cusp.nyu.edu/192.168.72.188:7337 after 3 ms (0 ms spent in bootstraps)
2021-05-19 02:46:17 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(10, hadoop18.cusp.nyu.edu, 48269, None)
2021-05-19 02:46:19 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 413
2021-05-19 02:46:19 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 415
2021-05-19 02:46:19 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 417
2021-05-19 02:46:19 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 419
2021-05-19 02:46:19 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 421
2021-05-19 02:46:19 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 422
2021-05-19 02:46:19 INFO  Executor:54 - Running task 29.1 in stage 7.0 (TID 421)
2021-05-19 02:46:19 INFO  Executor:54 - Running task 46.2 in stage 7.0 (TID 419)
2021-05-19 02:46:19 INFO  Executor:54 - Running task 21.1 in stage 7.0 (TID 413)
2021-05-19 02:46:19 INFO  Executor:54 - Running task 19.1 in stage 7.0 (TID 415)
2021-05-19 02:46:19 INFO  Executor:54 - Running task 42.1 in stage 7.0 (TID 417)
2021-05-19 02:46:19 INFO  Executor:54 - Running task 1.1 in stage 7.0 (TID 422)
2021-05-19 02:46:19 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 423
2021-05-19 02:46:19 INFO  Executor:54 - Running task 64.1 in stage 7.0 (TID 423)
2021-05-19 02:46:19 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 424
2021-05-19 02:46:19 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 425
2021-05-19 02:46:19 INFO  Executor:54 - Running task 12.1 in stage 7.0 (TID 424)
2021-05-19 02:46:19 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 426
2021-05-19 02:46:19 INFO  Executor:54 - Running task 39.1 in stage 7.0 (TID 425)
2021-05-19 02:46:20 INFO  Executor:54 - Running task 69.1 in stage 7.0 (TID 426)
2021-05-19 02:46:20 INFO  MapOutputTrackerWorker:54 - Updating epoch to 1 and clearing cache
2021-05-19 02:46:20 INFO  TorrentBroadcast:54 - Started reading broadcast variable 14
2021-05-19 02:46:20 INFO  TransportClientFactory:267 - Successfully created connection to hadoop18.cusp.nyu.edu/192.168.72.188:58292 after 3 ms (0 ms spent in bootstraps)
2021-05-19 02:46:20 INFO  MemoryStore:54 - Block broadcast_14_piece0 stored as bytes in memory (estimated size 22.9 KB, free 366.3 MB)
2021-05-19 02:46:20 INFO  TorrentBroadcast:54 - Reading broadcast variable 14 took 200 ms
2021-05-19 02:46:20 INFO  MemoryStore:54 - Block broadcast_14 stored as values in memory (estimated size 51.5 KB, free 366.2 MB)
2021-05-19 02:46:21 INFO  CodeGenerator:54 - Code generated in 349.958533 ms
2021-05-19 02:46:21 INFO  TorrentBroadcast:54 - Started reading broadcast variable 12
2021-05-19 02:46:22 INFO  MemoryStore:54 - Block broadcast_12_piece0 stored as bytes in memory (estimated size 580.1 KB, free 365.7 MB)
2021-05-19 02:46:22 INFO  TorrentBroadcast:54 - Reading broadcast variable 12 took 39 ms
2021-05-19 02:46:22 INFO  MemoryStore:54 - Block broadcast_12 stored as values in memory (estimated size 5.0 MB, free 360.7 MB)
2021-05-19 02:46:22 INFO  CodeGenerator:54 - Code generated in 40.135849 ms
2021-05-19 02:46:23 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00001, range: 0-134217728, partition values: [empty row]
2021-05-19 02:46:23 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00038, range: 134217728-172697253, partition values: [empty row]
2021-05-19 02:46:23 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00012, range: 0-134217728, partition values: [empty row]
2021-05-19 02:46:23 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00042, range: 0-134217728, partition values: [empty row]
2021-05-19 02:46:23 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00029, range: 0-134217728, partition values: [empty row]
2021-05-19 02:46:23 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00020, range: 134217728-175942625, partition values: [empty row]
2021-05-19 02:46:23 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00039, range: 0-134217728, partition values: [empty row]
2021-05-19 02:46:23 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00046, range: 0-134217728, partition values: [empty row]
2021-05-19 02:46:23 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00019, range: 0-134217728, partition values: [empty row]
2021-05-19 02:46:23 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00021, range: 0-134217728, partition values: [empty row]
2021-05-19 02:46:23 INFO  CodeGenerator:54 - Code generated in 35.228131 ms
2021-05-19 02:46:23 INFO  TorrentBroadcast:54 - Started reading broadcast variable 13
2021-05-19 02:46:23 INFO  MemoryStore:54 - Block broadcast_13_piece0 stored as bytes in memory (estimated size 33.4 KB, free 360.6 MB)
2021-05-19 02:46:23 INFO  TorrentBroadcast:54 - Reading broadcast variable 13 took 28 ms
2021-05-19 02:46:23 INFO  CodeGenerator:54 - Code generated in 78.551942 ms
2021-05-19 02:46:23 INFO  CodeGenerator:54 - Code generated in 41.112369 ms
2021-05-19 02:46:23 INFO  MemoryStore:54 - Block broadcast_13 stored as values in memory (estimated size 506.4 KB, free 360.1 MB)
2021-05-19 02:46:23 INFO  CodeGenerator:54 - Code generated in 48.081928 ms
2021-05-19 02:46:23 INFO  CodeGenerator:54 - Code generated in 29.922749 ms
2021-05-19 02:46:25 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: 22f-222@627-s8x-c5z, 2020-10-26T00:00:00-04:00, [1,0,0,0,0,0,0]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: 22f-222@627-s8x-c5z
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00042
2021-05-19 02:46:25 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: 22k-223@627-s8w-b49, 2018-12-31T00:00:00-05:00, [9,0,10,6,6,8,4]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: 22k-223@627-s8w-b49
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00001
2021-05-19 02:46:25 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: 22x-222@627-wgt-snq, 2020-07-13T00:00:00-04:00, [1,1,1,4,2,1,6]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: 22x-222@627-wgt-snq
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00039
2021-05-19 02:46:25 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: 22h-223@627-s96-73q, 2019-10-07T00:00:00-04:00, [5,3,1,1,5,1,3]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: 22h-223@627-s96-73q
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00046
2021-05-19 02:46:25 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: zzy-222@627-s93-26k, 2019-12-02T00:00:00-05:00, [4,6,9,13,8,11,4]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: zzy-222@627-s93-26k
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00029
2021-05-19 02:46:25 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: 233-222@627-s6b-5s5, 2018-12-31T00:00:00-05:00, [38,44,50,44,70,36,32]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: 233-222@627-s6b-5s5
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00021
2021-05-19 02:46:25 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: 22c-222@627-vv6-vvf, 2019-12-16T00:00:00-05:00, [0,0,0,0,1,0,0]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: 22c-222@627-vv6-vvf
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00019
2021-05-19 02:46:25 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: 22p-222@627-s5x-c3q, 2018-12-31T00:00:00-05:00, [3,2,4,4,4,6,0]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: 22p-222@627-s5x-c3q
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00012
2021-05-19 02:46:26 INFO  CodeGenerator:54 - Code generated in 18.941026 ms
2021-05-19 02:46:26 INFO  CodeGenerator:54 - Code generated in 25.331183 ms
2021-05-19 02:46:26 INFO  CodeGenerator:54 - Code generated in 37.223307 ms
2021-05-19 02:46:26 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:46:27 INFO  CodeGenerator:54 - Code generated in 34.773867 ms
2021-05-19 02:46:27 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:46:27 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:46:27 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:46:27 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:46:27 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:46:27 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:46:27 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:46:27 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:46:27 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:46:27 INFO  CodeGenerator:54 - Code generated in 37.470688 ms
2021-05-19 02:46:27 INFO  CodeGenerator:54 - Code generated in 18.300741 ms
2021-05-19 02:46:27 INFO  CodeGenerator:54 - Code generated in 20.22089 ms
2021-05-19 02:46:27 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00029, range: 134217728-172005177, partition values: [empty row]
2021-05-19 02:46:27 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00024, range: 134217728-175886494, partition values: [empty row]
2021-05-19 02:46:30 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00005, range: 134217728-171011271, partition values: [empty row]
2021-05-19 02:46:32 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00009, range: 134217728-175852891, partition values: [empty row]
2021-05-19 02:46:37 INFO  PythonUDFRunner:54 - Times: total = 15067, boot = 997, init = 2661, finish = 11409
2021-05-19 02:46:37 INFO  PythonUDFRunner:54 - Times: total = 15225, boot = 988, init = 2658, finish = 11579
2021-05-19 02:46:37 INFO  PythonUDFRunner:54 - Times: total = 15353, boot = 925, init = 2722, finish = 11706
2021-05-19 02:46:37 INFO  PythonUDFRunner:54 - Times: total = 15380, boot = 968, init = 2685, finish = 11727
2021-05-19 02:46:37 INFO  PythonUDFRunner:54 - Times: total = 15494, boot = 901, init = 2745, finish = 11848
2021-05-19 02:46:38 INFO  CodeGenerator:54 - Code generated in 28.71465 ms
2021-05-19 02:46:38 INFO  PythonUDFRunner:54 - Times: total = 15840, boot = 949, init = 2701, finish = 12190
2021-05-19 02:46:38 INFO  PythonUDFRunner:54 - Times: total = 16079, boot = 979, init = 2670, finish = 12430
2021-05-19 02:46:38 INFO  Executor:54 - Finished task 21.1 in stage 7.0 (TID 413). 4313 bytes result sent to driver
2021-05-19 02:46:38 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 445
2021-05-19 02:46:38 INFO  Executor:54 - Running task 23.3 in stage 7.0 (TID 445)
2021-05-19 02:46:38 INFO  PythonUDFRunner:54 - Times: total = 16121, boot = 935, init = 2719, finish = 12467
2021-05-19 02:46:38 INFO  Executor:54 - Finished task 19.1 in stage 7.0 (TID 415). 4313 bytes result sent to driver
2021-05-19 02:46:38 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 446
2021-05-19 02:46:38 INFO  Executor:54 - Running task 16.1 in stage 7.0 (TID 446)
2021-05-19 02:46:38 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00016, range: 0-134217728, partition values: [empty row]
2021-05-19 02:46:38 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00023, range: 0-134217728, partition values: [empty row]
2021-05-19 02:46:38 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: 222-222@627-s6k-dqf, 2019-01-14T00:00:00-05:00, [0,0,0,0,1,0,0]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: 222-222@627-s6k-dqf
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00016
2021-05-19 02:46:38 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: 22b-222@627-s4r-s3q, 2019-11-04T00:00:00-05:00, [20,15,14,25,21,16,15]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: 22b-222@627-s4r-s3q
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00023
2021-05-19 02:46:38 INFO  UnsafeExternalSorter:209 - Thread 127 spilling sort data of 34.0 MB to disk (0  time so far)
2021-05-19 02:46:38 INFO  Executor:54 - Finished task 39.1 in stage 7.0 (TID 425). 4313 bytes result sent to driver
2021-05-19 02:46:38 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 447
2021-05-19 02:46:38 INFO  Executor:54 - Running task 53.3 in stage 7.0 (TID 447)
2021-05-19 02:46:38 INFO  Executor:54 - Finished task 12.1 in stage 7.0 (TID 424). 4313 bytes result sent to driver
2021-05-19 02:46:38 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00026, range: 134217728-178435909, partition values: [empty row]
2021-05-19 02:46:38 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 448
2021-05-19 02:46:38 INFO  Executor:54 - Running task 63.1 in stage 7.0 (TID 448)
2021-05-19 02:46:38 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00031, range: 134217728-176028743, partition values: [empty row]
2021-05-19 02:46:38 INFO  Executor:54 - Finished task 29.1 in stage 7.0 (TID 421). 4270 bytes result sent to driver
2021-05-19 02:46:38 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 449
2021-05-19 02:46:38 INFO  Executor:54 - Running task 13.2 in stage 7.0 (TID 449)
2021-05-19 02:46:39 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00013, range: 0-134217728, partition values: [empty row]
2021-05-19 02:46:39 INFO  Executor:54 - Finished task 42.1 in stage 7.0 (TID 417). 4313 bytes result sent to driver
2021-05-19 02:46:39 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: 23b-222@627-wh4-vxq, 2019-01-07T00:00:00-05:00, [10,12,10,16,2,4,3]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: 23b-222@627-wh4-vxq
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00013
2021-05-19 02:46:39 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 450
2021-05-19 02:46:39 INFO  Executor:54 - Running task 32.1 in stage 7.0 (TID 450)
2021-05-19 02:46:39 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00032, range: 0-134217728, partition values: [empty row]
2021-05-19 02:46:39 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: 22g-222@627-rwv-q75, 2019-07-15T00:00:00-04:00, [12,11,14,8,11,9,7]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: 22g-222@627-rwv-q75
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00032
2021-05-19 02:46:39 INFO  PythonUDFRunner:54 - Times: total = 16818, boot = 915, init = 2729, finish = 13174
2021-05-19 02:46:39 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:46:39 INFO  Executor:54 - Finished task 46.2 in stage 7.0 (TID 419). 4313 bytes result sent to driver
2021-05-19 02:46:39 INFO  Executor:54 - Finished task 1.1 in stage 7.0 (TID 422). 4270 bytes result sent to driver
2021-05-19 02:46:39 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 451
2021-05-19 02:46:39 INFO  Executor:54 - Running task 31.2 in stage 7.0 (TID 451)
2021-05-19 02:46:39 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 452
2021-05-19 02:46:39 INFO  Executor:54 - Running task 38.3 in stage 7.0 (TID 452)
2021-05-19 02:46:39 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00031, range: 0-134217728, partition values: [empty row]
2021-05-19 02:46:39 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00038, range: 0-134217728, partition values: [empty row]
2021-05-19 02:46:39 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: 22f-222@627-wdh-sdv, 2019-06-10T00:00:00-04:00, [4,2,3,3,3,1,0]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: 22f-222@627-wdh-sdv
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00038
2021-05-19 02:46:39 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: 22q-222@627-s8x-bzf, 2019-12-16T00:00:00-05:00, [1,0,0,0,0,1,0]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: 22q-222@627-s8x-bzf
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00031
2021-05-19 02:46:39 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:46:39 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:46:39 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:46:39 ERROR CoarseGrainedExecutorBackend:43 - RECEIVED SIGNAL TERM
2021-05-19 02:46:39 INFO  DiskBlockManager:54 - Shutdown hook called
2021-05-19 02:46:39 INFO  ShutdownHookManager:54 - Shutdown hook called
2021-05-19 02:46:39 INFO  ShutdownHookManager:54 - Deleting directory /localhome/cdp/yarn/nm/usercache/catherine.ng60/appcache/application_1609183734776_5900/spark-d9eb7354-ade7-41ad-b94f-3837e2ff8c29
2021-05-19 02:46:39 ERROR TaskContextImpl:91 - Error in TaskCompletionListener
java.io.IOException: Filesystem closed
	at org.apache.hadoop.hdfs.DFSClient.checkOpen(DFSClient.java:808)
	at org.apache.hadoop.hdfs.DFSInputStream.close(DFSInputStream.java:710)
	at java.io.FilterInputStream.close(FilterInputStream.java:181)
	at org.apache.hadoop.util.LineReader.close(LineReader.java:150)
	at org.apache.hadoop.mapreduce.lib.input.LineRecordReader.close(LineRecordReader.java:231)
	at org.apache.spark.sql.execution.datasources.RecordReaderIterator.close(RecordReaderIterator.scala:62)
	at org.apache.spark.sql.execution.datasources.HadoopFileLinesReader.close(HadoopFileLinesReader.scala:73)
	at org.apache.spark.sql.execution.datasources.csv.TextInputCSVDataSource$$anonfun$4$$anonfun$apply$2.apply(CSVDataSource.scala:200)
	at org.apache.spark.sql.execution.datasources.csv.TextInputCSVDataSource$$anonfun$4$$anonfun$apply$2.apply(CSVDataSource.scala:200)
	at org.apache.spark.TaskContext$$anon$1.onTaskCompletion(TaskContext.scala:131)
	at org.apache.spark.TaskContextImpl$$anonfun$markTaskCompleted$1.apply(TaskContextImpl.scala:117)
	at org.apache.spark.TaskContextImpl$$anonfun$markTaskCompleted$1.apply(TaskContextImpl.scala:117)
	at org.apache.spark.TaskContextImpl$$anonfun$invokeListeners$1.apply(TaskContextImpl.scala:130)
	at org.apache.spark.TaskContextImpl$$anonfun$invokeListeners$1.apply(TaskContextImpl.scala:128)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.TaskContextImpl.invokeListeners(TaskContextImpl.scala:128)
	at org.apache.spark.TaskContextImpl.markTaskCompleted(TaskContextImpl.scala:116)
	at org.apache.spark.scheduler.Task.run(Task.scala:131)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:402)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:408)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2021-05-19 02:46:39 ERROR Executor:91 - Exception in task 13.2 in stage 7.0 (TID 449)
org.apache.spark.util.TaskCompletionListenerException: Filesystem closed

Previous exception in task: Filesystem closed
	org.apache.hadoop.hdfs.DFSClient.checkOpen(DFSClient.java:808)
	org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:868)
	org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:934)
	java.io.DataInputStream.read(DataInputStream.java:149)
	org.apache.hadoop.mapreduce.lib.input.UncompressedSplitLineReader.fillBuffer(UncompressedSplitLineReader.java:62)
	org.apache.hadoop.util.LineReader.readDefaultLine(LineReader.java:216)
	org.apache.hadoop.util.LineReader.readLine(LineReader.java:174)
	org.apache.hadoop.mapreduce.lib.input.UncompressedSplitLineReader.readLine(UncompressedSplitLineReader.java:94)
	org.apache.hadoop.mapreduce.lib.input.LineRecordReader.nextKeyValue(LineRecordReader.java:186)
	org.apache.spark.sql.execution.datasources.RecordReaderIterator.hasNext(RecordReaderIterator.scala:39)
	org.apache.spark.sql.execution.datasources.HadoopFileLinesReader.hasNext(HadoopFileLinesReader.scala:69)
	scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:462)
	scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:101)
	org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source)
	org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$11$$anon$1.hasNext(WholeStageCodegenExec.scala:619)
	scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	scala.collection.Iterator$GroupedIterator.takeDestructively(Iterator.scala:1073)
	scala.collection.Iterator$GroupedIterator.go(Iterator.scala:1089)
	scala.collection.Iterator$GroupedIterator.fill(Iterator.scala:1127)
	scala.collection.Iterator$GroupedIterator.hasNext(Iterator.scala:1130)
	scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	scala.collection.Iterator$class.foreach(Iterator.scala:891)
	scala.collection.AbstractIterator.foreach(Iterator.scala:1334)
	org.apache.spark.api.python.PythonRDD$.writeIteratorToStream(PythonRDD.scala:224)
	org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$2.writeIteratorToStream(PythonUDFRunner.scala:50)
	org.apache.spark.api.python.BasePythonRunner$WriterThread$$anonfun$run$1.apply(PythonRunner.scala:345)
	org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1945)
	org.apache.spark.api.python.BasePythonRunner$WriterThread.run(PythonRunner.scala:194)
	at org.apache.spark.TaskContextImpl.invokeListeners(TaskContextImpl.scala:138)
	at org.apache.spark.TaskContextImpl.markTaskCompleted(TaskContextImpl.scala:116)
	at org.apache.spark.scheduler.Task.run(Task.scala:131)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:402)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:408)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2021-05-19 02:46:39 INFO  Executor:54 - Not reporting error to driver during JVM shutdown.
2021-05-19 02:46:39 ERROR TaskContextImpl:91 - Error in TaskCompletionListener
java.io.IOException: Filesystem closed
	at org.apache.hadoop.hdfs.DFSClient.checkOpen(DFSClient.java:808)
	at org.apache.hadoop.hdfs.DFSInputStream.close(DFSInputStream.java:710)
	at java.io.FilterInputStream.close(FilterInputStream.java:181)
	at org.apache.hadoop.util.LineReader.close(LineReader.java:150)
	at org.apache.hadoop.mapreduce.lib.input.LineRecordReader.close(LineRecordReader.java:231)
	at org.apache.spark.sql.execution.datasources.RecordReaderIterator.close(RecordReaderIterator.scala:62)
	at org.apache.spark.sql.execution.datasources.HadoopFileLinesReader.close(HadoopFileLinesReader.scala:73)
	at org.apache.spark.sql.execution.datasources.csv.TextInputCSVDataSource$$anonfun$4$$anonfun$apply$2.apply(CSVDataSource.scala:200)
	at org.apache.spark.sql.execution.datasources.csv.TextInputCSVDataSource$$anonfun$4$$anonfun$apply$2.apply(CSVDataSource.scala:200)
	at org.apache.spark.TaskContext$$anon$1.onTaskCompletion(TaskContext.scala:131)
	at org.apache.spark.TaskContextImpl$$anonfun$markTaskCompleted$1.apply(TaskContextImpl.scala:117)
	at org.apache.spark.TaskContextImpl$$anonfun$markTaskCompleted$1.apply(TaskContextImpl.scala:117)
	at org.apache.spark.TaskContextImpl$$anonfun$invokeListeners$1.apply(TaskContextImpl.scala:130)
	at org.apache.spark.TaskContextImpl$$anonfun$invokeListeners$1.apply(TaskContextImpl.scala:128)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.TaskContextImpl.invokeListeners(TaskContextImpl.scala:128)
	at org.apache.spark.TaskContextImpl.markTaskCompleted(TaskContextImpl.scala:116)
	at org.apache.spark.scheduler.Task.run(Task.scala:131)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:402)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:408)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2021-05-19 02:46:39 ERROR Executor:91 - Exception in task 23.3 in stage 7.0 (TID 445)
org.apache.spark.util.TaskCompletionListenerException: Filesystem closed

Previous exception in task: Filesystem closed
	org.apache.hadoop.hdfs.DFSClient.checkOpen(DFSClient.java:808)
	org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:868)
	org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:934)
	java.io.DataInputStream.read(DataInputStream.java:149)
	org.apache.hadoop.mapreduce.lib.input.UncompressedSplitLineReader.fillBuffer(UncompressedSplitLineReader.java:62)
	org.apache.hadoop.util.LineReader.readDefaultLine(LineReader.java:216)
	org.apache.hadoop.util.LineReader.readLine(LineReader.java:174)
	org.apache.hadoop.mapreduce.lib.input.UncompressedSplitLineReader.readLine(UncompressedSplitLineReader.java:94)
	org.apache.hadoop.mapreduce.lib.input.LineRecordReader.nextKeyValue(LineRecordReader.java:186)
	org.apache.spark.sql.execution.datasources.RecordReaderIterator.hasNext(RecordReaderIterator.scala:39)
	org.apache.spark.sql.execution.datasources.HadoopFileLinesReader.hasNext(HadoopFileLinesReader.scala:69)
	scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:462)
	scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:101)
	org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source)
	org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$11$$anon$1.hasNext(WholeStageCodegenExec.scala:619)
	scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	scala.collection.Iterator$GroupedIterator.takeDestructively(Iterator.scala:1073)
	scala.collection.Iterator$GroupedIterator.go(Iterator.scala:1089)
	scala.collection.Iterator$GroupedIterator.fill(Iterator.scala:1127)
	scala.collection.Iterator$GroupedIterator.hasNext(Iterator.scala:1130)
	scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	scala.collection.Iterator$class.foreach(Iterator.scala:891)
	scala.collection.AbstractIterator.foreach(Iterator.scala:1334)
	org.apache.spark.api.python.PythonRDD$.writeIteratorToStream(PythonRDD.scala:224)
	org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$2.writeIteratorToStream(PythonUDFRunner.scala:50)
	org.apache.spark.api.python.BasePythonRunner$WriterThread$$anonfun$run$1.apply(PythonRunner.scala:345)
	org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1945)
	org.apache.spark.api.python.BasePythonRunner$WriterThread.run(PythonRunner.scala:194)
	at org.apache.spark.TaskContextImpl.invokeListeners(TaskContextImpl.scala:138)
	at org.apache.spark.TaskContextImpl.markTaskCompleted(TaskContextImpl.scala:116)
	at org.apache.spark.scheduler.Task.run(Task.scala:131)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:402)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:408)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2021-05-19 02:46:39 INFO  Executor:54 - Not reporting error to driver during JVM shutdown.
2021-05-19 02:46:39 ERROR TaskContextImpl:91 - Error in TaskCompletionListener
java.io.IOException: Filesystem closed
	at org.apache.hadoop.hdfs.DFSClient.checkOpen(DFSClient.java:808)
	at org.apache.hadoop.hdfs.DFSInputStream.close(DFSInputStream.java:710)
	at java.io.FilterInputStream.close(FilterInputStream.java:181)
	at org.apache.hadoop.util.LineReader.close(LineReader.java:150)
	at org.apache.hadoop.mapreduce.lib.input.LineRecordReader.close(LineRecordReader.java:231)
	at org.apache.spark.sql.execution.datasources.RecordReaderIterator.close(RecordReaderIterator.scala:62)
	at org.apache.spark.sql.execution.datasources.HadoopFileLinesReader.close(HadoopFileLinesReader.scala:73)
	at org.apache.spark.sql.execution.datasources.csv.TextInputCSVDataSource$$anonfun$4$$anonfun$apply$2.apply(CSVDataSource.scala:200)
	at org.apache.spark.sql.execution.datasources.csv.TextInputCSVDataSource$$anonfun$4$$anonfun$apply$2.apply(CSVDataSource.scala:200)
	at org.apache.spark.TaskContext$$anon$1.onTaskCompletion(TaskContext.scala:131)
	at org.apache.spark.TaskContextImpl$$anonfun$markTaskCompleted$1.apply(TaskContextImpl.scala:117)
	at org.apache.spark.TaskContextImpl$$anonfun$markTaskCompleted$1.apply(TaskContextImpl.scala:117)
	at org.apache.spark.TaskContextImpl$$anonfun$invokeListeners$1.apply(TaskContextImpl.scala:130)
	at org.apache.spark.TaskContextImpl$$anonfun$invokeListeners$1.apply(TaskContextImpl.scala:128)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.TaskContextImpl.invokeListeners(TaskContextImpl.scala:128)
	at org.apache.spark.TaskContextImpl.markTaskCompleted(TaskContextImpl.scala:116)
	at org.apache.spark.scheduler.Task.run(Task.scala:131)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:402)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:408)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2021-05-19 02:46:39 ERROR Executor:91 - Exception in task 38.3 in stage 7.0 (TID 452)
org.apache.spark.util.TaskCompletionListenerException: Filesystem closed

Previous exception in task: Filesystem closed
	org.apache.hadoop.hdfs.DFSClient.checkOpen(DFSClient.java:808)
	org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:868)
	org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:934)
	java.io.DataInputStream.read(DataInputStream.java:149)
	org.apache.hadoop.mapreduce.lib.input.UncompressedSplitLineReader.fillBuffer(UncompressedSplitLineReader.java:62)
	org.apache.hadoop.util.LineReader.readDefaultLine(LineReader.java:216)
	org.apache.hadoop.util.LineReader.readLine(LineReader.java:174)
	org.apache.hadoop.mapreduce.lib.input.UncompressedSplitLineReader.readLine(UncompressedSplitLineReader.java:94)
	org.apache.hadoop.mapreduce.lib.input.LineRecordReader.nextKeyValue(LineRecordReader.java:186)
	org.apache.spark.sql.execution.datasources.RecordReaderIterator.hasNext(RecordReaderIterator.scala:39)
	org.apache.spark.sql.execution.datasources.HadoopFileLinesReader.hasNext(HadoopFileLinesReader.scala:69)
	scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:462)
	scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:101)
	org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source)
	org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$11$$anon$1.hasNext(WholeStageCodegenExec.scala:619)
	scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	scala.collection.Iterator$GroupedIterator.takeDestructively(Iterator.scala:1073)
	scala.collection.Iterator$GroupedIterator.go(Iterator.scala:1089)
	scala.collection.Iterator$GroupedIterator.fill(Iterator.scala:1127)
	scala.collection.Iterator$GroupedIterator.hasNext(Iterator.scala:1130)
	scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	scala.collection.Iterator$class.foreach(Iterator.scala:891)
	scala.collection.AbstractIterator.foreach(Iterator.scala:1334)
	org.apache.spark.api.python.PythonRDD$.writeIteratorToStream(PythonRDD.scala:224)
	org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$2.writeIteratorToStream(PythonUDFRunner.scala:50)
	org.apache.spark.api.python.BasePythonRunner$WriterThread$$anonfun$run$1.apply(PythonRunner.scala:345)
	org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1945)
	org.apache.spark.api.python.BasePythonRunner$WriterThread.run(PythonRunner.scala:194)
	at org.apache.spark.TaskContextImpl.invokeListeners(TaskContextImpl.scala:138)
	at org.apache.spark.TaskContextImpl.markTaskCompleted(TaskContextImpl.scala:116)
	at org.apache.spark.scheduler.Task.run(Task.scala:131)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:402)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:408)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2021-05-19 02:46:39 INFO  Executor:54 - Not reporting error to driver during JVM shutdown.
2021-05-19 02:46:39 ERROR TaskContextImpl:91 - Error in TaskCompletionListener
java.io.IOException: Filesystem closed
	at org.apache.hadoop.hdfs.DFSClient.checkOpen(DFSClient.java:808)
	at org.apache.hadoop.hdfs.DFSInputStream.close(DFSInputStream.java:710)
	at java.io.FilterInputStream.close(FilterInputStream.java:181)
	at org.apache.hadoop.util.LineReader.close(LineReader.java:150)
	at org.apache.hadoop.mapreduce.lib.input.LineRecordReader.close(LineRecordReader.java:231)
	at org.apache.spark.sql.execution.datasources.RecordReaderIterator.close(RecordReaderIterator.scala:62)
	at org.apache.spark.sql.execution.datasources.HadoopFileLinesReader.close(HadoopFileLinesReader.scala:73)
	at org.apache.spark.sql.execution.datasources.csv.TextInputCSVDataSource$$anonfun$4$$anonfun$apply$2.apply(CSVDataSource.scala:200)
	at org.apache.spark.sql.execution.datasources.csv.TextInputCSVDataSource$$anonfun$4$$anonfun$apply$2.apply(CSVDataSource.scala:200)
	at org.apache.spark.TaskContext$$anon$1.onTaskCompletion(TaskContext.scala:131)
	at org.apache.spark.TaskContextImpl$$anonfun$markTaskCompleted$1.apply(TaskContextImpl.scala:117)
	at org.apache.spark.TaskContextImpl$$anonfun$markTaskCompleted$1.apply(TaskContextImpl.scala:117)
	at org.apache.spark.TaskContextImpl$$anonfun$invokeListeners$1.apply(TaskContextImpl.scala:130)
	at org.apache.spark.TaskContextImpl$$anonfun$invokeListeners$1.apply(TaskContextImpl.scala:128)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.TaskContextImpl.invokeListeners(TaskContextImpl.scala:128)
	at org.apache.spark.TaskContextImpl.markTaskCompleted(TaskContextImpl.scala:116)
	at org.apache.spark.scheduler.Task.run(Task.scala:131)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:402)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:408)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2021-05-19 02:46:39 ERROR Executor:91 - Exception in task 32.1 in stage 7.0 (TID 450)
org.apache.spark.util.TaskCompletionListenerException: Filesystem closed

Previous exception in task: Filesystem closed
	org.apache.hadoop.hdfs.DFSClient.checkOpen(DFSClient.java:808)
	org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:868)
	org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:934)
	java.io.DataInputStream.read(DataInputStream.java:149)
	org.apache.hadoop.mapreduce.lib.input.UncompressedSplitLineReader.fillBuffer(UncompressedSplitLineReader.java:62)
	org.apache.hadoop.util.LineReader.readDefaultLine(LineReader.java:216)
	org.apache.hadoop.util.LineReader.readLine(LineReader.java:174)
	org.apache.hadoop.mapreduce.lib.input.UncompressedSplitLineReader.readLine(UncompressedSplitLineReader.java:94)
	org.apache.hadoop.mapreduce.lib.input.LineRecordReader.nextKeyValue(LineRecordReader.java:186)
	org.apache.spark.sql.execution.datasources.RecordReaderIterator.hasNext(RecordReaderIterator.scala:39)
	org.apache.spark.sql.execution.datasources.HadoopFileLinesReader.hasNext(HadoopFileLinesReader.scala:69)
	scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:462)
	scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:101)
	org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source)
	org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$11$$anon$1.hasNext(WholeStageCodegenExec.scala:619)
	scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	scala.collection.Iterator$GroupedIterator.takeDestructively(Iterator.scala:1073)
	scala.collection.Iterator$GroupedIterator.go(Iterator.scala:1089)
	scala.collection.Iterator$GroupedIterator.fill(Iterator.scala:1127)
	scala.collection.Iterator$GroupedIterator.hasNext(Iterator.scala:1130)
	scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	scala.collection.Iterator$class.foreach(Iterator.scala:891)
	scala.collection.AbstractIterator.foreach(Iterator.scala:1334)
	org.apache.spark.api.python.PythonRDD$.writeIteratorToStream(PythonRDD.scala:224)
	org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$2.writeIteratorToStream(PythonUDFRunner.scala:50)
	org.apache.spark.api.python.BasePythonRunner$WriterThread$$anonfun$run$1.apply(PythonRunner.scala:345)
	org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1945)
	org.apache.spark.api.python.BasePythonRunner$WriterThread.run(PythonRunner.scala:194)
	at org.apache.spark.TaskContextImpl.invokeListeners(TaskContextImpl.scala:138)
	at org.apache.spark.TaskContextImpl.markTaskCompleted(TaskContextImpl.scala:116)
	at org.apache.spark.scheduler.Task.run(Task.scala:131)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:402)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:408)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2021-05-19 02:46:39 INFO  Executor:54 - Not reporting error to driver during JVM shutdown.
2021-05-19 02:46:39 ERROR TaskContextImpl:91 - Error in TaskCompletionListener
java.io.IOException: Filesystem closed
	at org.apache.hadoop.hdfs.DFSClient.checkOpen(DFSClient.java:808)
	at org.apache.hadoop.hdfs.DFSInputStream.close(DFSInputStream.java:710)
	at java.io.FilterInputStream.close(FilterInputStream.java:181)
	at org.apache.hadoop.util.LineReader.close(LineReader.java:150)
	at org.apache.hadoop.mapreduce.lib.input.LineRecordReader.close(LineRecordReader.java:231)
	at org.apache.spark.sql.execution.datasources.RecordReaderIterator.close(RecordReaderIterator.scala:62)
	at org.apache.spark.sql.execution.datasources.HadoopFileLinesReader.close(HadoopFileLinesReader.scala:73)
	at org.apache.spark.sql.execution.datasources.csv.TextInputCSVDataSource$$anonfun$4$$anonfun$apply$2.apply(CSVDataSource.scala:200)
	at org.apache.spark.sql.execution.datasources.csv.TextInputCSVDataSource$$anonfun$4$$anonfun$apply$2.apply(CSVDataSource.scala:200)
	at org.apache.spark.TaskContext$$anon$1.onTaskCompletion(TaskContext.scala:131)
	at org.apache.spark.TaskContextImpl$$anonfun$markTaskCompleted$1.apply(TaskContextImpl.scala:117)
	at org.apache.spark.TaskContextImpl$$anonfun$markTaskCompleted$1.apply(TaskContextImpl.scala:117)
	at org.apache.spark.TaskContextImpl$$anonfun$invokeListeners$1.apply(TaskContextImpl.scala:130)
	at org.apache.spark.TaskContextImpl$$anonfun$invokeListeners$1.apply(TaskContextImpl.scala:128)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.TaskContextImpl.invokeListeners(TaskContextImpl.scala:128)
	at org.apache.spark.TaskContextImpl.markTaskCompleted(TaskContextImpl.scala:116)
	at org.apache.spark.scheduler.Task.run(Task.scala:131)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:402)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:408)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2021-05-19 02:46:39 ERROR Executor:91 - Exception in task 31.2 in stage 7.0 (TID 451)
org.apache.spark.util.TaskCompletionListenerException: Filesystem closed

Previous exception in task: Filesystem closed
	org.apache.hadoop.hdfs.DFSClient.checkOpen(DFSClient.java:808)
	org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:868)
	org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:934)
	java.io.DataInputStream.read(DataInputStream.java:149)
	org.apache.hadoop.mapreduce.lib.input.UncompressedSplitLineReader.fillBuffer(UncompressedSplitLineReader.java:62)
	org.apache.hadoop.util.LineReader.readDefaultLine(LineReader.java:216)
	org.apache.hadoop.util.LineReader.readLine(LineReader.java:174)
	org.apache.hadoop.mapreduce.lib.input.UncompressedSplitLineReader.readLine(UncompressedSplitLineReader.java:94)
	org.apache.hadoop.mapreduce.lib.input.LineRecordReader.nextKeyValue(LineRecordReader.java:186)
	org.apache.spark.sql.execution.datasources.RecordReaderIterator.hasNext(RecordReaderIterator.scala:39)
	org.apache.spark.sql.execution.datasources.HadoopFileLinesReader.hasNext(HadoopFileLinesReader.scala:69)
	scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:462)
	scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:101)
	org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source)
	org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$11$$anon$1.hasNext(WholeStageCodegenExec.scala:619)
	scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	scala.collection.Iterator$GroupedIterator.takeDestructively(Iterator.scala:1073)
	scala.collection.Iterator$GroupedIterator.go(Iterator.scala:1089)
	scala.collection.Iterator$GroupedIterator.fill(Iterator.scala:1127)
	scala.collection.Iterator$GroupedIterator.hasNext(Iterator.scala:1130)
	scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	scala.collection.Iterator$class.foreach(Iterator.scala:891)
	scala.collection.AbstractIterator.foreach(Iterator.scala:1334)
	org.apache.spark.api.python.PythonRDD$.writeIteratorToStream(PythonRDD.scala:224)
	org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$2.writeIteratorToStream(PythonUDFRunner.scala:50)
	org.apache.spark.api.python.BasePythonRunner$WriterThread$$anonfun$run$1.apply(PythonRunner.scala:345)
	org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1945)
	org.apache.spark.api.python.BasePythonRunner$WriterThread.run(PythonRunner.scala:194)
	at org.apache.spark.TaskContextImpl.invokeListeners(TaskContextImpl.scala:138)
	at org.apache.spark.TaskContextImpl.markTaskCompleted(TaskContextImpl.scala:116)
	at org.apache.spark.scheduler.Task.run(Task.scala:131)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:402)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:408)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2021-05-19 02:46:39 INFO  Executor:54 - Not reporting error to driver during JVM shutdown.
2021-05-19 02:46:39 ERROR TaskContextImpl:91 - Error in TaskCompletionListener
java.io.IOException: Filesystem closed
	at org.apache.hadoop.hdfs.DFSClient.checkOpen(DFSClient.java:808)
	at org.apache.hadoop.hdfs.DFSInputStream.close(DFSInputStream.java:710)
	at java.io.FilterInputStream.close(FilterInputStream.java:181)
	at org.apache.hadoop.util.LineReader.close(LineReader.java:150)
	at org.apache.hadoop.mapreduce.lib.input.LineRecordReader.close(LineRecordReader.java:231)
	at org.apache.spark.sql.execution.datasources.RecordReaderIterator.close(RecordReaderIterator.scala:62)
	at org.apache.spark.sql.execution.datasources.HadoopFileLinesReader.close(HadoopFileLinesReader.scala:73)
	at org.apache.spark.sql.execution.datasources.csv.TextInputCSVDataSource$$anonfun$4$$anonfun$apply$2.apply(CSVDataSource.scala:200)
	at org.apache.spark.sql.execution.datasources.csv.TextInputCSVDataSource$$anonfun$4$$anonfun$apply$2.apply(CSVDataSource.scala:200)
	at org.apache.spark.TaskContext$$anon$1.onTaskCompletion(TaskContext.scala:131)
	at org.apache.spark.TaskContextImpl$$anonfun$markTaskCompleted$1.apply(TaskContextImpl.scala:117)
	at org.apache.spark.TaskContextImpl$$anonfun$markTaskCompleted$1.apply(TaskContextImpl.scala:117)
	at org.apache.spark.TaskContextImpl$$anonfun$invokeListeners$1.apply(TaskContextImpl.scala:130)
	at org.apache.spark.TaskContextImpl$$anonfun$invokeListeners$1.apply(TaskContextImpl.scala:128)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.TaskContextImpl.invokeListeners(TaskContextImpl.scala:128)
	at org.apache.spark.TaskContextImpl.markTaskCompleted(TaskContextImpl.scala:116)
	at org.apache.spark.scheduler.Task.run(Task.scala:131)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:402)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:408)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2021-05-19 02:46:39 ERROR Executor:91 - Exception in task 63.1 in stage 7.0 (TID 448)
org.apache.spark.util.TaskCompletionListenerException: Filesystem closed

Previous exception in task: Filesystem closed
	org.apache.hadoop.hdfs.DFSClient.checkOpen(DFSClient.java:808)
	org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:868)
	org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:934)
	java.io.DataInputStream.read(DataInputStream.java:149)
	org.apache.hadoop.mapreduce.lib.input.UncompressedSplitLineReader.fillBuffer(UncompressedSplitLineReader.java:62)
	org.apache.hadoop.util.LineReader.readDefaultLine(LineReader.java:216)
	org.apache.hadoop.util.LineReader.readLine(LineReader.java:174)
	org.apache.hadoop.mapreduce.lib.input.UncompressedSplitLineReader.readLine(UncompressedSplitLineReader.java:94)
	org.apache.hadoop.mapreduce.lib.input.LineRecordReader.nextKeyValue(LineRecordReader.java:186)
	org.apache.spark.sql.execution.datasources.RecordReaderIterator.hasNext(RecordReaderIterator.scala:39)
	org.apache.spark.sql.execution.datasources.HadoopFileLinesReader.hasNext(HadoopFileLinesReader.scala:69)
	scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:462)
	scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:101)
	org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source)
	org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$11$$anon$1.hasNext(WholeStageCodegenExec.scala:619)
	scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	scala.collection.Iterator$GroupedIterator.takeDestructively(Iterator.scala:1073)
	scala.collection.Iterator$GroupedIterator.go(Iterator.scala:1089)
	scala.collection.Iterator$GroupedIterator.fill(Iterator.scala:1127)
	scala.collection.Iterator$GroupedIterator.hasNext(Iterator.scala:1130)
	scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	scala.collection.Iterator$class.foreach(Iterator.scala:891)
	scala.collection.AbstractIterator.foreach(Iterator.scala:1334)
	org.apache.spark.api.python.PythonRDD$.writeIteratorToStream(PythonRDD.scala:224)
	org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$2.writeIteratorToStream(PythonUDFRunner.scala:50)
	org.apache.spark.api.python.BasePythonRunner$WriterThread$$anonfun$run$1.apply(PythonRunner.scala:345)
	org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1945)
	org.apache.spark.api.python.BasePythonRunner$WriterThread.run(PythonRunner.scala:194)
	at org.apache.spark.TaskContextImpl.invokeListeners(TaskContextImpl.scala:138)
	at org.apache.spark.TaskContextImpl.markTaskCompleted(TaskContextImpl.scala:116)
	at org.apache.spark.scheduler.Task.run(Task.scala:131)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:402)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:408)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2021-05-19 02:46:39 ERROR TaskContextImpl:91 - Error in TaskCompletionListener
java.io.IOException: Filesystem closed
	at org.apache.hadoop.hdfs.DFSClient.checkOpen(DFSClient.java:808)
	at org.apache.hadoop.hdfs.DFSInputStream.close(DFSInputStream.java:710)
	at java.io.FilterInputStream.close(FilterInputStream.java:181)
	at org.apache.hadoop.util.LineReader.close(LineReader.java:150)
	at org.apache.hadoop.mapreduce.lib.input.LineRecordReader.close(LineRecordReader.java:231)
	at org.apache.spark.sql.execution.datasources.RecordReaderIterator.close(RecordReaderIterator.scala:62)
	at org.apache.spark.sql.execution.datasources.HadoopFileLinesReader.close(HadoopFileLinesReader.scala:73)
	at org.apache.spark.sql.execution.datasources.csv.TextInputCSVDataSource$$anonfun$4$$anonfun$apply$2.apply(CSVDataSource.scala:200)
	at org.apache.spark.sql.execution.datasources.csv.TextInputCSVDataSource$$anonfun$4$$anonfun$apply$2.apply(CSVDataSource.scala:200)
	at org.apache.spark.TaskContext$$anon$1.onTaskCompletion(TaskContext.scala:131)
	at org.apache.spark.TaskContextImpl$$anonfun$markTaskCompleted$1.apply(TaskContextImpl.scala:117)
	at org.apache.spark.TaskContextImpl$$anonfun$markTaskCompleted$1.apply(TaskContextImpl.scala:117)
	at org.apache.spark.TaskContextImpl$$anonfun$invokeListeners$1.apply(TaskContextImpl.scala:130)
	at org.apache.spark.TaskContextImpl$$anonfun$invokeListeners$1.apply(TaskContextImpl.scala:128)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.TaskContextImpl.invokeListeners(TaskContextImpl.scala:128)
	at org.apache.spark.TaskContextImpl.markTaskCompleted(TaskContextImpl.scala:116)
	at org.apache.spark.scheduler.Task.run(Task.scala:131)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:402)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:408)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2021-05-19 02:46:39 INFO  Executor:54 - Not reporting error to driver during JVM shutdown.
2021-05-19 02:46:39 ERROR Executor:91 - Exception in task 16.1 in stage 7.0 (TID 446)
org.apache.spark.util.TaskCompletionListenerException: Filesystem closed

Previous exception in task: Filesystem closed
	org.apache.hadoop.hdfs.DFSClient.checkOpen(DFSClient.java:808)
	org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:868)
	org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:934)
	java.io.DataInputStream.read(DataInputStream.java:149)
	org.apache.hadoop.mapreduce.lib.input.UncompressedSplitLineReader.fillBuffer(UncompressedSplitLineReader.java:62)
	org.apache.hadoop.util.LineReader.readDefaultLine(LineReader.java:216)
	org.apache.hadoop.util.LineReader.readLine(LineReader.java:174)
	org.apache.hadoop.mapreduce.lib.input.UncompressedSplitLineReader.readLine(UncompressedSplitLineReader.java:94)
	org.apache.hadoop.mapreduce.lib.input.LineRecordReader.nextKeyValue(LineRecordReader.java:186)
	org.apache.spark.sql.execution.datasources.RecordReaderIterator.hasNext(RecordReaderIterator.scala:39)
	org.apache.spark.sql.execution.datasources.HadoopFileLinesReader.hasNext(HadoopFileLinesReader.scala:69)
	scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:462)
	scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:101)
	org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source)
	org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$11$$anon$1.hasNext(WholeStageCodegenExec.scala:619)
	scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	scala.collection.Iterator$GroupedIterator.takeDestructively(Iterator.scala:1073)
	scala.collection.Iterator$GroupedIterator.go(Iterator.scala:1089)
	scala.collection.Iterator$GroupedIterator.fill(Iterator.scala:1127)
	scala.collection.Iterator$GroupedIterator.hasNext(Iterator.scala:1130)
	scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	scala.collection.Iterator$class.foreach(Iterator.scala:891)
	scala.collection.AbstractIterator.foreach(Iterator.scala:1334)
	org.apache.spark.api.python.PythonRDD$.writeIteratorToStream(PythonRDD.scala:224)
	org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$2.writeIteratorToStream(PythonUDFRunner.scala:50)
	org.apache.spark.api.python.BasePythonRunner$WriterThread$$anonfun$run$1.apply(PythonRunner.scala:345)
	org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1945)
	org.apache.spark.api.python.BasePythonRunner$WriterThread.run(PythonRunner.scala:194)
	at org.apache.spark.TaskContextImpl.invokeListeners(TaskContextImpl.scala:138)
	at org.apache.spark.TaskContextImpl.markTaskCompleted(TaskContextImpl.scala:116)
	at org.apache.spark.scheduler.Task.run(Task.scala:131)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:402)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:408)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2021-05-19 02:46:39 ERROR TaskContextImpl:91 - Error in TaskCompletionListener
java.io.IOException: Filesystem closed
	at org.apache.hadoop.hdfs.DFSClient.checkOpen(DFSClient.java:808)
	at org.apache.hadoop.hdfs.DFSInputStream.close(DFSInputStream.java:710)
	at java.io.FilterInputStream.close(FilterInputStream.java:181)
	at org.apache.hadoop.util.LineReader.close(LineReader.java:150)
	at org.apache.hadoop.mapreduce.lib.input.LineRecordReader.close(LineRecordReader.java:231)
	at org.apache.spark.sql.execution.datasources.RecordReaderIterator.close(RecordReaderIterator.scala:62)
	at org.apache.spark.sql.execution.datasources.HadoopFileLinesReader.close(HadoopFileLinesReader.scala:73)
	at org.apache.spark.sql.execution.datasources.csv.TextInputCSVDataSource$$anonfun$4$$anonfun$apply$2.apply(CSVDataSource.scala:200)
	at org.apache.spark.sql.execution.datasources.csv.TextInputCSVDataSource$$anonfun$4$$anonfun$apply$2.apply(CSVDataSource.scala:200)
	at org.apache.spark.TaskContext$$anon$1.onTaskCompletion(TaskContext.scala:131)
	at org.apache.spark.TaskContextImpl$$anonfun$markTaskCompleted$1.apply(TaskContextImpl.scala:117)
	at org.apache.spark.TaskContextImpl$$anonfun$markTaskCompleted$1.apply(TaskContextImpl.scala:117)
	at org.apache.spark.TaskContextImpl$$anonfun$invokeListeners$1.apply(TaskContextImpl.scala:130)
	at org.apache.spark.TaskContextImpl$$anonfun$invokeListeners$1.apply(TaskContextImpl.scala:128)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.TaskContextImpl.invokeListeners(TaskContextImpl.scala:128)
	at org.apache.spark.TaskContextImpl.markTaskCompleted(TaskContextImpl.scala:116)
	at org.apache.spark.scheduler.Task.run(Task.scala:131)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:402)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:408)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2021-05-19 02:46:39 INFO  Executor:54 - Not reporting error to driver during JVM shutdown.
2021-05-19 02:46:39 ERROR Executor:91 - Exception in task 53.3 in stage 7.0 (TID 447)
org.apache.spark.util.TaskCompletionListenerException: Filesystem closed

Previous exception in task: Filesystem closed
	org.apache.hadoop.hdfs.DFSClient.checkOpen(DFSClient.java:808)
	org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:868)
	org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:934)
	java.io.DataInputStream.read(DataInputStream.java:149)
	org.apache.hadoop.mapreduce.lib.input.UncompressedSplitLineReader.fillBuffer(UncompressedSplitLineReader.java:62)
	org.apache.hadoop.util.LineReader.readDefaultLine(LineReader.java:216)
	org.apache.hadoop.util.LineReader.readLine(LineReader.java:174)
	org.apache.hadoop.mapreduce.lib.input.UncompressedSplitLineReader.readLine(UncompressedSplitLineReader.java:94)
	org.apache.hadoop.mapreduce.lib.input.LineRecordReader.nextKeyValue(LineRecordReader.java:186)
	org.apache.spark.sql.execution.datasources.RecordReaderIterator.hasNext(RecordReaderIterator.scala:39)
	org.apache.spark.sql.execution.datasources.HadoopFileLinesReader.hasNext(HadoopFileLinesReader.scala:69)
	scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:462)
	scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:101)
	org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source)
	org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$11$$anon$1.hasNext(WholeStageCodegenExec.scala:619)
	scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	scala.collection.Iterator$GroupedIterator.takeDestructively(Iterator.scala:1073)
	scala.collection.Iterator$GroupedIterator.go(Iterator.scala:1089)
	scala.collection.Iterator$GroupedIterator.fill(Iterator.scala:1127)
	scala.collection.Iterator$GroupedIterator.hasNext(Iterator.scala:1130)
	scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	scala.collection.Iterator$class.foreach(Iterator.scala:891)
	scala.collection.AbstractIterator.foreach(Iterator.scala:1334)
	org.apache.spark.api.python.PythonRDD$.writeIteratorToStream(PythonRDD.scala:224)
	org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$2.writeIteratorToStream(PythonUDFRunner.scala:50)
	org.apache.spark.api.python.BasePythonRunner$WriterThread$$anonfun$run$1.apply(PythonRunner.scala:345)
	org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1945)
	org.apache.spark.api.python.BasePythonRunner$WriterThread.run(PythonRunner.scala:194)
	at org.apache.spark.TaskContextImpl.invokeListeners(TaskContextImpl.scala:138)
	at org.apache.spark.TaskContextImpl.markTaskCompleted(TaskContextImpl.scala:116)
	at org.apache.spark.scheduler.Task.run(Task.scala:131)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:402)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:408)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2021-05-19 02:46:39 INFO  Executor:54 - Not reporting error to driver during JVM shutdown.

End of LogType:stdout
***********************************************************************


End of LogType:prelaunch.err
******************************************************************************

Container: container_e10_1609183734776_5900_02_000012 on hadoop18.cusp.nyu.edu_8041
LogAggregationType: AGGREGATED
===================================================================================
LogType:prelaunch.out
LogLastModifiedTime:Wed May 19 02:48:18 -0400 2021
LogLength:70
LogContents:
Setting up env variables
Setting up job resources
Launching container

End of LogType:prelaunch.out
******************************************************************************

Container: container_e10_1609183734776_5900_02_000012 on hadoop18.cusp.nyu.edu_8041
LogAggregationType: AGGREGATED
===================================================================================
LogType:stderr
LogLastModifiedTime:Wed May 19 02:48:18 -0400 2021
LogLength:529
LogContents:
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/localhome/cdp/yarn/nm/filecache/25/spark-jars-2.4.0-hadoop2.7.jar/slf4j-log4j12-1.7.16.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-6.1.0-1.cdh6.1.0.p0.770702/jars/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]

End of LogType:stderr
***********************************************************************

Container: container_e10_1609183734776_5900_02_000012 on hadoop18.cusp.nyu.edu_8041
LogAggregationType: AGGREGATED
===================================================================================
LogType:stdout
LogLastModifiedTime:Wed May 19 02:48:18 -0400 2021
LogLength:18489
LogContents:
2021-05-19 02:47:55 INFO  CoarseGrainedExecutorBackend:2566 - Started daemon with process name: 39403@hadoop18.cusp.nyu.edu
2021-05-19 02:47:55 INFO  SignalUtils:54 - Registered signal handler for TERM
2021-05-19 02:47:55 INFO  SignalUtils:54 - Registered signal handler for HUP
2021-05-19 02:47:55 INFO  SignalUtils:54 - Registered signal handler for INT
2021-05-19 02:47:56 INFO  SecurityManager:54 - Changing view acls to: catherine.ng60
2021-05-19 02:47:56 INFO  SecurityManager:54 - Changing modify acls to: catherine.ng60
2021-05-19 02:47:56 INFO  SecurityManager:54 - Changing view acls groups to: 
2021-05-19 02:47:56 INFO  SecurityManager:54 - Changing modify acls groups to: 
2021-05-19 02:47:56 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(catherine.ng60); groups with view permissions: Set(); users  with modify permissions: Set(catherine.ng60); groups with modify permissions: Set()
2021-05-19 02:47:57 INFO  TransportClientFactory:267 - Successfully created connection to hadoop02.cusp.nyu.edu/192.168.72.172:60108 after 112 ms (0 ms spent in bootstraps)
2021-05-19 02:47:57 INFO  SecurityManager:54 - Changing view acls to: catherine.ng60
2021-05-19 02:47:57 INFO  SecurityManager:54 - Changing modify acls to: catherine.ng60
2021-05-19 02:47:57 INFO  SecurityManager:54 - Changing view acls groups to: 
2021-05-19 02:47:57 INFO  SecurityManager:54 - Changing modify acls groups to: 
2021-05-19 02:47:57 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(catherine.ng60); groups with view permissions: Set(); users  with modify permissions: Set(catherine.ng60); groups with modify permissions: Set()
2021-05-19 02:47:57 INFO  TransportClientFactory:267 - Successfully created connection to hadoop02.cusp.nyu.edu/192.168.72.172:60108 after 6 ms (0 ms spent in bootstraps)
2021-05-19 02:47:57 INFO  DiskBlockManager:54 - Created local directory at /localhome/cdp/yarn/nm/usercache/catherine.ng60/appcache/application_1609183734776_5900/blockmgr-a2457e70-f598-4442-9180-70ea59a29297
2021-05-19 02:47:57 INFO  MemoryStore:54 - MemoryStore started with capacity 366.3 MB
2021-05-19 02:47:57 INFO  CoarseGrainedExecutorBackend:54 - Connecting to driver: spark://CoarseGrainedScheduler@hadoop02.cusp.nyu.edu:60108
2021-05-19 02:47:57 INFO  CoarseGrainedExecutorBackend:54 - Successfully registered with driver
2021-05-19 02:47:57 INFO  Executor:54 - Starting executor ID 11 on host hadoop18.cusp.nyu.edu
2021-05-19 02:47:58 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 38556.
2021-05-19 02:47:58 INFO  NettyBlockTransferService:54 - Server created on hadoop18.cusp.nyu.edu:38556
2021-05-19 02:47:58 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2021-05-19 02:47:58 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(11, hadoop18.cusp.nyu.edu, 38556, None)
2021-05-19 02:47:58 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(11, hadoop18.cusp.nyu.edu, 38556, None)
2021-05-19 02:47:58 INFO  BlockManager:54 - external shuffle service port = 7337
2021-05-19 02:47:58 INFO  BlockManager:54 - Registering executor with local external shuffle service.
2021-05-19 02:47:58 INFO  TransportClientFactory:267 - Successfully created connection to hadoop18.cusp.nyu.edu/192.168.72.188:7337 after 3 ms (0 ms spent in bootstraps)
2021-05-19 02:47:58 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(11, hadoop18.cusp.nyu.edu, 38556, None)
2021-05-19 02:47:58 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 422
2021-05-19 02:47:58 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 423
2021-05-19 02:47:58 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 424
2021-05-19 02:47:58 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 425
2021-05-19 02:47:58 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 426
2021-05-19 02:47:58 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 427
2021-05-19 02:47:58 INFO  Executor:54 - Running task 35.2 in stage 7.0 (TID 426)
2021-05-19 02:47:58 INFO  Executor:54 - Running task 26.3 in stage 7.0 (TID 425)
2021-05-19 02:47:58 INFO  Executor:54 - Running task 16.2 in stage 7.0 (TID 424)
2021-05-19 02:47:58 INFO  Executor:54 - Running task 15.2 in stage 7.0 (TID 422)
2021-05-19 02:47:58 INFO  Executor:54 - Running task 32.3 in stage 7.0 (TID 423)
2021-05-19 02:47:58 INFO  Executor:54 - Running task 31.2 in stage 7.0 (TID 427)
2021-05-19 02:47:58 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 428
2021-05-19 02:47:58 INFO  Executor:54 - Running task 58.1 in stage 7.0 (TID 428)
2021-05-19 02:47:58 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 429
2021-05-19 02:47:58 INFO  Executor:54 - Running task 60.1 in stage 7.0 (TID 429)
2021-05-19 02:47:58 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 430
2021-05-19 02:47:58 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 431
2021-05-19 02:47:58 INFO  Executor:54 - Running task 27.2 in stage 7.0 (TID 430)
2021-05-19 02:47:58 INFO  Executor:54 - Running task 38.2 in stage 7.0 (TID 431)
2021-05-19 02:47:58 INFO  MapOutputTrackerWorker:54 - Updating epoch to 1 and clearing cache
2021-05-19 02:47:58 INFO  TorrentBroadcast:54 - Started reading broadcast variable 14
2021-05-19 02:47:58 INFO  TransportClientFactory:267 - Successfully created connection to hadoop04.cusp.nyu.edu/192.168.72.174:35739 after 3 ms (0 ms spent in bootstraps)
2021-05-19 02:47:58 INFO  MemoryStore:54 - Block broadcast_14_piece0 stored as bytes in memory (estimated size 22.9 KB, free 366.3 MB)
2021-05-19 02:47:58 INFO  TorrentBroadcast:54 - Reading broadcast variable 14 took 186 ms
2021-05-19 02:47:58 INFO  MemoryStore:54 - Block broadcast_14 stored as values in memory (estimated size 51.4 KB, free 366.2 MB)
2021-05-19 02:48:00 INFO  CodeGenerator:54 - Code generated in 322.821688 ms
2021-05-19 02:48:00 INFO  TorrentBroadcast:54 - Started reading broadcast variable 12
2021-05-19 02:48:00 INFO  MemoryStore:54 - Block broadcast_12_piece0 stored as bytes in memory (estimated size 580.1 KB, free 365.7 MB)
2021-05-19 02:48:00 INFO  TorrentBroadcast:54 - Reading broadcast variable 12 took 34 ms
2021-05-19 02:48:00 INFO  MemoryStore:54 - Block broadcast_12 stored as values in memory (estimated size 5.0 MB, free 360.7 MB)
2021-05-19 02:48:00 INFO  CodeGenerator:54 - Code generated in 35.745268 ms
2021-05-19 02:48:01 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00013, range: 134217728-177061523, partition values: [empty row]
2021-05-19 02:48:01 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00016, range: 0-134217728, partition values: [empty row]
2021-05-19 02:48:01 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00027, range: 0-134217728, partition values: [empty row]
2021-05-19 02:48:01 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00032, range: 0-134217728, partition values: [empty row]
2021-05-19 02:48:01 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00035, range: 0-134217728, partition values: [empty row]
2021-05-19 02:48:01 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00015, range: 0-134217728, partition values: [empty row]
2021-05-19 02:48:01 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00026, range: 0-134217728, partition values: [empty row]
2021-05-19 02:48:01 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00038, range: 0-134217728, partition values: [empty row]
2021-05-19 02:48:01 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00030, range: 134217728-176820246, partition values: [empty row]
2021-05-19 02:48:01 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00031, range: 0-134217728, partition values: [empty row]
2021-05-19 02:48:01 INFO  CodeGenerator:54 - Code generated in 55.196232 ms
2021-05-19 02:48:01 INFO  TorrentBroadcast:54 - Started reading broadcast variable 13
2021-05-19 02:48:01 INFO  TransportClientFactory:267 - Successfully created connection to hadoop06.cusp.nyu.edu/192.168.72.176:44467 after 5 ms (0 ms spent in bootstraps)
2021-05-19 02:48:01 INFO  CodeGenerator:54 - Code generated in 61.033732 ms
2021-05-19 02:48:01 INFO  MemoryStore:54 - Block broadcast_13_piece0 stored as bytes in memory (estimated size 33.4 KB, free 360.6 MB)
2021-05-19 02:48:01 INFO  CodeGenerator:54 - Code generated in 44.510965 ms
2021-05-19 02:48:01 INFO  TorrentBroadcast:54 - Reading broadcast variable 13 took 124 ms
2021-05-19 02:48:01 INFO  CodeGenerator:54 - Code generated in 54.522431 ms
2021-05-19 02:48:01 INFO  CodeGenerator:54 - Code generated in 22.350906 ms
2021-05-19 02:48:01 INFO  MemoryStore:54 - Block broadcast_13 stored as values in memory (estimated size 506.4 KB, free 360.1 MB)
2021-05-19 02:48:03 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: 22h-222@627-wfy-m8v, 2019-08-05T00:00:00-04:00, [3,1,1,2,0,1,0]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: 22h-222@627-wfy-m8v
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00035
2021-05-19 02:48:03 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: 22c-222@627-s84-mrk, 2020-04-06T00:00:00-04:00, [0,0,0,0,2,0,0]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: 22c-222@627-s84-mrk
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00015
2021-05-19 02:48:03 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: 22f-222@627-wdh-sdv, 2019-06-10T00:00:00-04:00, [4,2,3,3,3,1,0]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: 22f-222@627-wdh-sdv
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00038
2021-05-19 02:48:03 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: 225-222@627-wbv-ht9, 2020-06-29T00:00:00-04:00, [1,3,1,4,8,6,5]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: 225-222@627-wbv-ht9
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00027
2021-05-19 02:48:03 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: 22g-222@627-rwv-q75, 2019-07-15T00:00:00-04:00, [12,11,14,8,11,9,7]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: 22g-222@627-rwv-q75
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00032
2021-05-19 02:48:03 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: 22h-223@627-s84-6hq, 2019-08-05T00:00:00-04:00, [2,2,0,2,1,3,1]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: 22h-223@627-s84-6hq
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00026
2021-05-19 02:48:03 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: 222-222@627-s6k-dqf, 2019-01-14T00:00:00-05:00, [0,0,0,0,1,0,0]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: 222-222@627-s6k-dqf
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00016
2021-05-19 02:48:03 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: 22q-222@627-s8x-bzf, 2019-12-16T00:00:00-05:00, [1,0,0,0,0,1,0]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: 22q-222@627-s8x-bzf
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00031
2021-05-19 02:48:04 INFO  CodeGenerator:54 - Code generated in 18.983617 ms
2021-05-19 02:48:04 INFO  CodeGenerator:54 - Code generated in 56.225802 ms
2021-05-19 02:48:04 INFO  CodeGenerator:54 - Code generated in 28.49561 ms
2021-05-19 02:48:04 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:48:04 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:48:04 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:48:04 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:48:04 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:48:04 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:48:04 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:48:04 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:48:04 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:48:04 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:48:04 INFO  CodeGenerator:54 - Code generated in 38.24107 ms
2021-05-19 02:48:04 INFO  CodeGenerator:54 - Code generated in 30.872533 ms
2021-05-19 02:48:05 INFO  CodeGenerator:54 - Code generated in 23.923385 ms
2021-05-19 02:48:05 INFO  CodeGenerator:54 - Code generated in 23.274 ms
2021-05-19 02:48:05 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00012, range: 134217728-176612852, partition values: [empty row]
2021-05-19 02:48:05 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00035, range: 134217728-177038143, partition values: [empty row]
2021-05-19 02:48:12 INFO  PythonUDFRunner:54 - Times: total = 12121, boot = 770, init = 2480, finish = 8871
2021-05-19 02:48:12 INFO  PythonUDFRunner:54 - Times: total = 12246, boot = 710, init = 2549, finish = 8987
2021-05-19 02:48:13 INFO  CodeGenerator:54 - Code generated in 26.821023 ms
2021-05-19 02:48:13 INFO  Executor:54 - Finished task 58.1 in stage 7.0 (TID 428). 4313 bytes result sent to driver
2021-05-19 02:48:13 INFO  Executor:54 - Finished task 60.1 in stage 7.0 (TID 429). 4313 bytes result sent to driver
2021-05-19 02:48:14 INFO  PythonUDFRunner:54 - Times: total = 13708, boot = 779, init = 2529, finish = 10400
2021-05-19 02:48:14 INFO  PythonUDFRunner:54 - Times: total = 13849, boot = 719, init = 2586, finish = 10544
2021-05-19 02:48:14 INFO  Executor:54 - Finished task 31.2 in stage 7.0 (TID 427). 4270 bytes result sent to driver
2021-05-19 02:48:14 INFO  Executor:54 - Finished task 15.2 in stage 7.0 (TID 422). 4313 bytes result sent to driver
2021-05-19 02:48:15 INFO  PythonUDFRunner:54 - Times: total = 14499, boot = 702, init = 2558, finish = 11239
2021-05-19 02:48:15 INFO  PythonUDFRunner:54 - Times: total = 14504, boot = 759, init = 2541, finish = 11204
2021-05-19 02:48:15 INFO  PythonUDFRunner:54 - Times: total = 14715, boot = 729, init = 2578, finish = 11408
2021-05-19 02:48:15 INFO  PythonUDFRunner:54 - Times: total = 14764, boot = 690, init = 2616, finish = 11458
2021-05-19 02:48:15 INFO  PythonUDFRunner:54 - Times: total = 14829, boot = 739, init = 2564, finish = 11526
2021-05-19 02:48:15 INFO  PythonUDFRunner:54 - Times: total = 14843, boot = 749, init = 2553, finish = 11541
2021-05-19 02:48:15 INFO  Executor:54 - Finished task 16.2 in stage 7.0 (TID 424). 4270 bytes result sent to driver
2021-05-19 02:48:15 INFO  Executor:54 - Finished task 38.2 in stage 7.0 (TID 431). 4270 bytes result sent to driver
2021-05-19 02:48:15 INFO  Executor:54 - Finished task 27.2 in stage 7.0 (TID 430). 4313 bytes result sent to driver
2021-05-19 02:48:15 INFO  Executor:54 - Finished task 35.2 in stage 7.0 (TID 426). 4270 bytes result sent to driver
2021-05-19 02:48:15 ERROR CoarseGrainedExecutorBackend:43 - RECEIVED SIGNAL TERM
2021-05-19 02:48:15 INFO  DiskBlockManager:54 - Shutdown hook called
2021-05-19 02:48:15 INFO  ShutdownHookManager:54 - Shutdown hook called
2021-05-19 02:48:15 INFO  ShutdownHookManager:54 - Deleting directory /localhome/cdp/yarn/nm/usercache/catherine.ng60/appcache/application_1609183734776_5900/spark-d4e7fd9e-7251-4019-862b-e7bfdd017b8d

End of LogType:stdout
***********************************************************************

Container: container_e10_1609183734776_5900_01_000010 on hadoop18.cusp.nyu.edu_8041
LogAggregationType: AGGREGATED
===================================================================================
LogType:container-localizer-syslog
LogLastModifiedTime:Wed May 19 02:48:18 -0400 2021
LogLength:506
LogContents:
2021-05-19 02:46:11,345 INFO [main] org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ContainerLocalizer: Disk Validator: yarn.nodemanager.disk-validator is loaded.
2021-05-19 02:46:12,622 WARN [ContainerLocalizer Downloader] org.apache.hadoop.ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ipc.StandbyException): Operation category READ is not supported in state standby. Visit https://s.apache.org/sbnn-error

End of LogType:container-localizer-syslog
*******************************************************************************************


End of LogType:prelaunch.err
******************************************************************************

Container: container_e10_1609183734776_5900_01_000010 on hadoop18.cusp.nyu.edu_8041
LogAggregationType: AGGREGATED
===================================================================================
LogType:prelaunch.out
LogLastModifiedTime:Wed May 19 02:48:18 -0400 2021
LogLength:70
LogContents:
Setting up env variables
Setting up job resources
Launching container

End of LogType:prelaunch.out
******************************************************************************

Container: container_e10_1609183734776_5900_01_000010 on hadoop18.cusp.nyu.edu_8041
LogAggregationType: AGGREGATED
===================================================================================
LogType:stderr
LogLastModifiedTime:Wed May 19 02:48:18 -0400 2021
LogLength:529
LogContents:
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/localhome/cdp/yarn/nm/filecache/25/spark-jars-2.4.0-hadoop2.7.jar/slf4j-log4j12-1.7.16.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-6.1.0-1.cdh6.1.0.p0.770702/jars/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]

End of LogType:stderr
***********************************************************************

Container: container_e10_1609183734776_5900_01_000010 on hadoop18.cusp.nyu.edu_8041
LogAggregationType: AGGREGATED
===================================================================================
LogType:stdout
LogLastModifiedTime:Wed May 19 02:48:18 -0400 2021
LogLength:32816
LogContents:
2021-05-19 02:46:14 INFO  CoarseGrainedExecutorBackend:2566 - Started daemon with process name: 37971@hadoop18.cusp.nyu.edu
2021-05-19 02:46:14 INFO  SignalUtils:54 - Registered signal handler for TERM
2021-05-19 02:46:14 INFO  SignalUtils:54 - Registered signal handler for HUP
2021-05-19 02:46:14 INFO  SignalUtils:54 - Registered signal handler for INT
2021-05-19 02:46:15 INFO  SecurityManager:54 - Changing view acls to: catherine.ng60
2021-05-19 02:46:15 INFO  SecurityManager:54 - Changing modify acls to: catherine.ng60
2021-05-19 02:46:15 INFO  SecurityManager:54 - Changing view acls groups to: 
2021-05-19 02:46:15 INFO  SecurityManager:54 - Changing modify acls groups to: 
2021-05-19 02:46:15 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(catherine.ng60); groups with view permissions: Set(); users  with modify permissions: Set(catherine.ng60); groups with modify permissions: Set()
2021-05-19 02:46:15 INFO  TransportClientFactory:267 - Successfully created connection to hadoop05.cusp.nyu.edu/192.168.72.175:47481 after 121 ms (0 ms spent in bootstraps)
2021-05-19 02:46:15 INFO  SecurityManager:54 - Changing view acls to: catherine.ng60
2021-05-19 02:46:15 INFO  SecurityManager:54 - Changing modify acls to: catherine.ng60
2021-05-19 02:46:15 INFO  SecurityManager:54 - Changing view acls groups to: 
2021-05-19 02:46:15 INFO  SecurityManager:54 - Changing modify acls groups to: 
2021-05-19 02:46:15 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(catherine.ng60); groups with view permissions: Set(); users  with modify permissions: Set(catherine.ng60); groups with modify permissions: Set()
2021-05-19 02:46:16 INFO  TransportClientFactory:267 - Successfully created connection to hadoop05.cusp.nyu.edu/192.168.72.175:47481 after 5 ms (0 ms spent in bootstraps)
2021-05-19 02:46:16 INFO  DiskBlockManager:54 - Created local directory at /localhome/cdp/yarn/nm/usercache/catherine.ng60/appcache/application_1609183734776_5900/blockmgr-5507d431-4c11-4e8d-a06b-a64a308c36c5
2021-05-19 02:46:16 INFO  MemoryStore:54 - MemoryStore started with capacity 366.3 MB
2021-05-19 02:46:16 INFO  CoarseGrainedExecutorBackend:54 - Connecting to driver: spark://CoarseGrainedScheduler@hadoop05.cusp.nyu.edu:47481
2021-05-19 02:46:16 INFO  CoarseGrainedExecutorBackend:54 - Successfully registered with driver
2021-05-19 02:46:16 INFO  Executor:54 - Starting executor ID 9 on host hadoop18.cusp.nyu.edu
2021-05-19 02:46:16 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 58292.
2021-05-19 02:46:16 INFO  NettyBlockTransferService:54 - Server created on hadoop18.cusp.nyu.edu:58292
2021-05-19 02:46:16 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2021-05-19 02:46:16 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(9, hadoop18.cusp.nyu.edu, 58292, None)
2021-05-19 02:46:16 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(9, hadoop18.cusp.nyu.edu, 58292, None)
2021-05-19 02:46:16 INFO  BlockManager:54 - external shuffle service port = 7337
2021-05-19 02:46:16 INFO  BlockManager:54 - Registering executor with local external shuffle service.
2021-05-19 02:46:16 INFO  TransportClientFactory:267 - Successfully created connection to hadoop18.cusp.nyu.edu/192.168.72.188:7337 after 2 ms (0 ms spent in bootstraps)
2021-05-19 02:46:16 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(9, hadoop18.cusp.nyu.edu, 58292, None)
2021-05-19 02:46:16 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 402
2021-05-19 02:46:16 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 403
2021-05-19 02:46:16 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 404
2021-05-19 02:46:16 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 405
2021-05-19 02:46:16 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 406
2021-05-19 02:46:16 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 407
2021-05-19 02:46:16 INFO  Executor:54 - Running task 16.0 in stage 7.0 (TID 407)
2021-05-19 02:46:16 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 408
2021-05-19 02:46:16 INFO  Executor:54 - Running task 31.1 in stage 7.0 (TID 405)
2021-05-19 02:46:16 INFO  Executor:54 - Running task 15.0 in stage 7.0 (TID 406)
2021-05-19 02:46:16 INFO  Executor:54 - Running task 60.2 in stage 7.0 (TID 403)
2021-05-19 02:46:16 INFO  Executor:54 - Running task 13.1 in stage 7.0 (TID 402)
2021-05-19 02:46:16 INFO  Executor:54 - Running task 53.2 in stage 7.0 (TID 404)
2021-05-19 02:46:16 INFO  Executor:54 - Running task 32.0 in stage 7.0 (TID 408)
2021-05-19 02:46:16 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 409
2021-05-19 02:46:16 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 410
2021-05-19 02:46:16 INFO  Executor:54 - Running task 35.0 in stage 7.0 (TID 409)
2021-05-19 02:46:16 INFO  Executor:54 - Running task 63.0 in stage 7.0 (TID 410)
2021-05-19 02:46:16 INFO  MapOutputTrackerWorker:54 - Updating epoch to 1 and clearing cache
2021-05-19 02:46:16 INFO  TorrentBroadcast:54 - Started reading broadcast variable 14
2021-05-19 02:46:17 INFO  TransportClientFactory:267 - Successfully created connection to hadoop07.cusp.nyu.edu/192.168.72.177:35847 after 2 ms (0 ms spent in bootstraps)
2021-05-19 02:46:17 INFO  MemoryStore:54 - Block broadcast_14_piece0 stored as bytes in memory (estimated size 22.9 KB, free 366.3 MB)
2021-05-19 02:46:17 INFO  TorrentBroadcast:54 - Reading broadcast variable 14 took 147 ms
2021-05-19 02:46:17 INFO  MemoryStore:54 - Block broadcast_14 stored as values in memory (estimated size 51.5 KB, free 366.2 MB)
2021-05-19 02:46:18 INFO  CodeGenerator:54 - Code generated in 323.869712 ms
2021-05-19 02:46:18 INFO  TorrentBroadcast:54 - Started reading broadcast variable 12
2021-05-19 02:46:18 INFO  TransportClientFactory:267 - Successfully created connection to hadoop05.cusp.nyu.edu/192.168.72.175:36982 after 5 ms (0 ms spent in bootstraps)
2021-05-19 02:46:18 INFO  MemoryStore:54 - Block broadcast_12_piece0 stored as bytes in memory (estimated size 580.1 KB, free 365.7 MB)
2021-05-19 02:46:18 INFO  TorrentBroadcast:54 - Reading broadcast variable 12 took 64 ms
2021-05-19 02:46:18 INFO  MemoryStore:54 - Block broadcast_12 stored as values in memory (estimated size 5.0 MB, free 360.7 MB)
2021-05-19 02:46:19 INFO  CodeGenerator:54 - Code generated in 41.833177 ms
2021-05-19 02:46:19 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00031, range: 134217728-176028743, partition values: [empty row]
2021-05-19 02:46:19 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00016, range: 0-134217728, partition values: [empty row]
2021-05-19 02:46:19 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00013, range: 0-134217728, partition values: [empty row]
2021-05-19 02:46:19 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00031, range: 0-134217728, partition values: [empty row]
2021-05-19 02:46:19 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00030, range: 134217728-176820246, partition values: [empty row]
2021-05-19 02:46:19 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00035, range: 0-134217728, partition values: [empty row]
2021-05-19 02:46:19 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00015, range: 0-134217728, partition values: [empty row]
2021-05-19 02:46:19 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00032, range: 0-134217728, partition values: [empty row]
2021-05-19 02:46:19 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00026, range: 134217728-178435909, partition values: [empty row]
2021-05-19 02:46:19 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 412
2021-05-19 02:46:19 INFO  Executor:54 - Running task 66.1 in stage 7.0 (TID 412)
2021-05-19 02:46:19 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00039, range: 134217728-175562757, partition values: [empty row]
2021-05-19 02:46:20 INFO  CodeGenerator:54 - Code generated in 71.020556 ms
2021-05-19 02:46:20 INFO  TorrentBroadcast:54 - Started reading broadcast variable 13
2021-05-19 02:46:20 INFO  MemoryStore:54 - Block broadcast_13_piece0 stored as bytes in memory (estimated size 33.4 KB, free 360.6 MB)
2021-05-19 02:46:20 INFO  CodeGenerator:54 - Code generated in 68.183638 ms
2021-05-19 02:46:20 INFO  TorrentBroadcast:54 - Reading broadcast variable 13 took 45 ms
2021-05-19 02:46:20 INFO  CodeGenerator:54 - Code generated in 34.34893 ms
2021-05-19 02:46:20 INFO  CodeGenerator:54 - Code generated in 39.397583 ms
2021-05-19 02:46:20 INFO  CodeGenerator:54 - Code generated in 31.178248 ms
2021-05-19 02:46:20 INFO  MemoryStore:54 - Block broadcast_13 stored as values in memory (estimated size 506.4 KB, free 360.1 MB)
2021-05-19 02:46:21 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: 23b-222@627-wh4-vxq, 2019-01-07T00:00:00-05:00, [10,12,10,16,2,4,3]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: 23b-222@627-wh4-vxq
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00013
2021-05-19 02:46:21 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: 22h-222@627-wfy-m8v, 2019-08-05T00:00:00-04:00, [3,1,1,2,0,1,0]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: 22h-222@627-wfy-m8v
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00035
2021-05-19 02:46:21 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: 222-222@627-s6k-dqf, 2019-01-14T00:00:00-05:00, [0,0,0,0,1,0,0]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: 222-222@627-s6k-dqf
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00016
2021-05-19 02:46:21 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: 22q-222@627-s8x-bzf, 2019-12-16T00:00:00-05:00, [1,0,0,0,0,1,0]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: 22q-222@627-s8x-bzf
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00031
2021-05-19 02:46:21 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: 22g-222@627-rwv-q75, 2019-07-15T00:00:00-04:00, [12,11,14,8,11,9,7]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: 22g-222@627-rwv-q75
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00032
2021-05-19 02:46:21 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: 22c-222@627-s84-mrk, 2020-04-06T00:00:00-04:00, [0,0,0,0,2,0,0]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: 22c-222@627-s84-mrk
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00015
2021-05-19 02:46:22 INFO  CodeGenerator:54 - Code generated in 18.266386 ms
2021-05-19 02:46:22 INFO  CodeGenerator:54 - Code generated in 23.262269 ms
2021-05-19 02:46:22 INFO  CodeGenerator:54 - Code generated in 48.105678 ms
2021-05-19 02:46:23 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:46:23 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:46:23 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:46:23 INFO  CodeGenerator:54 - Code generated in 68.751663 ms
2021-05-19 02:46:23 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:46:23 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:46:23 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:46:23 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:46:23 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:46:23 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:46:23 INFO  CodeGenerator:54 - Code generated in 36.186748 ms
2021-05-19 02:46:23 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:46:23 INFO  CodeGenerator:54 - Code generated in 19.34176 ms
2021-05-19 02:46:23 INFO  CodeGenerator:54 - Code generated in 19.41745 ms
2021-05-19 02:46:23 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00006, range: 134217728-175405184, partition values: [empty row]
2021-05-19 02:46:23 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00027, range: 134217728-178418906, partition values: [empty row]
2021-05-19 02:46:24 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00019, range: 134217728-176011571, partition values: [empty row]
2021-05-19 02:46:24 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00012, range: 134217728-176612852, partition values: [empty row]
2021-05-19 02:46:28 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00025, range: 134217728-175952635, partition values: [empty row]
2021-05-19 02:46:28 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00044, range: 134217728-175217045, partition values: [empty row]
2021-05-19 02:46:32 INFO  PythonUDFRunner:54 - Times: total = 13181, boot = 726, init = 2575, finish = 9880
2021-05-19 02:46:32 INFO  CodeGenerator:54 - Code generated in 27.442119 ms
2021-05-19 02:46:33 INFO  Executor:54 - Finished task 60.2 in stage 7.0 (TID 403). 4313 bytes result sent to driver
2021-05-19 02:46:33 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 430
2021-05-19 02:46:33 INFO  Executor:54 - Running task 38.2 in stage 7.0 (TID 430)
2021-05-19 02:46:33 INFO  PythonUDFRunner:54 - Times: total = 13880, boot = 769, init = 2571, finish = 10540
2021-05-19 02:46:33 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00038, range: 0-134217728, partition values: [empty row]
2021-05-19 02:46:33 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: 22f-222@627-wdh-sdv, 2019-06-10T00:00:00-04:00, [4,2,3,3,3,1,0]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: 22f-222@627-wdh-sdv
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00038
2021-05-19 02:46:33 ERROR CoarseGrainedExecutorBackend:43 - RECEIVED SIGNAL TERM
2021-05-19 02:46:33 INFO  DiskBlockManager:54 - Shutdown hook called
2021-05-19 02:46:33 INFO  ShutdownHookManager:54 - Shutdown hook called
2021-05-19 02:46:33 INFO  ShutdownHookManager:54 - Deleting directory /localhome/cdp/yarn/nm/usercache/catherine.ng60/appcache/application_1609183734776_5900/spark-2f0a27b6-6423-4684-bac7-287712944edb
2021-05-19 02:46:33 ERROR PythonUDFRunner:91 - Python worker exited unexpectedly (crashed)
org.apache.spark.api.python.PythonException: Traceback (most recent call last):
  File "/localhome/cdp/yarn/nm/usercache/catherine.ng60/appcache/application_1609183734776_5900/container_e10_1609183734776_5900_01_000010/pyspark.zip/pyspark/worker.py", line 357, in main
    eval_type = read_int(infile)
  File "/localhome/cdp/yarn/nm/usercache/catherine.ng60/appcache/application_1609183734776_5900/container_e10_1609183734776_5900_01_000010/pyspark.zip/pyspark/serializers.py", line 714, in read_int
    raise EOFError
EOFError

	at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:452)
	at org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$1.read(PythonUDFRunner.scala:81)
	at org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$1.read(PythonUDFRunner.scala:64)
	at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:406)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$JoinIterator.hasNext(Iterator.scala:212)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage3.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$11$$anon$1.hasNext(WholeStageCodegenExec.scala:619)
	at org.apache.spark.sql.execution.aggregate.ObjectHashAggregateExec$$anonfun$doExecute$1$$anonfun$2.apply(ObjectHashAggregateExec.scala:107)
	at org.apache.spark.sql.execution.aggregate.ObjectHashAggregateExec$$anonfun$doExecute$1$$anonfun$2.apply(ObjectHashAggregateExec.scala:105)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndexInternal$1$$anonfun$12.apply(RDD.scala:823)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndexInternal$1$$anonfun$12.apply(RDD.scala:823)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:402)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:408)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Filesystem closed
	at org.apache.hadoop.hdfs.DFSClient.checkOpen(DFSClient.java:808)
	at org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:868)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:934)
	at java.io.DataInputStream.read(DataInputStream.java:149)
	at org.apache.hadoop.mapreduce.lib.input.UncompressedSplitLineReader.fillBuffer(UncompressedSplitLineReader.java:62)
	at org.apache.hadoop.util.LineReader.readDefaultLine(LineReader.java:216)
	at org.apache.hadoop.util.LineReader.readLine(LineReader.java:174)
	at org.apache.hadoop.mapreduce.lib.input.UncompressedSplitLineReader.readLine(UncompressedSplitLineReader.java:94)
	at org.apache.hadoop.mapreduce.lib.input.LineRecordReader.nextKeyValue(LineRecordReader.java:186)
	at org.apache.spark.sql.execution.datasources.RecordReaderIterator.hasNext(RecordReaderIterator.scala:39)
	at org.apache.spark.sql.execution.datasources.HadoopFileLinesReader.hasNext(HadoopFileLinesReader.scala:69)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:462)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:101)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$11$$anon$1.hasNext(WholeStageCodegenExec.scala:619)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	at scala.collection.Iterator$GroupedIterator.takeDestructively(Iterator.scala:1073)
	at scala.collection.Iterator$GroupedIterator.go(Iterator.scala:1089)
	at scala.collection.Iterator$GroupedIterator.fill(Iterator.scala:1127)
	at scala.collection.Iterator$GroupedIterator.hasNext(Iterator.scala:1130)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	at scala.collection.Iterator$class.foreach(Iterator.scala:891)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1334)
	at org.apache.spark.api.python.PythonRDD$.writeIteratorToStream(PythonRDD.scala:224)
	at org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$2.writeIteratorToStream(PythonUDFRunner.scala:50)
	at org.apache.spark.api.python.BasePythonRunner$WriterThread$$anonfun$run$1.apply(PythonRunner.scala:345)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1945)
	at org.apache.spark.api.python.BasePythonRunner$WriterThread.run(PythonRunner.scala:194)
2021-05-19 02:46:33 ERROR PythonUDFRunner:91 - This may have been caused by a prior exception:
java.io.IOException: Filesystem closed
	at org.apache.hadoop.hdfs.DFSClient.checkOpen(DFSClient.java:808)
	at org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:868)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:934)
	at java.io.DataInputStream.read(DataInputStream.java:149)
	at org.apache.hadoop.mapreduce.lib.input.UncompressedSplitLineReader.fillBuffer(UncompressedSplitLineReader.java:62)
	at org.apache.hadoop.util.LineReader.readDefaultLine(LineReader.java:216)
	at org.apache.hadoop.util.LineReader.readLine(LineReader.java:174)
	at org.apache.hadoop.mapreduce.lib.input.UncompressedSplitLineReader.readLine(UncompressedSplitLineReader.java:94)
	at org.apache.hadoop.mapreduce.lib.input.LineRecordReader.nextKeyValue(LineRecordReader.java:186)
	at org.apache.spark.sql.execution.datasources.RecordReaderIterator.hasNext(RecordReaderIterator.scala:39)
	at org.apache.spark.sql.execution.datasources.HadoopFileLinesReader.hasNext(HadoopFileLinesReader.scala:69)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:462)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	at org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:101)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$11$$anon$1.hasNext(WholeStageCodegenExec.scala:619)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	at scala.collection.Iterator$GroupedIterator.takeDestructively(Iterator.scala:1073)
	at scala.collection.Iterator$GroupedIterator.go(Iterator.scala:1089)
	at scala.collection.Iterator$GroupedIterator.fill(Iterator.scala:1127)
	at scala.collection.Iterator$GroupedIterator.hasNext(Iterator.scala:1130)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	at scala.collection.Iterator$class.foreach(Iterator.scala:891)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1334)
	at org.apache.spark.api.python.PythonRDD$.writeIteratorToStream(PythonRDD.scala:224)
	at org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$2.writeIteratorToStream(PythonUDFRunner.scala:50)
	at org.apache.spark.api.python.BasePythonRunner$WriterThread$$anonfun$run$1.apply(PythonRunner.scala:345)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1945)
	at org.apache.spark.api.python.BasePythonRunner$WriterThread.run(PythonRunner.scala:194)
2021-05-19 02:46:33 ERROR TaskContextImpl:91 - Error in TaskCompletionListener
java.io.IOException: Filesystem closed
	at org.apache.hadoop.hdfs.DFSClient.checkOpen(DFSClient.java:808)
	at org.apache.hadoop.hdfs.DFSInputStream.close(DFSInputStream.java:710)
	at java.io.FilterInputStream.close(FilterInputStream.java:181)
	at org.apache.hadoop.util.LineReader.close(LineReader.java:150)
	at org.apache.hadoop.mapreduce.lib.input.LineRecordReader.close(LineRecordReader.java:231)
	at org.apache.spark.sql.execution.datasources.RecordReaderIterator.close(RecordReaderIterator.scala:62)
	at org.apache.spark.sql.execution.datasources.HadoopFileLinesReader.close(HadoopFileLinesReader.scala:73)
	at org.apache.spark.sql.execution.datasources.csv.TextInputCSVDataSource$$anonfun$4$$anonfun$apply$2.apply(CSVDataSource.scala:200)
	at org.apache.spark.sql.execution.datasources.csv.TextInputCSVDataSource$$anonfun$4$$anonfun$apply$2.apply(CSVDataSource.scala:200)
	at org.apache.spark.TaskContext$$anon$1.onTaskCompletion(TaskContext.scala:131)
	at org.apache.spark.TaskContextImpl$$anonfun$markTaskCompleted$1.apply(TaskContextImpl.scala:117)
	at org.apache.spark.TaskContextImpl$$anonfun$markTaskCompleted$1.apply(TaskContextImpl.scala:117)
	at org.apache.spark.TaskContextImpl$$anonfun$invokeListeners$1.apply(TaskContextImpl.scala:130)
	at org.apache.spark.TaskContextImpl$$anonfun$invokeListeners$1.apply(TaskContextImpl.scala:128)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.TaskContextImpl.invokeListeners(TaskContextImpl.scala:128)
	at org.apache.spark.TaskContextImpl.markTaskCompleted(TaskContextImpl.scala:116)
	at org.apache.spark.scheduler.Task.run(Task.scala:131)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:402)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:408)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2021-05-19 02:46:33 ERROR Executor:91 - Exception in task 38.2 in stage 7.0 (TID 430)
org.apache.spark.util.TaskCompletionListenerException: Filesystem closed

Previous exception in task: Filesystem closed
	org.apache.hadoop.hdfs.DFSClient.checkOpen(DFSClient.java:808)
	org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:868)
	org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:934)
	java.io.DataInputStream.read(DataInputStream.java:149)
	org.apache.hadoop.mapreduce.lib.input.UncompressedSplitLineReader.fillBuffer(UncompressedSplitLineReader.java:62)
	org.apache.hadoop.util.LineReader.readDefaultLine(LineReader.java:216)
	org.apache.hadoop.util.LineReader.readLine(LineReader.java:174)
	org.apache.hadoop.mapreduce.lib.input.UncompressedSplitLineReader.readLine(UncompressedSplitLineReader.java:94)
	org.apache.hadoop.mapreduce.lib.input.LineRecordReader.nextKeyValue(LineRecordReader.java:186)
	org.apache.spark.sql.execution.datasources.RecordReaderIterator.hasNext(RecordReaderIterator.scala:39)
	org.apache.spark.sql.execution.datasources.HadoopFileLinesReader.hasNext(HadoopFileLinesReader.scala:69)
	scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:462)
	scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:101)
	org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source)
	org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$11$$anon$1.hasNext(WholeStageCodegenExec.scala:619)
	scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	scala.collection.Iterator$GroupedIterator.takeDestructively(Iterator.scala:1073)
	scala.collection.Iterator$GroupedIterator.go(Iterator.scala:1089)
	scala.collection.Iterator$GroupedIterator.fill(Iterator.scala:1127)
	scala.collection.Iterator$GroupedIterator.hasNext(Iterator.scala:1130)
	scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	scala.collection.Iterator$class.foreach(Iterator.scala:891)
	scala.collection.AbstractIterator.foreach(Iterator.scala:1334)
	org.apache.spark.api.python.PythonRDD$.writeIteratorToStream(PythonRDD.scala:224)
	org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$2.writeIteratorToStream(PythonUDFRunner.scala:50)
	org.apache.spark.api.python.BasePythonRunner$WriterThread$$anonfun$run$1.apply(PythonRunner.scala:345)
	org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1945)
	org.apache.spark.api.python.BasePythonRunner$WriterThread.run(PythonRunner.scala:194)
	at org.apache.spark.TaskContextImpl.invokeListeners(TaskContextImpl.scala:138)
	at org.apache.spark.TaskContextImpl.markTaskCompleted(TaskContextImpl.scala:116)
	at org.apache.spark.scheduler.Task.run(Task.scala:131)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:402)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:408)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2021-05-19 02:46:33 INFO  Executor:54 - Not reporting error to driver during JVM shutdown.

End of LogType:stdout
***********************************************************************

Container: container_e10_1609183734776_5900_01_000005 on hadoop20.cusp.nyu.edu_8041
LogAggregationType: AGGREGATED
===================================================================================
LogType:container-localizer-syslog
LogLastModifiedTime:Wed May 19 02:48:18 -0400 2021
LogLength:506
LogContents:
2021-05-19 02:45:27,088 INFO [main] org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ContainerLocalizer: Disk Validator: yarn.nodemanager.disk-validator is loaded.
2021-05-19 02:45:28,425 WARN [ContainerLocalizer Downloader] org.apache.hadoop.ipc.Client: Exception encountered while connecting to the server : org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.ipc.StandbyException): Operation category READ is not supported in state standby. Visit https://s.apache.org/sbnn-error

End of LogType:container-localizer-syslog
*******************************************************************************************


End of LogType:prelaunch.err
******************************************************************************

Container: container_e10_1609183734776_5900_01_000005 on hadoop20.cusp.nyu.edu_8041
LogAggregationType: AGGREGATED
===================================================================================
LogType:prelaunch.out
LogLastModifiedTime:Wed May 19 02:48:18 -0400 2021
LogLength:70
LogContents:
Setting up env variables
Setting up job resources
Launching container

End of LogType:prelaunch.out
******************************************************************************

Container: container_e10_1609183734776_5900_01_000005 on hadoop20.cusp.nyu.edu_8041
LogAggregationType: AGGREGATED
===================================================================================
LogType:stderr
LogLastModifiedTime:Wed May 19 02:48:18 -0400 2021
LogLength:529
LogContents:
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/localhome/cdp/yarn/nm/filecache/31/spark-jars-2.4.0-hadoop2.7.jar/slf4j-log4j12-1.7.16.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/opt/cloudera/parcels/CDH-6.1.0-1.cdh6.1.0.p0.770702/jars/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]

End of LogType:stderr
***********************************************************************

Container: container_e10_1609183734776_5900_01_000005 on hadoop20.cusp.nyu.edu_8041
LogAggregationType: AGGREGATED
===================================================================================
LogType:stdout
LogLastModifiedTime:Wed May 19 02:48:18 -0400 2021
LogLength:58908
LogContents:
2021-05-19 02:45:29 INFO  CoarseGrainedExecutorBackend:2566 - Started daemon with process name: 27381@hadoop20.cusp.nyu.edu
2021-05-19 02:45:29 INFO  SignalUtils:54 - Registered signal handler for TERM
2021-05-19 02:45:29 INFO  SignalUtils:54 - Registered signal handler for HUP
2021-05-19 02:45:29 INFO  SignalUtils:54 - Registered signal handler for INT
2021-05-19 02:45:30 INFO  SecurityManager:54 - Changing view acls to: catherine.ng60
2021-05-19 02:45:30 INFO  SecurityManager:54 - Changing modify acls to: catherine.ng60
2021-05-19 02:45:30 INFO  SecurityManager:54 - Changing view acls groups to: 
2021-05-19 02:45:30 INFO  SecurityManager:54 - Changing modify acls groups to: 
2021-05-19 02:45:30 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(catherine.ng60); groups with view permissions: Set(); users  with modify permissions: Set(catherine.ng60); groups with modify permissions: Set()
2021-05-19 02:45:31 INFO  TransportClientFactory:267 - Successfully created connection to hadoop05.cusp.nyu.edu/192.168.72.175:47481 after 106 ms (0 ms spent in bootstraps)
2021-05-19 02:45:31 INFO  SecurityManager:54 - Changing view acls to: catherine.ng60
2021-05-19 02:45:31 INFO  SecurityManager:54 - Changing modify acls to: catherine.ng60
2021-05-19 02:45:31 INFO  SecurityManager:54 - Changing view acls groups to: 
2021-05-19 02:45:31 INFO  SecurityManager:54 - Changing modify acls groups to: 
2021-05-19 02:45:31 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(catherine.ng60); groups with view permissions: Set(); users  with modify permissions: Set(catherine.ng60); groups with modify permissions: Set()
2021-05-19 02:45:31 INFO  TransportClientFactory:267 - Successfully created connection to hadoop05.cusp.nyu.edu/192.168.72.175:47481 after 3 ms (0 ms spent in bootstraps)
2021-05-19 02:45:32 INFO  DiskBlockManager:54 - Created local directory at /localhome/cdp/yarn/nm/usercache/catherine.ng60/appcache/application_1609183734776_5900/blockmgr-de8a1c2b-c5a6-41bd-8468-c39baba6b162
2021-05-19 02:45:32 INFO  MemoryStore:54 - MemoryStore started with capacity 366.3 MB
2021-05-19 02:45:32 INFO  CoarseGrainedExecutorBackend:54 - Connecting to driver: spark://CoarseGrainedScheduler@hadoop05.cusp.nyu.edu:47481
2021-05-19 02:45:32 INFO  CoarseGrainedExecutorBackend:54 - Successfully registered with driver
2021-05-19 02:45:32 INFO  Executor:54 - Starting executor ID 4 on host hadoop20.cusp.nyu.edu
2021-05-19 02:45:32 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 55825.
2021-05-19 02:45:32 INFO  NettyBlockTransferService:54 - Server created on hadoop20.cusp.nyu.edu:55825
2021-05-19 02:45:32 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2021-05-19 02:45:32 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(4, hadoop20.cusp.nyu.edu, 55825, None)
2021-05-19 02:45:32 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(4, hadoop20.cusp.nyu.edu, 55825, None)
2021-05-19 02:45:32 INFO  BlockManager:54 - external shuffle service port = 7337
2021-05-19 02:45:32 INFO  BlockManager:54 - Registering executor with local external shuffle service.
2021-05-19 02:45:32 INFO  TransportClientFactory:267 - Successfully created connection to hadoop20.cusp.nyu.edu/192.168.72.190:7337 after 3 ms (0 ms spent in bootstraps)
2021-05-19 02:45:32 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(4, hadoop20.cusp.nyu.edu, 55825, None)
2021-05-19 02:45:42 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 5
2021-05-19 02:45:42 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 10
2021-05-19 02:45:42 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 15
2021-05-19 02:45:42 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 20
2021-05-19 02:45:42 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 25
2021-05-19 02:45:42 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 30
2021-05-19 02:45:42 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 35
2021-05-19 02:45:42 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 40
2021-05-19 02:45:42 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 45
2021-05-19 02:45:42 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 50
2021-05-19 02:45:42 INFO  Executor:54 - Running task 9.0 in stage 1.0 (TID 10)
2021-05-19 02:45:42 INFO  Executor:54 - Running task 14.0 in stage 1.0 (TID 15)
2021-05-19 02:45:42 INFO  Executor:54 - Running task 44.0 in stage 1.0 (TID 45)
2021-05-19 02:45:42 INFO  Executor:54 - Running task 19.0 in stage 1.0 (TID 20)
2021-05-19 02:45:42 INFO  Executor:54 - Running task 49.0 in stage 1.0 (TID 50)
2021-05-19 02:45:42 INFO  Executor:54 - Running task 29.0 in stage 1.0 (TID 30)
2021-05-19 02:45:42 INFO  Executor:54 - Running task 4.0 in stage 1.0 (TID 5)
2021-05-19 02:45:42 INFO  Executor:54 - Running task 24.0 in stage 1.0 (TID 25)
2021-05-19 02:45:42 INFO  Executor:54 - Running task 39.0 in stage 1.0 (TID 40)
2021-05-19 02:45:42 INFO  Executor:54 - Running task 34.0 in stage 1.0 (TID 35)
2021-05-19 02:45:43 INFO  TorrentBroadcast:54 - Started reading broadcast variable 3
2021-05-19 02:45:43 INFO  TransportClientFactory:267 - Successfully created connection to hadoop08.cusp.nyu.edu/192.168.72.178:54817 after 5 ms (0 ms spent in bootstraps)
2021-05-19 02:45:43 INFO  MemoryStore:54 - Block broadcast_3_piece0 stored as bytes in memory (estimated size 35.0 KB, free 366.3 MB)
2021-05-19 02:45:43 INFO  TorrentBroadcast:54 - Reading broadcast variable 3 took 175 ms
2021-05-19 02:45:43 INFO  MemoryStore:54 - Block broadcast_3 stored as values in memory (estimated size 129.0 KB, free 366.1 MB)
2021-05-19 02:45:45 INFO  Executor:54 - Finished task 34.0 in stage 1.0 (TID 35). 1449 bytes result sent to driver
2021-05-19 02:45:45 INFO  Executor:54 - Finished task 9.0 in stage 1.0 (TID 10). 1492 bytes result sent to driver
2021-05-19 02:45:45 INFO  Executor:54 - Finished task 44.0 in stage 1.0 (TID 45). 1492 bytes result sent to driver
2021-05-19 02:45:45 INFO  Executor:54 - Finished task 29.0 in stage 1.0 (TID 30). 1492 bytes result sent to driver
2021-05-19 02:45:45 INFO  Executor:54 - Finished task 39.0 in stage 1.0 (TID 40). 1492 bytes result sent to driver
2021-05-19 02:45:45 INFO  Executor:54 - Finished task 14.0 in stage 1.0 (TID 15). 1492 bytes result sent to driver
2021-05-19 02:45:45 INFO  Executor:54 - Finished task 19.0 in stage 1.0 (TID 20). 1492 bytes result sent to driver
2021-05-19 02:45:45 INFO  Executor:54 - Finished task 4.0 in stage 1.0 (TID 5). 1492 bytes result sent to driver
2021-05-19 02:45:45 INFO  Executor:54 - Finished task 49.0 in stage 1.0 (TID 50). 1492 bytes result sent to driver
2021-05-19 02:45:45 INFO  Executor:54 - Finished task 24.0 in stage 1.0 (TID 25). 1492 bytes result sent to driver
2021-05-19 02:45:45 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 52
2021-05-19 02:45:45 INFO  Executor:54 - Running task 1.0 in stage 2.0 (TID 52)
2021-05-19 02:45:45 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 57
2021-05-19 02:45:45 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 62
2021-05-19 02:45:45 INFO  Executor:54 - Running task 6.0 in stage 2.0 (TID 57)
2021-05-19 02:45:45 INFO  Executor:54 - Running task 11.0 in stage 2.0 (TID 62)
2021-05-19 02:45:45 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 67
2021-05-19 02:45:45 INFO  Executor:54 - Running task 16.0 in stage 2.0 (TID 67)
2021-05-19 02:45:45 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 72
2021-05-19 02:45:45 INFO  Executor:54 - Running task 21.0 in stage 2.0 (TID 72)
2021-05-19 02:45:45 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 77
2021-05-19 02:45:45 INFO  Executor:54 - Running task 26.0 in stage 2.0 (TID 77)
2021-05-19 02:45:45 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 82
2021-05-19 02:45:45 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 87
2021-05-19 02:45:45 INFO  Executor:54 - Running task 31.0 in stage 2.0 (TID 82)
2021-05-19 02:45:45 INFO  Executor:54 - Running task 36.0 in stage 2.0 (TID 87)
2021-05-19 02:45:45 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 92
2021-05-19 02:45:45 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 97
2021-05-19 02:45:45 INFO  Executor:54 - Running task 41.0 in stage 2.0 (TID 92)
2021-05-19 02:45:45 INFO  Executor:54 - Running task 46.0 in stage 2.0 (TID 97)
2021-05-19 02:45:45 INFO  TorrentBroadcast:54 - Started reading broadcast variable 4
2021-05-19 02:45:45 INFO  TransportClientFactory:267 - Successfully created connection to hadoop05.cusp.nyu.edu/192.168.72.175:36982 after 5 ms (0 ms spent in bootstraps)
2021-05-19 02:45:45 INFO  MemoryStore:54 - Block broadcast_4_piece0 stored as bytes in memory (estimated size 35.0 KB, free 366.1 MB)
2021-05-19 02:45:45 INFO  TorrentBroadcast:54 - Reading broadcast variable 4 took 53 ms
2021-05-19 02:45:45 INFO  MemoryStore:54 - Block broadcast_4 stored as values in memory (estimated size 129.0 KB, free 366.0 MB)
2021-05-19 02:45:45 INFO  Executor:54 - Finished task 11.0 in stage 2.0 (TID 62). 1449 bytes result sent to driver
2021-05-19 02:45:45 INFO  Executor:54 - Finished task 6.0 in stage 2.0 (TID 57). 1406 bytes result sent to driver
2021-05-19 02:45:45 INFO  Executor:54 - Finished task 31.0 in stage 2.0 (TID 82). 1449 bytes result sent to driver
2021-05-19 02:45:45 INFO  Executor:54 - Finished task 41.0 in stage 2.0 (TID 92). 1449 bytes result sent to driver
2021-05-19 02:45:45 INFO  Executor:54 - Finished task 26.0 in stage 2.0 (TID 77). 1449 bytes result sent to driver
2021-05-19 02:45:45 INFO  Executor:54 - Finished task 36.0 in stage 2.0 (TID 87). 1406 bytes result sent to driver
2021-05-19 02:45:46 INFO  Executor:54 - Finished task 46.0 in stage 2.0 (TID 97). 1449 bytes result sent to driver
2021-05-19 02:45:46 INFO  Executor:54 - Finished task 1.0 in stage 2.0 (TID 52). 1406 bytes result sent to driver
2021-05-19 02:45:46 INFO  Executor:54 - Finished task 16.0 in stage 2.0 (TID 67). 1406 bytes result sent to driver
2021-05-19 02:45:46 INFO  Executor:54 - Finished task 21.0 in stage 2.0 (TID 72). 1406 bytes result sent to driver
2021-05-19 02:45:51 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 119
2021-05-19 02:45:51 INFO  Executor:54 - Running task 1.0 in stage 5.0 (TID 119)
2021-05-19 02:45:51 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 124
2021-05-19 02:45:51 INFO  Executor:54 - Running task 7.0 in stage 5.0 (TID 124)
2021-05-19 02:45:51 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 128
2021-05-19 02:45:51 INFO  Executor:54 - Running task 11.0 in stage 5.0 (TID 128)
2021-05-19 02:45:51 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 132
2021-05-19 02:45:51 INFO  Executor:54 - Running task 15.0 in stage 5.0 (TID 132)
2021-05-19 02:45:51 INFO  MapOutputTrackerWorker:54 - Updating epoch to 1 and clearing cache
2021-05-19 02:45:51 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 136
2021-05-19 02:45:51 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 140
2021-05-19 02:45:51 INFO  Executor:54 - Running task 20.0 in stage 5.0 (TID 136)
2021-05-19 02:45:51 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 144
2021-05-19 02:45:51 INFO  Executor:54 - Running task 24.0 in stage 5.0 (TID 140)
2021-05-19 02:45:51 INFO  TorrentBroadcast:54 - Started reading broadcast variable 10
2021-05-19 02:45:51 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 148
2021-05-19 02:45:51 INFO  Executor:54 - Running task 29.0 in stage 5.0 (TID 144)
2021-05-19 02:45:51 INFO  Executor:54 - Running task 33.0 in stage 5.0 (TID 148)
2021-05-19 02:45:51 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 152
2021-05-19 02:45:51 INFO  Executor:54 - Running task 38.0 in stage 5.0 (TID 152)
2021-05-19 02:45:51 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 156
2021-05-19 02:45:51 INFO  Executor:54 - Running task 42.0 in stage 5.0 (TID 156)
2021-05-19 02:45:51 INFO  MemoryStore:54 - Block broadcast_10_piece0 stored as bytes in memory (estimated size 20.4 KB, free 366.3 MB)
2021-05-19 02:45:51 INFO  TorrentBroadcast:54 - Reading broadcast variable 10 took 31 ms
2021-05-19 02:45:51 INFO  MemoryStore:54 - Block broadcast_10 stored as values in memory (estimated size 40.9 KB, free 366.2 MB)
2021-05-19 02:45:52 INFO  MapOutputTrackerWorker:54 - Don't have map outputs for shuffle 0, fetching them
2021-05-19 02:45:52 INFO  MapOutputTrackerWorker:54 - Don't have map outputs for shuffle 0, fetching them
2021-05-19 02:45:52 INFO  MapOutputTrackerWorker:54 - Don't have map outputs for shuffle 0, fetching them
2021-05-19 02:45:52 INFO  MapOutputTrackerWorker:54 - Don't have map outputs for shuffle 0, fetching them
2021-05-19 02:45:52 INFO  MapOutputTrackerWorker:54 - Don't have map outputs for shuffle 0, fetching them
2021-05-19 02:45:52 INFO  MapOutputTrackerWorker:54 - Don't have map outputs for shuffle 0, fetching them
2021-05-19 02:45:52 INFO  MapOutputTrackerWorker:54 - Don't have map outputs for shuffle 0, fetching them
2021-05-19 02:45:52 INFO  MapOutputTrackerWorker:54 - Don't have map outputs for shuffle 0, fetching them
2021-05-19 02:45:52 INFO  MapOutputTrackerWorker:54 - Don't have map outputs for shuffle 0, fetching them
2021-05-19 02:45:52 INFO  MapOutputTrackerWorker:54 - Don't have map outputs for shuffle 0, fetching them
2021-05-19 02:45:52 INFO  MapOutputTrackerWorker:54 - Doing the fetch; tracker endpoint = NettyRpcEndpointRef(spark://MapOutputTracker@hadoop05.cusp.nyu.edu:47481)
2021-05-19 02:45:52 INFO  MapOutputTrackerWorker:54 - Got the output locations
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 18 ms
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 18 ms
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 18 ms
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 17 ms
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 18 ms
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 17 ms
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 16 ms
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 18 ms
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 22 ms
2021-05-19 02:45:52 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 18 ms
2021-05-19 02:45:52 INFO  CodeGenerator:54 - Code generated in 364.924131 ms
2021-05-19 02:45:52 INFO  CodeGenerator:54 - Code generated in 35.95858 ms
2021-05-19 02:45:53 INFO  CodeGenerator:54 - Code generated in 26.015772 ms
2021-05-19 02:45:53 INFO  CodeGenerator:54 - Code generated in 29.477093 ms
2021-05-19 02:45:53 INFO  Executor:54 - Finished task 38.0 in stage 5.0 (TID 152). 3733 bytes result sent to driver
2021-05-19 02:45:53 INFO  Executor:54 - Finished task 24.0 in stage 5.0 (TID 140). 3733 bytes result sent to driver
2021-05-19 02:45:53 INFO  Executor:54 - Finished task 11.0 in stage 5.0 (TID 128). 3733 bytes result sent to driver
2021-05-19 02:45:53 INFO  Executor:54 - Finished task 15.0 in stage 5.0 (TID 132). 3733 bytes result sent to driver
2021-05-19 02:45:53 INFO  Executor:54 - Finished task 29.0 in stage 5.0 (TID 144). 3733 bytes result sent to driver
2021-05-19 02:45:53 INFO  Executor:54 - Finished task 7.0 in stage 5.0 (TID 124). 3733 bytes result sent to driver
2021-05-19 02:45:53 INFO  Executor:54 - Finished task 20.0 in stage 5.0 (TID 136). 3733 bytes result sent to driver
2021-05-19 02:45:53 INFO  Executor:54 - Finished task 33.0 in stage 5.0 (TID 148). 3733 bytes result sent to driver
2021-05-19 02:45:53 INFO  Executor:54 - Finished task 1.0 in stage 5.0 (TID 119). 3733 bytes result sent to driver
2021-05-19 02:45:53 INFO  Executor:54 - Finished task 42.0 in stage 5.0 (TID 156). 3733 bytes result sent to driver
2021-05-19 02:45:56 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 317
2021-05-19 02:45:56 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 322
2021-05-19 02:45:56 INFO  Executor:54 - Running task 10.0 in stage 7.0 (TID 317)
2021-05-19 02:45:56 INFO  Executor:54 - Running task 18.0 in stage 7.0 (TID 322)
2021-05-19 02:45:56 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 327
2021-05-19 02:45:56 INFO  Executor:54 - Running task 31.0 in stage 7.0 (TID 327)
2021-05-19 02:45:56 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 332
2021-05-19 02:45:56 INFO  Executor:54 - Running task 45.0 in stage 7.0 (TID 332)
2021-05-19 02:45:56 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 337
2021-05-19 02:45:56 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 342
2021-05-19 02:45:56 INFO  Executor:54 - Running task 46.0 in stage 7.0 (TID 337)
2021-05-19 02:45:56 INFO  Executor:54 - Running task 50.0 in stage 7.0 (TID 342)
2021-05-19 02:45:56 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 347
2021-05-19 02:45:56 INFO  Executor:54 - Running task 53.0 in stage 7.0 (TID 347)
2021-05-19 02:45:56 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 352
2021-05-19 02:45:56 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 357
2021-05-19 02:45:56 INFO  Executor:54 - Running task 60.0 in stage 7.0 (TID 352)
2021-05-19 02:45:56 INFO  Executor:54 - Running task 65.0 in stage 7.0 (TID 357)
2021-05-19 02:45:56 INFO  TorrentBroadcast:54 - Started reading broadcast variable 14
2021-05-19 02:45:56 INFO  MemoryStore:54 - Block broadcast_14_piece0 stored as bytes in memory (estimated size 22.9 KB, free 366.3 MB)
2021-05-19 02:45:56 INFO  TorrentBroadcast:54 - Reading broadcast variable 14 took 27 ms
2021-05-19 02:45:56 INFO  MemoryStore:54 - Block broadcast_14 stored as values in memory (estimated size 51.5 KB, free 366.2 MB)
2021-05-19 02:45:56 INFO  CodeGenerator:54 - Code generated in 62.136893 ms
2021-05-19 02:45:56 INFO  TorrentBroadcast:54 - Started reading broadcast variable 12
2021-05-19 02:45:56 INFO  MemoryStore:54 - Block broadcast_12_piece0 stored as bytes in memory (estimated size 580.1 KB, free 365.7 MB)
2021-05-19 02:45:56 INFO  TorrentBroadcast:54 - Reading broadcast variable 12 took 32 ms
2021-05-19 02:45:56 INFO  MemoryStore:54 - Block broadcast_12 stored as values in memory (estimated size 5.0 MB, free 360.7 MB)
2021-05-19 02:45:56 INFO  CodeGenerator:54 - Code generated in 23.431633 ms
2021-05-19 02:45:57 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00010, range: 0-134217728, partition values: [empty row]
2021-05-19 02:45:57 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00030, range: 134217728-176820246, partition values: [empty row]
2021-05-19 02:45:57 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00046, range: 0-134217728, partition values: [empty row]
2021-05-19 02:45:57 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00045, range: 0-134217728, partition values: [empty row]
2021-05-19 02:45:57 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00031, range: 0-134217728, partition values: [empty row]
2021-05-19 02:45:57 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00041, range: 134217728-175666719, partition values: [empty row]
2021-05-19 02:45:57 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00026, range: 134217728-178435909, partition values: [empty row]
2021-05-19 02:45:57 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00010, range: 134217728-179164944, partition values: [empty row]
2021-05-19 02:45:57 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00018, range: 0-134217728, partition values: [empty row]
2021-05-19 02:45:57 INFO  CodeGenerator:54 - Code generated in 39.389102 ms
2021-05-19 02:45:57 INFO  TorrentBroadcast:54 - Started reading broadcast variable 13
2021-05-19 02:45:57 INFO  CodeGenerator:54 - Code generated in 88.203961 ms
2021-05-19 02:45:57 INFO  MemoryStore:54 - Block broadcast_13_piece0 stored as bytes in memory (estimated size 33.4 KB, free 360.6 MB)
2021-05-19 02:45:57 INFO  TorrentBroadcast:54 - Reading broadcast variable 13 took 22 ms
2021-05-19 02:45:57 INFO  CodeGenerator:54 - Code generated in 49.515793 ms
2021-05-19 02:45:57 INFO  CodeGenerator:54 - Code generated in 31.148033 ms
2021-05-19 02:45:57 INFO  MemoryStore:54 - Block broadcast_13 stored as values in memory (estimated size 506.4 KB, free 360.1 MB)
2021-05-19 02:45:57 INFO  CodeGenerator:54 - Code generated in 22.175156 ms
2021-05-19 02:45:57 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: 22r-222@627-vvk-swk, 2019-11-18T00:00:00-05:00, [7,32,20,27,42,29,34]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: 22r-222@627-vvk-swk
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00045
2021-05-19 02:45:57 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: 22h-223@627-s96-73q, 2019-10-07T00:00:00-04:00, [5,3,1,1,5,1,3]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: 22h-223@627-s96-73q
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00046
2021-05-19 02:45:57 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: 22k-222@627-vsp-3wk, 2020-08-10T00:00:00-04:00, [0,1,1,0,0,2,0]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: 22k-222@627-vsp-3wk
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00018
2021-05-19 02:45:57 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: 22q-222@627-s8x-bzf, 2019-12-16T00:00:00-05:00, [1,0,0,0,0,1,0]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: 22q-222@627-s8x-bzf
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00031
2021-05-19 02:45:57 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: 22x-224@627-s8r-c89, 2018-12-31T00:00:00-05:00, [21,42,46,76,70,52,8]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: 22x-224@627-s8r-c89
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00010
2021-05-19 02:45:58 INFO  CodeGenerator:54 - Code generated in 18.620979 ms
2021-05-19 02:45:58 INFO  CodeGenerator:54 - Code generated in 70.570106 ms
2021-05-19 02:45:58 INFO  CodeGenerator:54 - Code generated in 21.097033 ms
2021-05-19 02:45:59 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:45:59 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:45:59 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:45:59 INFO  CodeGenerator:54 - Code generated in 29.852023 ms
2021-05-19 02:45:59 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:45:59 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:45:59 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:45:59 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:45:59 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:45:59 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:45:59 INFO  CodeGenerator:54 - Code generated in 27.631164 ms
2021-05-19 02:45:59 INFO  CodeGenerator:54 - Code generated in 18.251932 ms
2021-05-19 02:45:59 INFO  CodeGenerator:54 - Code generated in 20.755523 ms
2021-05-19 02:45:59 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00012, range: 134217728-176612852, partition values: [empty row]
2021-05-19 02:45:59 INFO  CoarseGrainedExecutorBackend:54 - Got assigned task 366
2021-05-19 02:45:59 INFO  Executor:54 - Running task 2.0 in stage 7.0 (TID 366)
2021-05-19 02:45:59 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00002, range: 0-134217728, partition values: [empty row]
2021-05-19 02:45:59 WARN  CSVDataSource:66 - CSV header does not conform to the schema.
 Header: 226-223@627-wgt-z2k, 2018-12-31T00:00:00-05:00, [0,0,0,0,2,0,0]
 Schema: placekey, date_range_start, visits_by_day
Expected: placekey but found: 226-223@627-wgt-z2k
CSV file: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00002
2021-05-19 02:46:00 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00033, range: 134217728-175653848, partition values: [empty row]
2021-05-19 02:46:00 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00003, range: 134217728-178774105, partition values: [empty row]
2021-05-19 02:46:00 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00027, range: 134217728-178418906, partition values: [empty row]
2021-05-19 02:46:00 INFO  ObjectAggregationIterator:54 - Aggregation hash map reaches threshold capacity (128 entries), spilling and falling back to sort based aggregation. You may change the threshold by adjust option spark.sql.objectHashAggregate.sortBased.fallbackThreshold
2021-05-19 02:46:03 INFO  FileScanRDD:54 - Reading File path: hdfs://NameService1/data/share/bdm/weekly-patterns-nyc-2019-2020/part-00046, range: 134217728-175565011, partition values: [empty row]
2021-05-19 02:46:07 INFO  PythonUDFRunner:54 - Times: total = 10836, boot = 738, init = 1033, finish = 9065
2021-05-19 02:46:07 ERROR CoarseGrainedExecutorBackend:43 - RECEIVED SIGNAL TERM
2021-05-19 02:46:07 INFO  PythonUDFRunner:54 - Times: total = 11055, boot = 727, init = 1043, finish = 9285
2021-05-19 02:46:07 INFO  DiskBlockManager:54 - Shutdown hook called
2021-05-19 02:46:07 INFO  ShutdownHookManager:54 - Shutdown hook called
2021-05-19 02:46:07 INFO  ShutdownHookManager:54 - Deleting directory /localhome/cdp/yarn/nm/usercache/catherine.ng60/appcache/application_1609183734776_5900/spark-5ea89856-5e47-4311-8744-25f5790afb38
2021-05-19 02:46:07 INFO  CoarseGrainedExecutorBackend:54 - Driver commanded a shutdown
2021-05-19 02:46:07 ERROR Executor:91 - Exception in task 18.0 in stage 7.0 (TID 322)
java.net.SocketException: Connection reset
	at java.net.SocketInputStream.read(SocketInputStream.java:210)
	at java.net.SocketInputStream.read(SocketInputStream.java:141)
	at java.io.BufferedInputStream.fill(BufferedInputStream.java:246)
	at java.io.BufferedInputStream.read1(BufferedInputStream.java:286)
	at java.io.BufferedInputStream.read(BufferedInputStream.java:345)
	at java.io.DataInputStream.readFully(DataInputStream.java:195)
	at java.io.DataInputStream.readFully(DataInputStream.java:169)
	at org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$1.read(PythonUDFRunner.scala:74)
	at org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$1.read(PythonUDFRunner.scala:64)
	at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:406)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$JoinIterator.hasNext(Iterator.scala:212)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage3.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$11$$anon$1.hasNext(WholeStageCodegenExec.scala:619)
	at org.apache.spark.sql.execution.aggregate.ObjectAggregationIterator.processInputs(ObjectAggregationIterator.scala:188)
	at org.apache.spark.sql.execution.aggregate.ObjectAggregationIterator.<init>(ObjectAggregationIterator.scala:78)
	at org.apache.spark.sql.execution.aggregate.ObjectHashAggregateExec$$anonfun$doExecute$1$$anonfun$2.apply(ObjectHashAggregateExec.scala:114)
	at org.apache.spark.sql.execution.aggregate.ObjectHashAggregateExec$$anonfun$doExecute$1$$anonfun$2.apply(ObjectHashAggregateExec.scala:105)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndexInternal$1$$anonfun$12.apply(RDD.scala:823)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndexInternal$1$$anonfun$12.apply(RDD.scala:823)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:402)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:408)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2021-05-19 02:46:07 INFO  MemoryStore:54 - MemoryStore cleared
2021-05-19 02:46:07 ERROR Executor:91 - Exception in task 65.0 in stage 7.0 (TID 357)
java.net.SocketException: Connection reset
	at java.net.SocketInputStream.read(SocketInputStream.java:210)
	at java.net.SocketInputStream.read(SocketInputStream.java:141)
	at java.io.BufferedInputStream.fill(BufferedInputStream.java:246)
	at java.io.BufferedInputStream.read1(BufferedInputStream.java:286)
	at java.io.BufferedInputStream.read(BufferedInputStream.java:345)
	at java.io.DataInputStream.readFully(DataInputStream.java:195)
	at java.io.DataInputStream.readFully(DataInputStream.java:169)
	at org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$1.read(PythonUDFRunner.scala:74)
	at org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$1.read(PythonUDFRunner.scala:64)
	at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:406)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$JoinIterator.hasNext(Iterator.scala:212)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage3.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$11$$anon$1.hasNext(WholeStageCodegenExec.scala:619)
	at org.apache.spark.sql.execution.aggregate.ObjectAggregationIterator.processInputs(ObjectAggregationIterator.scala:188)
	at org.apache.spark.sql.execution.aggregate.ObjectAggregationIterator.<init>(ObjectAggregationIterator.scala:78)
	at org.apache.spark.sql.execution.aggregate.ObjectHashAggregateExec$$anonfun$doExecute$1$$anonfun$2.apply(ObjectHashAggregateExec.scala:114)
	at org.apache.spark.sql.execution.aggregate.ObjectHashAggregateExec$$anonfun$doExecute$1$$anonfun$2.apply(ObjectHashAggregateExec.scala:105)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndexInternal$1$$anonfun$12.apply(RDD.scala:823)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndexInternal$1$$anonfun$12.apply(RDD.scala:823)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:402)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:408)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2021-05-19 02:46:07 INFO  Executor:54 - Not reporting error to driver during JVM shutdown.
2021-05-19 02:46:07 ERROR Executor:91 - Exception in task 2.0 in stage 7.0 (TID 366)
org.apache.spark.SparkException: Python worker exited unexpectedly (crashed)
	at org.apache.spark.api.python.BasePythonRunner$ReaderIterator$$anonfun$3.applyOrElse(PythonRunner.scala:486)
	at org.apache.spark.api.python.BasePythonRunner$ReaderIterator$$anonfun$3.applyOrElse(PythonRunner.scala:475)
	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:36)
	at org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$1.read(PythonUDFRunner.scala:86)
	at org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$1.read(PythonUDFRunner.scala:64)
	at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:406)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$JoinIterator.hasNext(Iterator.scala:212)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage3.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$11$$anon$1.hasNext(WholeStageCodegenExec.scala:619)
	at org.apache.spark.sql.execution.aggregate.ObjectAggregationIterator.processInputs(ObjectAggregationIterator.scala:188)
	at org.apache.spark.sql.execution.aggregate.ObjectAggregationIterator.<init>(ObjectAggregationIterator.scala:78)
	at org.apache.spark.sql.execution.aggregate.ObjectHashAggregateExec$$anonfun$doExecute$1$$anonfun$2.apply(ObjectHashAggregateExec.scala:114)
	at org.apache.spark.sql.execution.aggregate.ObjectHashAggregateExec$$anonfun$doExecute$1$$anonfun$2.apply(ObjectHashAggregateExec.scala:105)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndexInternal$1$$anonfun$12.apply(RDD.scala:823)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndexInternal$1$$anonfun$12.apply(RDD.scala:823)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:402)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:408)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readFully(DataInputStream.java:197)
	at java.io.DataInputStream.readFully(DataInputStream.java:169)
	at org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$1.read(PythonUDFRunner.scala:74)
	... 33 more
2021-05-19 02:46:07 ERROR Executor:91 - Exception in task 45.0 in stage 7.0 (TID 332)
java.net.SocketException: Connection reset
	at java.net.SocketInputStream.read(SocketInputStream.java:210)
	at java.net.SocketInputStream.read(SocketInputStream.java:141)
	at java.io.BufferedInputStream.fill(BufferedInputStream.java:246)
	at java.io.BufferedInputStream.read1(BufferedInputStream.java:286)
	at java.io.BufferedInputStream.read(BufferedInputStream.java:345)
	at java.io.DataInputStream.readFully(DataInputStream.java:195)
	at java.io.DataInputStream.readFully(DataInputStream.java:169)
	at org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$1.read(PythonUDFRunner.scala:74)
	at org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$1.read(PythonUDFRunner.scala:64)
	at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:406)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$JoinIterator.hasNext(Iterator.scala:212)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage3.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$11$$anon$1.hasNext(WholeStageCodegenExec.scala:619)
	at org.apache.spark.sql.execution.aggregate.ObjectAggregationIterator.processInputs(ObjectAggregationIterator.scala:188)
	at org.apache.spark.sql.execution.aggregate.ObjectAggregationIterator.<init>(ObjectAggregationIterator.scala:78)
	at org.apache.spark.sql.execution.aggregate.ObjectHashAggregateExec$$anonfun$doExecute$1$$anonfun$2.apply(ObjectHashAggregateExec.scala:114)
	at org.apache.spark.sql.execution.aggregate.ObjectHashAggregateExec$$anonfun$doExecute$1$$anonfun$2.apply(ObjectHashAggregateExec.scala:105)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndexInternal$1$$anonfun$12.apply(RDD.scala:823)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndexInternal$1$$anonfun$12.apply(RDD.scala:823)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:402)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:408)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2021-05-19 02:46:07 INFO  Executor:54 - Not reporting error to driver during JVM shutdown.
2021-05-19 02:46:07 ERROR Executor:91 - Exception in task 46.0 in stage 7.0 (TID 337)
java.net.SocketException: Connection reset
	at java.net.SocketInputStream.read(SocketInputStream.java:210)
	at java.net.SocketInputStream.read(SocketInputStream.java:141)
	at java.io.BufferedInputStream.fill(BufferedInputStream.java:246)
	at java.io.BufferedInputStream.read1(BufferedInputStream.java:286)
	at java.io.BufferedInputStream.read(BufferedInputStream.java:345)
	at java.io.DataInputStream.readFully(DataInputStream.java:195)
	at java.io.DataInputStream.readFully(DataInputStream.java:169)
	at org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$1.read(PythonUDFRunner.scala:74)
	at org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$1.read(PythonUDFRunner.scala:64)
	at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:406)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$JoinIterator.hasNext(Iterator.scala:212)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage3.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$11$$anon$1.hasNext(WholeStageCodegenExec.scala:619)
	at org.apache.spark.sql.execution.aggregate.ObjectAggregationIterator.processInputs(ObjectAggregationIterator.scala:188)
	at org.apache.spark.sql.execution.aggregate.ObjectAggregationIterator.<init>(ObjectAggregationIterator.scala:78)
	at org.apache.spark.sql.execution.aggregate.ObjectHashAggregateExec$$anonfun$doExecute$1$$anonfun$2.apply(ObjectHashAggregateExec.scala:114)
	at org.apache.spark.sql.execution.aggregate.ObjectHashAggregateExec$$anonfun$doExecute$1$$anonfun$2.apply(ObjectHashAggregateExec.scala:105)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndexInternal$1$$anonfun$12.apply(RDD.scala:823)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndexInternal$1$$anonfun$12.apply(RDD.scala:823)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:402)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:408)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2021-05-19 02:46:07 INFO  Executor:54 - Not reporting error to driver during JVM shutdown.
2021-05-19 02:46:07 ERROR Executor:91 - Exception in task 50.0 in stage 7.0 (TID 342)
java.net.SocketException: Connection reset
	at java.net.SocketInputStream.read(SocketInputStream.java:210)
	at java.net.SocketInputStream.read(SocketInputStream.java:141)
	at java.io.BufferedInputStream.fill(BufferedInputStream.java:246)
	at java.io.BufferedInputStream.read1(BufferedInputStream.java:286)
	at java.io.BufferedInputStream.read(BufferedInputStream.java:345)
	at java.io.DataInputStream.readFully(DataInputStream.java:195)
	at java.io.DataInputStream.readFully(DataInputStream.java:169)
	at org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$1.read(PythonUDFRunner.scala:74)
	at org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$1.read(PythonUDFRunner.scala:64)
	at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:406)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$JoinIterator.hasNext(Iterator.scala:212)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage3.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$11$$anon$1.hasNext(WholeStageCodegenExec.scala:619)
	at org.apache.spark.sql.execution.aggregate.ObjectAggregationIterator.processInputs(ObjectAggregationIterator.scala:188)
	at org.apache.spark.sql.execution.aggregate.ObjectAggregationIterator.<init>(ObjectAggregationIterator.scala:78)
	at org.apache.spark.sql.execution.aggregate.ObjectHashAggregateExec$$anonfun$doExecute$1$$anonfun$2.apply(ObjectHashAggregateExec.scala:114)
	at org.apache.spark.sql.execution.aggregate.ObjectHashAggregateExec$$anonfun$doExecute$1$$anonfun$2.apply(ObjectHashAggregateExec.scala:105)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndexInternal$1$$anonfun$12.apply(RDD.scala:823)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndexInternal$1$$anonfun$12.apply(RDD.scala:823)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:402)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:408)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2021-05-19 02:46:07 INFO  Executor:54 - Not reporting error to driver during JVM shutdown.
2021-05-19 02:46:07 INFO  Executor:54 - Not reporting error to driver during JVM shutdown.
2021-05-19 02:46:07 INFO  BlockManager:54 - BlockManager stopped
2021-05-19 02:46:07 ERROR Executor:91 - Exception in task 31.0 in stage 7.0 (TID 327)
java.net.SocketException: Connection reset
	at java.net.SocketInputStream.read(SocketInputStream.java:210)
	at java.net.SocketInputStream.read(SocketInputStream.java:141)
	at java.io.BufferedInputStream.fill(BufferedInputStream.java:246)
	at java.io.BufferedInputStream.read1(BufferedInputStream.java:286)
	at java.io.BufferedInputStream.read(BufferedInputStream.java:345)
	at java.io.DataInputStream.readFully(DataInputStream.java:195)
	at java.io.DataInputStream.readFully(DataInputStream.java:169)
	at org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$1.read(PythonUDFRunner.scala:74)
	at org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$1.read(PythonUDFRunner.scala:64)
	at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:406)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$JoinIterator.hasNext(Iterator.scala:212)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage3.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$11$$anon$1.hasNext(WholeStageCodegenExec.scala:619)
	at org.apache.spark.sql.execution.aggregate.ObjectAggregationIterator.processInputs(ObjectAggregationIterator.scala:188)
	at org.apache.spark.sql.execution.aggregate.ObjectAggregationIterator.<init>(ObjectAggregationIterator.scala:78)
	at org.apache.spark.sql.execution.aggregate.ObjectHashAggregateExec$$anonfun$doExecute$1$$anonfun$2.apply(ObjectHashAggregateExec.scala:114)
	at org.apache.spark.sql.execution.aggregate.ObjectHashAggregateExec$$anonfun$doExecute$1$$anonfun$2.apply(ObjectHashAggregateExec.scala:105)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndexInternal$1$$anonfun$12.apply(RDD.scala:823)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndexInternal$1$$anonfun$12.apply(RDD.scala:823)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:402)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:408)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2021-05-19 02:46:07 INFO  Executor:54 - Not reporting error to driver during JVM shutdown.
2021-05-19 02:46:07 INFO  Executor:54 - Not reporting error to driver during JVM shutdown.
2021-05-19 02:46:07 ERROR Executor:91 - Exception in task 10.0 in stage 7.0 (TID 317)
java.net.SocketException: Connection reset
	at java.net.SocketInputStream.read(SocketInputStream.java:210)
	at java.net.SocketInputStream.read(SocketInputStream.java:141)
	at java.io.BufferedInputStream.fill(BufferedInputStream.java:246)
	at java.io.BufferedInputStream.read1(BufferedInputStream.java:286)
	at java.io.BufferedInputStream.read(BufferedInputStream.java:345)
	at java.io.DataInputStream.readFully(DataInputStream.java:195)
	at java.io.DataInputStream.readFully(DataInputStream.java:169)
	at org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$1.read(PythonUDFRunner.scala:74)
	at org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$1.read(PythonUDFRunner.scala:64)
	at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:406)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440)
	at scala.collection.Iterator$JoinIterator.hasNext(Iterator.scala:212)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)
	at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage3.processNext(Unknown Source)
	at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)
	at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$11$$anon$1.hasNext(WholeStageCodegenExec.scala:619)
	at org.apache.spark.sql.execution.aggregate.ObjectAggregationIterator.processInputs(ObjectAggregationIterator.scala:188)
	at org.apache.spark.sql.execution.aggregate.ObjectAggregationIterator.<init>(ObjectAggregationIterator.scala:78)
	at org.apache.spark.sql.execution.aggregate.ObjectHashAggregateExec$$anonfun$doExecute$1$$anonfun$2.apply(ObjectHashAggregateExec.scala:114)
	at org.apache.spark.sql.execution.aggregate.ObjectHashAggregateExec$$anonfun$doExecute$1$$anonfun$2.apply(ObjectHashAggregateExec.scala:105)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndexInternal$1$$anonfun$12.apply(RDD.scala:823)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndexInternal$1$$anonfun$12.apply(RDD.scala:823)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)
	at org.apache.spark.scheduler.Task.run(Task.scala:121)
	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:402)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:408)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2021-05-19 02:46:07 INFO  Executor:54 - Not reporting error to driver during JVM shutdown.

End of LogType:stdout
***********************************************************************

